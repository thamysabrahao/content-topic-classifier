id,full_text,topic_id,topic_id_grouped,label
c_b11d8c57d5c0,"in this video, we will look at what dilutions are in chemistry, how to calculate them using a very easy equation and even extending to multiple dilutions which are called serial dilutions.   dilution is the process of adding water (or another solvent) to a solution to decrease the concentration. so to dilute a solution means to add more solvent to a set amount of solute, therefore increasing the total amount of solution and decreasing the concentration.   there is a very easy equation to help us calculate dilutions: m1v1 = m2v2.   we will using this equation and work through some examples together in this video.  ",t_a64e6274e25d,other,0
c_200d265c00e3,"figuring out the acceleration of ice down a plane made of ice  let's say that i have a ramp made of ice. looks like maybe a wedge or some type of an inclined plane made of ice. and we'll make everything of ice in this video so that we have negligible friction. so this right here is my ramp. it's made of ice. and this angle right over here, let's just go with 30 degrees. and let's say on this ramp made of ice, i have another block of ice. so this is a block of ice. it is a block of ice, it's shiny like ice is shiny. and it has a mass of 10 kilograms. and what i want to do is think about what's going to happen to this block of ice. so first of all, what are the forces that we know are acting on it? well if we're assuming we're on earth, and we will, and we're near the surface, then there is the force of gravity. there's the force of gravity acting on this block of ice. and the force of gravity is going to be equal to-- it's going to be in the downward direction, and its magnitude is going to be the mass of the block of ice times the gravitational field times 9.8 meters per second squared. so it's going to be 98 newtons downward. so this is 98 newtons downward. i just took 10 kilograms. let me write it out. so the force due to gravity is going to be equal to 10 kilograms times 9.8 meters per second squared downward. this 9.8 meters per second squared downward, that is the field vector for the gravitational field of the surface of the earth, i guess is one way to think about it. sometimes you'll see the negative 9.8 meters per second squared. and then that negative is giving you the direction implicitly because the convention is normally that positive is upward and negative is downward. we'll just go with this right over here. so the magnitude of this vector is 10 times 9.8, which is 98 kilogram meters per second squared, which is the same thing as newtons. so the magnitude here is 98 newtons and it is pointing downwards. now what we want to do is break this vector up into the components that are perpendicular and parallel to the surface of this ramp. so let's do that. so first, let's think about perpendicular to the surface of the ramp. so perpendicular to the surface of the ramp. so this right over here is a right angle. and we saw in the last video, that whatever angle this over here is, that is also going to be this angle over here. so this angle over here is also going to be a 30-degree angle. and we can use that information to figure out the magnitude of this orange vector right over here. and remember, this orange vector is the component of the force of gravity that is perpendicular to the plane. and then there's going to be some component that is parallel to the plane. i'll draw that in yellow. some component of the force of gravity that is parallel to the plane. and clearly this is a right angle, because this is perpendicular to the plane. and this is parallel to the plane. if it's perpendicular to the plane, it's also perpendicular to this vector right over here. so we can use some basic trigonometry, like we did in the last video, to figure out the magnitude of this orange and this yellow vector right over here. this orange vector's magnitude over the hypotenuse is going to be equal to the cosine of 30. or you could say that the magnitude of this is 98 times the cosine of 30 degrees newtons. 98 times the cosine of 30 degrees newtons. and if you want the whole vector, it's in this direction. and the direction going into the surface of the plane. and, based on the simple trigonometry-- and we go into this in a little bit more detail in the last video-- we know that the component of this vector that is parallel to the surface of this plane is going to be 98 sine of 30 degrees. sine of 30 degrees. sine of 30 degrees. and this comes straight out of this magnitude, which is opposite to the angle over the hypotenuse. opposite over hypotenuse is equal to sine of an angle. and we did all the work over here. i don't want to keep repeating it. but i always want to emphasize that this is coming straight out of basic trigonometry, straight out of basic trigonometry. so once you do that, we know the different components. we can calculate them. cosine of 30 degrees is square root of 3 over 2. sine of 30 degrees is 1/2. that's just one of those things that you learn and you can derive it yourself using 30-60-90 triangles, or actually even equilateral triangles. or you could use a calculator. but it's also one of those things that you memorize when you take trigonometry. so no kind of magical trick i did here. and so if you evaluate this, 98 times the square root of 3 over 2 newtons, tells us that-- let me write it in that same orange color-- the force, the component of gravity that is perpendicular to the plane. and this kind of implicitly gives us this direction, it's perpendicular to the plane. but the force component of gravity that's perpendicular to the plane is equal to 98 times square root of 3 over 2. 98 divided by 2 is 49. so it's equal to 49 times the square root of 3 newtons. and its direction is into the surface of the plane, or downward or, let me just write, into surface of plane. surface of the plane, or the surface of the ramp. and it's in this direction over here. and i have to do this because it's a vector. i have to tell you what direction it's going in. and the component of the force of gravity that is parallel. the component of the force of gravity that is parallel, i drew it down here, but i could shift it up over here. it's the same exact vector. the component of gravity that is parallel to the surface of the plane is 98 times sine of 30. that's 98 times 1/2, which is 49 newtons. and it's going in that direction, or parallel to the surface of the plane. parallel, i always have trouble spelling parallel. parallel to-- don't even know if i spelled it right-- surface of the plane. so what's going to happen here? well, if these were the only forces acting on it. so if we had a net force going into the surface of the plane of 49 square roots of 3 newtons. if this was the only force acting in this dimension or in the dimension that is perpendicular to the surface of the plane, what would happen? well, then the block would just accelerate. at least just due to this force it would accelerate downward. it would accelerate into the surface of the plane. but we know it's not going to accelerate. we know that there's this big wedge of ice here that is keeping it from accelerating in that direction. so at least in this dimension, there will be no acceleration. when i talk about this dimension, i'm talking about in the direction that is perpendicular to the surface of the plane. there will be no acceleration because this wedge is here. so the wedge is exerting a force that completely counteracts the force, the perpendicular component of gravity. and that force. you might guess what it's called. so the wedge is exerting a force, just like that, that's going to be 98 newtons upward. the wedge is going to be exerting a force that is 49 square roots of 3, because this right here is 49 square roots of 3 newtons into. and so this is 49 square roots of 3 newtons out of the surface, out of the surface. and this is the normal force. it is the force perpendicular to the surface that essentially, you could kind of view as the contact force that the, in this case, that the surface is exerting to keep this block of ice from accelerating in that direction. we're not talking about accelerating straight towards the center of the earth. we're talking about accelerating in that direction. we broke up the force into kind of the perpendicular direction and the parallel direction. so you have this counteracting normal force. and that's why you don't have the block plummeting or accelerating into the plane. now what other forces do we have? well, we have the force that's parallel to the surface. and if we assume that there's no friction-- and i can assume that there's no friction in this video because we are assuming that it is ice on ice-- what is going to happen? there's no counteracting force to this 49 newtons. 49 newtons parallel downwards, i should say parallel downwards, to the surface of the plane. so what's going to happen? well, it's going to accelerate in that direction. you have force is equal to mass times acceleration. force is equal to mass times acceleration. or you divide both sides by mass, you get force over mass is equal to acceleration. over here, our force is 49 newtons in that direction, parallel downwards to the surface of the plane. and so if you divide both by mass, if you divide both of these by mass. so that's the same thing as dividing it by 10 kilograms, dividing by 10 kilograms, that will give you acceleration. that will give you our acceleration. so acceleration is 49 newtons divided by 10 kilograms in that direction, in this direction right over there. and 49 divided by 10 is 4.9, and then newtons divided by kilograms is meters per second squared. so then you get your acceleration. your acceleration is going to be 4.9 meters per second squared. and maybe i could say parallel. that's two bars. or maybe i'll write parallel. parallel downwards to the surface. now i'm going to leave you there, and i'll let you think about another thing that i'll address in the next video is, what if you had this just standing still? if it wasn't accelerating downwards, if it wasn't accelerating and sliding down, what would be the force that's keeping it in a kind of a static state? we'll think about that in the next video.",t_44a940281f80,other,0
c_a2c2491b9e09,"educational standards addressededucational standards addressed by the lesson, “pollination: saying it with flowers”  massachusetts biology learning standards 6. ecology central concept: ecology is the interaction among organisms and between organisms and their environment. 6.1 populations 6.2 biodiversity and environmental changes 6.3 food webs and ecosystem relationships 6.4 abiotic cycling, photosynthesis next generation science standards 2-ls2 ecosystems: interactions, energy, and dynamics http://www.nextgenscience.org/print/906",t_f3850f4e7c9e,other,0
c_e982b02a587f,"open learn works namba ya moduli 2: kutumia sauti za kijumuia darasani kwako  copyright © 2016 the open university  contents sehemu ya 1: kuchunguza hadithi 1. 2. 3. nyenzo-rejea nyenzo-rejea nyenzo-rejea nyenzo-rejea nyenzo-rejea nyenzo-rejea  ya 1: ngano za kimapokeo ya 2: kwa nini watu husimulia hadithi ya 3: maswali kuhusu hadithi ya 4: namna bibi mwenda alivyopata hadithi yake 5: mto uliofagilia mbali waongo 6: kukadiria hadithi yako  sehemu ya 2: njia za kukusanya na kutenda hadithi 1. 2. 3. nyenzo-rejeaya1: mfano wa barua ya mwaliko nyenzo-rejea ya 2: tathmini uigizaji wa hadithi za vikundi  4 4 5 7 8 9 10 10 11 12  12 13 14 15 17 17  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  18  1. 2. 3. nyenzo-rejea ya 1: duara la tenda - tafakari nyenzo-rejea ya 2: tathmini uigizaji wa hadithi za vikundi nyenzo rejea 3: utafiti juu ya michezo ya jadi katika mtalaa nyenzo rejea 4: michezo ya maneno nyenzo rejea 5: wimbo wa kurukaruka maneno  19 20 21 23 23 24 27 32  sehemu ya 4: utumizi wa hadithi na ushairi 1. 2. 3. nyenzo-rejea 37 nyenzo-rejea nyenzo-rejea nyenzo-rejea  32  33 34 36 ya 1: kuandaa masomo juu ya mashairi ya majina au ya kusifu ya 2: mashairi na hadithi za majina 3: mashairi na hadithi za kusifu 4: kuandaa masomo juu ya hadithi za maisha  38 39 41  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu 43 1. 43 2. 45 3. 46 nyenzo-rejea 1: jinsi hadithi zinavyoandikwa kuwa vitabu 47 nyenzo-rejea 2: orodha ya kuhakiki kwa ajili ya wanafunzi - ili kutumika wakati wanapohariri kazi zao kwa ajili ya kitabu 50 nyenzo-rejea 3: kubadilisha hadithi za wanafunzi kuwa ‘kitabu kikubwa’ 51 2 of 54  monday 27 june 2016  nyenzo-rejea 4: sifa za usanifishaji wa gamba la kitabu  3 of 54  53  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  sehemu ya 1: kuchunguza hadithi swali lengwa muhimu: je, unawezaje kutumia uchunguzi kuendeleza mawazo juu ya hadithi? maneno muhimu: utafiti; hadithi; lengo; maswali; kuchunguza; jumuia  matokeo ya ujifunzaji mwishoni mwa sehemu hii, utakuwa umeweza: l  kutumia njia za utafiti na uchunguzi katika kuendeleza mazoezi ya darasani mwako;  l  kuchunguza welewa wa wanafunzi juu ya hadithi;  l  kuchunguza njia za kutunga hadithi mpya.  utangulizi usimuliaji wa hadithi ni sehemu muhimu ya maisha na utamaduni wa jamii nyingi. moduli hii inachunguza jinsi ya kuimarisha uhusiano baina ya shule na jamii kwa kutumia jamii na hadithi zake kama rasilimali ya kujifunza. sehemu hii inakufahamisha juu ya umuhimu wa utafiti katika kufundisha na kujifunza. kwa kuandaa shughuli za utafiti, utaweza kupata majibu kwa maswali yako, kujaribu mawazo mapya na kisha kuyatumia katika kuunda kazi mpya halisi.  1. sote husimulia hadithi, kuhusu maisha yetu ya kila siku au yaliyopita.we all tell stories, about our daily lives or about the past. kuna desturi nyingi katika usimuliaji hadithi na mafundisho mengi kutoka kwenye hadithi. shughuli 1 talii kutafiti ni nini, unafanywaje, na matokeo yanaweza kuchanganuliwa. as you work alongside the class on the task, utajifunza ni nini wanafunzi wako wanakiweza. tunashauri usome nyenzo-rejea muhimu: kuchunguza darasani kabla ya kuanza. kama ungependa kusoma tafiti za watu wengine, nyenzo-rejea 1: ngano za kimapokeo pia ni nzuri, inatoa taarifa juu ya warsha iliyofanyika qunu mashariki ya rasi ya afrikakusini, ambapo wazazi, walimu na wanafunzi walijadili maswali unayotafiti.  uchunguzi kifani ya 1: kutafiti ni kwa nini watu husimulia hadithi bibi rashe na wanafunzi wake wa darasa la 3 katika shule ya nqamakwe, mashariki mwa rasi ya afrika kusini husimulia hadithi kila siku. siku moja aliandika swali ubaoni ‘kwa nini watu husimulia hadithi?’ na kuorodhesha majibu ya wanafunzi: kufurahisha kuogopesha watu kunifundisha nisifanye jambo fulani.  4 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  alimuomba kila mwanafunzi aende nyumbani na kumuuliza mtu mzima swali hilo hilo na kuleta majibu. alihakikisha kwamba amewakumbusha wanafunzi kuwa wanatakiwa kuwakabili watu kwa unyenyekevu pindi wanapouliza maswali. pia aliwakumbusha kuelezea vipi taarifa zingetumika. siku iliyofuata aliongezea majibu yao kwenye orodha. pale ambapo watu zaidi ya mmoja walitoa jibu sawa aliongeza alama (√) (angalia nyenzo-rejea 2: kwa nini watu husimulia hadithi ). aliwaomba wanafunzi kuongeza tiki kwa kila sababu. walijadili maswali yafuatayo: sababu zipi ni maarufu sana? umejuaje? unakubaliana na mawazo ya wakubwa? kwa nini ndio/hapana? baada ya majadiliano, bibi rashe aliwaomba wanafunzi wake waandike wamepata nini kutokana na utafiti wao.siku iliyofuata, aliwaomba wanafunzi wachahe wenye mawazo tofauti kusoma ripoti zao. alikuwa akishangazwa na kufurahishwa na mawazo tofauti ambayo wanafunzi walikuja nayo.  shughuli ya 1: kuchunguza usimuliaji hadithi waeleze wanafunzi kuhusu utafiti, tumia nyenzo-rejea muhimu: kuchunguza darasani ikusaidie kupanga unachotaka kusema. waeleze kuwa watakusaidia katika kuchunguza usimuliaji wa hadithi (angali nyenzo-rejea muhimu: kuelezea na kuonesha darasani) andika maswali ubaoni kutoka katika nyenzo-rejea 3: maswali kuhusu hadithi . eleza kuwa kila mwanafunzi ataenda kuuliza maswali haya kwa mtu mzima mmoja miongoni mwa jamii. wakumbushe pia kuwakabili watu wazima kwa heshima na kurekodi majibu watakayopewa. siku kadhaa baadaye, wagawe wanafunzi katika makundi ya watu sita mpaka nane na waache waorodheshe (kwa kila swali) majibu waliyoyapata; ongeza alama ya tiki kwa jibu lililotolewa na mtu zaidi ya mmoja. sasa kila kundi liripoti, na wewe kumalizia seti ya data (taarifa zilizokusanywa na darasa) ubaoni. jadili mawzo yaliozoeleka sana. je, wanafunzi wanakubaliana nayo? wasaidie wanafunzi kuandika ripoti rahisi kuhusiana na walichokipata (angalia nyenzorejea 2 kwa mpango wa ripoti ya utafiti).  2. unapokuwa na matokeo ya utafiti, yanatakiwa yatafsiriwe ili uweze kutumia taarifa. katika mfano wetu, hii ina maana kuwasaidia wanafunzi wako kutumia taarifa iliyopatikana kuelewa hadithi zaidi. shughuli 2 inakusaidia kutalii maana katika hadithi kama ufuatiliaji baada ya uchunguzi. uchunguzi-kifani 2 inatambulisha wazo muhimu la kuwasaidia wanafunzi kutunga maswali yao wenyewe na kujaribu kuyatafutia majibu. kuweza kuuliza maswali yao wenyewe katika makundi madogo huwajengea fikra huru na hukuza uwezo wa wanafunzi wa kufikiri kiubunifu na kwa makini.  5 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  uchunguzi kifani ya 2: kumalizia hadithi bibi mwenda kutoka dodoma alifanya utafiti makini katika vipengele vya hadithi nzuri ambayo haifahamiki sana (angalia nyenzo-rejea 4: namna bibi mwenda alivyopata hadithi yake ). siku moja aliwakusanya wanafunzi wake wa darasa la 2 kumzunguka, na aliwasimulia sehemu ya kwanza ya hadithi (aya tatu za mwanzo za nyenzo-rejea 5: mto ambao ulifagilia mbali waongo ). baadaye, aliwaomba kila mmoja afikirie swali juu ya kingetokea nini katika sehemu iliyobaki ya hadithi. baada ya dakika mbili walimpa maswali yao, na aliyaandika ubaoni. aliomba darasa kufikiria majibu ya maswali, kuchukua swali baada ya swali. wanafunzi walitoa sababu za majibu yao. baada ya kuyapitia maswali na majibu yote, aliwaomba kumsaidia kuandika mwisho wa hadithi. wallipendekeza nini kingeweza kutokea baadaye na aliyaandika maoni yao ubaoni. hakukurupua mchakato, au kulazimisha mawazo yake kwa wanafunzi. pale hadithi ilipokuwa imekamilika, waliisoma kwa pamoja. wanafunzi walipenda kushughulika pamoja kwenye hadithi. siku iliyofuata, katika watu wawili wawili, walichora picha za sehemu mbalimbali za hadithi. hizi ziliwekwa pamoja katika kitabu. mwisho, bibi mwenda aliwasomea hadithi yenyewe. wanafunzi walifurahishwa na mwisho wa hadithi zao ikilinganishwa na mwisho wa hadithi halisi na walizungumza mengi juu ya matatizo ya kusema uongo.  shughuli ya 2: kujadili kwa nini hadithi maalumu husimuliwa chagua hadithi nzuri kutokana na unazozijua. hakikisha una masimulizi kamili ya hadithi. andaa nakala moja kwa kila kikundi katika darasa lako, au uandike hadithi ubaoni, mahali ambapo wanaweza kuiona wote. pia andika sababu za kusimulia hadithi zilizotokana na utafiti wa darasa. wambie wanafunzi wako kujadili katika makundi kwanini wanafikiri watu wangewasimulia hii hadithi (k.v lengo lake). kadri makundi yatoavyo ripoti, waambie waeleze sababu zao. kasha, jadili wahusika wa hadithi na tabia zao. waulize wanafunzi ni jinsi gain wangeweza kutumia hadithi hii katika maisha yao wenyewe. waambie, katika makundi, kujadili lengo la hadithi nyingine, labda moja kutoka nyumbani na kasha kuandika aya juu ya lengo la hadithi. je, wote walielewa malengo ya hadithi zao? umelijuaje hili? hii shughuli haihitaji kumalizwa kwa muda wa somo wa dakika 30. inaweza ikaendelea katika vipindi vya somo jingine kama wanafunzi wako wana mambo mengi ya kujadili.  6 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  3. utafiti unaonesha kuwa watu hujifunza vizuri pale ambapo kile kilichokuwa kikifundishwa ni muhimu kwao. ukiwa kama mwalimu daima unatakiwa kuhakikisha kuwa wanafunzi wako wanapata maarifa ambayo yatawasaidia kuuelewa ulimwengu wao. wewe na darasa lako mmetafiti ni kwa nini watu husimulia hadithi na mmeangalia maana ya hadithi maalum. sasa tunaangalia ni jinsi gain unaweza kuwasaidia wanafunzi wako kutumia usimuliaji wa hadithi katika hali ya maisha halisi na kwenye matatizo.  uchunguzi kifani ya 3: kuandika hadithi bibi kaniki alitaka kuwasidia wanafunzi wake wa darasa la 6 pale arusha kuandika hadithi zao wenyewe katika vikundi vya watu wawili wawili. aliandika orodha ya sifa yamkini za hadithi (angalia chini) ubaoni na alizijadili na wanafunzi wake jinsi sifa hizo zinaweza kuabiri aina ya hadithi inaandikwa. wanyama wanawakilisha binadamu matukio ya ajabu, viumbe visivyo vya kawaida mtu kupata matatizo na kutafuta njia ya kuyatatua mwema na muovu maelezo ya jinsi vitu vilivyo pia aliwapa orodha ya matukio, mazuri na mabaya, yaliyotokea mjini hivi karibuni na alipendekeza watumie moja ya matukio haya kama muktadha wa hadithi zao. baadaye , aliwaambia wachague ikiwa wahusika wa hadithi zao wangekuwa ni watu au wanyama. mwisho, aliwauliza dhamira wangechagua, kama vile vita kati ya wema na uovu. walipokuwa wamshaamua dhamira, aliwapa moyo kila kikundi cha watu wali kuanza kuandika. baada ya wiki moja au mbili, bibi kaniki aliliambia kila kikundi kuchangia (mawazo) ya hadithi na darasa zima, halafu walijadili lengo la hadithi lilikuwa lipi. aliridhishwa na aina anuai za hadithi.  shughuli muhimu: kutunga hadithi mpya (halisi) waambie wanafunzi wafikirie matatizo katika familia zao, shule na jamii ambayo hutokana na jinsi wanavyotendeana. matatizo yangeweza kuanzia yale ya kila siku, kama uvivu hadi mambo mazito, kama vile virusi vya ukimwi na ukimwi. ungeweza kuwachochea kwa kueleza hali za kawaida zinazohusisha baadhi ya aina za tabia, lakini kuwa makini na hali binafsi za wanafunzi katika darasa lako. ungeweza kutumia magazeti kusaidia kupata mawazo ya hadithi. kila kundi lichague tatizo moja na kulitungia hadithi ambayo inaonesha athari za aina hii ya tabia na kutoa busara juu ya tabia hiyo. jadili baadhi ya sifa za hadithi kabla hawajaandika hadthi zao au panga jinsi gain wataisimulia (angalia uchunguzi-kifani 3 ). waambie kila kundi kusimulia hadithi zao darasani. jadili lengo la kila hadithi, yaorodheshe, na yalinganishe na matokeo ya utafiti wao kutoka shughuli 1.  7 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  waache wanavikundi wajiamulie kama hadithi yao ilifanikiwa na kwa nini (angalia maswali katika nyenzo-rejea 6: kuikadiria hadithi yako .) kwa kiasi gani walifanikiwa kujikadiria? je, unakubaliana na makadirio yao? kama una wanafunzi wadogo, ungeweza kufanya zoezi hili kama shughuli ya darasa zima ambapo unaandika mawzo yao ubaoni au kwenye karatasi.  nyenzo-rejea ya 1: ngano za kimapokeo usuli/taarifa ya mwanzo/uelewa wa mwalimu usuli warsha iliendeshwa kama sehemu ya kazi za kitengo cha maendeleo na kisomo vijijini cha mfuko wa nelson mandela na shule tano kutoka eneo la qunu mashariki mwa rasi zilishiriki. kutoka kila shule kulikuwa na walimu wawili na mwanafunzi mmoja na mzazi mmoja na mjumbe mmoja wa kamati ya shule. lengo la warsha lilikuwa ni kuakisi pamoja juu ya thamani ya ngano za kimapokeo katika elimu ya watoto na jamii, na kupanga njia za kutumia hadithi hizi ndani na nje ya shule. kifuatacho ni ripoti ya majadala uliokuwa ukiendeshwa katika makundi katika siku ya kwanza ya warsha. washiriki walitoa mawazo yao. je, unakubaliana na mwazo na maoni yao? ngano ni nini? ngano ni hadithi fupi zenye lengo maalum, zina baadhi ya mafundisho, ucheshi, maonyo. husifu, hukosoa na hurekebisha. hunoa ubongo kuufanya ufikiri kwa makini na hujenga ufikiriaji wa kina. baadhi ni matukio halisi ambayo baadaye hubadilishwa kuwa ngano; baadhi zimekuwa zikitungwa maalum kwa dhamira ya kuchoma au kuumiza ili kuachana na matukio yaliopita na kufundisha staha. ni watu gain husimulia au husimuliwa ngano? kwa kauli moja walisema ni watu wazima- bibi na babu, pia watoto wenyewe kwa wenyewe, kipindi cha mafunzo ya jando na unyago. pia walimu, watangazaji wa redio na luninga husimulia hadithi. waliwasimulia/huwasimulia nani? zilisimuliwa kwa watoto, vijana na watu wazima. lini na wapi ngano zinasimuliwa/zilisimuliwa? chumba cha kupumzikia mara nyingi hutumika, wakati mwingine chumba cha kulala na mara nyingine hadithi zilisimuliwa wakati wakiota jua karibu na maboma ya ng’ombe. seheme nyingine zilikuwa kingo za mito, malishoni, viwanja vya nyumba na kwenye kumbi za jando na unyago. kwa nini walisimuliwa/ wanasimuliwa hadithi? zilikuwa kwa ajili ya kufurahisha, kunoa ubongo, kama kikumbushi, kama katazo au onyo, kuchochea uzalendo kupitia tabia fulani, kutupa msamiati na vitatanishi vyake (kama tamathali za usemi, nahau, methali na maneno mapya ambayo huingia kwenye kamusi). wanasimuliwaje/ walisimuliwaje hadithi? (mtindo wa usimulizi) kulikuwa na mashindano katika usimuliaji wa hadithi. ilikuwa sanaa, iliyohusisha muziki, ucheshi na kubadili sauti. ngano za kimapokeo zina mwanzo na mwisho wa pekee. 8 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  hadithi mpya husimuliwa kama zinavyosimuliwa hadithi za zamani? kwa sababu zipi hadithi mpya hutungwa ? ngano za zamani na mpya zimekuwa zikitumika, na hufanya kazi moja. kwa kawida, hadithi mpya hujumuisha maeneo yote mpya za maisha. je, una masimulizi ya ngano yalioandikwa? yataje. kuna ngano za zamani chache zilizo katika maandishi ( baadhi zimetajwa) kilichokuwa kimeonekana ni kwamba ngano chache sana zilikumbukwa na kundi na haikuwa kazi rahisi kufanya hivyo.mtu mmoja pekee alikumbuka tatu, baadhi hawakuweza kukumbuka yoyote. kutokana na washiriki 23, ngano 19 tu zilitolewa. hii inamaanisha nini? wapi na kwa namna gain ngano zilizoandikwa hutumika? ngano husomwa kutoka vitabuni mara kwa mara. ndicho kinachotokea nyumbani ambapo ngano zile zile hurudiwa kusimuliwa kwa kujifurahisha. shuleni husomewa watoto. zina mchango kwa msamiati wa watoto. ni chache. kuna baadhi katika maktaba na wakati mwingine huigizwa jukwaani. lugha inayotumika lugha iliyozoeleka ni lahaja, lugha za kitoto pia hutumika, vile vile maneno yalioundwa kuonesha staha dondoo limendondolewa kutoka ripoti ya warsha juu ya ngano za kimapokeo iliyofanyika qunu, rasi ya mashiriki.  nyenzo-rejea ya 2: kwa nini watu husimulia hadithi mfano wa kazi za wanafunzi ubao wa bibi rashe ni kwa nini watu husimulia hadithi?  kufurahisha √√√√√ √√√√√ √√√√√ √√√√√ √√√√√ √√√√√ √√√√√ 35 kuogopesha watu √√√√√ √√ 7 kunifundisha kutofanya jambo fulani √√√√√ √√√√√ 10 kufundisha busara juu ya maisha √√√√√ √√√√√ √√√√ 14 kuonesha tabia sahihi, √√√√√ √√√√√ √√√√√ √√√√√ √√√√√ √√√√√ √√ 32 kukuza lugha yetu, √√√√√ √√ 7  mpango wa ripoti ya utafiti swali la utafiti tulifanya nini tunachambuaje data tulipata nini ripoti juu utafiti wa hadithi wanafunzi wa darasa la 3 waliwauliza watu wazima: ‘kwa nini watu husimulia hadithi?’ 9 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  watu wazima wapatao 35 walilijibu swali hilo. wanafunzi waliandaa orodha ya majibu, na walihesabu watu wangapi walijibu kila swali. kifani cha ripoti watu 34 walidhani kuwa hadithi husimuliwa kwa ajili ya kuwafurahisha wasikilizaji. watu 32 walidhani kuwa hadithi husimuliwa ili kuonesha tabia nzuri/sahihi. watu 14 walidhani kuwa hadithi husimuliwa ili kufundisha busara katika maisha. watu 10 walidhani kuwa hadithi husimuliwa ili kufundisha watu kutofanya jambo fulani. watu 7 wao walidhani hadithi husimuliwa ili kukuza lugha. watu 7 walidhani kuwa hadithim husimuliwa ili kuogofya watu.  nyenzo-rejea ya 3: maswali kuhusu hadithi usuli/taarifa ya mwanzo/uelewa wa mwalimu 1  ni watu gani ambao kwa kawaida husimulia hadithi?  2  wanawasimulia nani?  3  wapi na lini hadithi husimuliwa?  4  kwa nini watu husimulia hadithi?  5  husimuliaje hadithi? (mtindo wa usimulizi)  6  je, hadithi mpya pia husimuliwa kama zinavyosimuliwa za zamani ? ni sababu zipi zinazopelekea kutungwa kwa hadithi mpya?  nyenzo-rejea hii ni nzuri kwa matumizi ya wanafunzi wakubwa. kwa wanafunzi wadogo ungeweza kuwa na hiyari ya kuchagua swali moja au mawili kati ya haya kwa ajili wanafunzi wako kuchunguza.  nyenzo-rejea ya 4: namna bibi mwenda alivyopata hadithi yake usuli/taarifa ya mwanzo/uelewa wa mwalimu patricia mwenda alijaribu kutafakari juu ya hadithi ambayo haikutambulika sana. aliikumbuka nahau iliyorandana na hadithi yake. nahau yenyewe ilisema: ‘hakuna mbweha aliye mkubwa kuliko mwingine, mbweha wote wana umbo sawa.’ alikumbuka kuwa hadithi ilikuwa juu ya bwana na mtumishi wake waliokuwa wakisafiri juu ya farasi, na yule mtumishi alimsimulia bwana wake juu ya hadithi ya mbweha aliyekuwa na umbo la ndama au maksai. bibi mwenda alikumbuka pia kulikuwa na mito ipitayo, na mmoja wapo uliitwa ‘mto unao somba waongo wote’. alipokuwa hana uhakika na nini haswa kilijiri, alimuuliza wifi yake aitwaye amina juu ya hadithi. amina alimwambia kuwa, mtumishi yule alikuwa muongo sana. hapo zamani alijaribu pia kusimulia hadithi ya kunguni kumfananisha na kitu kikubwa sana, hadithi ambayo haiwezi kuwa kweli. bado walikuwa na tondoti chache, hivyo walikwenda kwa bwana majengo ambaye aliyewahi kuwa mwalimu wa kiswahili, kwa sasa ni mkaguzi wa  10 of 54  monday 27 june 2016  sehemu ya 1: kuchunguza hadithi  shule. hakuweza kukumbuka hadithi, lakini alikumbuka kuwa tafsiri yake ipo kwa msomaji maalum. siku moja, patricia alikuwa akiongea na bi. kolisa ngodwana, mwalimu wa hisabati, aligundua kuwa alifamu ujumbe uliopo kwenye hadithi. alisema kwamba yule bwana alitumia mbinu fulani kumsimamisha yule mtumishi kudanganya. hakutaka kumshutumu moja kwa moja kwa uongo. bi. ngodwana alisema kuwa mbinu zile zilifanikiwa, kwani mtumishi alitubu na kuzungumza kabla ya kufika mtoni. lakini bw. ngodwana pia hakuweza kukumbuka tondoti za hadithi yote. kisha patricia alikwenda kwa bw. mr hintsa siwisa, mwanasheria. alijua nahau na ujumbe wa hadithi. alifikiri ilitokana na jamii kuchoshwa na uongo wa mtu yule. waliamua kumuweka kwenye jaribio la nguvu na kumpa somo. masimulizi ya hadithi ya bw. siwisa ipo kwenye nyenzo- rejea 5: mto uliofyagilia mbali wa waongo. imenakiliwa kutoka: umthamo 2, university of fort hare distance education project  nyenzo-rejea 5: mto uliofagilia mbali waongo nyenzo ya mwalimu kwa ajili ya mpango au utohozi utakaotumiwa na wanafunzi bwana mmoja alikuwa safarini na mtumishi wake. ilikuwa ni safari ndefu juu ya farasi. kadri walivyokuwa wakisafiri, yule bwana aliona mbweha akikatiza kwenye njia.yule bwana alisema: ‘mbweha yule ni mkubwa sana.’ yule mtumishi akajibu, ‘oh, bwana huyu si chochote ukilinganisha na niliyemuona jana.’ ‘ndivyo hivyo?’ alidakia yule bwana. ‘oh! ndiyo, alikuwa mkubwa sana sana. kwa hakika alikuwa mkubwa kama maksai!’ ‘mkubwa kama maksai?’ bwana aliuliza. ‘ndiyo mkubwa kama maksai,’ alijibu mtumishi. bwana akasema tena, ‘umesema “ni mkubwa kama maksai”?’ ‘ndiyo haswa, mkubwa kama maksai,’ alisema mtumishi. yule bwana hakusema neno waliendelea na safari yao, bila kusemezana takribani kwa muda wa saa moja. mtumishi alibaini kuwa bwana wake hakuwa na raha na hukujua ni nini kilimsumbua. kwa hiyo alimuuliza alikuwa na jambo gani. yule bwana alimwambia kwamba wangevuka mito minne kabla ya kufika mwisho wa safari yao. mto wa mwisho ni mkubwa na hatari zaidi kuliko yote. mto huu ulikuwa na mzio na waongo na hakuna mwongo angeweza kuepuka hasira yake. iliwazoa waongo huku na huko hadi kwenye kina kirefu cha bahari ya bluu. haikuwahi kumkosa mwongo hata kama wakimuomba ‘ifa’ awaletee bahati (watu humuomba ifa awaletee bahati, na kuwapa nguvu ya kuwashinda pepo waovu). mtumishi aliposika hivi, alitishika sana kwa sababu alijua uwezo aliokuwa nao ifa. kama mto huu usingeshindwa na ifa, basi alijua wazi kuwa ni lazima utakuwa ni mto wenye nguvu sana. kwa kadri walivyokuwa wakiendelea na safari ndivyo alivyoendelea kukosa utulivu. bwana wake naye aliendelea kukasirika sana. na jinsi anavyoendelea kukasirika ndivyo mtumishi wake alivyoendelea kushikwa na hofu na hofu kubwa. wakati walipokwa wanaukaribia mto mmoja baada mwingine, ndivyo umbo la mbweha nalo lilivyokuwa likipungua. walipoukaribia mto wa kwanza, mtumishi alisema, ‘bwana wangu, mbweha si mkubwa kabisa kama maksai, ni mdogo kidogo kuliko maksai.’ bwana hakusema kitu chochote. walipoufikia mto wa pili, mtumishi alisema , ‘mbweha hata hakaribiani kwa umbo na maksai. ni mkubwa kama ndama.’ lakini yule bwana, akaendelea kukaa kimya. walipovuka mto wa pili yule bwana alieleza jinsi anavyojisikia kuhusiana na ule mto hatari wa mwisho na hakusema kitu tena.  11 of 54  monday 27 june 2016  sehemu ya 2: njia za kukusanya na kutenda hadithi  walivyoukaribia mto wa tatu, mtumishi alimwambia bwana wake, ‘mbweha sio mkubwa kama ndama. ni mkubwa kama mbuzi.’ kabla tu hawajakaribia mto wa mwisho, mbweha alikuwa na umbo sawa na mbweha wengine, ambao hupatikana kila sehemu. imenakiliwa kutoka: umthamo 2, university of fort hare distance education project  nyenzo-rejea 6: kukadiria hadithi yako usuli/taarifa ya mwanzo/uelewa wa mwalimu maswali 1  darasa lilifurahia hadithi yako?  2  umejuaje ?  3  darasa limejifunza kitu kutokana na hadithi yako?  4  hadithi yako inatoa ujumbe wake vizuri?  5  umejuaje?  kurudi kujua kusoma na kuandika ukurasa need to check translation  sehemu ya 2: njia za kukusanya na kutenda hadithi swali lengwa muhimu: unawezaje kutumia utendaji katika kukuza stadi za lugha za wanafunzi wako? maneno muhimu: hadithi; kusanya; kuigiza; kujiamini; uhodari; heshima; urithi wa utamaduni  matokeo ya ujifunzaji mwishoni mwa sehemu hii, utakuwa umeweza: l  kufanya kazi na jumuia yako katika kukuza /kujenga stadi za lugha na heshima katika urithi wa utamaduni;  l  kupanga na kusimamia nafasi za utendaji mbele ya hadhira.  utangulizi matumizi ya mazoezi mbalimbali ya mdomo yanaweza kukuza kujiamini kwa wanafunzi katika kuzungumza na kusikiliza na kuwajengea heshima katika lugha zao za nyumbani.  12 of 54  monday 27 june 2016  sehemu ya 2: njia za kukusanya na kutenda hadithi  jambo hili litakuwa na athari chanya katika kujistahi. wanafunzi wanaojiamini na kujitambua wataweza kujifunza kwa wepesi zaidi. uigizaji katika sehemu hii unatoa nafasi kwa wanafunzi wako katika kukusanya, kukariri na kusimulia hadithi mbele ya hadhira. inapendekezwa kwamba, ufanye kazi na wanajumuia wenye umri mkubwa kwa kuomba msaada wao katika kusimulia hadithi na kubadilishana ujuzi katika kusimulia hadithi. shughuli hizi zitajenga umahiri katika lugha za nyumbani, ambapo baadaye unaweza ukajenga stadi za kujifunza lugha nyingine.  1. ujuzi wa hadithi kwa wanajumuia ni nyenzo muhimu katika mazoezi ya kusikiliza na kuzungumza nje na ndani ya darasa. ni muhimu wanafunzi wajifunze kuheshimu na kupenda busara na urithi wa lugha zao za nyumbani na tamaduni zao. kwa kuimarisha stadi zao za kuzungumza na kusikiliza lugha za nyumbani kwa njia inayofurahisha, wanafunzi watakua katika hali ya kujiamini pia. kwa kuwa sanaa ya kusimulia hadithi haipewi thamani katika baadhi ya jumuia, watu wanaweza kuwa wamesahau baadhi ya tondoti na thamani za hadithi. njia ya kujenga nyenzo-rejea lugha kwa wanafunzi wako ni kuweka wazi matoleo ya zamani na halisi ya hadithi. unaweza kufanikisha jambo hili kwa kuzungumza na watu wengine katika jumuia.  uchunguzi kifani ya 1: matumizi ya lugha nyingi za wanafunzi wako darasani bwana kimaryo hufundisha darasa la 4 katika shule ya msingi makanya iliyopo nchini tanzania. shule ipo karibu na shamba la mkonge, ambapo wafanyakazi huzungumza lugha nyingi mbalimbali. katika darasa lake lenye wanafunzi 70, wanafunzi 10 wanazungumza kichaga, wanafunzi 6 wanazungumza kirundi, wanafunzi 3wanazungumza kinamwanga na waliobakia wanazungumza kipare. kwa kawaida yeye huzungumza kiswahili anapowafundisha bwana kimaryo aliwataka wanafunzi wake kukusanya hadithi toka majumbani mwao na kuwajengea hali ya kujiamini katika kuzungumza kwa kusimulia hadithi kwa kutumia lugha zao za nyumbani. alianza somo lake kwa kuwaonesha wanafunzi picha ya mtu wa makamo na baadhi ya wanafamilia waliokuwa wamekaa pembezoni mwa moto. kisha akawataka wanafunzi wawili wawili kujadili watu hawa wanafanya nini. vikundi viliwasilisha majibu yao darasani. kisha akawauliza wanafunzi kama na wao hukaa pembezoni mwa moto na kusikiliza hadithi, wengi waowalisema hawafanyi hivyo. aliwataka wanafunzi waende nyumbani na kumuomba mtu mmoja wa makamo awasimulie hadithi. katika somo lililofuata, aliwaganya wanafunzi katika vikundi. aliunda vikundi viwili vya wazungumzaji wa kichaga, kikundi kimoja cha wazungumzaji wa kirundi, na kikundi kimoja cha wazungumzaji wa kinamwanga. aliwagawanya wazungumzaji wa kipare katika vikundi kumi. akamtaka kila mwanafunzi asimulie hadithi yake kwa wanakikundi wenzake kwa kutumia lugha ya nyumbani. bwana kimaryo alizunguka katika vikundi na kusikiliza namna wanafunzi walivyokuwa wakisimulia hadithi. alifurahia sana namna walivyokuwa wakisimulia hadithi, hususani namna walivyokuwa wakitumia sauti zao kuongeza mvuto.  13 of 54  monday 27 june 2016  sehemu ya 2: njia za kukusanya na kutenda hadithi  shughuli ya 1: kusimuliana hadithi kwa kutumia lugha za nyumbani katika sehemu ya 1,wanafunzi wako wameshabaini mbinu muafaka ya kusimulia hadithi toka kwa wazee wao. huu sasa ni wakati muafaka kwa wao kukusanya hadithi toka kwao. zungumza na wanafunzi wako kuhusiana na uzoefu wao katika kusikiliza hadithi na kubaini ni aina gani ya hadithi wanazozifurahia. waulize kama wanasikiliza hadithi nyumbani na akina nani husimulia hadithi katika jumuia zao. waagize wamtafute mtu mmoja toka katika jumuia zao za nyumbani ili awasimulie hadithi. watatakiwa kuwa na kumbukumbu za hadithi hizi, kwa sababu watahitajika kuwasimulia wenzao darasani. njia nzuri ya kujifunza hadithi ni kwa wao kuwasimulia watu mbalimbali nyumbani. kadiri watakavyokuwa wanafanya hivi, watatakiwa kuzingatia kuwa wana taarifa zote muhimu za hadithi. katika somo lijalo, waweke pamoja wanafunzi wenye lugha za nyumbani zinazofana (tazama nyenzo-rejea muhimu: tumia kazi ya kikundi katika darasa lako). waagize wasimuliane hadithi walizokusanya kwa kutumia lugha zao za asili. je wanafunzi wako wamepokea vipi shughuli hii? je unaweza vipi kujenga utashi katika hadithi hizi?  2. kuwaalika wanajumuia darasani kutasaidia katika kuwahamasisha wanafunzi na kuwajengea ustadi katika kusimulia hadithi kwa kutumia lugha zao za asili. unaweza pia ukawataka wageni wako kutumia ujuzi wao wa hadithi ili kuhakikisha kwamba hadithi zinazosimuliwa na wanafunzi ni za kweli na zenye kujitosheleza kadiri iwezekanavyo. hii itamaanisha kwamba hadithi zitakuwa nyenzo za msingi ya kujifunzia. kama una darasa kubwa, aina hii ya uungwaji mkono na jumuia inasaidia sa kuomba kuungwa mkono na mkuu wako wa shule na walimu wenzio kutalifanya jambo hili kuwa katika msingi unaoeleweka.  uchunguzi kifani ya 2: kuwaalika wanajumuia katika siku wanajumuiya walimu wanne wa shule ya msingi ya mtakatifu maria iliyopo dar es salaam wameandikishwa katika programu ya kuwaendeleza walimu. moja ya moduli katika programu hii, inawataka kuchunguza ni kwa namna gani nyenzo-rejea zinazowazunguka zinaweza kutumika darasani. walifanya kazi ya kukusanya maboksi, chupa, mimea na nyenzo nyingine na kuzitumia katika mazoezi ya sayansi, hesabu na lugha.hata hivyo, moduli ziliwakumbusha kuwa watu ni nzenzo muhimu kwa ajili ya kujifunzia. ilipendekezwa kuwa wapange siku ya kuwakutanisha pamoja wanafunzi na wanajumuia wanye umri mkubwa kwa lengo la kubadilishana maarifa na ujuzi. siku ambayo walimu hawa wanne waliipanga, ilikuwa na mafanikio makubwa. bibi rwakatare, mwenyekiti anayeongoza bodi ya shule, alielezea historia ya shule. baadhi ya wanajumuia walioshiriki walionesha kwa vitendo stadi mbalimbali kama vile,ususi wa vikapu,ukaushaji wa tumbaku, na kutengeneza shanga,.wanawake walisifika kwa kutoa 14 of 54  monday 27 june 2016  sehemu ya 2: njia za kukusanya na kutenda hadithi  maelezo kuhusu mapishi ya vyakula vya asili. wazee mbalimbali, wanaume kwa wanawake walisimulia ngano. kisha ikafuata zamu ya wanafunzi kuonesha kwa vitendo mambo waliyojifunza shuleni. siku ilimalizika kwa kuimbwa nyimbo na dansi toka katika vikundi mbalimbali. kutokana na shughuli za siku hii, wanajumuia mbalimbali wakawa wanatembelea shule mara kwa mara. walitoa ujuzi wao katika stadi mbalimbali na pia walisimulia hadithi ambazo baadaye zilitumiwa darasani.  shughuli ya 2: mafunzo toka wanajumuia ‘mahiri’ utatakiwa kupangilia vema shughuli hii mapema na kutenga muda wote wa asubuhi au mchana kwa ajili ya shughuli hii. wapange wanafunzi wako katika vikundi kulingana na lugha zao za nyumbani. waagize kila kikundi kualika mtu mmoja toka katika jumuia zao kuja darasani ili kuwasaidia wanafunzi katika ustadi wao wa kusimulia hadithi. wape kila kikundi barua ya mwaliko waendenayo nyumbani. (tazama nyenzo-rejea 1: mfano wa barua ya mwaliko ). waagize wanajumuia wajiunge na kikundi na kusikiliza wanafunzi wakiwa wanasimulia hadithi siku hiyo. waombe wageni waalikwa wawape wanafunzi muongozo na ushauri juu ya namna ya kuboresha hadithi na masimulizi yao. kipindi cha mafunzo kikimalizika, vikundi vinaweza kukaa pamoja na kusikiliza hadithi kutoka kwa wageni waliowaalika. nyimbo, mashairi na vitendawili vinaweza vikatolewa siku hiyo. je, ushirikishwaji wa wanajumuia umeongeza nini katika ujifunzaji darasani mwako? je umefurahia namna ulivyopangilia shughuli zako? je utafanya nini cha tofauti wakati ujao?  3. ni muhimu kila mwanafunzi awe na uwezo wa kuwasiliana vema na kuwa kuwa anapewa nafasi ya kuwa mbunifu.uwasilishaji wa hadithi katika vikundi unatoa nafasi hata kwa wanafunzi wakimya kuzungumza, kuimba, kutenda,kucheza n.k bila ya shinikizo. kila mwanafunzi katika uigizaji wa hadithi anaweza kupata nafasi ya kuwa muhusika katika hadithi, msimuliaji ama kuwa sehemu ya kiitio. wanafunzi wenye vipaji maalum wanaweza wakaandaa ‘vifaa’ na ‘mavazi’ wakiwa na vitu kama vipande vya nguo ama karatasi ama matawi ya mti. katika madarasa ambapo wanafunzi wote hawazungumzi lugha moja ya nyumbani, kufanya kazi na wazungumzaji wa lugha inayofanana kwa lengo la kuandaa uigizaji katika lugha hii kunaweza kuwa na matokeo bora. sehemu inayofuata inakupa njia ya kukuza kujiamini na stadi kwa wanafunzi katika lugha zao za nyumbani. njia hizi pia zinaweza zikatumika katika kuimarisha stadi katika lugha ya mawasiliano ama lugha ya ziada.  15 of 54  monday 27 june 2016  sehemu ya 2: njia za kukusanya na kutenda hadithi  uchunguzi kifani ya 3: siku ya kuigiza hadithi katika darasa kubwa bibi rebecca kassam hufundisha darasa la tano lenye wanafunzi 100, katika kijiji kilichopo karibu na tanga kaskazini mwa tanzania. aliamua kuwa na siku ya kuigiza hadithi mwisho wa muhula. aliwapanga wanafunzi wake katika vikundi vya watu watanowatano na kisha kuwahimiza sio tu wasimulie hadithi bali pia waigize, hivyo, waigizaji na hadhira kwa pamoja wataweza kufurahia. aliwaeleza wanafunzi kwamba kama watataka kuigiza katika lugha ambayo si kila mtu anaifahamu, hawana budi kuamua kuisaidia hadhira kuelewa maana inayokusudiwa kwa kutumia vitendo, ishara na vitu mbalimbali. bibi kassam huwapa wanafunzi wake muda wa kuandaa na kukariri hadithi zao. wanapokuwa wanafanya kazi hii husimamia maendeleo yao na wakati mwingine huweza kufupisha ama kurefusha muda wa maandalizi. alibaini kuwa wanafunzi wanapendelea kuandaa na kuigizia kazi zao nje. kwa wanafunzi 80, itachukua muda mrefu kama makundi yote yataigiza darasani. katika siku ya kuigiza hadithi, bibi kassan huwaagiza wanafunzi waunde maduara manne ambapo kila duara linakuwa na makundi manne. huyapa namba makundi katika kila duara kuanzia 1-4. kikundi cha 1 huigiza katikati ya duara kwa ajili ya kikundi cha 2,3 na 4, kisha kikundi cha 2 huigiza kwa ajili ya kikundi cha 1,3,na 4 na kuendelea hadi makundi yote yamalize mzunguko baada ya uigizaji, bibi kassam, hukitaka kila kikundi kujadili juu ya kile walichojifunza. hufikiri juu ya kile ambacho mwanafunzi mkimya darasani mwake alichoonesha kuhusu uelewa wake wa siku ile na namna anavyoweza kutumia taarifa hizi kuandaa hatua nyingine ya kujifunzia. nyenzo-rejea muhimu: kufanyakazi na madarasa makubwa na/au madarasa ya viwango mbalimbali inatoa mawazo ya ziada kwa ajili ya kufundishia madarasa makubwa.  shughuli muhimu: kuigiza hadithi kwa ajili ya hadhira waagize wanafunzi kujigawa katika vikundi vya watu sita sita. waagize wanafunzi :: kukumbuka kuhusu hadithi walizosimulia na kusikiliza kuamua ni hadithi ipi wanadhani itakuwa bora kuigizwa kwa ajili ya darasa ambapo kila mmoja ataweza kuelewa na kuifurahia. kikundi zaidi ya kimoja kinaweza kuchagua hadithi ileile. wateue wahusika wote na kuamua kila nafasi itachukuliwa na nani. watahitaji pia kuwa na msimuliaji. toa maamuzi juu ya lugha (z)itakayotumika, athari za sauti, matumizi ya ishara,mavazi, na vitu vitakavyosaidia kuipa hadithi uhai na nani ataleta nyenzo-rejea zipi. wape muda wa kukariri na kuweka muda maalum kwa ajili ya uigizaji. simamia kila kikundi na kuwasaidia kadiri inavyowezekana kwa kutoa mawazo na mapendekezo juu ya njia ya kufanya kazia. itake hadhira kutoa kuleta mwitikio kwa kila kikundi. ( tazama nyenzo-rejea 2: tathmini uigizaji wa hadithi katika vikundi ).  16 of 54  monday 27 june 2016  sehemu ya 2: njia za kukusanya na kutenda hadithi  kama utaweza, rekodi hadithi zitakazoigizwa.vinginevyo chukua dondoo kwa ajili ya matumizi ya baadaye. hadithi zinaweza kuigizwa mbele ya wazazi na viongozi wa jumuia katika eneo lako kwa lengo la kukusanya michango kwa ajili ya kununulia nyenzo za darasa lako.  nyenzo-rejeaya1: mfano wa barua ya mwaliko nyenzo-rejea ya mwalimu kwa ajili ya kupanga au kutohoa na kutumia na wanafunzi. mpendwa ………………… darasa letu la …… linajifunza kuhusu hadithi za asili na stadi za kusimulia hadithi. tumesikia kuhusu ubingwa wako na tunapenda kukukaribisha kuja na kutusaidia kujifunza ni namna gani tunaweza kukuza stadi zetu za kusimulia na kujifunza hadithi pia. tungependa uje …………………………………. tafadhali tujulishe kama muda huu ni mwafaka kwako. ………………………………… kutoka katika darasa letu atakusubiri geti la shule saa 4.00 asubuhi. tunashukuru sana darasa la 5 shule ya msingi ya mtakatifu maria  nyenzo-rejea ya 2: tathmini uigizaji wa hadithi za vikundi matumizi ya mwanafunzi  sifa ya uigizaji  vizuri sana  vizuri  wastani  dhaifu  hadithi ya kufurahisha na rahisi kufuatilia. matumizi ya sauti mbalimbali matumizi ya athari za sauti matumizi ya miondoko matumizi ya mavazi na/au vifaa  17 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  watu wa afrika mashariki wakiigiza hadithi vyanzo vya asili: two help; website.  kurudi kujua kusoma na kuandika ukurasa need to check translation  sehemu ya 3: kutumia michezo ya jadi katika kujifunza swali lengwa muhimu: unawezaje kutumia michezo ya jadi ili kusaidia ujifunzaji wa lugha? maneno muhimu: kutafakari; utafiti; michezo ya jadi; mapokeo; mashairi; nyimbo; kuchunguza  matokeo ya ujifunzaji mwishoni mwa sehemu hii, utakuwa umeweza:  18 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  l  umetumia michezo ya jadi na ya mahali husika katika kusaidia shughuli za ujifunzaji;  l  umewahamasisha wanafunzi na kuongeza ujasiri wao wa kutumia lugha kwa njia ya michezo, nyimbo na mashairi;  l  umepanua stadi zako mwenyewe katika kutafakari wajibu na uwezo wako kwa kuchunguza thamani ya michezo katika ujifunzaji.  utangulizi baadhi ya walimu ambao wamefundisha kwa miaka 20 ni kama tu wanakuwa na uzoevu wa mwaka mmoja tu, ambao unarudiarudia. hii ni kwa sababu hawajifunzi tena kwa bidii au hawajiendelezi ili waweze kuwa walimu bora zaidi. walimu wazuri ni wale ambao wanapanga kile wanachotaka kukifanya, na mara wanapokifanya, wanarekodi kilichotokea, na kujiuliza wenyewe mafanikio ni yapi na ni wapi panahitaji kuboreshwa. wanatafakari endapo wanafunzi wamejifunza chochote, na kama wamejifunza, wamejifunza nini? kwa msingi huu wa ‘tafakari’, wanapanga tena kwa ajili ya shughuli inayofuata. nyenzo rejea 1: duara la tenda-tafakari huonesha mchakato huu katika muundo wa kielelezo.  1. watoto hawajifunzi tu wakiwa darasani, wanajifunza pia wakiwa wanacheza. wanajifunza kutoka kwa wengine, kwa kuangalia kile wanachokifanya wengine. hujifunza kwa kuzungumza, kuimba, kwa kukariri na kwa kushirikishana katika mazungumzo. unaweza kutumia mchezo ili kufanya ujifunzaji katika darasa lako uwe wa mafanikio na kuziba uwazi kati ya kinachotokea darasani na nje ya darasa. katika shughuli 1, wanafunzi wako wanakuwa kama watafiti, na wanakwenda kwenye uwanja wa michezo (au mahali pengine) ili kurekodi kile wanachofikiri kuwa wataweza kujifunza pale. wanaporudi darasani wanazungumzia kile ambacho wamekigundua: unaweza kusikiliza mazungumzo yao ili kuona kile ambacho unafikiri wanafunzi wako wamejifunza uwanjani hapo.  uchunguzi kifani ya 1: mwanafunzi wa miaka sita ajifunza na kufundishakiswahili maria ambaye ana umri wa miaka sita anasoma katika shule ambayo kiswahili ni lugha inayotumika darasani, ingawa si lugha yake ya kuzaliwa. kila siku kwa muda wa wiki nzima, maria aliweza kuonekana wakati wa mapumziko akiwaangalia watoto wengine wakiruka kamba. hakujiunga, lakini alisimama karibu ili kuweza kuona na ‘kusikiliza’ wimbo ambao wanafunzi walikuwa wakiuimba. siku ya kwanza ya wiki ya pili, maria alikuwa kwenye ile sehemu yake ya kawaida hatua chache kutoka eneo la kuchezea, lakini sasa aliweza kusikika ‘akitoa sauti’ za maneno ya kwenye wimbo. ‘ruu-ka, ruuu-kia ndani na seeema moja-aa mbili-iii, tatuuu, ruuu-kia na-a mimi.’  19 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  alirudia maneno haya tena na tena, akijitahidi kuyasema kwa sauti kubwa, kwa wororo na kwa kutumia mkazo tofauti tofauti kwenye sehemu za neno. alirudia wimbo huu mara kadhaa na kisha kuwasikiliza tena wanafunzi wengine. alitabasamu, na kuimba tena ule wimbo.mwishoni alitafuta kamba na kwenda kwa rafiki yake, migueli. aliimba ule wimbo, mstari kwa mstari, akimfundisha rafikiye huu wimbo. alitafsiri yale maneno ya kiswahili ili rafiki yake aweze kuelewa alichokuwa akijifunza. kwa muda mfupi migueli aliweza kuimba wimbo ule pamoja na maria.  shughuli ya 1: kuchunguza ujifunzaji wa asili kabla ya kuanza shughuli hii, soma nyenzo rejea 2: utafiti juu michezo ya jadi katika mtalaa . nyenzo rejea hii inaeleza kazi moja ya utafiti na micezo miwili ambayo walimu waliibuni kama matokeo ya utafiti huo. kusoma pia nyenzo rejea muhimu: kufanya utafiti darasani kutasaidia sana. zungumza na wanafunzi wako kuhusu ujifunzaji. je, wanajua kwamba daima hujifunzia: nyumbani, shuleni, wakati wanapocheza? liambie darasa lifanye uchunguzi katika ujifunzaji wa ‘asili’. swali lao ni: ujifunzaji gani unaotokea wakati watoto wanapocheza? wanafunzi lazima waandike na kuchora kuhusu ujifunzaji wanaouona kwenye uwanja wa michezo na baada ya kutoka shule, wakati wanafunzi wengine wanapocheza, na wanapocheza wao wenyewe. wwaambie wanafunzi darasani washirikishane matokeo yao, kwenye vikundi. kiambie kila kikundi kioneshe jinsi ya kucheza mchezo mmoja. rekodi nyimbo au mikarara/viitikio wanavyoimba wakati wa mchezo, kwenye tepu, au kwa kuandika. waambie wanafunzi kwenye kila kikundi wajadili kile ambacho wanaweza kujifunza kutokana na michezo hii. andika mawazo yao. umejifunza nini kutokana na shughuli hii inayohusu namna michezo inavyoweza kusaidia katika ujifunzaji?  2. aina zote za michezo zinaweza kutumika kwa kujifunzia na unahitaji kufikiri kiubunifu jinsi ya kuitumia michezo darasani (angalia shughuli 2). inasaidia kama unaweza kushirikiana na wenzako pamoja na rafiki zako, na pia kushirikiana na wanafunzi wako, katika kubuni mawazo mapya ambayo yanaweza kufanya ujifunzaji darasani kwako uwe wa kufurahisha na wenye mafanikio. katika sehemu hii, wewe na darasa lako panueni utafiti wenu kwa kuwauliza wanajumuiya kuhusu michezo waliyokuwa wanaicheza walipokuwa wadogo.  uchunguzi kifani ya 2: michezo na mikarara/viitikio katika kadi za kusoma kuna ongezeko la kupenda lugha nyingi za nyongeza katika mitalaa kote afrika. hii ina maana kuna ujifunzaji wa awali unaotumia lugha mama, na lugha nyingine za nyongeza (bila kuchukua nafasi ya ile lugha mama). mtalaa unalenga kuingiza lugha zote ambazo watoto wanazijua wakati wa masomo yao.  20 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  bwana maleke mkoani lindi hutumia shughuli ifuatayo, ambayo hujumuisha lugha nyingi za nyongeza, pamoja na wanafunzi wake wa darasa la 5. humpatia kila mwanafunzi kipande cha kadi. wanafunzi huchora picha katika upande mmoja wa kadi. kwa upande mwingine, huandika nyimbo, michezo, mikarara/viitikio au mashairi, ambayo wanayapata nyumbani. kila siku, wana kipindi cha kusoma ambapo wanafunzi wanasoma (au wanaimba!) kile kilichoandikwa kwenye zile kadi. wakati mwingine, msomaji bora husoma kadi na msomaji anayesoma polepole zaidi. wakati mwingine, mzungumzaji wa lugha moja, humsaidia mwanafunzi mwingine kusoma lugha yake na kuingiza sauti. wakati mwingine, wanaigiza hayo mashairi au wanacheza michezo hiyo. bwana maleke amegundua jinsi darasa lake linavyokuwa na furaha na jinsi wanafunzi wanavyoshirikiana vizuri katika mazungumzo na wanavyochanganyika vizuri zaidi tangu waanze kufanya hivi.  shughuli ya 2: michezo na nyimbo kutoka kwa wanajumuiya ambao ni watu wazima waambie wanafunzi wako wamwombe mtu mzima (mzazi, babu/bibi, jirani n.k.) awafundishe mchezo, wimbo au mkarara ambao walikuwa wakiufurahia wakati wa utotoni. wanatakiwa wajue kanuni za maneno na nyenzo zozote ambazo zinahitajika. siku inayofuata, orodhesha michezo na nyimbo ambazo wanafunzi wamezileta toka nyumbani. waweke pamoja wanafunzi wanaojifunza mchezo au wimbo wa aina moja. waambie wajiandae kufundisha darasa mchezo au wimbo huo. waambie waandike huo wimbo au huo mkarara au wacheze mchezo wa kwenye kadi. darasa litakapomaliza kujifunza mchezo au wimbo huo, jadilianeni kitu ambacho wanaweza kujifunza kutokana na mchezo au wimbo huo. andika tini kama ulivyofanya hapo awali. kwa masomo yatakayofuata, wahamasishe wanafunzi wasome magazeti ili kutafuta nyimbo, michezo, vitendawili na mizaha kama msingi wa kuandika vitu vyo wenyewe.  3. ‘kuakisi’ ni kutafakari juu ya kile kilichotokea na kuona jinsi ya kufanya vizuri zaidi wakati mwingine. baada ya kuwa umejaribu shughuli mpya, inasaidia sana kuakisi/kutafakari juu ya mafanikio na kitu gani kinahitaji maboresho. fanya mchakato wa ‘panga-tendarekodi-tafakari’ kuwa sehemu ya mazoea yako ya kila siku (angalia nyenzo rejea 1 ). sasa una mkusanyiko mzuri wa michezo, unaweza kuitumia michezo hii kama msingi wa shughuli za ujifunzaji, na kama msingi wa kuakisi/kutafakari na uboreshaji. (kazi hii pia inaweza kufanywa kwa kutumia hadithi.) nyenzo rejea 3: michezo ya maneno ina michezo kadhaa ambayo unaweza kuijaribu pamoja na wanafunzi wako.  21 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  uchunguzi kifani ya 3: vitenzi vya kiswahili katika wimbo wa kurukaruka maneno bi alison aliimba wimbo wa kurukaruka maneno wakati alipokuwa mtoto pale mazimbu, morogoro. aliamua kuutumia wimbo huo kufundishia wanafunzi wake wa darasa la 2 maneno kadhaa na virai vya wakati uliopo vya kiswahili. kwanza wanafunzi waliuimba kwa kiswahili na kisha aliwasaidia kuuimba kwa kiingereza. alimpatia kila mwanafunzi kipande cha karatasi chenye kitenzi (m.f. la, nywa, cheka, kohoa, ruka, kimbia, rukaruka) kilichoandikwa kwenye karatasi hiyo. alihakikisha kuwa kila mtoto anafahamu maana ya neno hilo na jinsi ya kufanya vitendo vinavohusiana na neno hilo. alimwambia kila mwanafunzi mmoja mmoja afanye vitendo bila maneno, na darasa liliimba ubeti mpya: ‘antoni, msichana huyu anafanya nini? antoni, msichana anacheka,’ n.k. baada ya somo, alitafakari kuhusu: kile kilichokwenda vema; kile ambacho hakikwenda vema sana; kile kilichomshangaza; kile ambacho angekibadili kama angerudia lile somo. bi alison alishangazwa na jinsi wanafunzi walivyoutumia muda katika kujifunza toleo la kiswahili lakini pia jinsi wanafunzi waliufurahia muda. aliona kuwa alihitaji kutumia muda zaidi katika shughuli hii, na pia kufundisha maneno machache zaidi. wiki iliyofuata, alitumia toleo la aina nyingine la kiswahili lililokuwa na wimbo wa kurukaruka maneno kwa jinsi ile ile, ya kutunga beti zenye aina mbalimbali za vyakula. (angalia nyenzo rejea 4: wimbo wa kurukaruka maneno kutoka katika wimbo wa kurukaruka maneno wa igbo.)  shughuli muhimu: kujifunza kutokana na mkarara, wimbo au mchezo je, kuna mkarara kwenye makusanyo ya darasa lako ambao lugha yake inaweza kubadilishwa na kuwa kama lugha ya nyongeza na kuweza kutumiwa katika kuhamasisha ujifunzaji wa lugha? bainisha sentensi katika mkarara ambayo neno (au maneno) yangeweza kubadilishana nafasi kwa zamu. kwa mfano, ‘anacheka’ lingeweza kubadilishana nafasi na (anaruka, anarukaruka, anakimbia’ n.k.). kila mwanafunzi, au kikundi, kinaweza baadaye kuimba ubeti mpya, wenye neno jipya katika sentensi ya mwanzo. ingeweza hata kufurahisha zaidi kama maneno au sentensi yataweza kuambatana na vitendo. panga jinsi utakavyopanga darasa lako kwa ajili ya kuimba/ kukariri na kuigiza (zoezi hili ni mbadala’. (huu ni mfululizo wa sentensi, ambazo zinafanana isipokuwa kwa neno au kishazi kimoja. sentensi hizi zinatumika kufanya mazoezi ya mitindo ya lugha.)  22 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  kama hutafanikiwa, utatakiwa kujaribu wimbo mwingine, au njia nyingine ya kuendesha shughuli hii.  nyenzo-rejea ya 1: duara la tenda - tafakari nyenzo-rejea ya mwalimu kwa ajili ya kupanga au kutohoa na kutumia na wanafunzi. mpendwa ………………… darasa letu la …… linajifunza kuhusu hadithi za asili na stadi za kusimulia hadithi. tumesikia kuhusu ubingwa wako na tunapenda kukukaribisha kuja na kutusaidia kujifunza ni namna gani tunaweza kukuza stadi zetu za kusimulia na kujifunza hadithi pia. tungependa uje …………………………………. tafadhali tujulishe kama muda huu ni mwafaka kwako. ………………………………… kutoka katika darasa letu atakusubiri geti la shule saa 4.00 asubuhi. tunashukuru sana darasa la 5 shule ya msingi ya mtakatifu maria  nyenzo-rejea ya 2: tathmini uigizaji wa hadithi za vikundi usuli/welewa wa somo wa mwalimu  23 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  kielelezo kinaonesha hatua zifuatazo katika mduara wa tenda- akisi/tafakari: panga shughuli. tenda kwa kuweka mpango katika vitendo, na chunguza unavyoendelea. rekodi kile unachokiona. akisi/tafakari juu ya kilichotokea. pitia tena mpango wako, au andaa mpango mpya. weka mpango uliopitiwa tena au mpango mpya katika vitendo, na angalia tena. rekodi na tafakari tena. na kadhalika, na kadhalika … kila kitu unachokifanya kama mwalimu kinaweza kuwa sehemu ya mduara wa tenda -tafakari. (angalia pia nyenzo rejea muhimu: kufanya utafiti darasani)  nyenzo rejea 3: utafiti juu ya michezo ya jadi katika mtalaa usuli/welewa wa somo wa mwalimu nonhlanhla shange alifanya utafiti katika shahada yake ya uzamili katika kitengo cha usomeshaji wa vijijini cha nelson mandela katika chuo kikuu cha fort hare nchini afrika kusini. alitafiti kuhusu utumizi wa michezo ya jadi darasani, utafiti ambao aliufanya katika shule nne za vijijini. wanafunzi na walimu wao walifanya utafiti wa vitendo katika michezo ya jadi.  24 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  walimu walisikiliza kwa makini na waliandika tini za michezo ambayo wanafunzi waliileta darasani. walijaribu kutayarisha masomo yanayohusu michezo hii. wanatunza juzuu, ambamo huwekwa kumbukumbu za masomo haya, na kujaribu kufanya maboresho kwa ajili ya matumizi ya baadaye. maelezo ya michezo miwili ambayo ilichezwa kama sehemu ya utafiti huu ni haya yafuatayo hapa chini. 1. mchezo wa duara matayarisho ya mchezo huu yanajumuisha uchoraji wa kielelezo kama hiki hapa chini ambacho huchorwa ardhini.  mchezo unachezwaje? mchezo huu unachezwa kwa vikundi vidogo vya wanafunzi watano watano au sita sita. mwanafunzi mmoja anarukia ndani ya nafasi za duara, akigeuka upande hadi upande, wakati wanafunzi wengine wakiimba wimbo mfupi au shairi fupi, kwanza kwa lugha ya asili, na kisha kwa kiswahili. shughuli gani za ujifunzaji zilizohusiana na mchezo huu? mchezo ulibuniwa ili kuonesha ni jinsi gani kurudia rudia kwa kutumia lugha ya wanafunzi wenyewe na lugha ya kiswahili kunavyoweza kusaidia katika kujifunza. kwa kutumia wimbo mfupi au shairi, mchezo huu pia uliweza kutumika katika kuwafundisha wanafunzi kuhesabu. 2. mcezo wa mawe matayarisho kwa ajili ya mchezo hujumuisha uchoraji wa duara chini ardhini na kuweka idadi fulanii ya mawe kwenye duara hilo. (duara lisizidi kipenyo cha mita moja.)  25 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  mchezo unachezwaje? wanafunzi wanagawanywa katika vikundi vya watano watano au sita sita. kila kikundi kinakuwa na duara lake lililochorwa ardhini na kuwekwa mawe ndani yake. mchezaji anarusha jiwe moja juu; kabla halijatua ardhini, lazima wajaribu kuokota mawe mengine ndani ya duara. kila mwanafunzi katika kikundi lazima ajipe namba mwenyewe (chini ya 10). namba hii ni idadi ya mawe ambayo mchezaji atajaribu kucheza na kuokota. mchezaji mmoja anaingia kwanza. kama mchezaji huyu ataokota idadi ya mawe inayotakiwa kutoka kwenye duara, wanasema orodha ya kuzidisha ya namba hii (kwa mfano, orodha ya 3 ya kuzidisha, wanakomea kwenye 30 – hii inaweza kuwa ni ya chini kwa wanafunzi wadogo zaidi). kama mchezaji atashindwa kuokota idadi inayotakiwa ya mawe kutoka kwenye duara, watapaswa kuzidisha idadi ya mawe waliyookota kwa idadi ya mawe ambayo walipaswa kuokota, na kupata jibu sahihi. kwa mfano, kama walitakiwa kuokota mawe hadi 5, lakini wakaokota mawe 3 tu, watatoa jibu sahihi la 5 x 3. wachezaji wengine watapima/watajaji endapo wametoa jibu sahihi au jibu ambalo si sahihi. shughuli gani za ujifunzaji ambazo zinahusishwa na mchezo huu? mchezo huu ulitumiwa ili kuwafanyia wanafunzi mazoezi ya ’ stadi’ za kuzidisha. chanzo cha asilia: shange, n., kitengo cha mfuko wa nelson mandela wa usomeshaji na maendeleo ya vijijini [ utafiti haujachapishwa ] nelson mandela foundation’s unit for rural schooling and development [unpublished research]  26 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  nyenzo rejea 4: michezo ya maneno nyenzo rejea ya mwalimu kwa ajili ya kupanga au kurekebisha ili kutumia na wanafunzi michezo hii inaweza kuchezwa kwa kutumia lugha yoyote na kwa umri wowote, ilimradi tu wanafunzi wanajua vizuri stadi za kusoma na kuandika. mchezo 1: bingo wasomee wanafunzi hadithi wanayoipenda na waambie wachague maneno mawili wanayoyataka. mwulize kila mwanafunzi maneno yao na andika maneno muhimu ubaoni ambapo kila mmoja ataweza kuona. ligawe darasa katika vikundi vya wanafunzi sita sita na kiambie kila kikundi kichague maneno 12 kwa ajili ya kikundi chao. haya yanaweza kutofautiana kwa kila kikundi. kila mwanafunzi atengeneze karatasi ya bingo kwa kuchora mraba mkubwa uliogawanyika katika miraba midogo tisa (angalia mfano hapa chini). mwambie kila mwanafunzi achague maneno yoyote tisa kutoka kwenye orodha yao ya maneno 12 na kuyanakili katika karatasi yao ya bingo, neno moja kwa kila mraba. makaratasi ya wanafunzi yatakuwa tofauti, kwa sababu wataweza tu kuchagua maneno tisa kati ya maneno 12. mwanafunzi mmoja atakuwa na karatasi kuu yenye maneno 12. watatoa maneno bila mpangilio maalum. neno linavyotajwa kila mwanafunzi ambaye atakuwa na neno hilo katika karatasi ya bingo atatakiwa kulikata. wa kwanza kukata maneno yake yote atapiga kelele ‘bingo’ na atakuwa ameshinda. kiache kila kikundi kicheze tena na kila mwanafunzi apate zamu ya kutaja maneno. kama unataka kutumia karatasi ya bingo zaidi ya mara moja, waambie wanafunzi wazibe maneno hayo kwa mawe au vihesabio wakati wa kutaja maneno. je, wanafunzi walijifunza maneno mapya? unajuaje? orodha ya sampuli ya maneno kwa ajili ya bingo: ndizi maharage kabeji mihogo nazi punje za mahindi maembe mahindi machungwa mapapai mapeasi spinachi viazi vitamu mifano miwili ya kadi za bingo:  27 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  mchezo 2: maneno yanayohusu supu 28 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  tengeneza orodha ya maneno tisa, mf. sehemu za mwili, vyumba vya nyumba, au mboga za majani. weka orodha hii ubaoni (pembeni mwa picha toa maelekezo ya maneno kama unaweza). mpatie kila mwanafunzi kipande cha karatasi cha mraba, herufi moja kwa kila mraba. waambie waingize maneno muhimu katika karatasi hiyo kwenye miraba hiyo, herufi moja kila mraba mmoja. waambie kuwa maneno yanaweza kutoka kushoto kwenda kulia, au juu mpaka chini. waambie wanafunzi wajaze miraba ya ziada kwa herufi zozote zile za alfabeti. (angalia mfano hapa chini). kila mwanafunzi akishafanya hivi, kusanya makaratasi yote na yachanganye. sasa wagawie wanafunzi makaratasi hayo bila mpangilio maalum, na waambie wanafunzi wazungushie maneno yote wanayoweza kuyapata. kila mwanafunzi anajua lazima maneno yawe tisa. wa kwanza kumaliza ndiye mshindi. wanafunzi wanaweza baadaye kuchagua somo lao wenyewe au eneo lao wenyewe na maneno yanayohusu supu kutoka kwenye orodha hii na kumpatia rafiki acheze. mfano wa maneno yanayohusu supu  29 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  maneno ya kutafuta kwenye maneno ya supu  mbuzi  ngamia  simba  twiga  nyoka  nyani  chui  farasi  30 of 54  monday 27 june 2016  sehemu ya 3: kutumia michezo ya jadi katika kujifunza  unaweza kufanya shughuli hii iwe ya kusisimua zaidi kwa kuwauliza ‘neno gani ambalo linalohusika katika supu?’ unaweza kutumia mchezo huu kwa maneno mengi mbalimbali na kwa masomo mbalimbali. kiolezo wazi kwa ajili ya maneno ya supu ni hiki hapa chini. unaweza kuongeza miraba zaidi au kuifanya iwe midogo zaidi ili kufanya mchezo uwe mgumu zaidi au mrahisi zaidi kutegemeana na umri na uwezo wa wanafunzi wako.  31 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  nyenzo rejea 5: wimbo wa kurukaruka maneno nyenzo rejea ya mwalimu kwa ajili ya kupanga au kurekebisha ili kutumia na wanafunzi  wimbo wa kiigbo wa kurukaruka maneno ikuku buru gi zamiriza buru gi buru nwa nnegi zamiriza nwa nnegi idobere na ukwu osisi kporonku chọ ya ịhuyi ya (2x) tafsiri ya kiswahili  acha upepo ukupeperushe zamiriza ukupeperushe wewe na mdogo wako wa kike zamiriza yule mdogo wako wa kike yupo chini ya mti wenye matawi yote yenye kivuli unamtafuta mdogo wako huyo, huwezi kumpata (x2)  kurudi kujua kusoma na kuandika ukurasa need to check translation  sehemu ya 4: utumizi wa hadithi na ushairi swali lengwa muhimu: unawezaje kutumia ushairi na hadithi kuhamasisha wanafunzi ili waandike? maneno muhimu: jina; sifa; mashairi; hadithi; wasifu, uandishi  matokeo ya ujifunzaji mwishoni mwa sehemu hii, utakuwa umeweza: l  umetumia mashairi au hadithi za majina au za kusifu ili kuchochea mawazo ya wanafunzi ya uandishi;  32 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  l  umetumia nyenzo-rejea kama vile makala za kwenye magazeti ili kuchochea mawazo ya uandishi wa hadithi za maisha (wasifu);  l  umetalii ‘uandishi wa rasimu ’ na ‘uandishi wa kisanaa’ wakati wa kuandika.  utangulizi afrika nzima, tuna utajiri wa fasihi simulizi na fasihi andishi kuhusu watu ambao bado ni muhimu au hapo zamani walikuwa muhimu kwa familia zao, jumuiya zao na nchi zao. watu hawa hushangiliwa kupitia nyimbo na mashairi ya kuwasifu na hadithi zinazohusu maisha yao (wasifu). kwa kutumia utajiri huu wa historia ya kitamaduni katika ufundishaji wako kunaweza kukusaidia ili kujua vitu vya kusoma kwa ajili ya lugha itakayotumika darasani na kuamsha mvuto wa wanafunzi katika uandishi.  1. kama wanafunzi wanasikiliza na kusoma mashairi na hadithi wanazozifurahia, ni rahisi sana wakapenda kuendeleza stadi zao za usomaji na uandishi kwa kutumia lugha zao za asili au lugha wanayoitumia darasani. ili kuwa waandishi wenye mafanikio, wanafunzi wanahitaji ‘zana’ mbalimbali. kwanza, wanahitaji mada ya kuandikia. katika shughuli ya 1, utatumia mifano ya mashairi ya majina au ya kusifu au hadithi ili kuwapatia wanafunzi mawazo. kisha utawaongoza katika kuandika rasimu ya kwanza ya shairi la majina au la kusifu au hadithi. hii ina maana kwamba itabidi kuandika matoleo kadhaa ya rasimu, ambayo yatazidi kuboreshwa, mpaka watakaporidhika kuwa shairi au hadithi zao ni nzuri na wanaweza kutoa toleo la mwisho.  uchunguzi kifani ya 1: kusoma na kuandika mashairi ya majina na hadithi katika warsha ya mwalimu katika warsha ya siku nne mjini johannesburg nchini afrika kusini, baadhi ya walimu wa kiingereza/kiswahili walisoma mashairi na hadithi kuhusu majina. katika warsha hii, waandishi walieleza jinsi walivyopata hayo majina yao, kitu walichokipenda au ambacho hawakukipenda kuhusiana na majina yao na maneno ambayo yalihusiana na majina hayo. kwa kweli walimu walifurahia kile walichokisoma na kuomba iwapo wangeweza kupatiwa nafasi ya kuweza kuandika mashairi au hadithi zinazohusu majina yao wenyewe wakati wa warsha. siku ya pili, kila mwalimu alimsomea mwenzake rasimu yake ya kwanza. walipeana majibu ya kile walichokipenda na kile ambacho walifikiri kinafaa kiboreshwe, kwa mfano kwa kuongeza maelezo na kuchagua msamiati tofauti au alama za uakifishi. siku ya nne, wakiwa wameshafanyia kazi rasimu zao siku moja kabla, kila mmoja alikisomea kikundi kizima shairi au hadithi ambayo ilikuwa imekamilika. kulikuwa na kicheko, kulikuwa na machozi na kulikuwa na makofi mengi. walipoambiwa waakisi uzoefu wao, walisema: l  hakuna mtu aliyekuwa ‘amekwama’ kuhusiana na kitu/mada ya kuandikia;  l  wakati wengi wao waliandika kwa kiingereza, walifurahia mara kadhaa kutumia maneno au virai vya lugha ya kiafrika ili kueleza wazo fulani;  33 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  l  walinufaika na matokeo ya rasimu zao za kwanza; walijisifu sana kutokana na toleo la mwisho; walifurahia kusikiliza hadithi/mashairi ya wengine;  l  mengi ya mashairi yalikuwa yanafanana na yale mashairi na zile nyimbo za jadi za kusifu.  walimu waliamua kuwasomea wanafunzi mashairi na hadithi zao pamoja na mashairi na hadithi nyinginezo za majina katika kuwasaidia ili waweze kuandika kuhusu majina yao.  shughuli ya 1: kuandika rasimu ya mashairi au hadithi za majina ili kupata mawazo jinsi ya kuandaa shughuli hii, tumia nyenzo-rejea 1: kuandaa masomo juu ya mashairi ya majina au ya kusifu na nyenzo-rejea 2: mashairi na hadithi za majina au nyenzo-rejea 3: mashairi na hadithi za kusifu. chagua ama mashairi/hadithi za majina au mashairi/hadithi za kusifu. waambie wanafunzi wapendekeze shairi/hadithi ya majina au shairi/hadithi ya kusifu itahusu nini. waambie wasikilize wakati wewe ukiwa unasoma shairi (ma)/hadithi uliyoandaa kwa sauti. waulize maswali kuhusu kile ulichowasomea. waambie wanafunzi wajadiliane na wenzao ama kuhusu kile wanachokijua kuhusu jina hili ulilowasomea, au kile wanachokijua kuhusu mtu, mnyama au kitu wanachotaka kukisifia. baadaye, waambie baadhi ya wanafunzi watoe ripoti ya mjadala wao darasani. waambie wanafunzi waandike rasimu ya kwanza ya shairi au hadithi kuhusu wao wenyewe au wanafamilia au kumsifu mtu, mnyama au kitu watakachokichagua. kusanya rasimu ili kutayarisha shughuli muhimu. je, kuandika mashairi/ hadithi za majina au za kusifu kunawapa wanafunzi mawazo ya kuandika? uliridhika na jinsi ulivyoendesha somo? utafanya marekebisha gani wakati ujao? ukiwa na watoto wadogo zaidi, unaweza kuandika mashairi ya majina kwa pamoja, mkishirikishana mawazo na kutumia maneno yaliyozoeleka katika lugha inayotumika darasani.  2. baadhi ya hadithi za kwanza wanazozisikia watoto ni zile ambazo zinahusu uzoefu wa maisha ya familia au wanajumuiya. hadithi za maisha ya watu mashuhuri (wasifu wao) mara nyingi huchapishwa katika magazeti na hata katika muundo wa vichekesho, hivyo, kama wanazisikia au wanazisoma, wanafunzi wengi watakuwa wana fununu juu ya hadithi kuhusu maisha. huu ni mwanzo mzuri ili kuamsha hamasa ya kusoma na kuandika. darasani, wanafunzi wanahitaji msaada kutoka kwa mwalimu wao na kutoka kwa wenzao wakati wanapojifunza kuzungumza, kusoma na kuandika –hasa kama lugha hii ni ya nyongeza. uchunguzi kifani 2 na shughuli 2 zinaonesha jinsi unavyoweza kuwapatia wanafunzi fursa ya kusoma, kuzungumza, kufanya kazi pamoja katika vikundi vidogo na kuandika rasimu za kwanza za hadithi za maisha ya watu wanaowapenda. 34 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  wanafunzi wanahitaji mifano ili kuwaendeleza kama waandishi. makala wanazozisoma zinaweza kuwasaidia katika kupangilia uandishi wao na kuwasaidia katika miundo ya sentensi na msamiati. wanafunzi wadogo watakuhitaji wewe ili ufanye nao kazi, uwaongoze katika uandishi wao na polepole wapanue msamiati wao.  uchunguzi kifani ya 2: kutumia mambo yanayowavutia wanafunzi ili kuendeleza stadi za usomaji na uandishi bw. simoni raphaeli aligundua kuwa, katika uwanja wa mpira, baadhi ya wavulana wa darasa la 6 –ambao hawakuonesha kuvutiwa na usomaji na uandishi wakati wa masomo ya kiingereza –mara kwa mara walikaa pamoja ili kusoma gazeti la soka, mwanaspoti. walimwambia bw. simon kuwa wanafurahia kutafuta taarifa zinazohusu maisha ya wachezaji wanaowapenda. hali hii ilimpa simoni wazo. aliwauliza wanafunzi wa darasa lake kama wameshawahi kusoma magazeti na, kama wameshawahi kuyasoma, walifurahia kusoma kitu gani. wengi walisema kuwa walijaribu kusoma hadithi kuhusu watu ambao waliwavutia, hata kama hawakuweza kuelewa maneno yote. simon aliandaa mkusanyiko wa magazeti kwa ajili ya darasa. kisha aliwauliza wanafunzi kuhusu mambo waliovutiwa nayo na kuwafanya wasome magazeti hayo. nyota wa michezo ndio waliopendwa zaidi (hasa wachezaji wa soka, pia mpira wa kikapu, mbio na ndondi), wanamuziki, nyota wa filamu na tv, wakifuatiwa na wanamitindo, wanasiasa, viongozi wa jumuiya na wafanyabiashara maarufu. simoni aliwapanga wanafunzi kufuatana na yale mambo yaliyowavutia. kulikuwa na vikundi kadhaa vya nyota wa michezo na wanamuziki! alikipatia kila kikundi magazeti na kuviambia vikundi vitafute makala/picha kuhusu mtu mmoja aliyewavutia wanakikundi. kisha, kama kikundi, walisaidiana kuandika sentensi fupi moja au mbili kuhusu maisha ya mtu huyo. walitumia maneno yao wenyewe na pia msamiati kutoka kwenye makala. waliandika kichwa cha habari chao wenyewe. simoni aliridhika kuona kuwa wanafunzi wengi walishiriki katika usomaji na, wengine wakiandika sana kuliko wengine, wote walishiriki. kila kikundi kilifurahia kusoma na kukisomea kikundi kingine wasifu wa kikundi.  shughuli ya 2: usomaji na uandishi wa hadithi za maisha ili kuandaa shughuli hii tumia nyenzo-rejea 4: kuandaa msomo ya hadithi za maisha. waambie wanafunzi wasome kwa pamoja hadithi uliyoinakili ubaoni au kwenye karatasi. au wasomee hadithi hiyo na eleza inahusu nini. jadilini sifa za hadithi za maisha (wasifu). waulize wanafunzi wakuambie ni kategoria gani za watu (m.f. wachezaji wa taifa wa mpira wa miguu, wanamuziki wa jadi) ambao wanawapenda, na kwa nini. kipatie kila kikundi chenye mwelekeo wa aina moja magazeti mbalimbali ambayo yana makala kuhusu kategoria ambayo wanakikundi wanaipenda/wanaifurahia. waambie watafute makala kuhusu mtu kutoka katika kwenye kategoria waliyoichagua na watumie taarifa ili kuandika mambo mawili yanayomhusu mtu huyu (angalia nyenzo-rejea 4 kwa mwongozo katika kuwasaidia wanafunzi wako kuweza kufanya kazi hii). kusanya rasimu hizi ili kuzitumia katika shughuli muhimu.  35 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  kama darasa lako ni kubwa sana, ungeweza kufanya shughuli hii kwa kuhusisha nusu ya darasa au vikundi vidogo kwa zamu. ungeweza pia kuwaweka wanafunzi katika vikundi kulingana na uwezo wao –ukichanganya wenye uwezo zaidi na wale wenye uwezo mdogo ili wasaidiane. ukiwa na wanafunzi wadogo, unaweza kufanya kazi hii kama zoezi la darasa zima ambapo unawasaidia kunukuu mawazo yao na kushirikishana maneno yao.  3. tunapoandika kitu, ni muhimu tuweke wazi kile tunachotaka kukisema. tunatakiwa tupange. baadaye, tunaanza kuandika na kusoma kile tulichokwisha andika. tunaweza kuamua kubadili mpangilio wa baadhi ya maneno, kuongeza, kupunguza baadhi ya maneno na kuongeza au kubadili baadhi ya taarifa. mwishoni, tunakagua uandisha ambao si sahihi, alama za kiuakifishi/uandishi au sarufi. kazi ya mwisho inaweza kuwa tofauti kabisa na ile rasimu yetu ya mwanzo. tunakuwa tumefanya uandishi wetu uwe wa kisanaa. katika darasa, kazi moja ingeweza kukamilika (yaani iwe imeandikwa kisanaa) kabla ya kuanza kazi nyingine. uchunguzi kifani 3 na shughuli muhimu hukuonesha jinsi ya kuandaa masomo ambapo wanafunzi wanatakiwa wafanye uandishi wao uwe wa kisanaa.  uchunguzi kifani ya 3: kushirikiana na mwenzako ili kuwasaidia wanafunzi katika uandishi bibi dorcas mabula na bibi beatrice mntambo wanafundisha wanafunzi wa darasa la 6 katika wilaya ya kinondoni somo la kiingereza. huwapatia wanafunzi maoni ya kina kuhusiana na uandishi wao, hivyo wakati mwingine walimu hawa hubaki shuleni baada ya saa za shule na kushirikiana katika kusahihisha. siku moja mchana, kabla ya kuanza kusahihisha wakiwa wanakunywa maltina, wote wawili walielezana kuwa walikuwa wanajisikia kuchanganyikiwa kutokana na baadhi ya wanafunzi kupuuzia maoni na masahihisho katika madaftari yao. marafiki hawa waliona kuwa hali hii ilikuwa inatisha, kwa sababu waligundua kuwa maoni waliyowapatia katika rasimu ya kwanza katika kazi zilizotangulia yaliwasaidia kuboresha matoleo yao ya mwisho ya kazi kwa ajili ya kuendeleza kozi zao za kitaalamu. baadaye dorcas aligundua kitu muhimu! wanafunzi wake hawakupata nafasi ya kufanya kazi nyingi zinazohusiana na kazi hii ya uandishi. badala yake, kulikuwa na mada mpya katika kila somo la uandishi. alipomwambia beatrice jambo hili, rafiki yake alikubali kuwa jambo hili pia lilitokea katika darasa lake. hivyo ndivyo walivyofundishwa walivyokuwa shuleni! waliamua kujaribu mkabala mpya. wakaamua kutumia masomo kadhaa kuandika rasimu na kuandika kisanaa andiko hilohilo. wakawapatia wanafunzi mawazo ya kuwaongoza katika uandishi wao na katika marudio ya andiko hilo. mwanzoni, wanafunzi hawakupenda kurudia kuandika andiko hilohilo, lakini walipoona jinsi kazi zao zilivyokuwa bora, walianza kulipenda zoezi hili.  shughuli muhimu: kutoka kwenye uandishi wa rasimu wa  36 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  mashairi/hadithi mpaka uandishi wa kisanaa kabla ya somo, soma rasimu za kwanza za wanafunzi na amua juu ya maswali ya jumla ya kuwauliza ili kuboresha kazi zao (angalia nyenzo-rejea 5: maswali kwa ajili ya wanafunzi ). yaandike maswali haya ubaoni. warudishie wanafunzi rasimu zao, zikiwa na maoni ya jumla juu ya kile unachotaka kuhusu uandishi wa wanafunzi. eleza kuwa sasa uandishi wao utakuwa wa kisanaa. waambie wasome tena rasimu zao za kwanza na watumie maswali yaliyoko ubaoni katika kuandika na kuboresha rasimu za pili. waambie wabadilishane na wenzao rasimu zao za pili na wapeane mapendekezo kwa ajili ya maboresho. waambie watumie mapendekezo haya kuandika toleo la mwisho. zungukia darasa na toa msaada inapobidi. wahimize watumie michoro katika uandishi wao. kama hakuna muda ili kumalizia shughuli hii katika muda wa kipindi darasani, waambie wanafunzi wamalizie shughuli hii nyumbani na watoe ripoti siku inayofuata. waulize jinsi mchakato huu wa kuandika rasimu ulivyowasaidia. kulikuwa na maboresho yoyote katika uandishi wa wanafunzi kama matokeo ya mchakato wa wanafunzi wa uandishi wa rasimu na uandishi wa kisanaa? unaweza kujenga mambo haya? ukiwa na wanafunzi wadogo au ambao hawajui sana lugha inayotumiwa darasani, ungeweza kufanya nao kazi ya kuandika rasimu na kuandika tena rasimu ya kazi rahisi kwa vipindi viwili – ukiwapatia muda katika somo ambao wataweza kutafakari kile ambacho walitaka hasa kukisema.  nyenzo-rejea ya 1: kuandaa masomo juu ya mashairi ya majina au ya kusifu usuli/welewa wa somo wa mwalimu amua kama unataka kuchagua mashairi/hadithi za majina au za kusifu ili kuzifanyia kazi na wanafunzi wako. 1  chagua mfano mmoja au zaidi kutoka nyenzo-rejea 2 au 3 au kutoka katika nyenzo-rejea nyingine ulizonazo au andika shairi au hadithi yako mwenyewe.  2  andika shairi (ma)/ hadithi hiyo au hadithi hizo kwenye karatasi kubwa au ubaoni ili unapozitumia darasani wanafunzi waweze kusoma chapa kubwa pamoja na wewe na baadaye waweze kurejelea mashairi na hadithi hizo wanapoandika mashairi au hadithi zao wenyewe. kama huna karatasi kubwa, andika kwenye ubao wako.  andaa maswali ya kuwauliza wanafunzi kuhusu shairi (ma)/hadithi. kwa hakika, aina ya swali itategemea kile ulichokichagua. kwa mfano, kama utachagua shairi la thabo, ungeweza kuanza na: ‘unagundua nini kuhusu jinsi shairi hili lilivyoandikwa?’ (jibu: kila mstari umeanza kwa herufi moja ya jina la thabo). ukichagua hadithi ya kusifu ya hugh lewin kuhusu mama yake jafta, ungeweza kuuliza: ‘ungependa kuwa na mama kama mama yake jafta? nipatie sababu ya jibu lako.’  37 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  ukishamaliza maandalizi haya, uko tayari kufundisha masomo kuhusu mashairi na hadithi za majina na za kusifu. wanafunzi wanapoanza kuandika, zungukia darasa ili kumsaidia yeyote ambaye atapata shida katika kuanza. wengine watahitaji msaada wa mawazo, wengine shida ya msamiati. nyenzo-rejea 2 na 3 zote ni mashairi, nyimbo na hadithi za kusifu lakini lugha ni ngumu kwa baadhi yazo kuliko nyingine.  nyenzo-rejea ya 2: mashairi na hadithi za majina nyenzo rejea ya mwalimu kwa ajili ya kupanga au kurekebisha ili kutumia na wanafunzi shairi la majina lililoandikwa na mwalimu nchini tanzania: hanna – jina langu la sifa lililoandikwa na hanna simpassa fahari ya moyo wangu – nani alileta jina hili? nililipataje? hakuna hata mmoja katika familia aliyeliota – ila mimi! jina langu la kikristo. wazazi wangu hawakulichagua – nililiunda, zamani kabla sijawa muislamu. hasina – jina linalomaanisha uzuri. hasina – jina langu maalumu. roho ziliniambia katika ndoto umebadilishwa dini kuwa mkristo hanna ni jina lako. hanna – jina linalomaanisha ‘neema, huruma na sala’. yeye ni wa thamani kama almasi, hujua thamani ya kujitoa, kamwe hakati tamaa, anapata marafiki kwa urahisi, furaha ni nguvu yake, kicheko chake ni dawa nzuri; mtu ambaye asili yake ni maarifa thabiti. yeye ni mtoto wa ulimwengu. hivyo nilibadilishwa dini hasina kuwa hanna na ninajivunia jina langu shairi la jina lililoandikwa na mwalimu nchini afrika kusini mawazo kuhusu herufi za jina langu na thabo x  38 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  t inasimama badala ya thabiti – mimi ni mtu imara h kwa ajili ya hafukasti – baba na mama yangu wana asili tofauti a ni aminifu… bora ona nilivyo–ni mimi hasa! hadithi ya jina iliyoandikwa na mwalimu nchini tanzania: hadithi ya kupewa jina niliyohadithiwa na nyalupala mtavangu zamani, katikati ya kiangazi, babu yangu, wakati huo alikuwa anaitwa nyalukolo, alikwenda mtoni ili kukamilisha sherehe za matambiko. pale mtoni alitokea simba mkubwa ambaye alikwenda kunywa maji. mnyama huyu alimshambulia, na nyalukolo alipambana naye. aliwaua wanyama wengi wa mwituni na haraka alikimbilia nyumbani kumwambia baba yake kuhusu kitendo hiki cha ushujaa cha kushangaza. baba yake, mungai, alituma ujumbe kijiji kizima na watu walikimbilia mtoni. ilikuwa kweli – simba aliyekufa alikuwa amelala pale chini! tangu siku ile, nyalukolo alipata heshima kutoka kwa kila mtu ambaye alijua alichokifanya. wanaume na wanawake, vijana na wazee, walimheshimu. katika sehemu nyingine walimtania kichinichini ‘nyalupala’. jina hilo la minong’ono lilimfikia baba yake, mungai, ambaye aliamua kuita watu wa kabila lile pamoja kwa ajili ya sherehe ya kubadili jina. nyalukolo aliitwa nyalupala rasmi, kwa maana ya ‘simba’ katika lugha ya kihehe. wakati nilipozaliwa, katikati ya karne ya 20, nilipewa jina la babu yangu. ni jina ninalolihusisha na ushujaa na ushupavu wa mzimu wangu na ninajivunia jina hili.  nyenzo-rejea 3: mashairi na hadithi za kusifu nyenzo rejea ya mwalimu kwa ajili ya kupanga au kurekebisha ili kutumia na wanafunzi shairi la kiyoruba la kusifia chatu baadhi ya ushairi wa kusifu husifia wanyama au vitu kuliko watu. hapa pana shairi kutoka kwa wayoruba wa naijeria. maelezo kwa baadhi ya lugha iliyotumika yametolewa baada ya shairi hili. chatu mwana wa mfalme mwenye mikogo [mstari 1] mkubwa miongoni mwa nyoka. wanasema chatu hana nyumba. nilisikia maneno haya zamani na nilicheka nikacheka na kucheka. kwani ni nani anamiliki ardhi chini ya nyasi za mlimao? [mstari 6] nani anamiliki ardhi chini ya nyasi za tembo? nani anamiliki kinamasi – baba wa mito? nani anamiliki dimbwi lililosimama – baba wa maji? kwa sababu hawatembei kwa kuongozana [mstari 10] watu wanasema kuwa nyoka hutembea tu pekee pekee.  39 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  lakini hebu fikiria chukulia kipiribao atembee mbele ya wote hongo afuatie na chatu atambae akinguruma nyuma yao [mstari 15] nani atakuwa jasiri kuwasubiri? tini 1  kutembea kwa mikogo ni kutembea kwa kujivuna – ukidhani kuwa wewe ni bora kuliko wote, kujidai. katika mstari 1, shairi linamweleza chatu kama mtoto wa mfalme mwenye mikogo.  2  maswali yaliyopo kwenye mstari wa 6 hadi wa 9 inaonesha kuwa chatu ana nyumba nyingi – sehemu zote mbili; katika ardhi na kwenye maji.  3  katika ubeti wa pili, shairi linaonesha kuwa wanyama na watu wengine wangeogopa sana kutembea karibu na nyoka – ndio maana nyoka ‘hutembea’ pwekepweke.  hadithi ya kumsifu mama mama na hugh lewin ningependa wewe, alisema jafta, ukutane na mama yangu. hakuna yeyote kati ya watu ninaowafahamu ambaye ni kama mama yangu. mama yangu ni kama ardhi – amejaa mambo mazuri, mwenye joto na nguvu, na wa rangi ya kahawia. mama yangu ni kama jua linalochomoza alfajiri, likiangaza sehemu zenye giza na kutuamsha likitubembeleza taratibu. huchochea moto ili uwake na baada ya muda kila mahali panajaa harufu ya chakula, ambayo hulifanya tumbo langu lingurume na kunifanya nitake kuamka. jinsi jua linavyoaanza siku yake na maua yakichanua na kurusha maua hayo angani ninamkumbuka mama yangu. kama lilivyo anga, daima yeye yuko pale. daima unaweza kumwangalia na kumwona. mchana jua linapokuwa kali, hutupatia kivuli na kutuburudisha, kama mti ulioko kwenye mto. au wakati hali ya hewa inapokuwa na joto sana na vurugu, anatupoza kama mvua ifanyavyo inapoondoa vumbi kwa njia ya mawimbi, na kunyeshea nyasi na kuzifanya tena za kijani. halalamiki mara kwa mara, hata katika saa mbaya. lakini kuwa makini! akikukamata unafanya mchezo wa kudang’anya, au kuwachokoza wadogo zako wa kike, anaweza kutoa sauti kama ya radi ya mchana na macho yake yakatoa mwanga kwenye mawingu meusi. mama yangu hakasiriki mara kwa mara, alisema jafta, ila ni vema zaidi anapoimba. anatuimbia anapopika mlo wa jioni. kama umeshawahi kusikia hopoe akiita kwenye mahindi, basi utakuwa umeshasikia mama yangu akiimba. baada ya mlo wa jioni, unafuata muda wa hadithi. kwa kiasi fulani, alisema jafta, takriban ninampenda mama wakati huo kuliko wakati wowote – baada ya kula chakula, na pilikapilika za hapo, pindi jua linapokuchwa na kila kitu ni kitulivu na kimepoa. hapo mama hutukumbatia na kuondoa masikitiko yetu. tunazungumzia ya leo, ya kesho, na hasa ya kesho. kisha blanketi la usiku linapofunika dunia, na mwezi ukiwa juu yake, mama yangu hutufunika kwa uangalifu na kutubusu na kututakia usiku mwema; hutulaza. vyanzo vya asili: 40 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  chatu imechukuliwa kutoka english matters, grade 7 anthology, iliyokusanywa na lloyd, g. & montgomery, k. mama na hugh lewin imechukuliwa kutoka new successful english, reading book, grade 6  nyenzo-rejea 4: kuandaa masomo juu ya hadithi za maisha usuli/welewa wa somo wa mwalimu 1  kusanya nyenzo-rejea utakazozihitaji. kazi hii inaweza kuchukua muda, lakini magazeti na vichekesho unavyokusanya vinaweza kutumika kwa masomo ya lugha nyingi mbalimbali pamoja na zile za usomaji na uandishi wa hadithi za maisha. baadhi ya wanafunzi wanaweza kuleta magazeti kutoka nyumbani, hivyo waambie waziombe familia zao ruhusa ya kuchukua magazeti hayo. waombe wenzako na rafiki zako wakukusanyie magazeti ambayo wameshamaliza kuyasoma. katika baadhi ya nchi, wachapishaji wa magazeti huweza kutoa msaada wa nakala za magazeti kwa shule yako. baadhi ya azaki pia zina machapisho mazuri sana. kwa mfano, makala kuhusu maisha ya julius nyerere yanapatikana kutoka magazeti mbalimbali ya kitanzania na nchini afrika kusini ucheshi kuhusu maisha ya nelson mandela unapatikana katika mfuko wa nelson mandela.  2  kabla ya kuanza masomo haya lazima uwe na vitu vya kutosha vya kusoma kuhusu aina mbalimbali za watu maarufu kwa ajili ya kufanyiwa kazi na kila kikundi cha wanafunzi.  3  nakili katika karatasi kubwa au ubaoni, hadithi ya maisha ya freddy macha (wasifu ufuatao hapa chini) au hadithi nyingine utakayoichagua ambayo imeandikwa kwa kutumia lugha rahisi.  4  tengeneza orodha ya vipengele vinavyofanana vya hadithi hizi za maisha ili kuvijadili pamoja na wanafunzi wako. hivi hujumuisha: (i)  kwa kawaida usimulizi wa hadithi huzingatia mfuatano wa wakati toka miaka ya awali mpaka ya baadaye ya maisha ya mtu;  (ii)  hudokeza mafanikio ya maisha ya mtu;  (iii) hutoa maelezo ya kina ya kitu fulani kinachovutia au cha kushangaza kuhusu maisha ya mtu. sasa uko tayari kuanza somo! waongoze wanafunzi wakati wanapoandika hadithi kuhusu maisha wakati wanafunzi wanafanya kazi katika vikundi vyao, zungukia darasa ili kukagua kama wameelewa kazi hiyo na wanaweza kupata makala za kutumia. ungeweza kuandika ‘orodha-kaguzi’ ubaoni ili kuwaongoza wanafunzi katika uandishi wao. kwa mfano: jina(ma) ya mtu huyo; sehemu aliyozaliwa; maelezo ya familia; ‘historia’ – siku za shule, mafanikio ya awali, mafanikio ya baadaye;  41 of 54  monday 27 june 2016  sehemu ya 4: utumizi wa hadithi na ushairi  vitu vya kuvutia/vya kuhuzunisha/vya kushangaza ambavyo vimetokea katika maisha ya mtu huyo. wahimize wanafunzi wafikirie kuhusu utaratibu watakaoutumia ili kuandika habari za mtu huyo na kutumia maneno yao wenyewe. wasinakili tu kutoka kwenye makala. hadithi ya maisha ya freddy macha (wasifu) freddy macha alizaliwa katika miteremko ya mlima kilimanjaro nchini tanzania. yeye ni mwandishi wa nathari, ushairi, tamthiliya na nyimbo, na pia ni mpiga-ala mbalimbali, mwimbaji na mwigizaji. akiwa na umri wa miaka 13, freddy alianza kuimba na kuigiza jukwaani. katika miaka ya 1970 na 1980, alikuwa anaishi na kufanya kazi kama mwandishi wa habari jijini dar es salaam na alikuwa na vitabu vyake alivyochapisha vikiwemo twenzetu ulaya (mkusanyiko wa hadithi za kiswahili ), wasifu wa mwana muziki maarufu remi ongala na mkusanyiko wa mashairi yanayoitwa papers! papers! papers! freddy alishinda tuzo ya bbc ya ushairi mwaka 1981 na mashairi hayo yalitokea katika mkusanyiko summer fires. mwaka1984, freddy alifanya ziara iliyokuwa ya mafanikio katika nchi za skandinavia ikiwa ni pamoja na tamasha la kimataifa la thieta la oslo pamoja na kikundi chake cka kitanzania cha sayari. baadaye, kwa kipindi cha miaka mine tangu 1988, freddy alikuwa anaongoza kikundi cha bendi cha rege kilichoitwa ‘reggae-afro-funk band os galas’, cha brazili. freddy alikwenda uingereza mwaka 1996 na alifanya miradi mingi ikiwa ni pamoja na warsha, drama na muziki. kwa kutembelea sehemu nyingi, freddy huzungumza na kuigiza kwa kutumia lugha mbalimbali. tangu 1998 mpaka 2001, katika miji ya stoke newington na brixton, freddy amefanya tamasha maarufu katika baa ya lorca lililoitwa usiku wa muziki wa dunia ambapo wanamuziki waliweza kukutana na kujaribu vifaa vipya. hili lilijulikana kama 'the local womad' na gazeti la ‘the hackney gazette’ na ndiyo sababu muhimu kwa freddy kuwa mwakilishi wa umoja wa wanamuziki wa dunia kwa upande wa sehemu ya muziki wa jadi na wa kimapokeo mwaka 1999–2001. hivi sasa, freddy anaweza kuendesha warsha na matamasha mbalimbali mashuleni na katika kumbi za uingereza. alitunga kichekesho cha kitashtiti kinachoitwa ‘news no news’, ambacho wakati mwingine anakiigiza peke yake au na bendi yake ya kitoto. bendi ya kitoto imeundwa na wanamuziki sita kutoka sehemu mbalimbali za afrika, karibiani, nchi za uingereza na amerika kusini. nchini uingereza, freddy ametoa rekodi mbili: albamu inayoitwa constipation (2000) yenye miziki 11 na wimbo mmoja unaoitwa kilimanjaro. constipation ina muziki, nathari na ushairi na inatumia lugha mbalimbali, ambayo imetengenezwa kutokana na utaalamu wa freddy. kwa mfano, kuna aina mbalimbali za nyimbo nzuri za kiswahili na nyimbo za kiingereza ambazo zinatoa mafunzo mazito kuhusiana na jamii. freddy anafanya kazi sana za kutoa albamu mpya kwa ajili ya watoto wa shule. matarajio ni kwamba albamu hiyo itakuwa bora kama constipation.  kurudi kujua kusoma na kuandika ukurasa need to check translation  42 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu swali lengwa muhimu: unawezaje kusaidia ujifunzaji wa lugha kwa kutunga na kusanifu vitabu? maneno muhimu: uandikaji; uchoraji wa vielelezo; usanifu; kitabu; gamba la kitabu (jalada la kitabu)  matokeo ya ujifunzaji mwishoni mwa sehemu hii, utakuwa umeweza: l  kutumia njia ya majadiliano kwasaidia wanafunzi kuelewa uhusiano na tofauti zilizopo kati ya matini simulizi na matini andishi;  l  kukuza njia ambazo wanafunzi wanaweza kuzitumia kubadilisha hadithi simulizi, mashairi, nyimbo au michezo kuwa katika maandiko na vielelezo;  l  kutalii jinsi ya kutoa vitabu vya hadithi, mashairi, michezo na nyimbo kwa ajili ya maktaba ya darasa.  utangulizi kipengele kimojawapo cha kufundisha ni kwa wanafunzi kuona lengo halisi la kazi unazowapa. kwa kuwasaidia wanafunzi kutengeneza vitabu kwa ajili ya maktaba ya darasa, utakuwa umewapa sababu ya kuwa waangalifu katika maandishi na michoro yao. hali hii itawasaidia kuthamini lugha zao za nyumbani na lugha ya mawasiliano darasani au lugha ya ziada. vitabu vinaweza kuandikwa katika lugha yao ya nyumbani, lugha ya mawasiliano darasani au lugha ya ziada. zaidi ya lugha moja inaweza kutumika katika kitabu kile kile. vitabu wanavyoandika wanafunzi, kwa msaada wako, vitakupa matini zaidi kwa ajili ya shughuli za kusoma.  1. wanafunzi wanaozungumza lugha ya nyumbani ambayo ni tofauti na wanayotumia darasani wanahitaji kujua kama unaithamini lugha yao ya nyumbani. hii ni muhimu kwa kuwa lugha ya nyumbani ni sehemu ya mtu alivyo. njia mojawapo ya kueleza hili ni kuwahimiza wanafunzi wako kutoa hadithi na vitendawili, kughani mashairi, kuimba nyimbo na kueleza michezo katika lugha za nyumbani na kisha kuziandika, ama kwa lugha zao za nyumbani au lugha nyinginezo. katika shughuli 1, uwasaidie wanafunzi wako kugundua tofauti kati ya matini simulizi na andishi. utawahimiza kufikiri kuhusu yaliyo na thamani katika utamaduni simulizi, kwa nini watu huandika na lugha zipi hutumika katika mazungumzo na katika maandishi.  uchunguzi kifani ya 1: kusimulia hadithi katika lugha za  43 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  nyumbani; kuziandika katika lugha ya mawasiliano darasani hivi karibuni bwana okitikpi, mwalimu mzungumzaji wa lugha ya kiyoruba, amehamishiwa kaskazini mwa nijeria katika jamii izungumzayo lugha ya kihausa ikiwa lugha kuu, lakini baadhi ya wanafunzi wanazungumza lugha tatu za kinijeria. wazazi wachache na vijana watu wazima wamekubali kuwa walimu ‘wasaidizi’. wanafahamu kihausa na kiingereza kidogo na wanamsaidia bwana okitikpi kujifunza kihausa ili aweze kwasiliana na wanafunzi vyema. kwa kuwa baadhi ya wanafunzi wake wanaweza kuzungumza lugha tatu za kinijeria, bwana okitikpi amewahusisha wasaidizi hawa katika shughuli za utambaji wa hadithi ili kujenga kujiamini kwa wanafunzi katika uzungumzaji na kuwaonesha kuwa lugha zao za nyumbani zinathaminiwa. anataka wanafunzi kuandika hadithi, hususan katika lugha zao za nyumbani. hata hivyo baadhi ya lugha hizo hazina mfumo wa maandishi, kwa hiyo ameamua waandike hadithi zao kwa kutumia lugha ya kihausa. mmoja wa wasaidizi wake amejadiliana na wanafunzi kuhusu sababu za watu kuandika hadithi. kisha, wanaandika hadithi wanayoipenda sana, kwa kutumia lugha ya kihausa, ili waiweke katika kitabu kwa ajili ya maktaba ya darasa. bwana okitikpi aliwaweka wanafunzi wake katika vikundi kwa ajili ya shughuli hii, akihakikisha kuwa angalau mwana-kikundi mmoja ni mzungumzaji mzuri wa lugha ya kihausa na anaweza kuwasaidia wengine. pia alimtaka msaidizi wake amsaidie kuangalia mchakato wa uandishi.  shughuli ya 1: uandishi wa fasihi simulizi na michezo kwanza, soma nyenzo-rejea 1: jinsi hadithi zinavyoandikwa katika vitabu, na fikiria juu ya majibu ya maswali matano kwa ajili ya wanafunzi. watake wanafunzi wakueleze vichwa vya habari vya hadithi, mashairi, nyimbo na michezo katika lugha za nyumbani. viandike ubaoni. jadili maswali haya na wanafunzi: je, matini hizi za lugha ya nyumbani zimeandikwa katika vitabu? kwa nini watu huandika hadithi, mashairi, nyimbo na michezo katika vitabu? ungependa hadithi, mashairi, nyimbo na michezo ya lugha yako ya nyumbani kuandikwa katika vitabu? kwa nini iandikwe au kwa nini isiandikwe? ni katika lugha ipi au zipi ambazo ungeandika mashairi, hadithi na michezo katika kitabu? vitabu vinaandikwaje na vinatolewaje? waambie wanafunzi watakuwa wanaandika vitabu kwa ajili ya maktaba yao ya darasa. watake wanafunzi kila mmoja kuchagua hadithi aipendayo na kuandika mswada wa jaribio la kwanza katika lugha aipendayo. umefurahia majadiliano? wanafunzi wamefanyaje katika shughuli hii?  44 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  2. baadhi ya ujifunzaji, kama kujifunza kucheza ala za muziki, kutumia kompyuta au kuendesha gari, huhitaji mazoezi mengi. kama mwalimu, unahitaji kuwapa wanafunzi nafasi ya kurudia na kufanya mazoezi ya kile walichokwishafanya kabla ili waweze kufanya maendeleo katika juhudi zao za mwanzo. wakati ambapo shughuli 2 katika sehemu hii inafanana na shughuli muhimu katika sehemu 4, marudio haya ni muhimu. wanafunzi watajifunza kuwa uandishi ni mchakato, na kuwa hadithi, mashairi na maelekezo yao ya michezo yaliyoandikwa yatawapa wengine furaha zaidi kama zitaandikwa kwa makini. kuandika, kuchora vielelezo na kusoma vitabu hivi yanaweza kuchukua masomo mengi, lakini kwa kuwa shughuli hizi huwezesha nafasi nyingi za kazi za lugha , muda utatumika vizuri. unaweza kutumia nyenzo-rejea 2: orodha ya kupimia ya wanafunzi ili kuwasaidia kutathmini kazi zao. uchunguzi-kifani unaelekeza jinsi walimu wanavyoweza kuandika vitabu pamoja na wanafunzi ambao hawajapata ujuzi wa kutosha wa uandishi.  uchunguzi kifani ya 2: kuwasaidia wasomaji na waandishi chipukizi jinsi ya kuandika kitabu cha hadithi mwalimu goodluck nkini anawafundisha kwa pamoja wanafunzi 60 wa darasa la 1 na la 2, katika shule mojawapo karibu na mji wa kigoma. mwalimu mwenzake anafundisha wanafunzi 48 wa darasa la 3 na la 4. mara kwa mara walimu hawa wawili huwakaribisha wazazi shuleni kusimulia hadithi kwa lugha ya kiha. mwalimu goodluck nkini aliwataka wanafunzi kumsaidia kugeuza hadithi wanayoipenda, ambayo wamesaidia kuitunga, ili iwe kitabu. kwanza alitengeneza daftari kubwa lisiloandikwa chochote (angalia nyenzo-rejea 3: kubadilisha hadithi za wanafunzi kuwa ‘kitabu kikubwa’ ). aliandika hadithi kwa kutumia vifungu na sentensi fupifupi. halafu aliamua mahali ambapo kila kifungu au sentensi iwekwe wapi katika lile daftari kubwa. alitumia rangi nyeusi pamoja na nta kuandika hadithi kwa herufi kubwa nzuri, akiacha nafasi kwa ajili ya picha. aliwaonesha wanafunzi kitabu darasani, na kusoma nao hadithi. alijadiliana nao aina ya picha zilizotakiwa katika kila ukurasa. aliwapa kila wanafunzi katika jozi vipande vya karatasi, na jozi mbili za wanafunzi walichora picha katika kila karatasi kati ya karatasi 15. aliwataka wanafunzi kutafuta ukurasa unaofaa kwa kila picha, na kuwasaidia kugundisha picha hizo katika kitabu.  shughuli ya 2: ustadi wa kuandika rasimu ya kwanza na kusanifu vitabu watake wanafunzi katika vikundi vya watu wanewane kusoma rasimu ya kwanza ya hadithi zao (kutoka shughuli 1). watake wachague rasimu mbili (kutoka katika zile nne) za kufanyia kazi katika jozi ili kuziboresha. wanatakiwa kutumia orodha ya kupimia ya wanafunzi katika nyenzo-rejea 2 ili kuwaelekeza jinsi ya kufanya kazi zao. hatua nyingine ni kuwataka waioneshe katika kundi la jozi nyingine ya wanafunzi kwa ajili ya kuiboresha. sasa kusanya kazi zao na sahihisha makosa ya tahijia, sarufi na vituo vya uandishi. 45 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  halafu vipe vikundi kitabu chao kisichoandikwa kitu chochote (angalia nyenzo-rejea 3) na watake wafanye yafuatayo: l  wapange ni sentensi zipi ziwe katika kila ukurasa na michoro iwe wapi;  l  waamue jinsi ya kugawa kazi za maandishi na michoro, ili kila mwana-kundi anashiriki.  watake waoneshe mpango wao; jadiliana nao na watake watekeleze mpango wao. kwa wanafunzi wadogo, mnaweza kuandika hadithi pamoja katika kitabu kikubwa na baadaye wanafunzi wanaweza kuchora kwa kila ukurasa.  3. mawasiliano sio kuhusu maneno tu. siku hizi magazeti mengi yana picha nyingi kuliko zamani na vitabu vya siku hizi vina vielelezo vingi zaidi kuliko vitabu vya zamani. watoa matangazo hutumia picha katika mabango, katika majarida na katika televisheni (luninga) ili kuuza bidhaa zao. skrini za kompyuta huchanganya maneno na picha katika hali ya kusisimua. wanafunzi wanahitaji kuandika na kusoma matini ambazo zinachanganya maelezo ya mazungumzo (maneno) na michoro (picha). ukiwa mwalimu majukumu yako ni: kuwa na habari za sasa za mambo yanayowafurahisha wanafunzi; ukijumlisha na shughuli za michoro ya ubunifu (kwa mfano, ubunifu wa michoro ya vifurushi vya kuchukulia bidhaa za madukani, mabango ya matangazo, matangazo ya biashara) katika lugha na masomo ya kusoma na kuandika. sehemu hii inazingatia uchoraji wa gamba la vitabu vya watoto vinavyohusu hadithi, mashairi, nyimbo na michezo.  uchunguzi kifani ya 3: kujadili na kutengeneza magamba ya vitabu mwalimu malaitji anawahimiza wanafunzi wake wa somo la kiingereza wa darasa la 6 kuuliza maswali wakati wa somo lao la kusoma kuhusu maneno na misemo ambayo wanaisikia au kuisoma lakini hawaielewi. siku moja asubuhi, mwanafunzi aliliambia darasa kuwa amesikia mhusika mmoja wa mchezo wa kuigiza katika televisheni akimwambia mwenzie kuwa ‘usihukumu kitabu kwa kuangalia gamba lake.’ mwalimu malaitji aliwauliza wanafunzi wake mawazo kuhusu msemo huo una maana gani na kwa nini ulitumika katika mchezo huo wa kuigiza. baada ya muda mfupi wa majadiliano, wanafunzi walielewa kuwa uchoraji wa gamba la kitabu unaweza au usiweze kutoa wazo zuri kuhusu yaliyomo katika kitabu. kwa mtazamo huo, mtu aonekanavyo au asemavyo inaweza isiwe kielelezo cha jinsi mtu huyo alivyo ‘ndani mwake’. mwalimu malaitji aliamua kuendeleza majadiliano. aliwataka wanafunzi darasani kufikiri kuhusu shabaha za gamba la vitabu, halafu waangalie gamba la kitabu cha hadithi ambacho alileta darasani. wanaweza kueleza kuhusu hadithi inahusu nini kwa kuangalia gamba la kitabu? wamependa nini au ni kitu gani ambacho hawakukipenda kuhusu gamba hilo la kitabu? gamba hilo linaweza kuboreshwa, na kama jibu ni ndiyo, linaweza kuboreshwaje? baada ya mjadala hai na kusoma hadithi kwa wanafunzi, aliwataka wafanye kazi katika vikundi vya wanafunzi wanewane kutengeneza gamba jipya kwa ajili 46 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  ya kitabu hiki na aliwapa makaratasi ya kufanyia kazi. walipomaliza, mwanafunzi mmoja kutoka kila kikundi alitoa maelezo darasani kwa nini wamechora gamba la kitabu katika namna waliyochagua. mwalimu malaitji aliyabandika magamba ya vitabu katika ukuta wa darasa.  shughuli muhimu: kuandika vitabu na kutayarisha gamba la vitabu baada ya kumaliza kuandika na kuchora kwa ajili ya vitabu vya hadithi, wanafunzi sasa wako tayari kutayarisha gamba la kitabu. unaweza kutumia migongo ya mabango, karatasi za maboksi na vifaa vingine ‘vilivyotupwa’, hasa kama vifaa havitoshi shuleni kwenu. tazama nyenzo-rejea muhimu: kuwa mwalimu mwenye msaada katika hali zenye changamoto kwa mawazo zaidi. waoneshe watoto magamba ya vitabu na waulize sifa nzuri za gamba hilo (tazama nyenzo-rejea: sifa za matayarisho ya gamba la vitabu). watake kila kikundi kutayarisha gamba la kitabu chao. wanapaswa kukubali kuhusu maneno watakayotumia, michoro na sehemu watakapoiweka na kuamua waamue nani ataandika au kuchora kila sehemu ya gamba. zungukia vikundi kujadiliana matayarisho yao na wasaidie na kuwaongoza wanapotengeneza gamba lao la kitabu vipe muda vikundi kukamilisha vitabu vyao. mtake mwanafunzi mmoja wa kila kikundi kuonesha kitabu chao na wahimize wanafunzi wengine katika vikundi kukisoma. viweke vitabu katika maktaba ya darasa. unafikiri wanafunzi wako wamejifunza nini katika shughuli hii? je, vitabu hivyo vilisomwa na wanafunzi wengine vilipowekwa katika maktaba ya darasa? kwa watoto wadogo, soma hadithi au mashairi na watake wachore picha kwa ajili ya gamba la kitabu au ndani ya kitabu.  nyenzo-rejea 1: jinsi hadithi zinavyoandikwa kuwa vitabu usuli wa welewa kwa ajili ya mwalimu uandishi wa kitabu kwa ajili ya darasa lako sambamba na shughuli zao za kawaida ili za usomaji na uandishi huwapa wanafunzi welewa wa umuhimu wa kuweza kusoma kupata taarifa na hadithi mpya. mchakato huu unaweza kuwahimiza wanafunzi wako kutaka kusoma zaidi kwa kuandika kitabu kwa ajili ya darasa kwa kutumia michoro/picha zao na maneno yao wenyewe kadiri wanavyokuwa waandishi hodari. hatua ya 1: vitabu huanza na wazo kuu mwandishi huandika hadithi. huenda mwandishi ataandika rasimu kadhaa za hadithi, akijaribu kuiboresha kila mara. mara nyingi waandishi hufanya uchunguzi kwa ajili ya hadithi zao kuhakikisha kuwa wanaandika maneno kwa tahijia sahihi na uhakika wa  47 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  mambo wanayoyaandika. wakati mwingine inamchukua mwandishi majuma kadhaa kabla ya kupata njia sahihi ya kuandika hadithi yake. mwandishi anaporidhika, ataandika maneno yake katika muswada, ambayo ataituma kwa mhariri wake katika jumba la uchapishaji hatua ya 2:wahariri wana majukumu mengi, na wanapaswa kusoma sana. miswada hupokelewa kila siku kutoka sehemu mbalimbali za dunia. wahariri wanapaswa kuichambua na kuamua ni hadithi zipi wanazofikiria kuchapisha. wahariri hufurahia kuwaambia waandishi kuwa wanataka kuchapisha hadithi zao. na bila shaka mwandishi husisimka! mhariri huamua pia nani atachora michoro ya muswada. si kawaida kufikiri kuwa kwa baadhi ya vitabu mhariri na mchoraji hawakubaliani! wakati mwingine mhariri husaidia mawasiliano. hatua ya 3: kuanza kazi kwa msanii. kabla ya mwandishi kuanza kuandika hadithi, hufikiria ukubwa wa kitabu utakuwaje, halafu hupanga karatasi. hutengeneza mfano wa kitabu, kikiwa na vielelezo vya awali, ili kumuonesha mhariri na msanii wa kitabu. katika hatua hii, mhariri anaweza kufanya mabadiliko katika matini ya hadithi. wahariri ni wazuri katika kuwasaidia waandishi kupata namna bora ya kujieleza. hatua ya 4: kuhusika kwa msanifu wa kitabu. msanifu huangalia kitabu cha mfano, na hutoa mapendekezo kwa ya michoro. hutafuta pia aina za maandishi za kutumia katika kitabu. mtindo na ukubwa wa herufi unaweza kuleta tofauti kubwa katika muonekano wa kitabu. msanii anaweza pia kumsaidia mchoraji kuamua jinsi maneno ya hadithi yatakavyofaa katika muono wa kitabu. halafu hadithi inapelekwa kwa mhariri ili ahakiki tahjia, sarufi, na uandishi wa vituo. mwandishi anapewa nafasi nyingine ya kubadilisha sehemu yoyote ya hadithi. wakati huohuo….. hatua ya 5: msanii anashughulika sana kutunga kazi za mwisho hutumia kitabu chake cha mfano kama kiongozi. lazima karatasi zipimwe kwa usahihi ili achore michoro katika sehemu husika. huchora alama katika mchirizi ambapo karatasi zitakaposhonwa na kubanwa, na huweka alama katika mikunjo ambapo karatasi zitakatwa. sio rahisi! anahitaji kutengeneza usanii kwa namna itakavyoonekana katika kitabu kilichochapishwa. inahitajika kuwa kazi nzuri. mistari inahitajika kuwa nyoofu, na panahitajika kuwepo na nafasi kwa ajili ya maneno ya hadithi. wakati kazi hii inapomalizika, anaipeleka kwa mhariri katika shirika la uchapishaji. kule, kazi inakaguliwa ili kuhakikisha kuwa hamna makosa, na mkurugenzi wa uzalishaji anafanya makadirio ya gharama itakayotumika kutengeneza kitabu. anaamua muda wa uchapishaji wa kitabu na kuagiza karatasi. hatua ya 6: kitabu kinapelekwa uzalishaji! msanii anaonesha jinsi maneno na michoro itakavyowekwa. prufu za rangi zinatengenezwa, na kila mmoja anakagua kuhakikisha kuwa rangi zilizochapishwa zinaoana na michoro ya msanii. hii ndicho kitu wanachokiangalia katika picha hii.  48 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  kila mmoja akisharidhika na jinsi michoro inavyoonekana katika kurasa, visahani vya maandishi ya kuchapisha vinatengenezwa. visahani hivyo vitatumika katika usindikaji wa uchapishaji kuchapisha kurasa. hatua ya 7: mwisho! ni wakati wa kuchapisha kitabu baada ya miezi ya matayarisho uchapishaji huchukua siku moja tu. vijisahani vyembamba (vyenye chapa ya kitabu) vinafungwa kuzunguka silinda kubwa ambayo hupelekwa kwenye mathaa. kila silinda inachapisha rangi mojawapo kati ya rangi nne za kitabu - ya kwanza ni ya njano, halafu bluu, halafu nyekundu, halafu nyeusi. rangi nyingine zinatengenezwa kutokana na mchanganyiko wa rangi hizo nne. kikamatiyo maalum na mikanda wa kuchukulia husaidia kusogeza karatasi kupitia katika mtambo wa kusindika.  hatua ya 8: hongera! dakika ambayo kila mmoja alikuwa akiisubiri imefika kitabu kimechapishwa na kimetoka vizuri sana! ulijua kuwa karatasi zote za kitabu zimechapishwa katika karatasi moja kubwa! nusu ya kurasa zimechapishwa katika sehemu moja ya kurasa za kusindika na nusu nyingine imechapishwa katika kurasa iliyopo kinyume chake. baada ya karatasi hizi kuchapishwa, zinakunjwa, kukatwa na kufungamanishwa katika kitabu. hatua ya 9: vitabu vipya vinasambazwa! vitabu vilivyofungamanishwa vinachukuliwa ghalani, ambapo hutunzwa hadi vinapouzwa katika maktaba na maduka ya vitabu.  49 of 54  monday 27 june 2016  sehemu ya 5: kubadilisha hadithi simulizi, mashairi na michezo kuwa vitabu  wakutubi na wauzaji wa vitabu wanajuaje kuwa vitabu vizuri vipya vimechapishwa? watu wengine katika ofisi za uchapishaji huuza na kutangaza vitabu. wakati mwingine mabango na maonesho maalum hufanywa. wachapishaji hupeleka nakala za",t_5af2795eb206,other,0
c_045bf4e5f95c,"male: in the last video we left off in 1922 in october where you have several hundreds of thousands of fascists march on rome, which causes the king to put benito mussolini in power and this picture right over here is from mussolini coming to power from the march on rome and not only does he get appointed as prime minister, but he has dictatorial powers for one year. those dictatorial powers are also backed up with the blackshirts,this loose band, kind of a paramillitary group. so he uses his powers and the fact that he has his own force so to speak to continue to just secure more and more power under him over the next few years. by 1923 he makes the blackshirts actually become a formal national militia, essentially the volunteer militia for national security. in italian the acronym is the mvsn. so, the blackshirts become formalized as the mvsn. he also gets parliament or gets the legislature to pass what's known as the acerbo law or acerbo law. i'm sure i'm mispronouncing it. acerbo law. this is an interesting one because this is a law that allowed whichever majority party, whatever the largest party in the deputy of ministers, whatever the largest party in parliament is that party, as long as they get more than 25% of the vote, they will get 2/3s of the seats in parliament. this is strange because traditionally in a parliamentary system if you got ... let's say you were the largest party and you got 26% of the vote, you still would not have enough seats to govern properly. you would have to form a coalition with several other parties so that you could essentially form a government. but this is saying whoever gets the plurality of votes, whoever gets the most votes without necessarily being a majority, they will be by default become a majority. and you could imagine why the fascists wanted this to happen. they felt that they could get 25% of the votes, one maybe through popular support but also with the help of the coercive tactics of the blackshirts and then that would give them stronger control in the legislature. now, the big question is is why would the legislature pass this? because at this point the fascists were not the dominant party. they did not have a majority in the legislature. in fact, this was why they wanted to pass a law because they didn't have a majority. and once again it's one of those questions of history. some would say that people were enamored with the fascists. they were enamored with mussolini. they were eager to have strong leadership. they didn't want this government of coalitions. they wanted one government to be able to take action. on the other side when the votes were happening you actually had blackshirts in the room. one argument is that there was also an element of pure intimidation. but needless to say the acerbo law actually passed. there is irony here because it was unnecessary. in 1924 when you actually have elections you have the fascists getting 2/3s of the vote. fascists get 2/3 of the vote. now, many today and many in italy at the time felt that this was a fraudulent election. they felt the reason why the fascists were able to get so many votes is because they were able to intimidate folks. they were able to commit fraud during the election. they were able to kind of throw other votes out, and one of the most outspoken individuals when it came to criticizing the fascists and their tactics of coming to power was giacomo matteotti. he wrote a book about the fascists. he gave two really strong speeches in the deputy of ministers where he talks about or the chamber of deputies i should say, where he talks about the corruption and the violence of the fascists. a few days after giving those speeches he gets killed by blackshirts. so, he gets actually quite violently murdered by blackshirts, and this puts mussolini at least initially in a bit of a bind. he doesn't want to look like a thug, someone who goes out and just murders people. it's not clear that he actually, mussolini, was involved in this in any way, but his followers had committed this act. to protest against the murder of giacomo matteotti you actually have the entire socialist party boycotts parliament. this was known as the aventine secession or at least the 20th century aventine secession. aventine secession. it's called the aventine secession because if you go back to roman times 2500 years ago you had the plebeians secede out of protest from harsh rule and they go to the aventine hill. so, it was named after that same idea. the whole reason why the socialists did this is they hoped that by boycotting parliament that that would convince the king to get rid of benito mussolini. mussolini, as i say, he's also in a bind. he doesn't know quite what to do, and on top of all of this the blackshirts are telling him, ""look, if you don't take control of the situation, if you don't become a strong ruler we're going to do it without you. we might even overthrow you mr. mussolini."" in 1925, early 1925, mussolini makes his famous january speech. 1925, his famous january speech. this is normally viewed as the formal start of his absolute dictatorship. in this mussolini, instead of the aventine secession somehow undermining mussolini's power because the king did not dismiss mussolini it actually strengthened mussolini's power. he used that as a pretext. he said, ""look, all of these deputies they've decided not to show up at parliament. they've essentially given up their seats, and he bans, he bans the italian socialist party. he embraces the blackshirts. he takes responsibility for them. he doesn't take responsibility directly for giacomo matteotti's murder, but he takes responsibility for the blackshirts, and he gives in kind of classic mussolini style a somewhat convoluted argument about how strength and violence is going to give stability to the italian people. obviously he is an amazing orator. he's very charismatic. this essentially gives him the control he needs, and by the end of 1925 you have the christmas eve law that's passed by parliament that esentially puts no checks on mussolini's power, and as you go then into 1926 they more, and more, the fascists under mussolini take absolute control, absolute power of italy. so in 1926 they're banning other parties. so, other parties are banned. they're starting to force people to become members of the fascist party if they want roles in the government or even in any type of institution. they're starting to take control of the press. they're starting to have a very strong state police architecture. if this looks familiar based on what we studied about the nazis it's not a coincidence. hitler, he admired mussolini. in fact, mussolini's march on rome inspired hitler to attempt his beer hall putsch in 1923. a lot of these tactics that brought mussolini to power you see kind of a parallel in what brought hitler to power only about seven years later.",t_8818770a6b82,other,0
c_a0eea103d4ea,"jump to navigation  anticipating the dream  michelle (grade 11) develops this eyewitness account by answering the “5 w’s and h” about her parents becoming american citizens. the writer also shares her sensory impressions.  anticipating the dream  “and we are scatterlings of africa  on a journey to the stars  far below we leave forever  dreams of what we were.”  —johnny clegg  i am sitting with my grandparents in the spectators’ section of the echoing auditorium, my baby brother on my lap. i’m not sure what i expected this morning, but thus far it has been an incredibly boring experience. the judge is half an hour late, and to add to that, graeme, my brother, is tired and fussing, and would evidently much prefer his mother’s lap to mine. unfortunately for him, my parents and older brother are sitting on the other side of the room with almost 200 others. thirty-one countries are represented here today.  this is a citizenship ceremony. my parents, my older brother, and i were all born in south africa. after living in the united states for 13 years, they are finally becoming citizens. i am not yet 18; consequently, i have to wait for my parents to obtain citizenship before i am eligible. all my younger siblings were born here, and are therefore americans by birth.  graeme was only momentarily distracted by the book we brought along to amuse him. he is now struggling noisily to climb off my lap. it’s time to bring out the secret weapon: candy. i just hope my supply doesn’t dwindle too quickly.  in our particular situation, it seems rather odd that the citizenship process works this way. having lived here since i was two, i have always been more american than anything else. i don’t speak afrikaans, but my parents do (as well as english). i am the one who briefed my mother on american history and government before she took the citizenship test. not only that, but i am always having to remind my parents that the word is flashlight, not torch, and that here in america we have a tooth fairy, not a mouse, who comes to fetch our teeth. after today, my parents will be americans, and i will be the unique one, the alien, the only south african remaining in our house. how bureaucratic of the american government to work that way.  the judge has arrived, and now that everyone has stopped talking, graeme has started to cry. i make a hasty retreat up the slanted aisle to the back of the room. maybe i can rock him to sleep.  i have often asked my parents why we moved here from our homeland, and from what i’ve gathered, there are several reasons. foremost is apartheid, the total segregation of south africa, whereby whites held all power and blacks were not even allowed to vote. the government established separate buses, bathrooms, even public lawns. my parents, who are by no means radical, were very strongly against apartheid and were arrested for protesting. they were released in the next moment because they were white, while their black friends were hauled off to jail. the atmosphere was growing more volatile every day, and when the building across the street from where my mother worked was bombed, my parents decided that it was no longer safe to stay, especially with two small children. consequently, my father took advantage of the first opportunity to get a job here in america. it must be incredibly difficult to live in a country that is so immoral, where people are looked down upon simply because their skin happens to be a different shade. how can you pledge allegiance to a government responsible for the obvious evil around you every day? america was segregated at one point also, but at least the government called it “separate but equal.” in south africa, the government did not even attempt to bring about equality. can anyone take pride in a government like that?  graeme is finally asleep, drooling on my shoulder, and i can return, victorious, to my seat. the judge has been giving a speech about the privileges and responsibilities that come with being an american citizen. i’m beginning to understand why my parents are so excited about this day. at first i expected nothing of great importance to occur in this ceremony. i imagined we would arrive here, say the pledge of allegiance, and my parents would receive a piece of paper declaring them “american citizens.” as it turns out, a lot more is involved than the mere title. today my parents will not only become eligible to vote and serve on jury duty, but they will automatically become part of american history, culture, and society. the united states becomes their country, a land that kindles pride. all of a sudden, they have a duty to serve this country and to be loyal to it above all others. it is a colossal decision for them to make.  south africa is a beautiful nation. my parents grew up there and have many fond recollections. they remember visiting game preserves and finding lions in the middle of the road. they remember going to school with their friends and tormenting substitute teachers. the different snacks they ate—biltong, chappie gum, and bovril—could never be found in the united states. my parents remember getting married in the city of florida on february 2, 1980. i’m certain it must have been difficult to leave everything, including family, and move to america. now, at this ceremony, everything is becoming finalized. they will no longer be a part of south africa, but south africa will always be a part of them. they have given up the past in anticipation of the future, one filled with hope for greater peace, prosperity, and happiness: the american dream.  i scan the room, the many different faces of my fellow spectators: grandparents, parents, and children of various races. anyone can read the pride in their eyes as they watch their loved ones from across the room. i snap to attention. people are rising. this is the moment; they are about to take the oath. now i have grown just as excited as my parents seemed to be this morning. my mother’s smile tells me she is enjoying herself. right hands raised, the would-be citizens repeat after the judge the words that will change their lives forever. piles of paperwork and months of waiting are now fulfilled in a few simple words. as the final echoes of the judge’s words die out, i hardly hear his congratulations. one fact only is the focus of my thoughts: my parents and another brother are americans. all my older brothers and my sister are americans. soon it will be my turn, and i can hardly wait.  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_92f0ffacc3d2,other,0
c_a9040831530d,"the adjective transient applies to system response that is dynamic for a finite time interval (often called the settling time), but is essentially static thereafter.  consider the 1st order problem presented in chapter 2,  \[\dot{x}-a x=b u e^{-w t}, x(0)=x_{0}, \text { solve for } x(t), t>0\]  with solution,  \[x(t)=x_{0} e^{a t}+\frac{b u}{a+w}\left(e^{a t}-e^{-w t}\right), \text { for } t \geq 0\]  if we let \(w\) = 0, then the input term becomes the step function, \(u\left[e^{-w t}\right]_{w=0}\) = \(u h(t)=u\) for \(t\) < 0, \(h(t)\) being the heaviside unit-step function defined in section 2.4. so the problem and solution become:  \[\dot{x}-a x=b u, x(0)=x_{0}, \text { solve for } x(t), t>0\]  \[x(t)=\frac{b u}{(-a)}\left(1-e^{-(-a) t}\right)+x_{0} e^{-(-a) t}, \text { for } t \geq 0\label{eqn:3.3}\]  in equation \(\ref{eqn:3.3}\), we write \(a=-(-a)\) because usually \(a\) < 0 for engineering systems, as in equation 3.3.3. we want to consider two special cases of solution equation \(\ref{eqn:3.3}\):  pure initial condition response for \(u\) = 0 and  pure step response for \(x_{0}\) = 0.  stable initial condition (ic) response  \[x(t)=x_{0} e^{-(-a) t}, \text { for } t \geq 0\label{eqn:3.4}\]  define the 1st order-system time constant,  \[\tau_{1} \equiv \frac{1}{(-a)}\label{eqn:3.5}\]  for example, the time constant for the reaction wheel from equation 3.3.3 is \(\tau_{1} \equiv \frac{j}{c_{\theta}}\). you should satisfy yourself, using table 3.1.1 if necessary, that the quantity \(j / c_{\theta}\) has the dimension of time (unit of second). with this definition of time constant \(\tau_{1}\), solution equation \(\ref{eqn:3.4}\) becomes:  \[x(t)=x_{0} e^{-t / \tau_{1}} \equiv x_{0} \exp \left(-t / \tau_{1}\right), \text { for } t \geq 0\label{eqn:3.6}\]  figure \(\pageindex{1}\): 1st order initial-condition response  at the time constant, \(t=\tau_{1}\), the response has decayed to \(e^{-1}\) = 37% of the initial value. the other time “milestone” to which we shall often refer is \(t=4 \tau_{1}\), which we call the settling time, at which time the response has decayed to \(e^{−4}\) = 2% of the initial value. for most practical engineering purposes, this settling time is considered to be the time required for the response essentially to reach its final steady-state value, which is \(x\) = 0 in this case of ic response. mathematically, \(x\rightarrow 0\) only as \(t \rightarrow \infty\).  if the constant \(a\) is positive, then we write ic solution equation \(\ref{eqn:3.4}\) as \(x(t)=x_{0} e^{a t}\). the mathematical response represented by this solution is unbounded: \(x \rightarrow \infty\) as \(t \rightarrow \infty\). in reality, no engineering variable will ever become infinite: as the variable becomes large, something in the system will fail or overload, or the system will become nonlinear, or the response will be limited by a governor, etc. even though the actual response will not become infinite, an exponentially increasing linear mathematical response such as this is usually undesirable for practical purposes; an engineering system that exhibits this kind of response is considered to be engineering system with unstable. on the other hand, a negative constant \(a\) is stable.  the time constant \(\tau_1\) is such an important quantity for stable 1st order systems that we shall re-cast the standard 1st order system ode in terms of \(\tau_1\), rather than constant \(a\), using equation \(\ref{eqn:3.5}\). thus, rather than analyzing equation 1.2.1, \(\dot{x}-a x=b u(t)\), hereafter we shall usually consider the following standard stable form for 1st order systems:  \[\dot{x}+\frac{1}{\tau_{1}} x=b u(t)\label{eqn:3.7}\]  stable step response  in equation \(\ref{eqn:3.3}\), we set \(x_0\) = 0 and use time constant definition equation \(\ref{eqn:3.5}\) to obtain  \[x(t)=b u \tau_{1}\left(1-e^{-t / \tau_{1}}\right) \equiv b u \tau_{1}\left[1-\exp \left(-t / \tau_{1}\right)\right], \text { for } t \geq 0\label{eqn:3.8}\]  figure \(\pageindex{2}\) is a graph of the exponential rise to a positive final value that is indicated in equation \(\ref{eqn:3.8}\).  figure \(\pageindex{2}\): 1st order step response  the final value of unit-step response is \(b u \tau_{1}\), and it is approached asymptotically as \(t \rightarrow \infty\). at the time constant, \(t=\tau_{1}\), the response has risen from the ic of zero to \(1-e^{-1}\) = 63%. at \(t=4 \tau_{1}\), the settling time, the response has risen to \(1-e^{-4}\) = 98% of the final value.  step response solutions such as equation \(\ref{eqn:3.8}\) are usually an approximation to the actual response since, in reality, a pure, discontinuous step change in a physical input quantity is rarely achievable. nevertheless, step input is a sufficiently close approximation to many real physical inputs that step response solutions such as equation \(\ref{eqn:3.8}\) are close approximations to actual physical responses.  consider again the reaction wheel of the previous section. let us denote a step input from the motor as \(m_{m}(t)=m \times h(t)\). then ode equation 3.3.3 becomes  \[\dot{p}-a p=b m_{m}(t)=b m h(t)=b m \text { for } t>0, \text { where } a=-\frac{c_{\theta}}{j}=-\frac{1}{\tau_{1}} \text { and } b=\frac{1}{j}\label{eqn:3.9}\]  so the time constant is \(\tau_{1}=-1 / a=j / c_{\theta}\), and solution equation \(\ref{eqn:3.8}\) becomes  \[p(t)=b m \tau_{1}\left(1-e^{-t / \tau_{1}}\right)=\frac{1}{j} m \frac{j}{c_{\theta}}\left(1-e^{-t / \tau_{1}}\right)=\frac{m}{c_{\theta}}\left(1-e^{-t / \tau_{1}}\right) \mathrm{rad} / \mathrm{sec}, \text { for } t \geq 0\label{eqn:3.10}\]  note that in this case we adapt the “standard” mathematical solution equation \(\ref{eqn:3.8}\) to a particular physical problem. this approach is common in system dynamics. in other words, it is not always necessary to solve an ode for every new physical problem; if a standard ode solution has already been derived, you may just adapt that standard solution to the physical problem at hand, rather than re-deriving the ode solution.",t_7ed2c6e7d328,other,0
c_1bbbd82c5a2e,"i’m sure you know that yoghurt  comes from milk but did you know that bacteria are also a key ingredient?  yes – bacteria!  but don’t worry, these are good bacteria and are often called probiotics.   your gut has thousands of types of bacteria happily living inside, whose job it is to aid digestion. yoghurt is thought to be a good vehicle to bring more of these good bacteria in.  so in this video, we’re going to learn a bit more about how yoghurt is made.  first off we need milk   before we start the next steps, all of our equipment needs to be sterilised to kill off any unwanted bacteria and other microorganisms.  now we’re ready to start.  the milk is heated to somewhere between 85 and 95 degrees celsius for between 15 and 30 minutes. this is a process called pasturisation, and is also done to kill off any bacteria and other microorganisms that are naturally found in the milk.   the milk is then homogenised. this breaks down the fat droplets in milk to make them smaller so that they stay suspended in the yoghurt, rather than sinking and making it all lumpy.  so we’ve sterilised our equipment, then pasturised and homogenised the milk.  now the mixture is cooled to 40 to 45 degree celsius. now the mixture is cooled to 40 to 45 degrees celsius and we add our special yoghurt-making bacteria. the mixture needs to be cooled first so that the bacteria aren’t killed by the high temperature.   you might be wondering why on earth are we adding bacteria when we’ve gone to all the effort so far of killing all the bacteria??!!   we’re adding lactic acid bacteria, which are also used in cheese manufacturing. the two species used to make yoghurt are lactobacilli and streptococci. but don’t worry, you don’t need to learn these names, just remember that lactic acid bacteria are added.   these lactic acid bacteria are known as the starter culture.  the bacteria ferment the milk and change it into yoghurt. lactose is the main sugar in milk, and during fermentation the bacteria turn the lactose into lactic acid.   the bacteria also start to digest the milk proteins. fermentation takes many hours and during this time, the mixture is kept at the optimum temperature of 40 to 45 degrees celsius so that the bacteria can work fastest.   as fermentation produces lactic acid, a type of acid, the ph of the milk drops to about ph 4.4. this is why natural yoghurt has a sharp, tangy taste.  as the ph levels drop, the milk solidifies to become raw yoghurt. once the ph drops too low, the lactic-acid bacteria that make the yoghurt also stop working so the yoghurt doesn’t become too solid.   the ph drop also stops any bad bacteria growing.   the solidification happens because the proteins begin to coagulate   coagulation is when something which is liquid turns into a more solid state. so we’ve sterilised our equipment, then pasturised and homogenised the milk. added lactic acid bacteria so fermentation happens, and then coagulation.  the mixture is now stirred and cooled to 5 degrees celsius. and we’ve made natural, unflavoured yoghurt!   at this stage, we can add flavourings and fruit. now it’s ready to be packaged and sold. delicious!  can you match the words to the definitions of the different stages of the yoghurt making process? pause the video and give it a go.  now what about completing the missing words? again, pause the video and work them out. so there we have the process of yoghurt making, from milk to a tasty strawberry flavoured yoghurt    ",t_c5f481e4a715,other,0
c_52b6784d5b39,"65-69, pgs. 160-161  we're on problem 65. they wrote 2, 4, 6, 8, n, 3, 5, 7, and 9. and they tell us, in the list above, if n is an integer between 1 and 10, inclusive-- so that means n could be 1, and it could be 10, or any number inbetween, and it's an integer-- then the median must be-- the median, right, not the mean, the median. so the median means the middle number, right? let's put all the other numbers in order. so we have 2, 3, 4, 5, 6, 7, 8, 9. and they're essentially saying that n could be anywhere in this. it could be a 1 here, it could be right here, it could be another 2, it doesn't tell us. it could be any number, it could be 2, could be another 3, could be 10. we don't know. but before we stick n in here, let's figure out what the middle is. right here we have eight numbers, so the middle of the range is actually-- there is no middle number-- but when we add n, there will be a middle number. so let's just think about it for a little bit. if n is 5 or less, so n goes into this bucket, n goes someplace here, then what happens? then what becomes the middle number? if n is 5 or less, then we'll have n here. and n might be 5, n might go right here. but what becomes the middle number? then we have 1, 2, 3, 4 on this side of the middle number, and we have 1, 2, 3, 4 on that side of the number. so then, the median, which is the middle number, becomes 5. that's if n is 5 or less. if n is less than or equal to 5, then we know that the median will be equal to 5. now let's do the opposite thought experiment. what if n is 6 or more? what if n is greater than or equal to 6? so it goes someplace over here, so n will go someplace here. could be 6, i might have to put it right there. but wherever i put it on the side, i'll have 4 to the right of 6, and i'll have 4 to the left of 6. n isn't on this side anymore, 4 to the left of 6. so then the median would be 6. and either of these cases have to be true for n. so the median is either 5 or 6, and that is choice b. problem 66. i like this brownish color. reminds me of when i was in middle school math competitions. 4u7, n23, 162. and you add them all together, you get one 1,222. and what they want to know is, if n and u represent single digits in the correctly worked computation above, what is the value of n plus u? so the best thing to do is to try to work these out, and see what happens. so 7 plus 3 is 10, plus 2 is 12. so you would write a 2 here, which they already wrote, and carry a 1. and now we have 1 plus u-- let me write this down-- 1 plus u plus 2 plus 6 is equal to, well, it's either going to be equal to 2, or some digit and a 2. so let's just think about it a little bit. 1 plus u plus 2 plus 6, that's equal to u plus 9. u plus 9 is going to have to equal something. so if u is 9, and it has to be something that ends with a 2. and remember, u can only be between 0 and 9. it's a digit, it has to be an integer, it has to be a digit. so let's think about it a little bit. it has to be something that ends in a 2. so the only next thing above 9 that ends as a 2 is 12. because you can't get to 22. to get to 22, you would have to add 13, and you can't be 13. so this has to be a 12, so u has to be equal to 3. that's the only possibility that'll give you something that ends in a 2. so if we assume that u is 3, then we have 1 plus 3 plus 2 plus 6, which is 12, carry the 1, you get 1 plus 4 plus n plus 1 is equal to 12. so you get 1 plus 4 plus 1. that's 6, plus n is equal to 12, and n would be equal to 6. and they want to know what n plus u is. so n plus u, 6 plus 3. that's equal to 9. and that is choice b, 9. 67. look at that, this is a dense looking one, but let me write down the little equation they wrote on top. r is equal to 400 times d plus s minus p, all of that over p. if stock is sold three months after it is purchased, the formula above relates p, d, s, and r, where p is the purchase price of the stock. that's the purchase price. d is the amount of any dividend received. fair enough. s is the selling price of the stock, and r is the yield of the investment as a percent. fair enough. if rose purchased $400 worth of stock-- so p is equal to $400-- received a $5 dividend-- so d is equal to $5-- and sold the stock for $420, for three months after purchasing-- so this formula applies, because this is the formula for selling after three months-- what was the yield of her investment, according to the formula? assuming she paid no commissions. we just substitute in. so let's see. the yield would be equal to 400 times 5 plus 420 minus 400, p is 400, all of that over 420. that is equal to 420 minus 400 is 20, plus 5 is 25. 400 times 25 over-- this shouldn't be 420, this is p. the price you paid was 400. 25 over 400. i just substituted these values into this equation. this cancels out, and i'm just left with a yield of 25, and it's probably in terms of percent. yep, 25%. e. all right, problem 68. let's switch colors. 68. the temperatures in degree celsius recorded at 6:00 in the morning in various parts of a certain country were 10 degrees, i'm not going to write all of it, 5, minus 2, minus 1, minus 5, and 15. what is the median of these temperatures? the median just means the middle. don't confuse that with the average, which is the mean. or the mean, which is the average. median means middle, so let's just put them in order and figure out the middle. so the smallest of these numbers is minus 5, cross it out. then we have minus 2, cross it out. then we have minus 1, cross it out. then we have 5, cross it out, then we have 10, cross it out. then we have 15. so this is interesting about median. if there is no true middle number, you have three on this side of negative 1, or negative 1 and less, and you have three on that side, so there's no middle number, because we have an even number of numbers. so what you want to do is, you take the two middle numbers, which are negative 1 and 5, and you average them. so it's negative 1 plus 5 over 2, which equals 4 over 2, which is equal to 2. 2 degrees celsius, which is choice c. problem 69. if y times three 3x minus 5 over 2 is equal to y, and y does not equal 0, then x is equal to what? well the simplest thing, since y doesn't equal 0, we can divide both sides of this equation by y. you divide both sides by y. y divided by y is 1, y divided by y is 1. so then we're left with 3x minus 5 over 2 is equal to 1. multiply both sides by 2, you get 3x minus 5 is equal to 2. add 5 to both sides, 3x is equal to 7. and you get x is equal to 7 over 3, which is choice c. and i'm out of time, so i'll see you in the next video.",t_1accb7e17f50,other,0
c_0cc0aaf3000b,"learn the basics about testing for hydrogen, oxygen, carbon dioxide and chlorine. why do we need to test these particular gases? find out more in this video!  this open educational resource is free of charge, under a creative commons license: attribution-noncommercial cc by-nc ( view license deed: http://creativecommons.org/licenses/by-nc/4.0/ ).  you are allowed to download the video for nonprofit, educational use. if you would like to modify the video, please contact us: info@fuseschool.org  ",t_5d881f93678a,other,0
c_c428d8818c56,"kelly talks about her responsibilities and salary as a freelance audio engineer in denver.  my name is kelly kramarik. i'm 25 years old, and i'm a freelance audio engineer, and i'm set to make about $40,000 this year. some people just stay in one trade, one part of audio. i like to do a little bit of everything, so i work in a studio as a recording and mixing engineer. i work in live sound as a monitor and front house engineer. in film, i'm a production sound mixer, so my main goal is to get the dialogue on set. then in post-production, that's when we focus on sound effects, creating them, taking them from a library, foley, recording that, footsteps, basically re-creating the world that we already recorded in a studio setting so we have more control over it, and i also am a graduate student, and i'm in the recording arts program. so i'll be graduating soon. it was only a two-year program, but just fine tuning all of my skills for the real world. one of my favorite projects so far has been i was working monitors at a festival, and so one of the bands that i worked for, i just absolutely love them. they were awesome, their music, everything about them, and so i gave them my card and said, ""you know, if you ever want to record, ""i work at a studio, and it'd be cool if you came on down,"" and they contacted me, and so i brought them into the studio, and it was their first time in a studio, and they were so excited. so the extra cool part is that we're making an ep, a three-song ep, and once it's mixed, fully recorded, they're gonna bring that out on their live tour this summer, and then i'll probably mix them again this summer. so it's really cool to work in live and in the studio just because i get the opportunity to find artists that maybe didn't think that the studio was a possibility. when people have an idea to make music, even from the smallest part, like the beginning, they just have a guitar with a couple of chords and some lyrics, helping them make it into a song, record it, mix it, produce it, that whole process is just super rewarding because then they have something for the rest of their lives, and it helps music in general. you know, it's meant to invoke feelings in people, and that's awesome. that's why i love music is because i get goosebumps. you know, when you listen to a seven-minute rock ballad, it's like, ""oh my god, this is epic,"" and that i want to help make other people feel that on the other side of things. having a good ear is obviously very important in audio engineering. you just have to know good rhythm. you have to know the different frequencies, the different frequency ranges that instruments live in, and that's just kind of the basis of audio engineering. if you're in a live sound setting, you know, frequencies that pop out feedback, feedback is when the speaker picks up the signal from the microphone. it creates a loop, and that's when you hear that like screeching, high-frequency noise. that's my biggest enemy as a monitor engineer. if one of those pitches starts ringing out, i have to be able to know exactly what frequency that is and then pull it out immediately because once it happens and it starts going it's just gonna get worse and louder, and it'll just ruin the performance. so i have to be able to exactly know what frequency that is to pull it out fast, and that's why it's super important to know all of your frequencies exactly what they sound like, and that can be taught, i think. if you just sit with headphones on, it's really annoying, but if you just sit there and listen to different pitches, that's how you learn how. i mean, that's how i did it. other skills that are super important is just having a great personality, being easy to talk to. when i'm a monitor engineer in a festival setting, i have 15-minute changeovers from one band to the next and no sound check basically. you just have a line check to make sure that the signal's coming through, and in that 15 minutes, we have to get the other band off, the new band on, and then maybe while they're walking on stage they say, ""i want kick, snare, and bass in my mix,"" and i say, ""okay,"" and then i just kind of pull it up a little bit, and then for the first song, they're looking at me and saying, like... it's all about hand signals, which is funny 'cause everyone's different, but you know, the guitar player will point to the bass and be like, ""up,"" and i'm like, ""okay,"" and then i have to like look at them. i'm always like the weirdest person when i'm a monitor engineer 'cause i'm always like... like constantly just like seeing who i can help and how because when you're dialing it in, i mean, you want to make their performance go off without a hitch. if they can't hear everything, that's just not gonna happen. sometimes you have to make a mistake to learn something for real, and it's usually big mistakes that you learn something, and you're like, ""i will never do that again,"" you know. so making a mistake in live sound is something that i haven't done yet, and i know it's gonna happen, so that's like really scary for me. i just don't... maybe it won't ever happen. i'll knock on wood, but that's really scary because in these high-stakes settings, you know, when you make a mistake it's big, but that's also another part of coming back from that mistake, how fast you can fix your mistake, and if the artist even knows that you made a mistake is another part of it. in denver, colorado, being a freelance engineer, there's a ton of live work all over the place. in the studio world, everybody is mostly freelance unless you own a studio, and that means that you have to bring your own clients in. my boss is awesome, and i get studio leads from him, but for the most part, you're expected to bring your own work in if you want to make money. you can make anywhere from 30,000 or less, depending on how often you do this, up to $200,000 or, you know, millions every year. it just depends on who you record, who you work for. if i were to get picked up by a national touring act and then go on tour with them for a year, i would be in that higher bracket. if i landed someone in the studio and i recorded their first album and then it went platinum, you know, i would make money off of that, not necessarily, because once my job is done in the studio with that album, i don't continue to make money off of it, but i would hope that that artist would bring me back for the next one, and then you know, you get your name out there, and you keep going from there. the way that i have gotten where i am is just going to meet people all the time. i know everybody that is an engineer in denver. i've been to every studio in denver. i'm a very friendly and outgoing. if i ever meet someone, i ask them how their studio works, who they hire, how all of that goes, and if they have any opportunities. i'm always looking for new opportunities, and if someone ever brings one my way, i say, ""yes."" even if it's unpaid, i end up saying, ""yes."" it could lead to just a new connection with someone, and that's huge in this industry because i don't really want to have to advertise myself. i think it would be cool to just keep getting gigs by word of mouth.",t_d3828e58d326,other,0
c_af527d04bf5e,"a close reading of the beginnings of the declaration of independence to identify ideas of natural rights, social contract, limited government and popular sovereignty in the text.      [read the full text of the declaration of independence](https://www.khanacademy.org/humanities/ap-us-government-and- politics/resources-and-exam-preparation/required-documents-and-cases/a/the- declaration-of-independ- [instructor] the goal of this video is to appreciate how ideas of natural rights and social contract and limited government and popular sovereignty are embedded in america's founding documents. before we start looking at the documents themselves, let's just make sure we understand the context in which they were written. as we enter into the mid 1770s, you have the beginning of the american revolutionary war, which begins in 1775. a little more than a year after the beginning of the war, you have the second continental congress decide to formally declare independence on july 2nd and the declaration of independence, which we will study a bit in this video is formally approved on july 4th, 1776, which is when we now celebrate independence day, even though some could argue that it was july 2nd. now, as soon as the colonies decide that they are independent from the kingdom of great britain, they have to think about how do we govern ourselves? within roughly a week, a little more than a week after the declaration of independence is approved, they start drafting the articles of confederation. remember the revolutionary war is still going on. eventually what will be known as the articles of confederation go into effect in 1781. now, this articles of confederation really treat the various colonies as you could almost view it as separate states that agree to work together for purposes of getting independence from great britain, for purposes of fighting the war, for purposes of diplomacy. now, over the course of the next several years, it becomes clear, especially through things like shays' rebellion, which we will look at in other videos that the articles of confederation don't provide a strong enough central government. in may 1787, you have what is called as a constitutional convention convening. it's presided over by george washington, who led the americans in the revolutionary war, which they eventually will win as you see and obviously we're independent country now. the original intent of the constitutional convention was to revise the articles of confederation, but folks like madison and hamilton were really intent on just completely replacing it. what they replace it with was what is now the us constitution, which goes into effect in march of 1789 and shortly thereafter, you have the beginning of washington's two terms. to be clear, the idea of even having a powerful executive, the idea of even having a president was not present in the articles of confederation that comes with the constitution. with that context out of the way, let's look at, especially the declaration of independence and the us constitution. here's the beginning of the declaration of independence, written by jefferson and edited by benjamin franklin and john adams. i encourage you to pause this video and first try to read it on your own and see if you can identify these ideas of natural rights, limited government, popular sovereignty, republicanism and social contract. let's read this together now. when in the course of human events, it becomes necessary for one people to dissolve the political bonds, which have connected them with another ... remember, this is a declaration of independence. they are dissolving the political bonds with the kingdom of great britain and to assume among the powers of the earth, the separate and equal station to which the laws of nature and of nature's god entitle them, so that's starting to refer a little bit to natural rights, a decent respect to the opinions of mankind requires that they should declare the causes which impel them to the separation. they're saying, ""hey, we're writing this document because ""we're trying to show the rest of mankind why the reasons ""for which we are deciding to declare ""our independence from great britain."" we hold these truths to be self-evident that all men are created equal, let me underline this, that all men are created equal, that they are endowed by their creator with certain unalienable rights, that among these are life, liberty and the pursuit of happiness. this is a direct reference to natural rights. in fact, the phrase life, liberty and the pursuit of happiness, most historians believe is in direct reference to john locke's phrase life, liberty and property when he talks about natural rights. this is direct reference to the enlightenment ideas or even the pre-enlightenment ideas of natural rights. that to secure these rights, governments are instituted among men, deriving their just powers from the consent of the governed. this is worth underlining as well because they're talking about governments being instituted among men to secure these rights. this is all about social contract, so that's social contract that we form a government in order to secure rights. we might give it some rights, but in exchange the government has to protect our rights. they derive their powers from the consent of the governed. let me underline that actually in a different color, derive their powers from the consent of the governed. that is popular sovereignty, popular. i'll just write as pop sov, popular sovereignty right over here. that the people are the sovereigns. that whenever any form of government becomes destructive to these ends, it is the right of the people to alter or to abolish it and to institute a new government, laying its foundation on such principles and organizing its powers in such form as to them shall seem most likely to effect their safety and happiness. this is more about social contract. they're like, ""look, if a government breaks its social ""contract, we have a right to replace it."" the document also makes reference to organizing its powers in such form, so that's really talking about limited government. they're talking about, ""hey, this government just won't ""have the absolute right to do anything,"" so that right over there is limited government. prudence, indeed, will dictate that governments long established should not be changed for light and transient causes. they're essentially saying, ""look, you shouldn't just ""overthrow your government on a whim,"" and accordingly all experience hath shown that mankind are more disposed to suffer while evils are sufferable, than to right themselves by abolishing the forms to which they are accustomed. they're saying, ""look, if you're prudent, you wouldn't just ""overthrow your government on a whim,"" but they're kind of saying, ""we're not so worried about that because history ""has shown us, experience has shown us that if anything, ""people are more likely to keep suffering even when they ""should be overthrowing their government."" but when a long train of abuses and usurpations, pursuing invariably the same object evinces a design to reduce them under absolute despotism, it is their right, it is their duty to throw off such government and to provide new guards for their future security. they're saying, ""hey, look, the kingdom of great britain, ""they are abusing us, they are usurping power."" usurping is taking something from you that is yours and so we need to throw off such a government for our own future security. here it says, ""provide new guards for their future security,"" so this provide new guards, once again making reference to limited government. now, let's fast forward roughly 13 years to the us constitution, which continues of course to be in effect. this over here is a picture of the constitutional convention, which we mentioned happened in 1787. the original intent of the constitutional convention was to revise the articles of confederation, but folks like alexander hamilton and james madison really wanted to replace the articles of confederation. you can see it's being presided over by george washington. it starts, the preamble says, ""we the people of the united states, in order to form a more ""perfect union, establish justice, ""insure domestic tranquility, provide for the ""common defense, promote the general welfare and secure the ""blessings of liberty to ourselves and our posterity, do ""ordain and establish this constitution for ""the united states of america."" once again, pause this video and think about whether you see ideas of popular sovereignty, limited government, social contract, natural rights going on even in this preamble or even from the fact that they took the trouble to create this constitution. well, let's start at the beginning. it starts with, ""we the people,"" we the people are the ones that are creating this constitution and not only does it start with we the people, but we the people is intentionally written in this very, very large writing right over here. this is a picture of the constitution. it's really of all about we the people, the people are sovereign, so this idea of popular sovereignty comes out loud and clear in not just the declaration of independence, but also the us constitution. the fact that we the people are setting up this government, this is all about social contract. they are forming a government. they're forming a social contract with a government that is going to protect, that is going to establish justice, provide for the common defense, promote the general welfare. let me make this clear. that is this, this is all social contract. this is what we expect, this government that we're creating to do, promote the general welfare and secure the blessings of liberty to ourselves and our posterity. now, what about things like limited government? well, just the very fact that we have a constitution is a sign of limited government that it isn't just a pure democracy that whoever is governing is going to be constrained. the rights of the government are going to be described by this constitution. we also talk about the blessings of liberty, so this is another reference to natural rights. the declaration of independence is a little bit more clear about natural rights or a little bit more explicit, but the blessings of liberty does talk about or that's maybe in reference to natural rights. i will leave you there. as we study us government, both the declaration of independence and even more so, the us constitution are going to be things that we keep going back to to understand how we are trying to form a more perfect union and what is in line with the vision of our founding fathers and what isn't.",t_b7508a64f69a,other,0
c_ce3c5fe3a53b,"section ""you may also like"" of the book on react js.you may also like",t_5a4483298428,other,0
c_1899b29239eb,"jhs 3 mathematics  lesson 9  ms. rhoda  topic: sub-topics:  rigid motion rotation  objectives: by the end of this lesson, you should be able to;  identify a rotation of an object (shape) about a centre and through a given angle of rotation.  introduction rotation belongs to the class of transformation called rigid motion. just as translation and reflection, the object and image in rotation are congruent. we will study more about rotation in this lesson.  rotation let’s begin this session by finding out what is meant by rotation. a rotation is a circular movement of an object around a center of rotation. the rotation may be clockwise or anticlockwise. the object below show some form of rotation.  what then is a rotational symmetry? an object or a figure has rotational symmetry if it can be rotated about a fixed axis(or point) called axis of symmetry to a new position and it still looks the same as before. the ceiling fan with 3 blades can be rotated three times about the axis of symmetry before it will get back to the blade it started with whiles the merry-go-round can be rotated six times. we say the fan has rotational symmetry of order 3 and the merry-go-round has rotational symmetry of order 6.  let’s now try some questions concerning rotational symmetry. worked examples state the order of rotational symmetry of the following shapes: 1.  2.  1) 4 order of rotational symmetry. 2) 3 order of rotational symmetry. 3.  4.  3) 2 order of rotational symmetry 4) 2 order of rotational symmetry  finding the coordinates of the image of a point under a rotation. to rotate a point, we need to know the direction and angle of rotation. • •  the direction is either clockwise (negative rotation) or anticlockwise (positive rotation). the angles to be considered here will be 900, 1800, and 2700.  let’s now consider the procedure involves in rotating an object. to rotate an object on a graph sheet; plot the given point on the graph • • •  draw a line to join the plotted point to the centre of rotation. use the protractor to measure the given angle in the given direction. use the pair of compass to locate the image point such that from the origin to the image is same as the origin to the object as shown below:  let’s now have a look at some sample question on rotation.  worked example 1 a. using a scale of 2cm to 2 units on each axis, draw on a graph sheet two perpendicular axes ox and oy. b. on this graph, mark the x-axis from -12 to 8 and y-axis from -18 to 6. c. plot the point (0,0), q(4,-2), r(4,4) and join them to form a triangle  draw the image ∆p1q1r1 of ∆pqr under anticlockwise rotation of 900 about the origin where p q q1 and r r1 e) draw the image ∆abc of ∆pqr under a rotation through 1800 about the origin, where p a, q b and r c.  solution  p1  summary • • • • •  rotation is one of the components of rigid motion. a rotation is a circular movement of an object around a center of rotation. a rotation may be clockwise or anticlockwise. a rotation is made through given angle. an object or a figure has rotational symmetry if it can be rotated about a fixed axis (or points) called axis of symmetry to a new position and it still looks the same as before.  end of lesson 9  please send comments or queries to instantschools.gh@vodafone.com",t_c30920f97aa5,other,0
c_9e376fa953a9,"chapter 15 | poverty and economic inequality  15 | poverty and economic inequality  figure 15.1 occupying wall street on september 17, 2011, occupy wall street began in new york city’s wall street financial district. (credit: modification of work by david shankbone/flickr creative commons)  occupy wall street in september 2011, a group of protesters gathered in zuccotti park in new york city to decry what they perceived as increasing social and economic inequality in the united states. calling their protest “occupy wall street,” they argued that the concentration of wealth among the richest 1% in the united states was both economically unsustainable and inequitable, and needed to be changed. the protest then spread to other major cities, and the occupy movement was born. why were people so upset? how much wealth is concentrated among the top 1% in our society? how did they acquire so much wealth? these are very real, very important questions in the united states now, and this chapter on poverty and economic inequality will help us address the causes behind this sentiment.  introduction to poverty and economic inequality in this chapter, you will learn about: • drawing the poverty line • the poverty trap • the safety net • income inequality: measurement and causes  351  352  chapter 15 | poverty and economic inequality  • government policies to reduce income inequality the labor markets that determine the pay that workers receive do not take into account how much income a family needs for food, shelter, clothing, and health care. market forces do not worry about what happens to families when a major local employer goes out of business. market forces do not take time to contemplate whether those who are earning higher incomes should pay an even higher share of taxes. however, labor markets do create considerable income inequalities. in 2014, the median american family income was $57,939 (the median is the level where half of all families had more than that level and half had less). according to the u.s. census bureau, the federal government classified almost nine million u.s. families as below the poverty line in that year. think about a family of three—perhaps a single mother with two children—attempting to pay for the basics of life on perhaps $17,916 per year. after paying for rent, healthcare, clothing, and transportation, such a family might have $6,000 to spend on food. spread over 365 days, the food budget for the entire family would be about $17 per day. to put this in perspective, most cities have restaurants where $17 will buy you an appetizer for one. this chapter explores how the u.s. government defines poverty, the balance between assisting the poor without discouraging work, and how federal antipoverty programs work. it also discusses income inequality—how economists measure inequality, why inequality has changed in recent decades, the range of possible government policies to reduce inequality, and the danger of a tradeoff that too great a reduction in inequality may reduce incentives for producing output.  15.1 | drawing the poverty line by the end of this section, you will be able to: • explain economic inequality and how the poverty line is determined • analyze the u.s. poverty rate over time, noting its prevalence among different groups of citizens comparisons of high and low incomes raise two different issues: economic inequality and poverty. poverty is measured by the number of people who fall below a certain level of income—called the poverty line—that defines the income one needs for a basic standard of living. income inequality compares the share of the total income (or wealth) in society that different groups receive. for example, compare the share of income that the top 10% receive to the share of income that the bottom 10% receive. in the united states, the official definition of the poverty line traces back to a single person: mollie orshansky. in 1963, orshansky, who was working for the social security administration, published an article called “children of the poor” in a highly useful and dry-as-dust publication called the social security bulletin. orshansky’s idea was to define a poverty line based on the cost of a healthy diet. her previous job had been at the u.s. department of agriculture, where she had worked in an agency called the bureau of home economics and human nutrition. one task of this bureau had been to calculate how much it would cost to feed a nutritionally adequate diet to a family. orshansky found that the average family spent one-third of its income on food. she then proposed that the poverty line be the amount one requires to buy a nutritionally adequate diet, given the size of the family, multiplied by three. the current u.s. poverty line is essentially the same as the orshansky poverty line, although the government adjusts the dollar amounts to represent the same buying power over time. the u.s. poverty line in 2015 ranged from $11,790 for a single individual to $25,240 for a household of four people. figure 15.2 shows the u.s. poverty rate over time; that is, the percentage of the population below the poverty line in any given year. the poverty rate declined through the 1960s, rose in the early 1980s and early 1990s, but seems to have been slightly lower since the mid-1990s. however, in no year in the last four decades has the poverty rate been less than 11% of the u.s. population—that is, at best about one american in nine is below the poverty line. in recent years, the poverty rate appears to have peaked at 15.9% in 2011 before dropping to 14.5% in 2013. table 15.1 compares poverty rates for different groups in 2011. as you will see when we delve further into these numbers, poverty rates are relatively low for whites, for the elderly, for the well-educated, and for male-headed households. poverty rates for females, hispanics, and african americans are much higher than for whites. while hispanics and  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  353  african americans have a higher percentage of individuals living in poverty than others, most people in the united states living below the poverty line are white.  visit this website (http://openstaxcollege.org/l/povertyprogram) for more information on u.s. poverty.  figure 15.2 the u.s. poverty rate since 1960 the poverty rate fell dramatically during the 1960s, rose in the early 1980s and early 1990s, and, after declining in the 1990s through mid-2000s, rose to 15.9% in 2011, which is close to the 1960 levels. in 2013, the poverty dropped slightly to 14.5%. (source: u.s. census bureau)  group  poverty rate  females  15.8%  males  13.1%  white  9.6%  black  27.1%  hispanic  23.5%  table 15.1 poverty rates by group, 2013  354  chapter 15 | poverty and economic inequality  group  poverty rate  under age 18  19.9%  ages 18–24  20.6%  ages 25–34  15.9%  ages 35–44  12.2%  ages 45–54  10.9%  ages 55–59  10.7%  ages 60–64  10.8%  ages 65 and older  9.5%  table 15.1 poverty rates by group, 2013  the concept of a poverty line raises many tricky questions. in a vast country like the united states, should there be a national poverty line? after all, according to the federal register, the median household income for a family of four was $102,552 in new jersey and $57,132 in mississippi in 2013, and prices of some basic goods like housing are quite different between states. the poverty line is based on cash income, which means it does not account for government programs that provide assistance to the poor in a non-cash form, like medicaid (health care for lowincome individuals and families) and food aid. also, low-income families can qualify for federal housing assistance. (we will discuss these and other government aid programs in detail later in this chapter.) should the government adjust the poverty line to account for the value of such programs? many economists and policymakers wonder whether we should rethink the concept of what poverty means in the twenty-first century. the following clear it up feature explains the poverty lines set by the world bank for low-income countries around the world.  how do economists measure poverty in low-income countries? the world bank sets two poverty lines for low-income countries around the world. one poverty line is set at an income of $1.25/day per person. the other is at $2/day. by comparison, the u.s. 2015 poverty line of $20,090 annually for a family of three works out to $18.35 per person per day. clearly, many people around the world are far poorer than americans, as table 15.2 shows. china and india both have more than a billion people; nigeria is the most populous country in africa; and egypt is the most populous country in the middle east. in all four of those countries, in the mid-2000s, a substantial share of the population subsisted on less than $2/day. about half the world lives on less than $2.50 a day, and 80 percent of the world lives on less than $10 per day. (of course, the cost of food, clothing, and shelter in those countries can be very different from those costs in the united states, so the $2 and $2.50 figures may mean greater purchasing power than they would in the united states.)  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  355  share of population below $1.25/ day  share of population below $2.00/ day  brazil (in 2009)  6.1%  10.8%  china (in 2009)  11.8%  27.2%  egypt (in 2008)  1.7%  15.4%  india (in 2010)  32.7%  68.8%  mexico (in 2010)  0.7%  4.5%  nigeria (in 2010)  68.0%  84.5%  country  table 15.2 poverty lines for low-income countries, mid-2000s (source: http://data.worldbank.org/indicator/si.pov.dday)  any poverty line will be somewhat arbitrary, and it is useful to have a poverty line whose basic definition does not change much over time. if congress voted every few years to redefine poverty, then it would be difficult to compare rates over time. after all, would a lower poverty rate change the definition, or that people were actually better off? government statisticians at the u.s. census bureau have ongoing research programs to address questions like these.  15.2 | the poverty trap by the end of this section, you will be able to: • explain the poverty trap, noting how government programs impact it • identify potential issues in government programs that seek to reduce poverty • calculate a budget constraint line that represents the poverty trap can you give people too much help, or the wrong kind of help? when people are provided with food, shelter, healthcare, income, and other necessities, assistance may reduce their incentive to work. consider a program to fight poverty that works in this reasonable-sounding manner: the government provides assistance to the poor, but as the poor earn income to support themselves, the government reduces the level of assistance it provides. with such a program, every time a poor person earns $100, the person loses $100 in government support. as a result, the person experiences no net gain for working. economists call this problem the poverty trap. consider the situation a single-parent family faces. figure 15.3 illustrates a single mother (earning $8 an hour) with two children. first, consider the labor-leisure budget constraint that this family faces in a situation without government assistance. on the horizontal axis is hours of leisure (or time spent with family responsibilities) increasing in quantity from right to left. also on the horizontal axis is the number of hours at paid work, going from zero hours on the right to the maximum of 2,500 hours on the left. on the vertical axis is the amount of income per year rising from low to higher amounts of income. the budget constraint line shows that at zero hours of leisure and 2,500 hours of work, the maximum amount of income is $20,000 ($8 × 2,500 hours). at the other extreme of the budget constraint line, an individual would work zero hours, earn zero income, but enjoy 2,500 hours of leisure. at point a on the budget constraint line, by working 40 hours a week, 50 weeks a year, the utility-maximizing choice is to work a total of 2,000 hours per year and earn $16,000.  356  chapter 15 | poverty and economic inequality  now suppose that a government antipoverty program guarantees every family with a single mother and two children $18,000 in income. this is represented on the graph by a horizontal line at $18,000. with this program, each time the mother earns $1,000, the government will deduct $1,000 of its support. table 15.3 shows what will happen at each combination of work and government support.  figure 15.3 the poverty trap in action the original choice is 500 hours of leisure, 2,000 hours of work at point a, and income of $16,000. with a guaranteed income of $18,000, this family would receive $18,000 whether it provides zero hours of work or 2,000 hours of work. only if the family provides, say, 2,300 hours of work does its income rise above the guaranteed level of $18,000—and even then, the marginal gain to income from working many hours is small.  amount worked (hours)  total earnings  government support  total income  0  0  $18,000  $18,000  500  $4,000  $14,000  $18,000  1,000  $8,000  $10,000  $18,000  1,500  $12,000  $6,000  $18,000  2,000  $16,000  $2,000  $18,000  2,500  $20,000  0  $20,000  table 15.3 total income at various combinations of work and support  the new budget line, with the antipoverty program in place, is the horizontal and heavy line that is flat at $18,000. if the mother does not work at all, she receives $18,000, all from the government. if she works full time, giving up 40 hours per week with her children, she still ends up with $18,000 at the end of the year. only if she works 2,300 hours in the year—which is an average of 44 hours per week for 50 weeks a year—does household income rise to $18,400. even in this case, all of her year’s work means that household income rises by only $400 over the income she would receive if she did not work at all. she would need to work 50 hours a week to reach $20,000. the poverty trap is even stronger than this simplified example shows, because a working mother will have extra expenses like clothing, transportation, and child care that a nonworking mother will not face, making the economic gains from working even smaller. moreover, those who do not work fail to build up job experience and contacts, which makes working in the future even less likely. to reduce the poverty trap the government could design an antipoverty program so that, instead of reducing  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  357  government payments by $1 for every $1 earned, the government would reduce payments by some smaller amount instead. imposing requirements for work as a condition of receiving benefits and setting a time limit on benefits can also reduce the harshness of the poverty trap. figure 15.4 illustrates a government program that guarantees $18,000 in income, even for those who do not work at all, but then reduces this amount by 50 cents for each $1 earned. the new, higher budget line in figure 15.4 shows that, with this program, additional hours of work will bring some economic gain. because of the reduction in government income when an individual works, an individual earning $8.00 will really net only $4.00 per hour. the vertical intercept of this higher budget constraint line is at $28,000 ($18,000 + 2,500 hours × $4.00 = $28,000). the horizontal intercept is at the point on the graph where $18,000 and 2500 hours of leisure is set. table 15.4 shows the total income differences with various choices of labor and leisure. however, this type of program raises other issues. first, even if it does not eliminate the incentive to work by reducing government payments by $1 for every $1 earned, enacting such a program may still reduce the incentive to work. at least some people who would be working 2,000 hours each year without this program might decide to work fewer hours but still end up with more income—that is, their choice on the new budget line would be like s, above and to the right of the original choice p. of course, others may choose a point like r, which involves the same amount of work as p, or even a point to the left of r that involves more work. the second major issue is that when the government phases out its support payments more slowly, the antipoverty program costs more money. still, it may be preferable in the long run to spend more money on a program that retains a greater incentive to work, rather than spending less money on a program that nearly eliminates any gains from working.  figure 15.4 loosening the poverty trap: reducing government assistance by 50 cents for every $1 earned on the original labor-leisure opportunity set, the lower budget set shown by the smaller dashed line in the figure, the preferred choice p is 500 hours of leisure and $16,000 of income. then, the government created an antipoverty program that guarantees $18,000 in income even to those who work zero hours, shown by the larger dashed line. in addition, every $1 earned means phasing out 50 cents of benefits. this program leads to the higher budget set, which the diagram shows. the hope is that this program will provide incentives to work the same or more hours, despite receiving income assistance. however, it is possible that the recipients will choose a point on the new budget set like s, with less work, more leisure, and greater income, or a point like r, with the same work and greater income.  358  chapter 15 | poverty and economic inequality  amount worked (hours)  total earnings  government support  total income  0  0  $18,000  $18,000  500  $4,000  $16,000  $20,000  1,000  $8,000  $14,000  $22,000  1,500  $12,000  $12,000  $24,000  2,000  $16,000  $10,000  $26,000  2,500  $20,000  $8,000  $28,000  table 15.4 the labor-leisure tradeoff with assistance reduced by 50 cents for every dollar earned  the next module will consider a variety of government support programs focused specifically on the poor, including welfare, snap (supplemental nutrition assistance program), medicaid, and the earned income tax credit (eitc). although these programs vary from state to state, it is generally a true statement that in many states from the 1960s into the 1980s, if poor people worked, their level of income barely rose—or did not rise at all—after factoring in the reduction in government support payments. the following work it out feature shows how this happens.  calculating a budget constraint line jason earns $9.00 an hour, and a government antipoverty program provides a floor of $10,000 guaranteed income. the government reduces government support by $0.50 for each $1.00 earned. what are the horizontal and vertical intercepts of the budget constraint line? assume the maximum hours for work or leisure is 2,500 hours. step 1. determine the amount of the government guaranteed income. in this case, it is $10,000. step 2. plot that guaranteed income as a horizontal line on the budget constraint line. step 3. determine what jason earns if he has no income and enjoys 2,500 hours of leisure. in this case, he will receive the guaranteed $10,000 (the horizontal intercept). step 4. calculate how much jason’s salary will be reduced due to the reduction in government income. in jason’s case, it will be reduced by one half. he will, in effect, net only $4.50 an hour. step 5. if jason works 1,000 hours, at a maximum what income will jason receive? jason will receive $10,000 in government assistance. he will net only $4.50 for every hour he chooses to work. if he works 1,000 hours at $4.50, his earned income is $4,500 plus the $10,000 in government income. thus, the total maximum income (the vertical intercept) is $10,000 + $4,500 = $14,500.  15.3 | the safety net by the end of this section, you will be able to: • identify the antipoverty government programs that comprise the safety net • explain the the safety net programs' primary goals and how these programs have changed over time • discuss the complexities of these safety net programs and why they can be controversial the u.s. government has implemented a number of programs to assist those below the poverty line and those who have incomes just above the poverty line, to whom we refer as the near-poor. such programs are called the safety  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  359  net, to recognize that they offer some protection for those who find themselves without jobs or income.  temporary assistance for needy families from the great depression until 1996, the united states’ most visible antipoverty program was aid to families with dependent children (afdc), which provided cash payments to mothers with children who were below the poverty line. many just called this program “welfare.” in 1996, congress passed and president bill clinton signed into law the personal responsibility and work opportunity reconciliation act, more commonly called the “welfare reform act.” the new law replaced afdc with temporary assistance for needy families (tanf).  visit this website (http://openstaxcollege.org/l/clinton_speech) to watch a video of president bill clinton’s welfare reform speech.  tanf brought several dramatic changes in how welfare operated. under the old afdc program, states set the level of welfare benefits that they would pay to the poor, and the federal government guaranteed it would chip in some of the money as well. the federal government’s welfare spending would rise or fall depending on the number of poor people, and on how each state set its own welfare contribution. under tanf, however, the federal government gives a fixed amount of money to each state. the state can then use the money for almost any program with an antipoverty component: for example, the state might use the money to give cash to poor families, or to reduce teenage pregnancy, or even to raise the high school graduation rate. however, the federal government imposed two key requirements. first, if states are to keep receiving the tanf grants, they must impose work requirements so that most of those receiving tanf benefits are working (or attending school). second, no one can receive tanf benefits with federal money for more than a total of five years over his or her lifetime. the old afdc program had no such work requirements or time limits. tanf attempts to avoid the poverty trap by requiring that welfare recipients work and by limiting the length of time they can receive benefits. in its first few years, the program was quite successful. the number of families receiving payments in 1995, the last year of afdc, was 4.8 million. by 2012, according to the congressional research service, the average number of families receiving payments under tanf was 1.8 million—a decline of more than half. tanf benefits to poor families vary considerably across states. for example, again according to the congressional research service, in 2011 the highest monthly payment in alaska to a single mother with two children was $923, while in mississippi the highest monthly payment to that family was $170. these payments reflect differences in states’ cost of living. total spending on tanf was approximately $16.6 billion in 1997. as of 2012, spending was at $12 billion, an almost 28% decrease, split about evenly between the federal and state governments. when you take into account the effects of inflation, the decline is even greater. moreover, there seemed little evidence that poor families were suffering a reduced standard of living as a result of tanf—although, on the other side, there was not much evidence that poor families had greatly improved their total levels of income, either.  the earned income tax credit (eitc) the earned income tax credit (eitc), first passed in 1975, is a method of assisting the working poor through the tax system. the eitc is one of the largest assistance program for low-income groups, and projections for 2013 expected 26 million households to take advantage of it at an estimated cost of $50 billion. in 2013, for example, a single parent with two children would have received a tax credit of $5,372 up to an income level of $17,530. the amount of the tax break increases with the amount of income earned, up to a point. the earned income tax credit has often been  360  chapter 15 | poverty and economic inequality  popular with both economists and the general public because of the way it effectively increases the payment received for work. what about the danger of the poverty trap that every additional $1 earned will reduce government support payments by close to $1? to minimize this problem, the earned income tax credit is phased out slowly. according to the tax policy center, for a single-parent family with two children in 2013, the credit is not reduced at all (but neither is it increased) as earnings rise from $13,430 to $17,530. then, for every $1 earned above $17,530, the amount received from the credit is reduced by 21.06 cents, until the credit phases out completely at an income level of $46,227. figure 15.5 illustrates that the earned income tax credits, child tax credits, and the tanf program all cost the federal government money—either in direct outlays or in loss of tax revenues. ctc stands for the government tax cuts for the child tax credit.  figure 15.5 real federal spending on ctc, eitc, and tanf, 1975-2013 eitc increased from more than $20 billion in 2000 to over an estimated $50 billion by 2013, far exceeding estimated 2013 outlays in the ctc (child tax credits) and tanf of over $20 billion and $10 billion, respectively. (source: office of management and budget)  in recent years, the eitc has become a hugely expensive government program for providing income assistance to the poor and near-poor, costing about $60 billion in 2012. in that year, the eitc provided benefits to about 27 million families and individuals and, on average, is worth about $2,296 per family (with children), according to the tax policy center. one reason that the tanf law worked as well as it did is that the government greatly expanded eitc in the late 1980s and again in the early 1990s, which increased the returns to work for low-income americans.  supplemental nutrition assistance program (snap) often called “food stamps,” supplemental nutrition assistance program (snap) is a federally funded program, started in 1964, in which each month poor people receive a card like a debit card that they can use to buy food. the amount of food aid for which a household is eligible varies by income, number of children, and other factors but, in general, households are expected to spend about 30% of their own net income on food, and if 30% of their net income is not enough to purchase a nutritionally adequate diet, then those households are eligible for snap. snap can contribute to the poverty trap. for every $100 earned, the government assumes that a family can spend $30 more for food, and thus reduces its eligibility for food aid by $30. this decreased benefit is not a complete disincentive to work—but combined with how other programs reduce benefits as income increases, it adds to the problem. snap, however, does try to address the poverty trap with its own set of work requirements and time limits. why give debit cards and not just cash? part of the political support for snap comes from a belief that since recipients must spend the the cards on food, they cannot “waste” them on other forms of consumption. from an economic point of view, however, the belief that cards must increase spending on food seems wrong-headed. after all, say that a poor family is spending $2,500 per year on food, and then it starts receiving $1,000 per year in snap aid. the family might react by spending $3,500 per year on food (income plus aid), or it might react by continuing to spend $2,500 per year on food, but use the $1,000 in food aid to free up $1,000 that it can now spend on other goods.  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  361  thus, it is reasonable to think of snap cards as an alternative method, along with tanf and the earned income tax credit, of transferring income to the working poor. anyone eligible for tanf is also eligible for snap, although states can expand eligibility for food aid if they wish to do so. in some states, where tanf welfare spending is relatively low, a poor family may receive more in support from snap than from tanf. in 2014, about 40 million people received food aid at an annual cost of about $76 billion, with an average monthly benefit of about $287 per person per month. snap participation increased by 70% between 2007 and 2011, from 26.6 million participants to 45 million. according to the congressional budget office, the 2008-2009 great recession and rising food prices caused this dramatic rise in participation. the federal government deploys a range of income security programs that it funds through departments such as health and human services, agriculture, and housing and urban development (hud) (see figure 15.6). according to the office of management and budget, collectively, these three departments provided an estimated $62 billion of aid through programs such as supplemental feeding programs for women and children, subsidized housing, and energy assistance. the federal government also transfers funds to individual states through special grant programs.  figure 15.6 expenditure comparison of tanf, snap, hud, and other income security programs, 1988–2013 (est.) total expenditures on income security continued to rise between 1988 and 2010, while payments for tanf have increased from $13 billion in 1998 to an estimated $17.3 billion in 2013. snap has seen relatively small increments. these two programs comprise a relatively small portion of the estimated $106 billion dedicated to income security in 2013. note that other programs and housing programs increased dramatically during the 2008 and 2010 time periods. (source: table 12.3 section 600 income security, https://www.whitehouse.gov/sites/default/files/omb/ budget/fy2013/assets/hist.pdf)  the safety net includes a number of other programs: government-subsidized school lunches and breakfasts for children from low-income families; the special supplemental food program for women, infants and children (wic), which provides food assistance for pregnant women and newborns; the low income home energy assistance program, which provides help with home heating bills; housing assistance, which helps pay the rent; and supplemental security income, which provides cash support for the disabled and the elderly poor.  medicaid congress created medicaid in 1965. this is a joint health insurance program between both the states and the federal government. the federal government helps fund medicaid, but each state is responsible for administering the program, determining the level of benefits, and determining eligibility. it provides medical insurance for certain lowincome people, including those below the poverty line, with a focus on families with children, the elderly, and the disabled. about one-third of medicaid spending is for low-income mothers with children. while an increasing share of the program funding in recent years has gone to pay for nursing home costs for the elderly poor. the program ensures that participants receive a basic level of benefits, but because each state sets eligibility requirements and provides varying levels of service, the program differs from state to state.  362  chapter 15 | poverty and economic inequality  in the past, a common problem has been that many low-paying jobs pay enough to a breadwinner so that a family could lose its eligibility for medicaid, yet the job does not offer health insurance benefits. a poor parent considering such a job might choose not to work rather than lose health insurance for his or her children. in this way, health insurance can become a part of the poverty trap. many states recognized this problem in the 1980s and 1990s and expanded their medicaid coverage to include not just the poor, but the near-poor earning up to 135% or even 185% of the poverty line. some states also guaranteed that children would not lose coverage if their parents worked. these expanded guarantees cost the government money, of course, but they also helped to encourage those on welfare to enter the labor force. as of 2014, approximately 69.7 million people participated in medicaid. of those enrolled, almost half are children. healthcare expenditures, however, are highest for the elderly population, which comprises approximately 25% of participants. as figure 15.7 (a) indicates, the largest number of households that enroll in medicaid are those with children. lower-income adults are the next largest group enrolled in medicaid at 28%. the blind and disabled are 16% of those enrolled, and seniors are 9% of those enrolled. figure 15.7 (b) shows how much actual medicaid dollars the government spends for each group. out of total medicaid spending, the government spends more on seniors (20%) and the blind and disabled (44%). thus, 64% of all medicaid spending goes to seniors, the blind, and disabled. children receive 21% of all medicaid spending, followed by adults at 15%.  figure 15.7 medicaid enrollment and spending part (a) shows the medicaid enrollment by different populations, with children comprising the largest percentage at 47%, followed by adults at 28%, and the blind and disabled at 16%. part (b) shows that medicaid spending is principally for the blind and disabled, followed by the elderly. although children are the largest population that medicaid covers, expenditures on children are only at 21%.  15.4 | income inequality: measurement and causes by the end of this section, you will be able to: • explain the distribution of income, and analyze the sources of income inequality in a market economy • measure income distribution in quintiles • calculate and graph a lorenz curve • show income inequality through demand and supply diagrams poverty levels can be subjective based on the overall income levels of a country. typically a government measures poverty based on a percentage of the median income. income inequality, however, has to do with the distribution of that income, in terms of which group receives the most or the least income. income inequality involves comparing those with high incomes, middle incomes, and low incomes—not just looking at those below or near the poverty line. in turn, measuring income inequality means dividing the population into various groups and then comparing the groups, a task that we can be carry out in several ways, as the next clear it up feature shows.  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  363  how do you separate poverty and income inequality? poverty can change even when inequality does not move at all. imagine a situation in which income for everyone in the population declines by 10%. poverty would rise, since a greater share of the population would now fall below the poverty line. however, inequality would be the same, because everyone suffered the same proportional loss. conversely, a general rise in income levels over time would keep inequality the same, but reduce poverty. it is also possible for income inequality to change without affecting the poverty rate. imagine a situation in which a large number of people who already have high incomes increase their incomes by even more. inequality would rise as a result—but the number of people below the poverty line would remain unchanged.  why did inequality of household income increase in the united states in recent decades? a trend toward greater income inequality has occurred in many countries around the world, although the effect has been more powerful in the u.s. economy. economists have focused their explanations for the increasing inequality on two factors that changed more or less continually from the 1970s into the 2000s. one set of explanations focuses on the changing shape of american households. the other focuses on greater inequality of wages, what some economists call “winner take all” labor markets. we will begin with how we measure inequality, and then consider the explanations for growing inequality in the united states.  measuring income distribution by quintiles one common way of measuring income inequality is to rank all households by income, from lowest to highest, and then to divide all households into five groups with equal numbers of people, known as quintiles. this calculation allows for measuring the distribution of income among the five groups compared to the total. the first quintile is the lowest fifth or 20%, the second quintile is the next lowest, and so on. we can measure income inequality by comparing what share of the total income each quintile earns. u.s. income distribution by quintile appears in table 15.5. in 2011, for example, the bottom quintile of the income distribution received 3.2% of income; the second quintile received 8.4%; the third quintile, 14.3%; the fourth quintile, 23.0%; and the top quintile, 51.14%. the final column of table 15.5 shows what share of income went to households in the top 5% of the income distribution: 22.3% in 2011. over time, from the late 1960s to the early 1980s, the top fifth of the income distribution typically received between about 43% to 44% of all income. the share of income that the top fifth received then begins to rise. census bureau researchers trace, much of this increase in the share of income going to the top fifth to an increase in the share of income going to the top 5%. the quintile measure shows how income inequality has increased in recent decades. year  lowest quintile  second quintile  third quintile  fourth quintile  highest quintile  top 5%  1967  4.0  10.8  17.3  24.2  43.6  17.2  1970  4.1  10.8  17.4  24.5  43.3  16.6  1975  4.3  10.4  17.0  24.7  43.6  16.5  1980  4.2  10.2  16.8  24.7  44.1  16.5  1985  3.9  9.8  16.2  24.4  45.6  17.6  1990  3.8  9.6  15.9  24.0  46.6  18.5  table 15.5 share of aggregate income received by each fifth and top 5% of households, 1967–2013 (source: u.s. census bureau, table 2)  364  chapter 15 | poverty and economic inequality  year  lowest quintile  second quintile  third quintile  fourth quintile  highest quintile  top 5%  1995  3.7  9.1  15.2  23.3  48.7  21.0  2000  3.6  8.9  14.8  23.0  49.8  22.1  2005  3.4  8.6  14.6  23.0  50.4  22.2  2010  3.3  8.5  14.6  23.4  50.3  21.3  2013  3.2  8.4  14.4  23.0  51  22.2  table 15.5 share of aggregate income received by each fifth and top 5% of households, 1967–2013 (source: u.s. census bureau, table 2)  it can also be useful to divide the income distribution in ways other than quintiles; for example, into tenths or even into percentiles (that is, hundredths). a more detailed breakdown can provide additional insights. for example, the last column of table 15.5 shows the income received by the top 5% percent of the income distribution. between 1980 and 2013, the share of income going to the top 5% increased by 5.7 percentage points (from 16.5% in 1980 to 22.2% in 2013). from 1980 to 2013 the share of income going to the top quintile increased by 7.0 percentage points (from 44.1% in 1980 to 51% in 2013). thus, the top 20% of householders (the fifth quintile) received over half (51%) of all the income in the united states in 2013.  lorenz curve we can present the data on income inequality in various ways. for example, you could draw a bar graph that showed the share of income going to each fifth of the income distribution. figure 15.8 presents an alternative way of showing inequality data in a lorenz curve. this curve shows the cumulative share of population on the horizontal axis and the cumulative percentage of total income received on the vertical axis.  figure 15.8 the lorenz curve a lorenz curve graphs the cumulative shares of income received by everyone up to a certain quintile. the income distribution in 1980 was closer to the perfect equality line than the income distribution in 2011—that is, the u.s. income distribution became more unequal over time.  every lorenz curve diagram begins with a line sloping up at a 45-degree angle. we show it as a dashed line in figure 15.8. the points along this line show what perfect equality of the income distribution looks like. it would mean, for example, that the bottom 20% of the income distribution receives 20% of the total income, the bottom 40% gets 40% of total income, and so on. the other lines reflect actual u.s. data on inequality for 1980 and 2011. the trick in graphing a lorenz curve is that you must change the shares of income for each specific quintile, which we show in the first column of numbers in table 15.6, into cumulative income, which we show in the second column of numbers. for example, the bottom 40% of the cumulative income distribution will be the sum of the first and second quintiles; the bottom 60% of the cumulative income distribution will be the sum of the first, second, and third  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  365  quintiles, and so on. the final entry in the cumulative income column needs to be 100%, because by definition, 100% of the population receives 100% of the income. share of income in 1980 (%)  cumulative share of income in 1980 (%)  share of income in 2013 (%)  cumulative share of income in 2013 (%)  first quintile  4.2  4.2  3.2  3.2  second quintile  10.2  14.4  8.4  11.6  third quintile  16.8  31.2  14.4  26.0  fourth quintile  24.7  55.9  23.0  49.0  fifth quintile  44.1  100.0  51.0  100.0  income category  table 15.6 calculating the lorenz curve  in a lorenz curve diagram, a more unequal distribution of income will loop farther down and away from the 45-degree line, while a more equal distribution of income will move the line closer to the 45-degree line. figure figure 15.8 illustrates the greater inequality of the u.s. income distribution between 1980 and 2013 because the lorenz curve for 2013 is farther from the 45-degree line than for 1980. the lorenz curve is a useful way of presenting the quintile data that provides an image of all the quintile data at once. the next clear it up feature shows how income inequality differs in various countries compared to the united states.  how does economic inequality vary around the world? the u.s. economy has a relatively high degree of income inequality by global standards. as table 15.7 shows, based on a variety of national surveys for a selection of years in the last five years of the 2000s (with the exception of germany, and adjusted to make the measures more comparable), the u.s. economy has greater inequality than germany (along with most western european countries). the region of the world with the highest level of income inequality is latin america, illustrated in the numbers for brazil and mexico. the level of inequality in the united states is lower than in some of the low-income countries of the world, like china and nigeria, or some middle-income countries like the russian federation. however, not all poor countries have highly unequal income distributions. india provides a counterexample.  366  chapter 15 | poverty and economic inequality  survey year  first quintile  second quintile  third quintile  fourth quintile  fifth quintile  united states  2013  3.2%  8.4%  14.4%  23.0%  51.0%  germany  2000  8.5%  13.7%  17.8%  23.1%  36.9%  brazil  2009  2.9%  7.1%  12.4%  19.0%  58.6%  mexico  2010  4.9%  8.8%  13.3%  20.2%  52.8%  china  2009  4.7%  9.7%  15.3%  23.2%  47.1%  india  2010  8.5%  12.1%  15.7%  20.8%  42.8%  russia  2009  6.1%  10.4%  14.8%  21.3%  47.1%  nigeria  2010  4.4%  8.3%  13.0%  20.3%  54.0%  country  table 15.7 income distribution in select countries (source: u.s. data from u.s. census bureau table 2. other data from the world bank poverty and inequality data base, http://databank.worldbank.org/data/views/reports/tableview.aspx#)  visit this website (http://openstaxcollege.org/l/inequality/) to watch a video of wealth inequality across the world.  causes of growing inequality: the changing composition of american households in 1970, 41% of married women were in the labor force, but by 2015, according to the bureau of labor statistics, 56.7% of married women were in the labor force. one result of this trend is that more households have two earners. moreover, it has become more common for one high earner to marry another high earner. a few decades ago, the common pattern featured a man with relatively high earnings, such as an executive or a doctor, marrying a woman who did not earn as much, like a secretary or a nurse. often, the woman would leave paid employment, at least for a few years, to raise a family. however, now doctors are marrying doctors and executives are marrying executives, and mothers with high-powered careers are often returning to work while their children are quite young. this pattern of households with two high earners tends to increase the proportion of high-earning households. according to data in the national journal, even as two-earner couples have increased, so have single-parent households. of all u.s. families, 13.1% were headed by single mothers. the poverty rate among single-parent households tends to be relatively high.  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  367  these changes in family structure, including the growth of single-parent families who tend to be at the lower end of the income distribution, and the growth of two-career high-earner couples near the top end of the income distribution, account for roughly half of the rise in income inequality across households in recent decades.  visit this website (http://openstaxcollege.org/l/us_wealth) to watch a video that illustrates the distribution of wealth in the united states.  causes of growing inequality: a shift in the distribution of wages another factor behind the rise in u.s. income inequality is that earnings have become less equal since the late 1970s. in particular, the earnings of high-skilled labor relative to low-skilled labor have increased. winner-take-all labor markets result from changes in technology, which have increased global demand for “stars,”—whether the best ceo, doctor, basketball player, or actor. this global demand pushes salaries far above productivity differences versus educational differences. one way to measure this change is to take workers' earnings with at least a four-year college bachelor’s degree (including those who went on and completed an advanced degree) and divide them by workers' earnings with only a high school degree. the result is that those in the 25–34 age bracket with college degrees earned about 1.67 times as much as high school graduates in 2010, up from 1.59 times in 1995, according to u.s. census data. winner-take-all labor market theory argues that the salary gap between the median and the top 1 percent is not due to educational differences. economists use the demand and supply model to reason through the most likely causes of this shift. according to the national center for education statistics, in recent decades, the supply of u.s. workers with college degrees has increased substantially. for example, 840,000 four-year bachelor’s degrees were conferred on americans in 1970. in 2013-2014, 1,894,934 such degrees were conferred—an increase of over 90%. in figure 15.9, this shift in supply to the right, from s0 to s1, should result in a lower equilibrium wage for high-skilled labor. thus, we can explain the increase in the price of high-skilled labor by a greater demand, like the movement from d0 to d1. evidently, combining both the increase in supply and in demand has resulted in a shift from e0 to e1, and a resulting higher wage.  368  chapter 15 | poverty and economic inequality  figure 15.9 why would wages rise for high-skilled labor? the proportion of workers attending college has increased in recent decades, so the supply curve for high-skilled labor has shifted to the right, from s 0 to s1. if the demand for high-skilled labor had remained at d0, then this shift in supply would have led to lower wages for highskilled labor. however, the wages for high-skilled labor, especially if there is a large global demand, have increased even with the shift in supply to the right. the explanation must lie in a shift to the right in demand for high-skilled labor, from d0 to d1. the figure shows how a combination of the shift in supply, from s0 to s1, and the shift in demand, from d0 to d1, led to both an increase in the quantity of high-skilled labor hired and also to a rise in the wage for such labor, from w0 to w1.  what factors would cause the demand for high-skilled labor to rise? the most plausible explanation is that while the explosion in new information and communications technologies over the last several decades has helped many workers to become more productive, the benefits have been especially great for high-skilled workers like top business managers, consultants, and design professionals. the new technologies have also helped to encourage globalization, the remarkable increase in international trade over the last few decades, by making it more possible to learn about and coordinate economic interactions all around the world. in turn, the rising impact of foreign trade in the u.s. economy has opened up greater opportunities for high-skilled workers to sell their services around the world, and lower-skilled workers have to compete with a larger supply of similarly skilled workers around the globe. we can view the market for high-skilled labor as a race between forces of supply and demand. additional education and on-the-job training will tend to increase the high-skilled labor supply and to hold down its relative wage. conversely, new technology and other economic trends like globalization tend to increase the demand for high-skilled labor and push up its relative wage. we can view the greater inequality of wages as a sign that demand for skilled labor is increasing faster than supply. alternatively, if the supply of lower skilled workers exceeds the demand, then average wages in the lower quintiles of the income distribution will decrease. the combination of forces in the highskilled and low-skilled labor markets leads to increased income disparity.  15.5 | government policies to reduce income inequality by the end of this section, you will be able to: • explain the arguments for and against government intervention in a market economy • identify beneficial ways to reduce the economic inequality in a society • show the tradeoff between incentives and income equality no society should expect or desire complete equality of income at a given point in time, for a number of reasons. first, most workers receive relatively low earnings in their first few jobs, higher earnings as they reach middle age, and then lower earnings after retirement. thus, a society with people of varying ages will have a certain amount of income inequality. second, people’s preferences and desires differ. some are willing to work long hours to have income for large houses, fast cars and computers, luxury vacations, and the ability to support children and grandchildren.  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  369  these factors all imply that a snapshot of inequality in a given year does not provide an accurate picture of how people’s incomes rise and fall over time. even if we expect some degree of economic inequality at any point in time, how much inequality should there be? there is also the difference between income and wealth, as the following clear it up feature explains.  how do you measure wealth versus income inequality? income is a flow of money received, often measured on a monthly or an annual basis. wealth is the sum of the value of all assets, including money in bank accounts, financial investments, a pension fund, and the value of a home. in calculating wealth, one must subtract all debts, such as debt owed on a home mortgage and on credit cards. a retired person, for example, may have relatively little income in a given year, other than a pension or social security. however, if that person has saved and invested over time, the person’s accumulated wealth can be quite substantial. in the united states, the wealth distribution is more unequal than the income distribution, because differences in income can accumulate over time to make even larger differences in wealth. however, we can measure the degree of inequality in the wealth distribution with the same tools we use to measure the inequality in the income distribution, like quintile measurements. once every three years the federal reserve bank publishes the survey of consumer finance which reports a collection of data on wealth.  even if they cannot answer the question of how much inequality is too much, economists can still play an important role in spelling out policy options and tradeoffs. if a society decides to reduce the level of economic inequality, it has three main sets of tools: redistribution from those with high incomes to those with low incomes; trying to assure that a ladder of opportunity is widely available; and a tax on inheritance.  redistribution redistribution means taking income from those with higher incomes and providing income to those with lower incomes. earlier in this chapter, we considered some of the key government policies that provide support for the poor: the welfare program tanf, the earned income tax credit, snap, and medicaid. if a reduction in inequality is desired, these programs could receive additional funding. the federal income tax, which is a progressive tax system designed in such a way that the rich pay a higher percent in income taxes than the poor funds the programs. data from household income tax returns in 2009 shows that the top 1% of households had an average income of $1,219,700 per year in pre-tax income and paid an average federal tax rate of 28.9%. the effective income tax, which is total taxes paid divided by total income (all sources of income such as wages, profits, interest, rental income, and government transfers such as veterans’ benefits), was much lower. the effective tax paid by that top 1% of householders paid was 20.4%, while the bottom two quintiles actually paid negative effective income taxes, because of provisions like the earned income tax credit. news stories occasionally report on a high-income person who has managed to pay very little in taxes, but while such individual cases exist, according to the congressional budget office, the typical pattern is that people with higher incomes pay a higher average share of their income in federal income taxes. of course, the fact that some degree of redistribution occurs now through the federal income tax and government antipoverty programs does not settle the questions of how much redistribution is appropriate, and whether more redistribution should occur.  the ladder of opportunity economic inequality is perhaps most troubling when it is not the result of effort or talent, but instead is determined by the circumstances under which a child grows up. one child attends a well-run grade school and high school and heads on to college, while parents help out by supporting education and other interests, paying for college, a first car, and a first house, and offering work connections that lead to internships and jobs. another child attends a poorly run grade school, barely makes it through a low-quality high school, does not go to college, and lacks family and peer support. these two children may be similar in their underlying talents and in the effort they put forth, but their  370  chapter 15 | poverty and economic inequality  economic outcomes are likely to be quite different. public policy can attempt to build a ladder of opportunities so that, even though all children will never come from identical families and attend identical schools, each child has a reasonable opportunity to attain an economic niche in society based on their interests, desires, talents, and efforts. table 15.8 shows some of those initiatives. children  college level  adults  • improved day care  • widespread loans and grants for those in financial need  • opportunities for retraining and acquiring new skills  • enrichment programs for preschoolers  • public support for a range of institutions from two-year community colleges to large research universities  • prohibiting discrimination in job markets and housing on the basis of race, gender, age, and disability  • improved public schools  -  -  • after school and community activities  -  -  • internships and apprenticeships  -  -  table 15.8 public policy initiatives  some have called the united states a land of opportunity. although the general idea of a ladder of opportunity for all citizens continues to exert a powerful attraction, specifics are often quite controversial. society can experiment with a wide variety of proposals for building a ladder of opportunity, especially for those who otherwise seem likely to start their lives in a disadvantaged position. the government needs to carry out such policy experiments in a spirit of open-mindedness, because some will succeed while others will not show positive results or will cost too much to enact on a widespread basis.  inheritance taxes there is always a debate about inheritance taxes. it goes like this: why should people who have worked hard all their lives and saved up a substantial nest egg not be able to give their money and possessions to their children and grandchildren? in particular, it would seem un-american if children were unable to inherit a family business or a family home. alternatively, many americans are far more comfortable with inequality resulting from high-income people who earned their money by starting innovative new companies than they are with inequality resulting from high-income people who have inherited money from rich parents. the united states does have an estate tax—that is, a tax imposed on the value of an inheritance—which suggests a willingness to limit how much wealth one can pass on as an inheritance. however, according to the center on budget and policy priorities, in 2015 the estate tax applied only to those leaving inheritances of more than $5.43 million and thus applies to only a tiny percentage of those with high levels of wealth.  the tradeoff between incentives and income equality government policies to reduce poverty or to encourage economic equality, if carried to extremes, can injure incentives for economic output. the poverty trap, for example, defines a situation where guaranteeing a certain level of income can eliminate or reduce the incentive to work. an extremely high degree of redistribution, with very high taxes on the rich, would be likely to discourage work and entrepreneurship. thus, it is common to draw the tradeoff between economic output and equality, as figure 15.10 (a) shows. in this formulation, if society wishes a high level of economic output, like point a, it must also accept a high degree of inequality. conversely, if society wants a high level of equality, like point b, it must accept a lower level of economic output because of reduced incentives for  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  371  production. this view of the tradeoff between economic output and equality may be too pessimistic, and figure 15.10 (b) presents an alternate vision. here, the tradeoff between economic output and equality first slopes up, in the vicinity of choice c, suggesting that certain programs might increase both output and economic equality. for example, the policy of providing free public education has an element of redistribution, since the value of the public schooling received by children of low-income families is clearly higher than what low-income families pay in taxes. a well-educated population, however, is also an enormously powerful factor in providing the skilled workers of tomorrow and helping the economy to grow and expand. in this case, equality and economic growth may complement each other. moreover, policies to diminish inequality and soften the hardship of poverty may sustain political support for a market economy. after all, if society does not make some effort toward reducing inequality and poverty, the alternative might be that people would rebel against market forces. citizens might seek economic security by demanding that their legislators pass laws forbidding employers from ever laying off workers or reducing wages, or laws that would impose price floors and price ceilings and shut off international trade. from this viewpoint, policies to reduce inequality may help economic output by building social support for allowing markets to operate.  figure 15.10 the tradeoff between incentives and economic equality (a) society faces a trade-off where any attempt to move toward greater equality, like moving from choice a to b, involves a reduction in economic output. (b) situations can arise like point c, where it is possible both to increase equality and also to increase economic output, to a choice like d. it may also be possible to increase equality with little impact on economic output, like the movement from choice d to e. however, at some point, too aggressive a push for equality will tend to reduce economic output, as in the shift from e to f.  the tradeoff in figure 15.10 (b) then flattens out in the area between points d and e, which reflects the pattern that a number of countries that provide similar levels of income to their citizens—the united states, canada, european union nations, japan, and australia—have different levels of inequality. the pattern suggests that countries in this range could choose a greater or a lesser degree of inequality without much impact on economic output. only if these countries push for a much higher level of equality, like at point f, will they experience the diminished incentives that lead to lower levels of economic output. in this view, while a danger always exists that an agenda to reduce poverty or inequality can be poorly designed or pushed too far, it is also possible to discover and design policies that improve equality and do not injure incentives for economic output by very much—or even improve such incentives.  occupy wall street the occupy movement took on a life of its own over the last few months of 2011, bringing to light issues that many people faced on the lower end of the income distribution. the contents of this chapter indicate that there is a significant amount of income inequality in the united states. the question is: what should be done about  372  chapter 15 | poverty and economic inequality  it? the 2008-2009 great recession caused unemployment to rise and incomes to fall. many people attribute the recession to mismanagement of the financial system by bankers and financial managers—those in the 1% of the income distribution—but those in lower quintiles bore the greater burden of the recession through unemployment. this seemed to present the picture of inequality in a different light: the group that seemed responsible for the recession was not the group that seemed to bear the burden of the decline in output. a burden shared can bring a society closer together. a burden pushed off onto others can polarize it. on one level, the problem with trying to reduce income inequality comes down to whether you still believe in the american dream. if you believe that one day you will have your american dream—a large income, large house, happy family, or whatever else you would like to have in life—then you do not necessarily want to prevent anyone else from living out their dream. you certainly would not want to run the risk that someone would want to take part of your dream away from you. thus, there is some reluctance to engage in a redistributive policy to reduce inequality. however, when those for whom the likelihood of living the american dream is very small are considered, there are sound arguments in favor of trying to create greater balance. as the text indicated, a little more income equality, gained through long-term programs like increased education and job training, can increase overall economic output. then everyone is made better off, and the 1% will not seem like such a small group any more.  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  373  key terms earned income tax credit (eitc) a method of assisting the working poor through the tax system effective income tax percentage of total taxes paid divided by total income estate tax a tax imposed on the value of an inheritance income a flow of money received, often measured on a monthly or an annual basis income inequality when one group receives a disproportionate share of total income or wealth than others lorenz curve a graph that compares the cumulative income actually received to a perfectly equal distribution of income; it shows the share of population on the horizontal axis and the cumulative percentage of total income received on the vertical axis medicaid a federal–state joint program enacted in 1965 that provides medical insurance for certain (not all) low-income people, including the near-poor as well as those below the poverty line, and focusing on low-income families with children, the low-income elderly, and the disabled near-poor those who have incomes just above the poverty line poverty the situation of being below a certain level of income one needs for a basic standard of living poverty line the specific amount of income one requires for a basic standard of living poverty rate percentage of the population living below the poverty line poverty trap antipoverty programs set up so that government benefits decline substantially as people earn more income—as a result, working provides little financial gain progressive tax system a tax system in which the rich pay a higher percentage of their income in taxes, rather than a higher absolute amount quintile dividing a group into fifths, a method economists often use to look at distribution of income redistribution taking income from those with higher incomes and providing income to those with lower incomes safety net the group of government programs that provide assistance to the poor and the near-poor supplemental nutrition assistance program (snap) a federally funded program, started in 1964, in which each month poor people receive snap cards they can use to buy food wealth the sum of the value of all assets, including money in bank accounts, financial investments, a pension fund, and the value of a home  key concepts and summary 15.1 drawing the poverty line wages are influenced by supply and demand in labor markets influence wages. this can lead to very low incomes for some people and very high incomes for others. poverty and income inequality are not the same thing. poverty applies to the condition of people who cannot afford the necessities of life. income inequality refers to the disparity between those with higher and lower incomes. the poverty rate is what percentage of the population lives below the poverty line, which the amount of income that it takes to purchase the necessities of life determines. choosing a poverty line will always be somewhat controversial.  374  chapter 15 | poverty and economic inequality  15.2 the poverty trap a poverty trap occurs when government-support payments for the poor decline as the poor earn more income. as a result, the poor do not end up with much more income when they work, because the loss of government support largely or completely offsets any income that one earns by working. phasing out government benefits more slowly, as well as imposing requirements for work as a condition of receiving benefits and a time limit on benefits can reduce the harshness of the poverty trap. 15.3 the safety net we call the group of government programs that assist the poor the safety net. in the united states, prominent safety net programs include temporary assistance to needy families (tanf), the supplemental nutrition assistance program (snap), the earned income tax credit (eitc), medicaid, and the special supplemental food program for women, infants, and children (wic). 15.4 income inequality: measurement and causes measuring inequality involves making comparisons across the entire distribution of income, not just the poor. one way of doing this is to divide the population into groups, like quintiles, and then calculate what share of income each group receives. an alternative approach is to draw lorenz curves, which compare the cumulative income actually received to a perfectly equal distribution of income. income inequality in the united states increased substantially from the late 1970s and early 1980s into the 2000s. the two most common explanations that economists cite are changes in household structures that have led to more two-earner couples and single-parent families, and the effect of new information and communications technology on wages. 15.5 government policies to reduce income inequality policies that can affect the level of economic inequality include redistribution between rich and poor, making it easier for people to climb the ladder of opportunity; and estate taxes, which are taxes on inheritances. pushing too aggressively for economic equality can run the risk of decreasing economic incentives. however, a moderate push for economic equality can increase economic output, both through methods like improved education and by building a base of political support for market forces.  self-check questions 1. describe how each of these changes is likely to affect poverty and inequality: a. incomes rise for low-income and high-income workers, but rise more for the high-income earners. b. incomes fall for low-income and high-income workers, but fall more for high-income earners. 2. jonathon is a single father with one child. he can work as a server for $6 per hour for up to 1,500 hours per year. he is eligible for welfare, and so if he does not earn any income, he will receive a total of $10,000 per year. he can work and still receive government benefits, but for every $1 of income, his welfare stipend is $1 less. create a table similar to table 15.4 that shows jonathan’s options. use four columns, the first showing number of hours to work, the second showing his earnings from work, the third showing the government benefits he will receive, and the fourth column showing his total income (earnings + government support). sketch a labor-leisure diagram of jonathan’s opportunity set with and without government support. 3. imagine that the government reworks the welfare policy that was affecting jonathan in question 1, so that for each dollar someone like jonathan earns at work, his government benefits diminish by only 30 cents. reconstruct the table from question 1 to account for this change in policy. draw jonathan’s labor-leisure opportunity sets, both for before this welfare program is enacted and after it is enacted. 4. we have discovered that the welfare system discourages recipients from working because the more income they earn, the less welfare benefits they receive. how does the earned income tax credit attempt to loosen the poverty trap? 5. how does the tanf attempt to loosen the poverty trap?  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  375  6. a group of 10 people have the following annual incomes: $24,000, $18,000, $50,000, $100,000, $12,000, $36,000, $80,000, $10,000, $24,000, $16,000. calculate the share of total income that each quintile receives from this income distribution. do the top and bottom quintiles in this distribution have a greater or larger share of total income than the top and bottom quintiles of the u.s. income distribution? 7. table 15.9 shows the share of income going to each quintile of the income distribution for the united kingdom in 1979 and 1991. use this data to calculate what the points on a lorenz curve would be, and sketch the lorenz curve. how did inequality in the united kingdom shift over this time period? how can you see the patterns in the quintiles in the lorenz curves? share of income  1979  1991  top quintile  39.7%  42.9%  fourth quintile  24.8%  22.7%  middle quintile  17.0%  16.3%  second quintile  11.5%  11.5%  bottom quintile  7.0%  6.6%  table 15.9 income distribution in the united kingdom, 1979 and 1991  8. using two demand and supply diagrams, one for the low-wage labor market and one for the high-wage labor market, explain how information technology can increase income inequality if it is a complement to high-income workers like salespeople and managers, but a substitute for low-income workers like file clerks and telephone receptionists. 9. using two demand and supply diagrams, one for the low-wage labor market and one for the high-wage labor market, explain how a program that increased educational levels for a substantial number of low-skill workers could reduce income inequality. 10. here is one hypothesis: a well-funded social safety net can increase economic equality but will reduce economic output. explain why this might be so, and sketch a production possibility curve that shows this tradeoff. 11. here is a second hypothesis: a well-funded social safety net may lead to less regulation of the market economy. explain why this might be so, and sketch a production possibility curve that shows this tradeoff. 12. which set of policies is more likely to cause a tradeoff between economic output and equality: policies of redistribution or policies aimed at the ladder of opportunity? explain how the production possibility frontier tradeoff between economic equality and output might look in each case. 13. why is there reluctance on the part of some in the united states to redistribute income so that greater equality can be achieved?  review questions 14. how is the poverty rate calculated? 15. what is the poverty line? 16. what is the difference between poverty and income inequality?  17. how does the poverty trap discourage people from working? 18. how can the effect of the poverty trap be reduced? 19. who are the near-poor? 20. what is the safety net?  376  21. briefly explain the differences between tanf, the earned income tax credit, snap, and medicaid. 22. who is included in the top income quintile? 23. what is measured on the two axes of a lorenz curve? 24. if a country had perfect income equality what would the lorenz curve look like? 25. how has the inequality of income changed in the u.s. economy since the late 1970s?  chapter 15 | poverty and economic inequality  26. what are some reasons why a certain degree of inequality of income would be expected in a market economy? 27. what are the main reasons economists give for the increase in inequality of incomes? 28. identify some public policies that can reduce the level of economic inequality. 29. describe how a push for economic equality might reduce incentives to work and produce output. then describe how a push for economic inequality might not have such effects.  critical thinking questions 30. what goods and services would you include in an estimate of the basic necessities for a family of four? 31. if a family of three earned $20,000, would they be able to make ends meet given the official poverty threshold? 32. exercise 15.2 and exercise 15.3 asked you to describe the labor-leisure tradeoff for jonathon. since, in the first example, there is no monetary incentive for jonathon to work, explain why he may choose to work anyway. explain what the opportunity costs of working and not working might be for jonathon in each example. using your tables and graphs from exercise 15.2 and exercise 15.3, analyze how the government welfare system affects jonathan’s incentive to work. 33. explain how you would create a government program that would give an incentive for labor to increase hours and keep labor from falling into the poverty trap. 34. many critics of government programs to help lowincome individuals argue that these programs create a poverty trap. explain how programs such as tanf, eitc, snap, and medicaid will affect low-income individuals and whether or not you think these programs will benefit families and children. 35. think about the business cycle: during a recession, unemployment increases; it decreases in an expansionary phase. explain what happens to tanf, snap, and medicaid programs at each phase of the business cycle (recession, trough, expansion, and peak).  36. explain how a country may experience greater equality in the distribution of income, yet still experience high rates of poverty. hint: look at the clear it up ""how do governments measure poverty in low-income countries?"" and compare to table 15.5. 37. the demand for skilled workers in the united states has been increasing. to increase the supply of skilled workers, many argue that immigration reform to allow more skilled labor into the united states is needed. explain whether you agree or disagree. 38. explain a situation using the supply and demand for skilled labor in which the increased number of college graduates leads to depressed wages. given the rising cost of going to college, explain why a college education will or will not increase income inequality. 39. what do you think is more important to focus on when considering inequality: income inequality or wealth inequality? 40. to reduce income inequality, should the marginal tax rates on the top 1% be increased? 41. redistribution of income occurs through the federal income tax and government antipoverty programs. explain whether or not this level of redistribution is appropriate and whether more redistribution should occur. 42. how does a society or a country make the decision about the tradeoff between equality and economic output? hint: think about the political system. 43. explain what the long- and short-term consequences are of not promoting equality or working to reduce poverty.  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality  377  problems 44. in country a, the population is 300 million and 50 million people are living below the poverty line. what is the poverty rate? 45. in country b, the population is 900 million and 100 million people are living below the poverty line. what is the poverty rate?  46. susan is a single mother with three children. she can earn $8 per hour and works up to 2,000 hours per year. however, if she does not earn any income at all, she will receive government benefits totaling $16,000 per year. for every $1 of income she earns, her level of government support will be reduced by $1. create a table, patterned after table 15.8. the first column should show susan’s choices of how many hours to work per year, up to 2,000 hours. the second column should show her earnings from work. the third column should show her level of government support, given her earnings. the final column should show her total income, combining earnings and government support. 47. a group of 10 people have the following annual incomes: $55,000, $30,000, $15,000, $20,000, $35,000, $80,000, $40,000, $45,000, $30,000, $50,000. calculate the share of total income each quintile of this income distribution received. do the top and bottom quintiles in this distribution have a greater or larger share of total income than the top and bottom quintiles of the u.s. income distribution for 2005?  378  this openstax book is available for free at http://cnx.org/content/col12170/1.7  chapter 15 | poverty and economic inequality",t_5b94762be0d1,other,0
c_11b5765aeda1,"chapter 42 of the book on mysql.chapter 42: character sets and collations section 42.1: which character set and collation? there are dozens of character sets with hundreds of collations. (a given collation belongs to only one character set.) see the output of show collation;. there are usually only 4 character sets that matter: ascii -- basic 7-bit codes. latin1 -- ascii, plus most characters needed for western european languages. utf8 -- the 1-, 2-, and 3-byte subset of utf8. this excludes emoji and some of chinese. utf8mb4 -- the full set of utf8 characters, covering all current languages.  all include english characters, encoded identically. utf8 is a subset of utf8mb4. best practice... use utf8mb4 for any text or varchar column that can have a variety of languages in it. use ascii (latin1 is ok) for hex strings (uuid, md5, etc) and simple codes (country_code, postal_code, etc). utf8mb4 did not exist until version 5.5.3, so utf8 was the best available before that. outside of mysql, ""utf8"" means the same things as mysql's utf8mb4, not mysql's utf8. collations start with the charset name and usually end with _ci for ""case and accent insensitive"" or _bin for ""simply compare the bits. the 'latest' utf8mb4 collation is utf8mb4_unicode_520_ci, based on unicode 5.20. if you are working with a single language, you might want, say, utf8mb4_polish_ci, which will rearrange the letters slightly, based on polish conventions.  section 42.2: setting character sets on tables and ﬁelds you can set a character set both per table, as well as per individual ﬁeld using the character set and charset statements: create table address ( `addressid` integer not null primary key, `street` varchar(80) character set ascii, `city` varchar(80), `country` varchar(80) default ""united states"", `active` boolean default 1, ) engine=innodb default charset=utf8; city and country will use utf8, as we set that as the default character set for the table. street on the other hand  will use ascii, as we've speciﬁcally told it to do so. setting the right character set is highly dependent on your dataset, but can also highly improve portability between systems working with your data.  section 42.3: declaration create table foo ( ... name character set utf8mb4  goalkicker.com – mysql® notes for professionals  122  ... );  section 42.4: connection vital to using character sets is to tell the mysql-server what encoding the client's bytes are. here is one way: set names utf8mb4;  each language (php, python, java, ...) has its own way the it usually preferable to set names. for example: set names utf8mb4, together with a column declared character set latin1 -- this will convert from latin1 to utf8mb4 when inserting and convert back when selecting.  goalkicker.com – mysql® notes for professionals  123",t_4ba4e5cf6f39,other,0
c_65a05c6b2441,"david explains how to determine the torque exerted by a non-perpendicular force.  - [instructor] i don't know about you, but torque problems used to give me anxiety, and i think it was because i didn't really understand well what torque meant or how to find it. so what i want to do in this video is show you how to find the torque. there are conceptual ways and tricks to figure it out, so i want to share those with you so that going forward we don't have to be so anxious when we're solving a torque problem. and specifically the problems i got most anxious about were these problems where the force was at a weird angle, so let's do this. let's figure out how to find the torque from say this 10 newton force exerted at this angle of 30 degrees. now one of the first things you want to do when finding the torque is identify the axis. the axis is the point about which the object's gonna rotate. so let's say it was told to us that in this problem the object, whatever it is, rotates around the center. so the center here of the object would be the axis. maybe this is a board with a nail through it, or maybe this is a bird's eye view of one of those fancy revolving glass doors at the nice restaurants and hotels. regardless, let's say the axis was in the very center, and that's crucial to know because if a force is gonna exert a torque, it has to be applied at some point besides the axis. in other words, if you go try to push open this revolving glass door at the very center, nothing's gonna happen because it's not gonna rotate. but the farther out you apply this force, the more torque you will get for the amount of force that you're exerting. so a force out here would apply much more torque than a force right here. that's why the door knobs are near the edge of the door. it'd be really hard to open a door right near the hinge. if you haven't tried it, try it out. it's really hard. now that we've identified the axis, we could figure out how much torque we're exerting. now the first thing i might try to figure out the torque here is i'd just say, alright torque, i know what torque is. torque is f times d, or f times r. you could call it an r. but what's important to know is that this r represents the vector that points from the axis to the point where the force was applied. so in this case, that would represent from this axis right here to the point where the force was applied would be this. this would be r. note that r is not the entire radius necessarily, and it's not the entire length of the object. always from the axis to the point where the force is applied and technically this r is a vector. you can think of it as a position vector, but regardless it points from the axis to the point where the force is applied. it doesn't point the other way. the direction is not toward the axis, the direction is always away from the axis to that point where the force happens to be applied to the object. so let's give this a number. let's say this happened to be two meters from this axis to the point where this 10 newtons was applied. now we can solve for this torque, but you have to be careful. a mistake i might've made is to say just well, the force was 10 newtons, the r here is two meters, so my torque should just be 20, right? two times 10? but that's not right 'cause this force is not representing the total force necessarily. if you just write this formula for torque like this, what you really mean is that this force is the perpendicular force to this r. so only the perpendicular component of this force is gonna exert a torque on the door. the component parallel to the r doesn't exert any torque, and that should make sense. so if i draw this out, let me draw the components. if i break this 10 newtons up into a component that goes this way, i'll call that f parallel because that force is parallel to r. it runs the same direction as r does. and i'll break it up into this component as well, this perpendicular component, and i'll call that f perpendicular 'cause this component is perpendicular to this r vector. only this perpendicular component is gonna exert a torque, and that should make sense. torque is a force that causes something to start rotating, or to change its rotation. so the only component of this force, of this 10 newtons that is gonna cause this door to rotate, is this perpendicular component. this is the way you push on a door to make it rotate. you don't pull the axis this way. if i came up and tried to open this revolving glass door by pushing that way, you'd think i was crazy 'cause that's not gonna cause the door to rotate. similarly, trying to pull the door that way is not gonna cause this door to rotate. you need to exert a force perpendicular to this r vector in order to get the door to rotate. in other words, only perpendicular components of the force, that is perpendicular to the r, are going to exert a torque. so it's only this component of the 10 newtons that's going to contribute toward the torque, and we can find that. if this was 30 degrees, this is an alternate interior angle. that means that this is also 30 degrees. so these angles are identical based on geometry. that means this component that's perpendicular, i can write as well let's see, it's the opposite side. that side is opposite of this 30 degrees, so i can say that it's gonna be 10 newtons, the hypotenuse would be 10 newtons times sine of 30. and 10 newtons times sine of 30 degrees is five newtons. so finally i can say that the torque exerted on this door by this force of 10 newtons at 30 degrees would be the perpendicular component, which is five newtons, times how far that force was applied from the axis, and that was two meters, and i get that the torque here is gonna be 10 newton meters. so at this point i wouldn't blame you if you weren't like, see, this is why i hate torque. i've gotta remember that this two meters is from the axis to the point where the force is applied. i've gotta remember that i'm only supposed to take the perpendicular component, and i'm supposed to remember that perpendicular means perpendicular to this r vector. you might wonder, is there an easier way to do this? is there a formula that makes it so i don't have to carry so much cognitive load when i'm trying to solve these problems? and there is. since this force component is always the component that's perpendicular to the r, we can take that into account when writing down the formula. in other words, the way you find that perpendicular component is by taking the magnitude of the total force, the 10 newtons, and you multiply by sine of the angle between the r vector and the f vector. that's what we did to get this five newtons, so why not just write down this formula explicitly in terms of the total force times sine theta? that's gonna be the perpendicular component, and then multiply by r. so what this represents is this here, this f sine theta is f perpendicular, and then you multiply by r just like we always do. now in most textbooks you'll see it written like this. they like putting the sine theta at the end. looks a little cleaner. so if we do f times r times sine theta, now we can just plug in the entire 10 newtons in for the force, the entire two meters in for the r, and this theta would be the angle between the force and the r vector, but that's crucial. you gotta remember if you're gonna use this formula instead of this formula, you've gotta remember that this angle here is always the angle between the force vector and the r vector, which is the vector from the axis to the point where the force is applied. which in this case, was 30 degrees. so sometimes it's not obvious. how do you figure out the angle between f and r? well first you identify the direction of f and the direction of r. the safest way to figure it out would be to imagine taking this f vector and just moving it so its tail is at the tail of the r vector. and then you'd want to figure out okay, how much angle is there between this f and this r? well alternate interior angles again, that makes 30. so that is the angle. the angle between the f vector and the r vector is the angle we're looking for when we're solving for the torque exerted by a certain force. so let's use this formula. let me take this formula, let's take this, we're gonna use this to solve another example, 'cause the only way to get good at this and to not fear it is to practice a few. let's take our new formula, torque is f r sine theta, and let's say there was a force applied right here. and let's say you were given these distances here and we want to figure out how much torque does this force of 20 newtons apply if it's at this angle of 60 degrees. so we use our formula. we're gonna use this f is the entire f. now we don't have to break the f into components. we can just say that it's the entire 20 newtons of force. the entire magnitude of the force times r, but we got all these. we got three different rs here. which one do we use? remember, r is defined to be from the axis, which again is gonna be in the middle, to the point where the force was applied. that's this way, so the magnitude of r is one. it's not three, it's not four. if you're given multiple numbers you have to be careful. you have to select that vector that goes from the axis to the point where the force is applied, so this is the magnitude of that vector, which is one meter. and then it's gonna be sine of the angle between the force vector and the r vector. so think about it. force goes this way, down and right. r goes to the left. the true angle between r and f would be we'd have to imagine moving f so that they're tail to tail, and then we could say that f is gonna point down and right. r goes to the left. the angle between them would be this much angle. now we can find that in a variety of ways. one thing we could do is imagine making a right triangle here. if that's 60 degrees and this is 90, then this has to be 30 degrees since the interior angles of a triangle have to add up to 180. and if that's 30 and this is 90, then that angle has to be 120. so we can stick 120 degrees up here as the actual angle between the force vector and the r vector. now if you missed that, the reason we're saying 120 is because 90 plus 30 is 120. so if the angle between r and f is 90 degrees plus 30 degrees, then it's gonna be 120 degrees. that's why we're putting 120 up here as the angle between r and f, but you might be concerned. you might be like, that was a lot of work. i don't want to have to do that. i just want to take my f vector and determine what the angle is between f and r. do i really have to imagine moving it? and you don't, so it's not that hard. yes technically, tail to tail is the way to determine the angle between two vectors, but head to head gives you the same angle. so i could've just looked at this angle here. i knew that this was 60, and i knew 180 minus 60 gives me 120, so that's another way to figure out the angle you put into here. so in other words, you do not have to imagine moving this vector tail to tail. if the vectors are butting heads, if you have your f vector and your r vector butting heads, just find the angle between the f vector and the r vector that way. it'll still give you the same angle, which is 120 degrees. now you might wonder, what if i totally screw up? what if instead of putting in 120, i just throw in the 60? i mean that was the angle that was given. what would happen then? turns out you'd still get the right answer. the torque formula is kind in this sense because even if i put in 60, sine of 60 is the same as sine of 120. that's not a coincidence here. it's because this angle here, this 120 between f and r is supplementary to this 60 degrees. think about it. this whole angle from this point all the way to there is 180. if this is 120, this 60 degrees would have to be the supplementary angle 'cause these have to add up to 180. and the sine of supplementary angles gives you the same answer. so if i plug in 60 degrees up here it would still work. so long story short, even though we defined the angle between vectors as the angle between them when they're tail to tail, you put 'em head to head, that still gives you the same angle as tail to tail, and since we're taking sine of that angle, we can use either of these supplementary angles to get the same answer. so just stick your f vector next to your r vector, find either of these angles. you can use that in this torque formula and you'll get the right answer. so recapping, you can find the torque from a force by taking the perpendicular component of that force and multiplying by the magnitude of the r vector where this r vector is the vector that points from the axis to the point where the force is applied. and by perpendicular, we mean perpendicular to the r vector. or you could use this formula where f would represent the entire magnitude of the force. r would be the magnitude of the r vector, and the theta in here represents the angle between the force and the r vector when they're head to head, when they're tail to tail, or because sine of supplementary angles are equal, you could also take the supplementary angle to that angle between f and r.",t_55fbaaacf500,other,0
c_2b2563f2c8df,"sal analyzes two different factorizations of 16x^2-64 and determines whether they are correct.  - [voiceover] moussa and fatu were each asked to factor the quadratic expression 16 x-squared minus 64. their responses are shown below. so moussa factored it this way. fatu factored it this way. which student wrote an expression that is equivalent to 16 x-squared minus 64? so i encourage you to pause the video and figure that out. which student wrote an expression that is equivalent to our original one, 16 x-squared minus 64? well let's work through it together, so let's see if first we can factor this out somehow to get what moussa got and it looks like moussa first factored out a 16 and then he was left with a difference of squares. so let's see if we can do that. so, we can write our original expression. 16 x-squared minus 64, we can write that as 16 times x-squared minus 16 times four. and when you write it like that, it's very clear that you can factor out a 16. so this is going to be equal to 16 times what you have left over is x-squared minus four and then x-squared minus four, that's a difference of squares right over there. so, that part we can factor as, so we have our original 16 and then... this part right over here, we can write as x plus two times x minus two. x plus two times x minus two. if what i just did in this last step, going from x-squared minus four to x plus two times x minus two doesn't make any sense, i encourage you to watch some of the introductory videos on factoring and difference of squares. but the basic idea, i have a form here of a-squared minus b-squared, so it's going to have the form of a plus b times a minus b and in this case it's x-squared minus two squared. so it's going to be x plus two times x minus two. so that's exactly what moussa got. so this one, so moussa, did get an expression that is equivalent to 16 x-squared minus 64. now let's think about fatu. so fatu didn't factor out a 16 from the get-go. it looks like he just immediately recognized that our original expression is itself a difference of squares even if we don't factor out a 16, and so let's re-write it. so our original expression, we could write as, so instead of writing, well i'm just going to write it like this, this is our original expression. 16 x-squared minus 64. that's the same thing as, 16 x-squared is the same thing as four x, the whole thing squared and then minus eight squared. so when you write it like this, it's clear that this is a difference of squares, so this is going to be four x plus eight times four x minus eight. four x plus eight times four x minus eight. once again, if this last step that i did doesn't make a lot of sense i encourage you to watch the video on factoring difference of squares where we go a lot more into the intuition of it. but when you see it this way you realize that fatu also got an expression that is equivalent to 16 x-squared minus 64, so they both did.",t_afa80e7cd8f9,other,0
c_f4ef8e48c5ba,"create a memorable class mascot.jump to navigation  class mascot  class mascot  mark poe/shutterstock.com  many sports teams have a mascot—a character who represents the team in a memorable, sometimes goofy way. now imagine that you need to create a mascot for one of your classes in school. use your best creative thinking to come up with a great mascot.  your turn follow the directions below to create a mascot for a class you are taking.  list at least ten possible mascots for the class.  pick your three favorite ideas and tell why each one would represent the class well.  choose your best idea and list at least five great names for it. choose the best one.  draw a picture of the mascot.  list at least three possible catch-phrases for your mascot. choose the best one.  list at least three signature moves your mascot makes.  compare your mascot to other mascots created for the class.  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_3912319b6628,other,0
c_7289341c9bef,"learning objectives  compare the two classes of antibiotics: bactericidal and bacteriostatic antibiotic  antibiotics can be divided into two classes based on their mechanism of action. bactericidal antibiotics kill bacteria; bacteriostatic antibiotics inhibit their growth or reproduction.  one way that bactericidal antibodies kill bacteria is by inhibiting cell wall synthesis. examples include the beta-lactam antibiotics (penicillin derivatives (penams) ), cephalosporins (cephems), monobactams, and carbapenems) and vancomycin. other ways that bactericidal antibiotics kill bacteria include inhibiting bacterial enzymes or protein translation. other batericidal agents include daptomycin, fluoroquinolones, metronidazole, nitrofurantoin, co-trimoxazole and telithromycin. aminoglycosidic antibiotics are usually considered bactericidal, although they may be bacteriostatic with some organisms. the mbc (minimum bactericidal concentration) is the minimum concentration of drug which can kill 99.99% of the population.  mechanism of penicillin inhibition: penicillin and most other β-lactam antibiotics act by inhibiting penicillin-binding proteins, which normally catalyze cross-linking of bacterial cell walls.  bacteriostatic antibiotics limit the growth of bacteria by interfering with bacterial protein production, dna replication, or other aspects of bacterial cellular metabolism. this group includes: tetracyclines, sulfonamides, spectinomycin, trimethoprim, chloramphenicol, macrolides and lincosamides. they must work together with the immune system to remove the microorganisms from the body. however, there is not always a precise distinction between them and bactericidal antibiotics. high concentrations of some bacteriostatic agents are also bactericidal. the mic (minimum inhibitory concentration) is the minimum concentration of drug which can inhibit the growth of the microorganism.  structure of tetracycline: tetracycline antibiotics are protein synthesis inhibitors, inhibiting the binding of aminoacyl-trna to the mrna-ribosome complex. they do so mainly by binding to the 30s ribosomal subunit in the mrna translation complex.  further categorization is based on their target specificity. “narrow-spectrum” antibacterial antibiotics target specific types of bacteria, such as gram-negative or gram-positive bacteria, whereas broad-spectrum antibiotics affect a wide range of bacteria, usually both gram positive and gram negative cells. following a 40-year hiatus in discovering new classes of antibacterial compounds, three new classes of antibacterial antibiotics have been brought into clinical use: cyclic lipopeptides (such as daptomycin), glycylcyclines (such as tigecycline), and oxazolidinones (such as linezolid).  key points  bactericidal antibodies inhibit cell wall synthesis.  bacteriostatic antibiotics limit the growth of bacteria by interfering with bacterial protein production, dna replication, or other aspects of bacterial cellular metabolism.  bacteriostatic antibiotics must work together with the immune system to remove the microorganisms from the body.  key terms  bactericidal: an agent that kills bacteria.  bacteriostatic: a drug that prevents bacterial growth and reproduction but does not necessarily kill them. when it is removed from the environment the bacteria start growing again.  licenses and attributions  cc licensed content, shared previously  curation and revision. provided by: boundless.com. license:  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  cc licensed content, specific attribution  antibacterial. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antibacterial (http://en.wikipedia.org/wiki/antibacterial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antimicrobial. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antimicrobial (http://en.wikipedia.org/wiki/antimicrobial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  penicillin. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/penicillin (http://en.wiktionary.org/wiki/penicillin)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antimicrobial. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/antimicrobial (http://en.wiktionary.org/wiki/antimicrobial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  alexander fleming. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:alexander_fleming.jpg (http://en.wikipedia.org/wiki/file:alexander_fleming.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  antimicrobial. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antimicrobial (http://en.wikipedia.org/wiki/antimicrobial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  chemotherapy. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/chemotherapy (http://en.wiktionary.org/wiki/chemotherapy)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  micro-organism. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/micro-organism (http://en.wikipedia.org/wiki/micro-organism)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infection. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/infection (http://en.wiktionary.org/wiki/infection)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  alexander fleming. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:alexander_fleming.jpg (http://en.wikipedia.org/wiki/file:alexander_fleming.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  louis pasteur. provided by: wikipedia. located at: . license:  http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg (http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  antibacterial. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antibacterial (http://en.wikipedia.org/wiki/antibacterial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antibacterial. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antibacterial%23side-effects (http://en.wikipedia.org/wiki/antibacterial%23side-effects)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antibiotics. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antibiotics (http://en.wikipedia.org/wiki/antibiotics)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  production of antibiotics. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/production_of_antibiotics (http://en.wikipedia.org/wiki/production_of_antibiotics)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antibacterial. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/antibacterial (http://en.wiktionary.org/wiki/antibacterial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  bactericidal. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/bactericidal (http://en.wiktionary.org/wiki/bactericidal)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  bacteriostatic. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/bacteriostatic (http://en.wikipedia.org/wiki/bacteriostatic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  alexander fleming. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:alexander_fleming.jpg (http://en.wikipedia.org/wiki/file:alexander_fleming.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  louis pasteur. provided by: wikipedia. located at: . license:  http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg (http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  microbial cultures fridge. provided by: wikimedia. located at: . license:  http://commons.wikimedia.org/wiki/file:microbial_cultures_fridge.jpg (http://commons.wikimedia.org/wiki/file:microbial_cultures_fridge.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  pharmacology/antibiotics. provided by: wikibooks. located at: . license:  http://en.wikibooks.org/wiki/pharmacology/antibiotics (http://en.wikibooks.org/wiki/pharmacology/antibiotics)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antibacterial. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antibacterial (http://en.wikipedia.org/wiki/antibacterial)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  gram stain. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/gram_stain (http://en.wikipedia.org/wiki/gram_stain)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  broad-spectrum antibiotic. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/broad-spectrum_antibiotic (http://en.wikipedia.org/wiki/broad-spectrum_antibiotic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  broad spectrum antibiotic. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/broad%20spectrum%20antibiotic (http://en.wikipedia.org/wiki/broad%20spectrum%20antibiotic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  narrow spectrum antibiotic. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/narrow%20spectrum%20antibiotic (http://en.wikipedia.org/wiki/narrow%20spectrum%20antibiotic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  gram stain. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/gram%20stain (http://en.wikipedia.org/wiki/gram%20stain)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  alexander fleming. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:alexander_fleming.jpg (http://en.wikipedia.org/wiki/file:alexander_fleming.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  louis pasteur. provided by: wikipedia. located at: . license:  http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg (http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  microbial cultures fridge. provided by: wikimedia. located at: . license:  http://commons.wikimedia.org/wiki/file:microbial_cultures_fridge.jpg (http://commons.wikimedia.org/wiki/file:microbial_cultures_fridge.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  gram stain 01. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:gram_stain_01.jpg (http://en.wikipedia.org/wiki/file:gram_stain_01.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  bactericidal. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/bactericidal (http://en.wikipedia.org/wiki/bactericidal)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  antibiotic classification. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/antibiotic_classification%23classes (http://en.wikipedia.org/wiki/antibiotic_classification%23classes)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  pharmacology/antibiotics. provided by: wikibooks. located at: . license:  http://en.wikibooks.org/wiki/pharmacology/antibiotics%23bacteriostatic (http://en.wikibooks.org/wiki/pharmacology/antibiotics%23bacteriostatic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  bacteriostatic agent. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/bacteriostatic_agent (http://en.wikipedia.org/wiki/bacteriostatic_agent)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  bacteriostatic. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/bacteriostatic (http://en.wikipedia.org/wiki/bacteriostatic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  bactericidal. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/bactericidal (http://en.wiktionary.org/wiki/bactericidal)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  alexander fleming. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:alexander_fleming.jpg (http://en.wikipedia.org/wiki/file:alexander_fleming.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  louis pasteur. provided by: wikipedia. located at: . license:  http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg (http://simple.wikipedia.org/wiki/file:louis_pasteur.jpg)  public domain: no known copyright (https://creativecommons.org/about/pdm)  microbial cultures fridge. provided by: wikimedia. located at: . license:  http://commons.wikimedia.org/wiki/file:microbial_cultures_fridge.jpg (http://commons.wikimedia.org/wiki/file:microbial_cultures_fridge.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  gram stain 01. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:gram_stain_01.jpg (http://en.wikipedia.org/wiki/file:gram_stain_01.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  file:penicillin inhibition.svg - wikipedia, the free encyclopedia. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/w/index.php?title=file:penicillin_inhibition.svg&page=1 (http://en.wikipedia.org/w/index.php?title=file:penicillin_inhibition.svg&page=1)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  tetracyclines. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:tetracyclines.png (http://en.wikipedia.org/wiki/file:tetracyclines.png)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)",t_5a784af1153a,other,0
c_add383cabea2,"we derive the natural response of an rc circuit and discover it has an exponential form.  - [voiceover] now what i want to to do for the rc circuit is a formal derivation of exactly what these two curves look like. and then we'll have a precise definition of the natural response. what i want to do now is draw our circuit again. there's r, there's c. and we have some initial voltage, we said, on the capacitor, which is v naught. and what we want to find is v of t. and there's r, and there's c. so let me also label the currents in these guys. this is the current in the resistor, and this is the current in the capacitor. so now i'm gonna write the two voltage current relationships for these two components. and ohm's law tells me that equals one over r times v. and the current in a capacitor, this is ir, current in a capacitor equals c times dv, dt. that's the two currents in our devices. now, gonna use kirchhoff's current law on this node right here, and that says that all the currents flying out of that node have to add up to zero. so let's do that. let's say ic plus ir equals zero. this is kcl, kirchhoff's current law. c dv, dt, plus one over r, times v, equals zero. now i'm just gonna divide through by c just to be tidy. dv, dt plus one over rc, times v, equals zero. so what we have here, this expression here is referred to as an ordinary differential equation. it has a derivative in it, and that's what makes it a differential equation, and you can go look up ode and search for this in khan academy and elsewhere and in the mathematical videos, you'll find out different ways to solve this equation. now we're gonna do the same thing here, and we're gonna try to find an expression for v of t. we're gonna define v of t in a way that makes this equation true. so we plug the function in here, whatever it is, and then we take its derivative and plug that in here and that has to make this whole expression true. there's a couple of different ways to do this, and the one that we're gonna use here is we're gonna guess at an answer. so what we need is, we need a function whose derivative looks kind of like itself, because this thing has to add up to zero. so that means that the function v and the function dv, dt they have to be of the same form so that they have a chance of adding up to zero. the function that i know whose derivative looks like itself is the exponential. so we're gonna propose that there's gonna be an exponential and the way we do it is say, we'll put in some constant here that we can adjust, and then we'll put some constant out here. so this is our guess. our guess is gonna be that the solution for v of t is gonna be something of the form, some constant times e to another constant, s, times t. the way we test our guess is to put it back into the equation and see if it works. and if it does, then we made a good guess. if it doesn't work, then we have to go back and try something else. so one of the things we need, we're gonna plug v of t in right here. we're gonna need derivative of v with respect to time. so let's take a derivative here. equals d dt of k, e to the st. and that equals k, and the s comes down. and e to the st remains. so we just took the derivative of our proposed solution and now we're gonna plug it into the equation and see what happens. so now i'm gonna plug in the derivative that we had, plus the proposed solution, and see if our equation comes out true. so dv, dt is sk, e to the st, plus one over rc stays here. and we plug in v, and v was ke to the st. and that'll all equal zero. now i'm gonna factor out, here's the common term for each one of these, so we'll just factor that out. so now we get ke to the st, times s plus one over rc equals zero. okay, now let's take a little peek at this. we have to make this zero by the way we pick k and s. how can we make this zero? there's three terms in here, there's three terms in the product. there's this, this, and that. any three of these terms could be zero. the first one, k is zero, that's a boring one because it says if we have a circuit with no energy it sits there with no energy. so that's not so interesting. now, e to the st, we can make that go to zero but that takes a long time because we have to let t go to infinity. s would have to be a negative number, and t would have to go to infinity, which is a long time to wait for something to happen, so that's not a very interesting solution either. so here's the interesting one. the interesting one is when s plus rc equals zero so the interesting solution is s plus one over rc equals zero, and that says that s equals minus one over rc. that makes this solution true. and if that's the case, now we can say v of t, we're making good progress here, k, some k, times e to the minus t over rc. now something really interesting just happened here. look up here where we have this rc term here. see this right here? this whole exponent has to have no units by the time we evaluate it. that means that rc has to have units of time. rc is a measure, it's in seconds. rc is the units of r times c, ohms times farads, is actually seconds. this whole exponent has to have no units by the time we evaluate it. and that means that rc has to have units of time. and it's actually ohms times farads, comes out to be seconds. now we solve for s, and that means we only have to find k. let's work on k now. k is a variable here, time is a variable, and voltage is a variable. if we knew v and t at the same time, we would be able to figure out k. and there's a time when we do know that. and that is t equals zero. at t equals zero we know that the battery was hooked up and there's a bunch of charge on the capacitor so we know that the voltage on the capacitor at time zero, is equal to v naught. so now we have a pair of variables here. we know v and t at the same time, so let's plug that into our proposed solution and see how k pops up. so we're gonna put these two into our proposed solution and see what happens to k. v, at time equals zero, is v naught, and that's equal to k times e to the minus t, minus zero at time zero, over rc. now this whole expression is e to the zero, or one. so it drops out of the expression and all we get is k equals v naught. k is the starting voltage on the capacitor. and that gives us to our final answer, which is v of t equals v naught, starting voltage, e to the minus time over rc. we can go one small step further and find out what is i of t. well, i of t is equal to v of t over r, that's just ohm's law, and so i of t equals v naught over r, e to the minus t over rc. that is the natural response of an rc circuit.",t_cc0c87525651,other,0
c_39284a06a3eb,"most people assume that the government prints money, and that is how money is created. that is not entirely true. watch this video to find out the role that banks play in the creation of the money supply.  - [instructor] let's say, for some reason, you had lent the government $1,000, and so the government has given you a formally issued piece of paper that says, ""hey, we, the government, owe you $1,000."" this is issued by the treasury. this could be a treasury bond. it could be a t-bill of some kind. and let's say that the federal reserve, the central bank is interested in inserting money into our system. so let's say this is the federal reserve right over here. federal reserve. and so what they do is they create $1,000 of federal reserve notes, what we associate as paper money, and they pay it to you and they buy the treasury, so the treasury goes to the federal reserve from you. and so, in an exchange, you get this newly created money that the federal reserve just created. so, there you go. you have, this is $1,000. now, what would you likely do with that $1,000? well, it might not be safe to walk around town with your pockets bulging like that, so a lot of folks would deposit it into a bank. so let's think about what would happen to the bank's balance sheet. so, you go to the bank a and i'm just gonna think about what was the balance sheet, the pre-existing balance sheet for the bank, but let's just think about what happens to its assets and its liabilities when you make the deposit. a for assets, l for liabilities. if you deposit those thousand dollars, then your assets for the bank is going to get $1,000 in reserves, but you didn't just give them the money. they have a liability to you. you should have a checkable deposit account now, so we could say checking account. so now, you have a $1,000 checking account which you would use an asset for yourself but it's a liability for the bank. at any time, you could come and ask for that thousand dollars. $1,000 checking account and this would be for you. now, we've already spent several videos talking about fractional-reserve lending and there's two ways we can conceptualize it as we've seen in those videos but i'm gonna go with the simpler version of fractional-reserve lending. and so this bank says, ""look, we are in a world ""where our reserve requirement,"" i will do a reserve requirement. this actually is a typical reserve requirement. the reserve requirement in this country is 10%, which says that the bank only has to keep 10% of these cash reserves and then it could loan out the rest, and so it does that. that's its business model or a significant part of its business model. and so, what it does is instead of having $1,000 in reserves, it keeps 10%, so it keeps $100, and it loans out the rest. and so, it loans out $900. so, it's loaning out now $900 to someone else, hopefully someone who is good for the money, who maybe they're gonna invest it into their business or they're going to buy a house, or whatever else. now once again, the bank just didn't give them the money. in exchange, they get an asset, which is an iou from that person. that person owes the bank money. they owe them $900. so, we could say that in exchange for giving 'em that cash, they're going to have a $900 loan on their balance sheet as an asset. now once again, the person that they lent the money to, the loan would be a liability, they owe the money, but for the bank, that's an asset. ""hey, someone owes me, the bank, $900."" but then what's this person going to do? well once again, their pocket's are gonna bulge quite as much but they still might not wanna walk around town with $900 in their pocket, so they are likely to deposit in a bank and they could deposit it in bank a or they could deposit it in another bank. let's call it very creatively, bank b, all right (chuckles). so, bank b, same exercise. i think you might see where this is going, so its assets, its liabilities. and so they go and they deposit this $900, so you have $900 right over there. and the corresponding liability, that person then give the money to the bank, that person can demand that money at any point from the bank, and so you have a $900 checking account, checking account. and that person would drop on that checking account to buy the machinery for their business or whatever else. but once again, we have a 10% reserve requirement, which says that the bank only has to keep 10% of that, and so their business model is they do only keep 10% of it and then the rest of it, they loan out. so, they loan out $810. it could be a loan or it could be multiple loans altogether. and i think you see where this is going. so, this is lent out to someone else, so now we have $810, which can then be deposited in another bank, bank c. they can lend out 90% of that and that process keeps going on and on and on and on. so, an interesting question is given this infusion of a thousand dollars and given this reserve requirement, how much total money has been created? well, in one other videos, we talk about the multiple measures of the money supply. when the federal reserve put this $1,000, a federal reserve notes into circulation, they increased the monetary base by $1,000, but one measure of the monetary supply is, well, what are the federal reserve notes, the coins, and the paper money that's in circulation, plus the amount of checkable deposits, and we talk about that in other videos as m1. and so, our m1 over here, what's it gonna be? well, this person has a thousand dollar checking account, $1,000 checking out, they think they have $1,000 that they can write checks against and they do. and this person has a $900 checking account, $900 checking out. and then this person right over here that when they deposit their money, they're gonna think they have an $810 checking account. they have that. and then that process, they're gonna go on and on and on and on. someone else, when this $810 gets deposited, the bank's gonna lend out 90% of that. that person's gonna think they have that amount of money. and so what we do is we're just multiplying by .9 every time. we're multiplying by one minus the reserve requirement every time. and we've done the mathematics on this multiple times. this is going to be equal to $1,000, the initial amount that was put into the monetary base, times one over one minus 0.9 and that is just going to be equal to $1,000 times one over 0.1 or you could just view this as one over the reserve requirement. it just happened to be 0.1 in this example. reserve requirement. and you could do the math on what that's going to be. one divided by 1/10 is going to be 10, and so our m1 money supply that has been created in this very simple example is going to be equal to 10 times the thousand dollars, so it's gonna be equal to $10,000. so, big picture. when the monetary base is increased by a certain amount, if you know the reserve requirement and if you assume that all the banks minimize their reserves, that they keep only the 10%, they don't keep 11% or 12% or 20%, then what this calculation is gonna show you is what is going to be the maximum effect on m1 given that infusion into the monetary base. and all it is is the amount that was infused times one over the reserve requirement.",t_cba97e484d52,other,0
c_744ae2a53f5d,"41-45, polygons, exterior angles  we're on 41. lea made two candles in the shape of right rectangular prisms. so i'm assuming when they say right rectangular prisms, they mean a kind of three dimensional rectangular shape. the first candle is 15 centimeters height, 8 centimeters long and 8 centimeters wide. so let's see, it's 15 centimeters high. so that's 15. 8 centimeters long. so maybe that's 8. and 8 centimeters wide. so maybe it goes back 8. so it looks something like that. that's candle number one. the second candle is 5 centimeters higher, but the same length and width. so the second candle is just 5 centimeters higher. so it looks something like this. where this is still 8 and 8. but the height is 5 more than 15, so it's 20. fair enough. how much additional wax was needed to make the taller candle? so if you think about it, we just have to think about how much incremental volume did we create by making that section five centimeters higher? so this candle, you can kind of view it as going up to here. it's 15 centimeters high. and then we added 5 right here. so what's the volume of this volume right there? so it's 8 by 8 by 5. so 5 times 8 times 8. 5 times 8 is 40 times 8 is 320. so we have to add 320 cubic centimeters more of wax to make the taller candle. problem 42. two angles of a triangle have measures of 55 and 65. which of the following could not be a measure of an exterior angle of the triangle? so i think this is a good time to introduce what an exterior angle even is. so if i draw any polygon, and i'll draw a triangle since that's what this question is about. so let's say that that's my triangle. an exterior angle of one of the vertices is, you essentially extend one of the lines of the vertices out. so this is an interior angle right here. the exterior angle is if you extend this line out, so if i were to draw a dotted line that extends out this bottom line. this is the exterior angle right here. as you can see, it's going to be the supplement to this interior angle. and we could have extended the line out there. or we could have extended this line this way. and we could have used this one. but we wouldn't add these two if we wanted to find all of the exterior angles. the exterior angle of this vertex right here is either this one or this one. and they are the same because both of these are supplements of this angle. this angle plus either of this angle or that one will add up to 180 degrees. so that's what an exterior angle is. so let's go back to the question. two angles of a triangle have measures of 55 and 65. so let's say this is 55 and this is 65. which of the following could not be a measure of an exterior angle of the triangle? well we can figure out all of the exterior angles. so first of all what's this third interior angle going to be? well they all have to add up to 180. so let's call that x. so we know that x plus 65 plus 55 is equal to 180. 65 plus 55 is 120. 120 is equal to 180. so x is equal to 60 degrees. so this angle right here, i'll do it in another color, this is 60 degrees. so what are all the possible exterior angles. so if i extended this line out like i did in the example of when i defined what an exterior angle is, this exterior angle would be 120 degrees. if were to do it here, if i would extend this out right here, what would this exterior angle be? let's see, this plus 65 is 180. what's 180 minus 65. 180 minus 60 is 120, so this would have to be 115. so that exterior angle is 115. and then this one, let's see if i extend it out. one of the two lines that form the vertex. this is going to be supplementary to 55. so 180 minus 55 is 125. 180 minus 60 would be 120, and then it's only 55 so 125. so the three supplementary, or the three exterior angles of this triangle are 125. and they want to know what could not be a measure. so 125 is a measure of an exterior angle. so is 115. and so is 120. so our answer is d. none of the exterior angles are equal to 130 degrees. problem 43. ok, they say the sum of the interior angles of a polygon is the same as the sum of its exterior angles, what type of polygon is it? and this is an interesting question. and it's something to experiment with for yourself. but i want you to draw random polygons with angle measures, because you know what the angles all have to add up to in a polyogon. and i think you'll find, that no matter what polygon you draw, all of the exterior angles are going to add up to 360 degrees. in fact, in that example we just did, what were they they were, for that triangle. if i remember, it's 115, 125, and 120. this was for a triangle. if you added them up, you get 5 plus 5, 10. and then that's 6. 360 degrees. for that triangle, which had kind of strange angles. it wasn't like an equilateral triangle or anything beautiful. and it's also the same if i were to draw a rectangle. well let me not draw a solid rectangle. so if i have a rectangle like that. what are the exterior angles here? well, i can continue this line right here. this angle right here is going to be 90. i could go either way, i could continue this up, but you can only do it once though for each of the vertices. well that exterior angle is 90. i could go like that, that exterior angle is 90. i could go like that. that exterior angle is 90. so once again, 90 plus 90 plus 90 plus 90 that's 360 degrees. so it's a good thing to know that the sum of the exterior angles of any polygon is actually 360 degrees. and maybe we'll prove that in another video for a polygon with n sides. but now that we know that, so they say that the sum of the interior angles of a polygon is the same as the sum of its exterior angles, this is the same as saying the sum of the interior angles is equal to 360. because this is always going to be 360 degrees no matter what the polygon is. so they're essentially saying what polygon's interior angles add up to 360 degrees. and that of course is a quadrilateral. my mouth got ahead of me. and if you think in a quadrilateral you have 90, 90, 90, 90 and they add up to 360 degrees. next question. let me copy and paste a couple of them so i don't have to keep doing this. ok. all right. what is a measure of angle x. so this is an exterior angle to the vertex b. so how do we figure this out? well there's kind of a fast way and a slow way. and the slow way is to figure out this angle. because you know that the sum of the angles add up to 180. and you say oh, x is going to be 180 minus that. let's just do it the slow way and i think you'll see the intuition of a slightly faster way you could have done it. this plus 60 plus 25 is 85 degrees. let's call this angle y. so we know that y plus 85 degrees is equal to 180. i got this 85 just by adding 60 to 25. so this is just saying that the interior angles of a triangle add up to 180 degrees. and we could figure out y right now. you could subtract 85 from both sides and you'd get y is equal to 95. and then we could figure out x from y, because x is the supplement of y. so then you could say x is equal to 180 minus 95 and you'd get 85. and that would be fine, it didn't take you too long, c is the answer. but a slightly faster way of saying it. ok, y plus 85 is equal to 180. and you also know that y plus x is equal to 180. so clearly, x is equal to 85. if you add 85 to y, you get 180, if you add x to y you get 180. so x would be 85. that would be a slightly faster way of thinking about it. but either way is fine if you're not under time pressure. ok, problem 45. if the measure of an exterior angle of a regular polygon. regular polygon, so that means that all of the angles are congruent. of a regular polygon is 120 degrees, how many sides does the polygon have? so this is the vertex in question, let's say that's the vertex of this polygon we're thinking about. we want to measure its exterior angles. so i'd extend one side of the vertex. and they're saying that that is 120 degrees. that tells me that the interior angle at that vertex is 60 degrees. it's the supplement to the exterior angle. so what regular polygon has all of its sides equal to 60 degrees? well, the equilateral triangle. regular polygon, all the angles and all the sides are congruent. so an equilateral triangle looking something like that would do the trick. it's a regular polygon, all the sides are the same. and its angles are 60, 60 and 60. so when they say how many sides does the polygon have? it has three, it's a triangle. i'm out of time. i'll see you in the next video.",t_bb686ac001f6,other,0
c_1a843cd1b03e,"you can display the value of a variable using print or println. the following statements declare a variable named firstline, assign it the value ""hello, again!"", and display that value.  string firstline = ""hello, again!""; system.out.println(firstline);  when we talk about displaying a variable, we generally mean the value of the variable. to display the name of a variable, you have to put it in quotes.  system.out.print(""the value of firstline is ""); system.out.println(firstline);  for this example, the output is:  the value of firstline is hello, again!  conveniently, the syntax for displaying a variable is the same regardless of its type. for example:  int hour = 11; int minute = 59; system.out.print(""the current time is ""); system.out.print(hour); system.out.print("":""); system.out.print(minute); system.out.println(""."");  the output of this program is:  the current time is 11:59.  to output multiple values on the same line, it’s common to use several print statements followed by println at the end. but don’t forget the println! on many computers, the output from print is stored without being displayed until println is run; then the entire line is displayed at once. if you omit the println, the program might display the stored output at unexpected times or even terminate without displaying anything.",t_f5f118eca9cf,other,0
c_4fa96e7c9912,"given the algebraic expressions that represent a pair of supplementary angles, sal forms and solves an equation.  we're told that the measure of angle qpr-- so that's this angle right over here-- is 2x plus 122. and i'll assume that these are in degrees. so it's 2x plus 122 degrees. and the measure of angle rps-- so that's this angle right over here-- is 2x plus 22 degrees. and they ask us to find the measure of angle rps. so we need to figure out this right over here. so we would be able to figure that out if we just knew what x is. and lucky for us, we can use the information given to solve for x and then figure out what 2 times x plus 22 is. and the main big idea here, the thing that pops out here, is that the outside rays for both of these angle form a line. these two angles form a line. you could say that they are supplementary. both of these angles are supplementary. 2x plus 22 plus another 2x plus 122 is going to add up to 180. we know that this entire angle right over here is 180 degrees. so we can say that the measure of angle qpr, this angle right over here, 2x plus 122, plus the green angle, plus angle rps-- so plus 2x plus 22-- is going to be equal to 180 degrees. and now we can start simplifying this. we have two x's. we have another two x's. so those are going to add up to be 4x. and then we have 122 plus 22. so that's going to be 144. and the sum of those two are going to be equal to 180 degrees. we can subtract 144 from both sides. on the left-hand side, we're just going to be left with a 4x, this 4x right here. and on the right-hand side, we're going to have-- let's see, if we were subtracting 140, we would have 40 left. and then we have to subtract another 4, so it's going to be 36. divide both sides by 4, and we get x is equal to 9. now remember, we're not done yet. they didn't say solve for x. they said find the measure of angle rps, which is 2 times x plus 22 or 2 times 9 plus 22, which is 18 plus 22, which is equal to 40. so the measure of angle rps is 40 degrees.",t_2770a51a6786,other,0
c_590feb9cfb91,"loops are often used in programs that compute numerical results by starting with an approximate answer and iteratively improving it.  for example, one way of computing square roots is newton’s method. suppose that you want to know the square root of a. if you start with almost any estimate, x, you can compute a better estimate with the following formula:  \[ y = \dfrac{x + a/x}{2} \nonumber \]  for example, if a is 4 and x is 3:  >>> a = 4.0 >>> x = 3.0 >>> y = (x + a/x) / 2 >>> print y 2.16666666667  which is closer to the correct answer \( (\sqrt{4} = 2) \). if we repeat the process with the new estimate, it gets even closer:  >>> x = y >>> y = (x + a/x) / 2 >>> print y 2.00641025641  after a few more updates, the estimate is almost exact:  >>> x = y >>> y = (x + a/x) / 2 >>> print y 2.00001024003 >>> x = y >>> y = (x + a/x) / 2 >>> print y 2.00000000003  in general we don’t know ahead of time how many steps it takes to get to the right answer, but we know when we get there because the estimate stops changing:  >>> x = y >>> y = (x + a/x) / 2 >>> print y 2.0 >>> x = y >>> y = (x + a/x) / 2 >>> print y 2.0  when y == x, we can stop. here is a loop that starts with an initial estimate, x, and improves it until it stops changing:  while true:     print x     y = (x + a/x) / 2     if y == x:         break     x = y  for most values of a this works fine, but in general it is dangerous to test float equality. floating-point values are only approximately right: most rational numbers, like 1/3, and irrational numbers, like \( \sqrt{2} \), can’t be represented exactly with a float.  rather than checking whether x and y are exactly equal, it is safer to use the built-in function abs to compute the absolute value, or magnitude, of the difference between them:  if abs(y-x) < epsilon:         break  where epsilon has a value like 0.0000001 that determines how close is close enough.  exercise \(\pageindex{1}\)  encapsulate this loop in a function called square_root that takes a as a parameter, chooses a reasonable value of x, and returns an estimate of the square root of a.",t_4ad79daacc32,other,0
c_f818dc8cf929,"function values can be positive or negative, and they can increase or decrease as the input increases. here we introduce these basic properties of functions.  - [voiceover] what i hope to do in this video is look at this graph y is equal to f of x and think about the intervals where this graph is positive or negative and then think about the intervals when this graph is increasing or decreasing. so first let's just think about when is this function, when is this function positive? well positive means that the value of the function is greater than zero. it means that the value of the function this means that the function is sitting above the x-axis. so it's sitting above the x-axis in this place right over here that i am highlighting in yellow and it is also sitting above the x-axis over here. and if we wanted to, if we wanted to write those intervals mathematically. well let's see, let's say that this point, let's say that this point right over here is x equals a. let's say that this right over here is x equals b and this right over here is x equals c. then it's positive, it's positive as long as x is between a and b. at x equals a or at x equals b the value of our function is zero but it's positive when x is between a and b, a and b or if x is greater than c. x is, we could write it there, c is less than x or we could write that x is greater than c. these are the intervals when our function is positive. let me write this, f of x, f of x positive when x is in this interval or this interval or that interval. so when is f of x negative? let me do this in another color. f of x is going to be negative. well, it's gonna be negative if x is less than a. so this is if x is less than a or if x is between b and c then we see that f of x is below the x-axis. f of x is down here so this is where it's negative. so here or, or x is between b or c, x is between b and c. and i'm not saying less than or equal to because at b or c the value of the function f of b is zero, f of c is zero. that's where we are actually intersecting the x-axis. so that was reasonably straightforward. now let's ask ourselves a different question. when is the function increasing or decreasing? so when is f of x, f of x increasing? well increasing, one way to think about it is every time that x is increasing then y should be increasing or another way to think about it, you have a, you have a positive rate of change of y with respect to x. we could even think about it as imagine if you had a tangent line at any of these points. if you had a tangent line at any of these points the slope of that tangent line is going to be positive. but the easiest way for me to think about it is as you increase x you're going to be increasing y. so where is the function increasing? well i'm doing it in blue. so it's increasing right until we get to this point right over here, right until we get to that point over there then it starts decreasing until we get to this point right over here and then it starts increasing again. it starts, it starts increasing again. so let me make some more labels here. so let's say that this, this is x equals d and that this right over here, actually let me do that in green color, so let's say this is x equals d. now it's not a, d, b but you get the picture and let's say that this is x is equal to, x is equal to, let me redo it a little bit, x is equal to e. x is equal to e. so when is this function increasing? well it's increasing if x is less than d, x is less than d and i'm not gonna say less than or equal to 'cause right at x equals d it looks like just for that moment the slope of the tangent line looks like it would be, it would be constant. we're going from increasing to decreasing so right at d we're neither increasing or decreasing. but then we're also increasing, so if x is less than d or x is greater than e, or x is greater than e. and where is f of x decreasing? so f of x, let me do this in a different color. when is, let me pick a mauve, so f of x decreasing, decreasing well it's going to be right over here. it's gonna be right between d and e. between x equals d and x equals e but not exactly at those points 'cause at both of those points you're neither increasing nor decreasing but you see right over here as x increases, as you increase your x what's happening to your y? if you go from this point and you increase your x what happened to your y? your y has decreased. you increase your x, your y has decreased, you increase your x, y has decreased, increase x, y has decreased all the way until this point over here. so f of x is decreasing for x between d and e. so hopefully that gives you a sense of things. notice, these aren't the same intervals. that we are, the intervals where we're positive or negative don't perfectly coincide with when we are increasing or decreasing. so it's very important to think about these separately even though they kinda sound the same.",t_9c1425c5b459,other,0
c_fc6bf9b35a4a,"microwave engineers want to work with total voltage and current when possible and the art of design synthesis usually requires relating the total voltage and current world of a lumped element circuit to the traveling voltage world of transmission lines. this section develops the important abstractions that enable the total voltage and current view of the world to be used with transmission lines. the first step in this process is in section 2.3.1 where total voltages and currents are related to forward- and backward-  figure \(\pageindex{1}\): a terminated transmission line.  traveling voltages and currents. insight into traveling waves and reflections is presented in section 2.3.2. important abstractions are presented first for the input reflection coefficient of a terminated lossless line in section 2.3.3 and then for the input impedance of the line in section 2.3.4. the last section, section 2.3.5, presents a view of the total voltage on the transmission line and describes the voltage standing wave concept.  2.3.1 total voltage and current on the line  consider the terminated line shown in figure \(\pageindex{1}\)(a). assume an incident or forward-traveling wave, with traveling voltage \(v_{0}^{+}e^{−\jmath\beta z}\) and current \(i_{0}^{+}e^{−\jmath\beta z}\) propagating toward the load \(z_{l}\) at \(z = 0\). the characteristic impedance of the transmission line is the ratio of the voltage and current traveling waves so that  \[\label{eq:1}\frac{v_{0}^{+}(z)}{i_{0}^{+}(z)}=\frac{v_{0}^{+}e^{-\jmath\beta z}}{i_{0}^{+}e^{-\jmath\beta z}}=\frac{v_{0}^{+}(0)}{i_{0}^{+}(0)}=\frac{v_{0}^{+}}{i_{0}^{+}}=z_{0}\]  the reflected wave has a similar relationship (but note the sign change):  \[\label{eq:2}\frac{v_{0}^{-}e^{\jmath\beta z}}{-i_{0}^{-}e^{\jmath\beta z}}=\frac{v_{0}^{-}}{-i_{0}^{-}}=z_{0}\]  the load \(z_{l}\) imposes an additional constraint on the relationship of the total voltage and current at \(z = 0\):  \[\label{eq:3}\frac{v_{l}}{i_{l}}=\frac{v(z=0)}{i(z=0)}=z_{l}\]  when \(z_{l}\neq z_{0}\) there must be a reflected wave with appropriate amplitude to satisfy the above equations. now the total voltage  \[\label{eq:4}v(z)=v_{0}^{+}e^{-\jmath\beta z}+v_{0}^{-}e^{\jmath\beta z}\]  and the total current, \(i(z)\), is related to the traveling current waves by  \[\label{eq:5}i(z)=\frac{v_{0}^{+}}{z_{0}}e^{-\jmath\beta z}-\frac{v_{0}^{-}}{z_{0}}e^{\jmath\beta z}=i_{0}^{+}e^{-\jmath\beta z}+i_{0}^{-}e^{\jmath\beta z}\]  thus at the termination of the line \((z = 0)\),  \[\frac{v(0)}{i(0)}=z_{l}=z_{0}\frac{v_{0}^{+}+v_{0}^{-}}{v_{0}^{+}-v_{0}^{-}}\nonumber\]  this can be rearranged as the ratio of the reflected voltage to the incident voltage:  \[\frac{v_{0}^{-}}{v_{0}^{+}}=\frac{z_{l}-z_{0}}{z_{l}+z_{0}}\nonumber\]  this ratio is defined as the voltage reflection coefficient at the load,  \[\label{eq:6}\gamma_{l}=\gamma_{l}^{v}=\frac{v_{0}^{-}(0)}{v_{0}^{+}(0)}=\frac{v_{0}^{-}}{v_{0}^{+}}=\frac{z_{l}-z_{0}}{z_{l}+z_{0}}\]  that is, at the load  \[\label{eq:7}v_{0}^{-}=\gamma_{l}v_{0}^{+}\]  the relationship of the traveling waves on the line can also be described using the transmission coefficient \(t\) (this is the capital greek letter tau which looks the same as the english letter ‘t’.)  the voltage transmission coefficient from a port at position \(z\) to a port at position \(0\) is (for the transmission line)  \[\label{eq:8}t=t^{v}=\frac{v_{0}^{+}\text{ (at end of line)}}{v_{0}^{+}\text{ (at start of line)}}=\frac{v_{0}^{+}(0)}{v_{0}^{+}(z)}=\frac{v_{0}^{+}}{v_{0}^{+}e^{-\jmath\beta z}}=e^{\jmath\beta z}\]  the relationship in equation \(\eqref{eq:6}\) can be rewritten so that the input load impedance can be obtained from the reflection coefficient:  \[\label{eq:9}z_{l}=z_{0}\frac{1+\gamma^{v}}{1-\gamma^{v}}\]  similarly, the current reflection coefficient can be written as  \[\label{eq:10}\gamma^{i}=\frac{i_{0}^{-}}{i_{0}^{+}}=\frac{-z_{l}+z_{0}}{z_{l}+z_{0}}=-\gamma^{v}\]  the voltage reflection coefficient is used most of the time, so the reflection coefficient, \(\gamma\), on its own refers to the voltage reflection coefficient, \(\gamma^{v}=\gamma\).  there are several special cases that are noteworthy. the most important of these is the case when there is no reflected wave and \(\gamma=0\). to obtain \(\gamma=0\), the value of load impedance, \(z_{l}\), is equal to \(z_{0}\), the characteristic impedance of the transmission line as seen in equation \(\eqref{eq:6}\).  the total voltage and current waves on the line can be written as  \[\label{eq:11}v(z)=v_{0}^{+}[e^{-\jmath\beta z}+\gamma e^{\jmath\beta z}]\]  \[\label{eq:12}i(z)=\frac{v_{0}^{+}}{z_{0}}[e^{-\jmath\beta z}-\gamma e^{\jmath\beta z}]\]  from equations \(\eqref{eq:11}\) and \(\eqref{eq:12}\) it can be seen that the total voltage and current on the line consist of superpositions of incident and reflected waves.  example \(\pageindex{1}\): forward- and backward- traveling waves at an open circuit  a lossless transmission line is terminated in an open circuit. what is the relationship between the forward- and backward-traveling voltage waves at the end of the line?  solution  at the end of the line the total current is zero, so that \(i^{+} + i^{−} = 0\) and so  \[\label{eq:13}i^{-}=-i^{+}\]  the forward- and backward traveling voltages and currents are related to the characteristic impedance by  \[\label{eq:14}z_{0}=v^{+}/i^{+}=-v^{-}/i^{-}\]  note the change in sign, as a result of the direction of propagation changing but the positive reference for current is in the same direction. substituting for i− at the termination,  \[\label{eq:15}v^{+}=-v^{-}i^{+}/i^{-}=-v^{-}i^{+}/(-i^{+})=v^{-}\]  thus the total voltage at the end of the line, \(v_{\text{total}}\), is \(v^{+} + v^{−} = 2v^{+}\). note that the total voltage at the end of the line is twice the incident (forward-traveling) voltage.  example \(\pageindex{2}\): current reflection coefficient  a load consists of a shunt connection of a capacitor of \(10\text{ pf}\) and a resistor of \(60\:\omega\). the load terminates a lossless \(50\:\omega\) transmission line. the operating frequency is \(5\text{ ghz}\).  what is the impedance of the load?  what is the normalized impedance of the load (normalized to \(z_{0}\) of the line)?  what is the reflection coefficient of the load?  what is the current reflection coefficient of the load?  solution  \(c = 10\cdot 10^{−12}\text{ f};\: r = 60\:\omega ;\: f = 5\cdot 10^{9}\text{ hz};\: \omega = 2πf;\: z_{0} = 50\:\omega\)      \[z_{l} = r||c = (1/r + \jmath\omega c)^{−1} = 0.168 −\jmath 3.174\:\omega\nonumber\]  \(z_{l} = z_{l}/z_{0} = 3.368\cdot 10^{−3} −\jmath 0.063\).  this is the voltage reflection coefficient. \(\gamma_{l} = (z_{l} − 1)/(z_{l} + 1) = −0.985 −\jmath 0.126 = 0.993\angle 187.3^{\circ}\).  \(\gamma_{l}^{i} = −\gamma_{l} = 0.985 +\jmath 0.126 = 0.993\angle (187.3 − 180)^{\circ} = 0.993\angle 7.3^{\circ}\).  2.3.2 forward- and backward-traveling pulses  reflections at the end of a line produce a backward-traveling signal. forward- and backward-traveling pulses are shown in figure \(\pageindex{2}\)(a) for the situation where the resistance at the end of the line is lower than the characteristic impedance of the line \((z_{l} < z_{0})\). the voltage source is a step voltage that is zero for time \(t < 0\). at time \(t = 0\), the step is applied to the line and it begins traveling down the line, as shown at time \(t = 1\). this voltage step moving from left to right is called the forward-traveling voltage wave.  at time \(t = 2\), the leading edge of the step reaches the load, and as the load has lower resistance than the characteristic impedance of the line, the total voltage across the load drops below the level of the forward-traveling voltage step. the reflected wave is called the backward-traveling wave and it must be negative, as it adds to the forward-traveling wave to yield the total voltage. thus the voltage reflection coefficient, \(\gamma\), is negative and the total voltage on the line, which is all that can be directly observed, drops. a reflected, smaller, and opposite step signal travels in the backward direction and adds to the forward-traveling step to produce the waveform shown at \(t = 3\). the impedance of the source matches the transmission line impedance so that the reflection at the source is zero. the signal on the line at time \(t = 4\), the time for round-trip propagation on the line, therefore remains at the lower value. the easiest way to remember the polarity of the reflected pulse is to consider the situation with a short-circuit at the load. then the total voltage on the line at the load must be zero. the only way this can occur when a signal is incident is if the reflected signal is equal in magnitude but opposite in sign, in this case \(\gamma = −1\). so whenever \(|z_{l}| < |z_{0}|\), the reflected pulse will tend to subtract from the incident pulse.  the opposite situation occurs when the resistance at the load is higher than the characteristic impedance of the line (figure \(\pageindex{2}\)(b)). in this case the reflected pulse has the same polarity as the incident signal. again, to remember this, think of the open-circuited case. the voltage across the load doubles, as the reflected pulse has the same sign as well as magnitude as that of the incident signal, in this case \(\gamma = +1\). this is required so that the total current is zero.  a more illustrative situation is shown in figure \(\pageindex{3}\), where a more  figure \(\pageindex{2}\): reflection of a voltage pulse from a load: (a) when the resistance of the load, \(r_{l}\) is lower than the characteristic impedance of the line, \(z_{0}\); and (b) when \(r_{l}\) is greater than \(z_{0}\).  figure \(\pageindex{3}\): reflection of a pulse on an interconnect showing forward- and backward-traveling pulses. \(z_{l} > z_{0}\).  complicated signal is incident on a load that has a resistance higher than that of the characteristic impedance of the line. the peaking of the voltage that results at the load is typically the design objective in many long digital interconnects, as less overall signal energy needs to be transmitted down the line, or equivalently a lower current drive capability of the source is required to achieve first incidence switching. this is at the price of having reflected signals on the interconnects, but these are dissipated through a combination of line loss and absorption of the reflected signal at the driver.  2.3.3 input reflection coefficient of a lossless line  the reflection coefficient looking into a line varies with position along the line as the forward- and backward-traveling waves change in relative phase. referring to figure \(\pageindex{4}\), at a distance \(\ell\) from the load (i.e., \(z = −\ell\)), the input  figure \(\pageindex{4}\): terminated transmission line: (a) a transmission line terminated in a load impedance, \(z_{l}\), with an input impedance of \(z_{\text{in}}\); and (b) a transmission line with source impedance \(z_{g}\) and load \(z_{l}\).  figure \(\pageindex{5}\): the forward-traveling wave \(v^{+}(t, z) = |v^{+}| \cos(\omega t −\beta z) = |v^{+}| \cos(\omega t + \phi (z))\) and the backward-traveling wave \(v^{−}(t, z) = |v^{+}| \cos(\omega t +\beta z) = |v^{+}| \cos[\omega t + \phi (z)]\). the phase, \(\phi\), of the forward-traveling wave becomes increasingly negative along the line as \(z\) increases, and when reflected the phase \(\phi\) of the backward-traveling wave becomes increasingly negative as the wave moves away from the load (i.e. as \(z\) decreases).  reflection looking into a terminated lossless line is  \[\label{eq:16}\gamma_{\text{in}}|_{z=-\ell}=\frac{v^{-}(z=-\ell)}{v^{+}(z=-\ell)}=\frac{v^{-}(z=0)e^{-\jmath\beta\ell}}{v^{+}(z=0)e^{+\jmath\beta\ell}}=\frac{v^{-}(z=0)}{v^{+}(z=0)}\frac{e^{-\jmath\beta\ell}}{e^{+\jmath\beta\ell}}=\gamma_{l}e^{-\jmath 2\beta\ell}\]  note that \(\gamma_{\text{in}}\) has the same magnitude as \(\gamma_{l}\) but rotates in the clockwise direction (becomes increasingly negative) at twice the rate of increase of the electrical length \(\beta\ell\).  it is important to graphical concepts introduced later that there be a full appreciation for the angle of \(\gamma_{\text{in}}\) becoming increasingly negative at twice the rate at which the electrical length of the line increases. figure \(\pageindex{5}\) is a way of visualizing this. the transmission line here is \(\lambda/4\) long with an electrical length of \(90^{\circ}\) and is terminated in a load with reflection coefficient \(\gamma_{l} = +1\). at position \(z = 0\) the forward-traveling voltage wave is \(v^{+}(t, 0) = |v^{+}| \cos(\omega t)\), and this then propagates down the line in the \(+z\) direction. the forward-traveling voltage at point \(z = \lambda /8\) at \(t = 0\) will be the same as the voltage at \(z = 0\) at a time one-eighth of a period in the past. the voltage at \(z =\lambda/8\) is \(v^{+}(t, \lambda/8) = |v^{+}| \cos(\omega t − 2π/8)\), i.e. there is a phase rotation of \(−45^{\circ}\). then at \(z = \lambda /4\), \(v^{+}(t, \lambda/4) = |v^{+}| \cos(\omega t − 2π/4)\), i.e. at time \(t = 0\) there is a phase rotation of \(−90^{\circ}\) relative to \(v^{+}(0, 0)\), and this is the negative of the electrical length of the line. the voltage wave reflects at the load and becomes a backward-traveling wave. here \(\gamma_{l} = +1\) and so, at the load, the phase of the backward- and forward-traveling waves are the same. the backward-traveling wave continues to travel in the \(−z\) direction and its phase at \(t = 0\) becomes increasingly negative as \(z\) gets closer to the input of the line. the phase of the backward-traveling wave at \(z = 0\) is rotated \(−90^{\circ}\) with respect to the backward-traveling wave at the load, and has rotated \(−180^{\circ}\) relative to the forward-traveling wave at \(z = 0\). for a lossless line, in general, the angle of \(\gamma_{\text{in}} = [\text{phase of }v^{−}(z = 0)\) relative to the phase of \(v^{+}(z = 0)] + (\text{the phase of }\gamma_{l}) = −2(\text{electrical length of the line}) + (\text{the phase of }\gamma_{l})\).  2.3.4 input impedance of a lossless line  the impedance looking into a lossless line varies with position, as the forward- and backward-traveling waves combine to yield position-dependent total voltage and current. at a distance \(\ell\) from the load (i.e., \(z = −\ell\)), the input impedance seen looking toward the load is  \[\label{eq:17}z_{\text{in}}|_{z=-\ell}=\frac{v(z=-\ell)}{i(z=-\ell)}=z_{0}\frac{1+|\gamma|e^{\jmath(\theta -2\beta\ell)}}{1-|\gamma|e^{\jmath(\theta-2\beta\ell)}}=z_{0}\frac{1+\gamma_{l}e^{\jmath(-2\beta\ell)}}{1-\gamma_{l}e^{\jmath(-2\beta\ell)}}\]  another form is obtained by substituting equation \(\eqref{eq:6}\) in equation \(\eqref{eq:17}\):  \[\begin{align}z_{\text{in}}&=z_{0}\frac{(z_{l}+z_{0})e^{\jmath\beta\ell}+(z_{l}-z_{0})e^{-\jmath\beta\ell}}{(z_{l}+z_{0})e^{\jmath\beta\ell}-(z_{l}-z_{0})e^{-\jmath\beta\ell}}=z_{0}\frac{z_{l}\cos(\beta\ell)+\jmath z_{0}\cos(\beta\ell)}{z_{0}\cos(\beta\ell)+\jmath z_{l}\cos(\beta\ell)}\nonumber \\ \label{eq:18}&=z_{0}\frac{z_{l}+\jmath z_{0}\tan\beta\ell}{z_{0}+\jmath z_{l}\tan\beta\ell}\end{align}\]  this is the lossless telegrapher’s equation. the electrical length, \(\beta\ell\), is in radians when used in calculations.  2.3.5 standing waves and voltage standing wave ratio  the total voltage on a terminated line is the sum of forward- and backward-traveling waves. this sum produces what is called a standing wave. figure \(\pageindex{6}\) shows the total and traveling waveforms on a line terminated in a reactance and evaluated at times equal to multiples of an eighth of a period. here the traveling waves have the same amplitude indicating that the termination of the line is reactive, \(|\gamma| = 1\). the interesting property here is that the total voltage appears as a standing wave with fixed points called nodes where the total voltage is always zero. this is more easily seen in figure \(\pageindex{7}\)(a), where the total voltage is overlaid for many times. if the termination has resistance, then the magnitude of the backward-traveling wave will be less than that of the forward-traveling wave and the overlaid total voltage is as shown in figure \(\pageindex{7}\)(b). this is still a standing wave, but the minima are now not zero. the envelope of this standing wave is shown in figure \(\pageindex{7}\)(c), where there is a maximum amplitude \(v_{\text{max}}\) and a minimum amplitude \(v_{\text{min}}\).  now this situation will be examined mathematically to relate the standing wave to the reflection coefficient. if \(\gamma=0\), then the magnitude of the total voltage on the line, \(|v(z)|\), is equal to \(|v_{0}^{+}|\) anywhere on the line. for this reason, such a line is said to be “flat.” if there is reflection the magnitude of the total voltage on the line is not constant (see figure \(\pageindex{7}\)(b)). thus from equations \(\eqref{eq:11}\) and \(\eqref{eq:12}\):  \[\label{eq:19}|v(z)|=|v_{0}^{+}||1+\gamma e^{2\jmath\beta z}|=|v_{0}^{+}||1+\gamma e^{-2\jmath\beta\ell}|\]  figure \(\pageindex{6}\): evolution of a standing wave with a reactive load as the sum of forward- and backward-traveling waves (to the right and left, respectively) of equal amplitude evaluated at times \(t\) equal to eighths of the period \(t\). at \(t = t/8\) and \(t = 5t/8\) the total voltage everywhere on the line is zero.  figure \(\pageindex{7}\): standing waves as an overlay of waveforms at many times: (a) when the forward-and backward-traveling waves have the same amplitude; (b) when the waves have different amplitudes; and (c) the envelope of the standing wave. n is a node (a minimum) and an is an antinode (a maximum). nodes, n, are separated by \(\lambda/2\). antinodes, an, are separated by \(\lambda/2\).  where \(z = −\ell\) is the positive distance measured from the load at \(z = 0\) toward the generator. or, setting \(\gamma = |\gamma|e^{\jmath\theta}\),  \[\label{eq:20}|v(z)|=|v_{0}^{+}|\left|1+|\gamma|e^{\jmath(\theta-2\beta\ell)}\right|\]  where \(\theta\) is the phase of the reflection coefficient \((\gamma = |\gamma|e^{\jmath\theta})\) at the load. this result shows that the voltage magnitude oscillates with position \(z\) along the line. the maximum value occurs when \(e^{\jmath(\theta−2\beta\ell)} = 1\) and is given by  \[\label{eq:21}v_{\text{max}}=|v_{0}^{+}|(1+|\gamma|)\]  similarly the minimum value of the total voltage magnitude occurs when the phase term is \(e^{\jmath(\theta−2\beta\ell)} = −1\), and is given by  \[\label{eq:22}v_{\text{min}}=|v_{0}^{+}|(1-|\gamma|)\]  a mismatch can be defined by the voltage standing wave ratio (vswr):  \[\label{eq:23}\text{vswr}=\frac{v_{\text{max}}}{v_{\text{min}}}=\frac{(1+|\gamma|)}{(1-|\gamma|)}\]  also  \[\label{eq:24}|\gamma|=\frac{\text{vswr}-1}{\text{vswr}+1}\]  notice that in general \(\gamma\) is complex, but \(\text{vswr}\) is necessarily always real and \(1 ≤ \text{vswr} ≤ ∞\). for the matched condition, \(\gamma =0\) and \(\text{vswr} = 1\), and the closer \(\text{vswr}\) is to \(1\), the closer the load is to being matched to the line and the more power is delivered to the load. the magnitude of the reflection coefficient on a line with a short-circuit or open-circuit load is \(1\), and in both cases the \(\text{vswr}\) is infinite.  to determine the position of the standing wave maximum, \(\ell_{\text{max}}\), consider equation \(\eqref{eq:20}\) and note that at the maximum  \[\label{eq:25}\theta-2\beta\ell_{\text{max}}=2n\pi,\quad n=0,1,2,\ldots\]  here \(\theta\) is the angle of the reflection coefficient at the load:  \[\label{eq:26}\theta-2n\pi =2\frac{2\pi}{\lambda_{g}}\ell_{\text{max}}\]  thus the position of the voltage maxima, \(\ell_{\text{max}}\), normalized to wavelength is  \[\label{eq:27}\frac{\ell_{\text{max}}}{\lambda_{g}}=\frac{1}{2}\left(\frac{\theta}{2\pi}-n\right),\quad n=0,-1,-2,\ldots\]  similarly the position of the voltage minima is (using equation \(\eqref{eq:20}\))  \[\label{eq:28}\theta-2\beta\ell_{\text{min}}=(2n+1)\pi\]  after rearranging the terms,  \[\label{eq:29}\frac{\ell_{\text{min}}}{\lambda_{g}}=\frac{1}{2}\left(\frac{\theta}{2\pi}-n+\frac{1}{2}\right),\quad n=0,-1,-2,\ldots\]  summarizing from equations \(\eqref{eq:27}\) and \(\eqref{eq:29}\):  the distance between two successive maxima is \(\lambda_{g}/2\).  the distance between two successive minima is \(\lambda_{g}/2\).  the distance between a maximum and an adjacent minimum is \(\lambda_{g}/4\).  from the measured \(\text{vswr}\) the magnitude of the reflection coefficient \(|\gamma|\) can be found. from the measured \(\ell_{\text{max}}\) the angle \(\theta\) of \(\gamma\) can be found. then from \(\gamma\) the load impedance can be found.  in a similar manner to that above, the magnitude of the total current on the line is  \[\label{eq:30}|i(\ell)|=\frac{|v_{0}^{+}|}{z_{0}}\left|1-|\gamma|e^{\jmath(\theta-2\beta\ell)}\right|\]  hence the standing wave current is maximum where the standing-wave voltage amplitude is minimum, and minimum where the standing-wave voltage amplitude is maximum.  \(z_{\text{in}}\) in equation \(\eqref{eq:18}\) is a periodic function of length with period \(\lambda/2\) and it varies between \(z_{\text{max}}\) and \(z_{\text{min}}\), where  \[\label{eq:31}z_{\text{max}}=\frac{v_{\text{max}}}{i_{\text{min}}}=z_{0}\times\text{vswr}\quad\text{and}\quad z_{\text{min}}=\frac{v_{\text{min}}}{i_{\text{max}}}=\frac{z_{0}}{\text{vswr}}\]  example \(\pageindex{3}\): standing wave ratio  in example \(\pageindex{2}\) the load consisted of a capacitor of \(10\text{ pf}\) in shunt with a resistor of \(60\:\omega\). the load terminated a lossless \(50\:\omega\) transmission line. the operating frequency is \(5\text{ ghz}\).  what is the \(\text{swr}\)?  what is the current standing wave ratio (\(\text{iswr}\))? (when \(\text{swr}\) is used on its own it is assumed to refer to \(\text{vswr}\).)  solution  from example \(\pageindex{2}\) \(\gamma_{l} = 0.993\angle 187.3^{\circ}\) and so     \[\text{vswr}=\frac{1+|\gamma_{l}|}{1-|\gamma_{l}|}=\frac{1+0.993}{1-0.993}=285\nonumber\]  \(\text{iswr}=\text{vswr}=285\)  example \(\pageindex{4}\): standing waves  a load has an impedance \(z_{l} = 45 + \jmath 75\:\omega\) and the system reference impedance, \(z_{0}\), is \(100\:\omega\).  what is the reflection coefficient?  what is the current reflection coefficient?  what is the \(\text{swr}\)?  what is the \(\text{iswr}\)?  the power available from a source with a \(100\:\omega\) thevenin equivalent impedance is \(1\text{ mw}\). the source is connected directly to the load, \(z_{l}\). use the reflection coefficient to calculate the power delivered to \(z_{l}\).  what is the total power absorbed by the thevenin equivalent source impedance?  discuss the effect on power flow of inserting a lossless \(100\:\omega\) transmission line between the source and the load.  solution  the voltage reflection coefficient is     \[\begin{align}\gamma_{l}&amp;=(z_{l} − z_{0})/(z_{l} + z_{0}) = (45 +\jmath 75 − 100)/(45 + \jmath 75 + 100) \nonumber \\ &amp;=(93.0\angle (2.204\text{ rads}))/(163.2\angle (0.4773\text{ rads}))\nonumber \\ \label{eq:32} &amp;=0.570\angle (1.726\text{ rads})=0.570\angle 98.9^{\circ} = −0.0881 + \jmath 0.563 = \gamma^{v} \end{align}\]  the current reflection coefficient is     \[\label{eq:33}\gamma^{i}=-\gamma^{v}=0.0881-\jmath 0.563=0.570\angle (98.9^{\circ} − 180^{\circ})=0.570\angle 81.1^{\circ}\]  the \(\text{swr}\) is the \(\text{vswr}\), so     \[\label{eq:34}\text{swr}=\text{vswr}=\frac{v_{\text{max}}}{v_{\text{min}}}=\frac{1+|\gamma^{v}|}{1-|\gamma^{v}|}=\frac{1+0.570}{1-0.570}=3.65\]  the current \(\text{swr}\) is \(\text{iswr} = \text{vswr}\).  to determine the reflection coefficient of the load, begin by developing the thevenin equivalent circuit of the load. the power available from the source is \(p_{a} = 1\text{ mw}\), so the thevenin equivalent circuit is      figure \(\pageindex{8}\)     the power reflected by the load is     \[p_{r} = p_{a}|\gamma_{l}^{2}| = 1\text{ mw}\cdot (0.570)^{2} = 0.325\text{ mw}\nonumber\]     and the power delivered to the load is     \[p_{d}=p_{a}(1-|\gamma_{l}^{2}|)=0.675\text{ mw}\nonumber\]  it is tempting to think that the power dissipated in \(r_{\text{th}}\) is just \(p_{r}\). however, this is not correct. instead, the current in \(r_{\text{th}}\) must be determined and then the power dissipated in \(r_{\text{th}}\) found. let the current through \(r_{\text{th}cdot}\) be \(i\), and this is composed of forward-and backward-traveling components:     \[i=i^{+}+i^{-}=(1+\gamma_{i})i^{+}\nonumber\]     where \(i^{+}\) is the forward-traveling current wave. thus     \[p_{a}=\frac{1}{2}|i^{+}|^{2}r_{\text{th}}=\frac{1}{2}|i^{+}|^{2}\times 100=1\text{ mw}=10^{-3}\text{ w}\nonumber\]     so \(i^{+} = 4.47\text{ ma}\), and     \[i = (1 + \gamma_{i})i^{+} = (1 + 0.0881 −\jmath 0.563)\times 4.47\times 10^{−3}\text{ a},\quad |i| = 5.48\text{ ma}\nonumber\]     the power dissipated in \(r_{\text{th}}\) is     \[\label{eq:35}p_{\text{th}}=\frac{1}{2}|i|^{2}r_{\text{th}}=\frac{1}{2}(5.48\times 10^{−3})^{2} r_{\text{th}} = 1.50\text{ mw}\]     the circuit is that shown in part (e) and so the current in \(r_{\text{th}}\) is the same as the current in \(z_{l}\). thus the power delivered to the load \(z_{l}\) is due to the real part of \(z_{l}\):     \[\label{eq:36}p_{d} =\frac{1}{2}|i|^{2}\re (z_{l}) = \frac{1}{2} (5.48\times 10^{−3})^{2}\times 45 = 0.676\text{ mw}\]  inserting a transmission line with the same characteristic impedance as the thevenin equivalent impedance will have no effect on power flow.  vswr measurement  the measurement of standing waves can be used to calculate the impedance of a load. the device that does this measurement, called a slotted line, is shown in figure \(\pageindex{9}\)(a). a probe is inserted a small distance into the transmission line to measure the electric field. the rf electric field produces an rf voltage on the probe that is rectified by the diode detector. the dc voltage at the output of the detector is proportional to the total voltage on the line. the probe can be moved along the line and the ratio of \(v_{\text{max}}\) to \(v_{\text{min}}\) determined. this is just the \(\text{vswr}\). to find the complex load impedance it is also necessary to determine the position of the node of the standing wave. from the measured \(\text{vswr}\) the magnitude of the reflection coefficient \(|\gamma|\) can be found. from the measured ℓmax the angle \(\theta\) of \(\gamma\) can be found. from \(\gamma\) the load impedance can be found. this is demonstrated in the next example.  figure \(\pageindex{9}\): measurement of standing waves: (a) coaxial slotted line; (b) schematic of slotted line; (c) measured standing wave.  example \(\pageindex{5}\): slotted line measurement of impedance  a slotted line is used to determine the properties of the standing wave on a terminated \(50\:\omega\) line see figure \(\pageindex{7}\)(c). \(v_{\text{max}} = 5\text{ v}\) and \(v_{\text{min}} = 2\text{ v}\), and the first minimum is \(2\text{ cm}\) from the load. the guide wavelength is \(10\text{ cm}\). what is the load impedance \(z_{l}\)?  solution  now \(\text{vswr} = v_{\text{max}}/v_{\text{min}} = 5/2=2.5\). so from equation \(\eqref{eq:24}\)  \[\label{eq:37}|\gamma|=|\gamma_{l}|=\frac{\text{vswr}-1}{\text{vswr}+1}=\frac{2.5-1}{2.5+1}=0.428\]  equation \(\eqref{eq:29}\) and the position of the first node can be used to determine the angle of \(\gamma_{l}\). for the first node (minimum), \(n = 0\) and  \[\label{eq:38}\frac{\ell_{\text{min}}}{\lambda_{g}}=\frac{1}{2}\left(\frac{\theta}{2\pi}+\frac{1}{2}\right)\]  rearranging,  \[\label{eq:39} \theta=2\pi\left(2\frac{\ell_{\text{min}}}{\lambda_{g}}-\frac{1}{2}\right)\text{ radians}\]  now \(\ell_{\text{min}} = 2\text{ cm}\) and \(\lambda_{g} = 10\text{ cm}\). so, in degrees,  \[\label{eq:40}\theta=360\left(2\frac{\ell_{\text{min}}}{\lambda_{g}}-\frac{1}{2}\right)=360\left(2\frac{2}{10}-\frac{1}{10}\right)=-36^{\circ}\]  thus \(\gamma_{l} = 0.428\angle (−36^{\circ}) = 0.3463 −\jmath 0.2516\), so the load impedance is (where \(z_{0} = 50\:\omega\))  \[\label{eq:41}z_{l}=z_{0}\left(\frac{1+\gamma_{l}}{1-\gamma_{l}}\right)=83.2-\jmath 51.3\:\omega\]  2.3.6 summary  this section related the physics of traveling voltage and current waves on lossless transmission lines to the total voltage and current view. first the input reflection coefficient of a terminated lossless line was developed and from this the input impedance, which is the ratio of total voltage and total current, derived. at any point along a line the amplitude of total voltage varies sinusoidally, tracing out a standing wave pattern along the line and yielding the \(\text{vswr}\) metric which is the ratio of the maximum amplitude of the total voltage to the minimum amplitude of that voltage. this is an important metric that is often used to provide an indication of how good a match, i.e. how small the reflection is, with a \(\text{vswr}= 1\) indicating no reflection and a \(\text{vswr} = ∞\) indicating total reflection, i.e. a reflection coefficient magnitude of \(1\).",t_18205ba13bc3,other,0
c_a5ef161f3476,"introduction to experiment design. explanatory and response variables. control and treatment groups.  - [instructor] so let's say that i am a drug company and i have come up with a medicine that i think will help folks with diabetes, and in particular, i think it will help reduce their hemoglobin a1c levels, and for those of you who aren't familiar with what hemoglobin a1c is, i encourage you, we have a video on that on khan academy, but the general idea is if you have high blood sugar over roughly a three-month period of time, high blood sugar, and i can say high average blood sugar, you're going to have a high a1c, a high hemoglobin a1c level and if you have a low average blood sugar over roughly a three-month time, you're going to have a lower hemoglobin a1c. so if taking the pill seems to lower folks' a1c levels more than is likely to happen due to randomly or due to other variables, well then that means that your new pill might be effective at controlling folks' diabetes. so in this situation, when we're constructing an experiment to test this, we would say that whether or not you are taking the pill, this is the explanatory variable. explanatory variable, and the thing that it is affecting, the thing that you're hoping has some response, in this case the a1c levels are your indicator of whether it is help controlling the blood sugar, we call that the response variable. that right over there is the response variable. so how are we actually going to conduct this experiment? well let's say that we have a group of folks, let's say that we have been given a group of 100 folks who need to control their diabetes. so 100 people here who need to control their diabetes, and we say, ""alright, well let's take half of this group ""and put them into, i guess you could say a treatment group ""and another half and put them into a control group ""and see if the treatment group, the one that actually ""gets my pill is going to improve their a1c levels in a way ""that seems like it would not be just random chance."" so let's do that, so we're going to have a control group, so this is my control group, control, and this is the treatment group, this is the treatment group. and you might say, ""okay, we'll just give these folks, ""the treatment group the pill and then we won't give ""the pill that i created to the control group."" but that might introduce a psychological aspect that maybe the benefit of the pill is just people feeling, ""hey i'm taking something that'll control my diabetes,"" maybe that psychologically affects their blood sugar in some way and this is actually possible, maybe it makes them act healthier in certain ways, maybe that makes them act unhealthier in certain ways 'cause they're like, ""oh i have a pill to control ""my diabetes, my blood sugar, i can go eat ""more sweets now and it'll control it."" and so to avoid that, in order for just the very fact that someone says, ""hey i think i'm taking a medicine, ""i might behave in a different way or it might even ""psychologically affect my body in a certain way,"" what we wanna do is give both groups a pill, and we wanna do it in a way that neither group knows which pill they're getting. so what we would do here is we would give this group a placebo, a placebo, and this group would actually get the medicine, the medicine, but those pills should look the same, and people should not know which group they are in and that is a, when we do that, that is a blind experiment, experiment. now you might have heard about double-blind experiments. well that would be the case where not only do people not know which group they're in, but even their physician or the person who's administering the experiment, they don't know which one they're giving, they don't know if they're giving the placebo or the actual medicine to the group. so let's say we wanna do that. so we could do double, double-blind experiment, so even the person giving the pill doesn't know which pill they're giving. and you might say, ""well why is that important?"" well if the physician knows, or the person administering or interfacing with the patient, they might give a tell somehow, they might not put as much emphasis on the importance of taking the pill if it's a placebo, they might by accident give away some type of information. so to avoid that type of thing happening, you could do a double-blind, and there's even, some people talk about a triple-blind experiment where even the people analyzing the data don't know which group was the control group and which group was the treatment group, and once again, that's another way to avoid bias. so now that we've kinda figured out, we have a control group, we have a treatment group, we're using a1c as our response variable, so we would wanna measure folks' a1c levels, their hemoglobin a1c levels before they get either the placebo or the medicine and then maybe after three months, we would measure their a1c after, but the next question is, how do you divvy these 100 people up into these two groups, and you might say, ""well i would wanna do it randomly,"" and you would be right 'cause if you didn't do it randomly, if you put all the men here and all the women here, well that might, first of all, sex might explain it or behavior of men versus women might explain the differences or the non-differences you see in a1c level, if you get a lot of people of one age or one part of the country or one type of dietary habit, you don't want that, so in order to avoid having an imbalance of some of those lurking variables, you would want to randomly sample and we've done multiple videos already on ways to randomly sample, so you're going to randomly sample and put people into either groups. and a very simple way of doing that, you could give everyone here a number from one to 100, use a random number generator to do that and then, or you could use a random number generator, pick 50 names to put in the control group or 50 names to put in the treatment group and then everyone else gets put in the other group. now, to avoid a situation, just randomly by doing a random sample, you might have a situation where there's some probability that you disproportionately have more men in one group or more women in another group and to avoid that, you could do really a version of stratified sampling that we've talked about in other videos, which is you could do what's called a block design for your random assignment where you actually split everyone into men and women and it might be 50-50 or it might even be just randomly here you got 60 women, 60 women and 40 men and what you do here is you say, ""okay let's randomly ""take 30 of these women and put 'em in the control group ""and 30 of the women and put 'em in the treatment group ""and let's put randomly 20 of the men in the control group ""and 20 of the men in the treatment group"" and that way someone's sex is less likely to introduce bias into what actually happens here, so once again, doing this is called a block design, really a version of stratified sampling. block design, and there might be other lurking variables that you wanna make sure doesn't just show up here randomly and so you might want, there's other ways of randomly assigning. now once you do this, you see what was a change in a1c. if you see that, hey, the change in a1c, one if you see there's no difference in a1c levels between these two groups, and you're like, ""hey, there's a good probability that my pill does nothing"" and once again it's all about probabilities, there's some chance that you're just unlucky and it might be a very small chance and that's why you wanna do this with a good number of people and as we forward our statistics understandings, we will better understand at what threshold levels do we think the probability is high or low enough for us to really feel good about our findings. but let's say that you do see an improvement, you need to think about, is that improvement, could that have happened due to random chance or is it very unlikely that that happened due purely to random chance, and if it was very unlikely that it happened due purely to random chance, then you would feel pretty good, and other people when you publish the results, would feel pretty good about your medicine. now, even then, science is not done. no one will say that they are 100% sure that your medicine is good, there still might have been some lurking variables that we did not, that our experiment did not properly adjust for, that just when we even did this block design, we might have disproportionately gotten randomly older people in one of the groups or the other or people from one part of the country in one group or another so there's always things to think about and the most important thing to think about, even if you did this as good as you could, you still, some random chance might have given you a false positive, you got good results even though it was random, or a false negative, you got bad results even though it was actually random. and so a very important idea in experiments and this is in science in general is that this experiment, you should document it well and it should be, the process of replication, other people should be able to replicate this experiment and hopefully get consistent results so it's not just about the results, it's your experiment design, other people should, it should be an experiment that other people could and should replicate to reinforce the idea that your results are actually true and not just random or just due to some bad administration of the actual experiment.",t_17e7ff75fd00,other,0
c_b3d67604f3aa,"ever wish you could travel back in time to see ancient rome? thanks to rome reborn® you can!   learn more about the architecture seen in this video visit:  arch of constantine   https://smarthistory.org/arch-of-constantine-rome/  arch of titus   https://smarthistory.org/the-arch-of-titus/  basilica of maxentius and constantine   https://smarthistory.org/basilica-of-maxentius-and-constantine/  roma(piano music) - [steven] i'm with dr. bernie frischer, the creator of rome reborn. it's a beautiful day, and we're flying low over the tiber river. - [bernie] this is rome in the year 320 c.e. you see this big plaza, that's the so-called circus flaminius, beyond which is a theater, the theatre of marcellus, and to the left is the capitoline hill. - [steven] and now we're approaching a large stadium, a place for sporting events. - [bernie] this is the circus maximus used for the chariot races among other things, it also was used for parades, for example the triumphal parade. it could seat up to, we think, 250,000 people. it was quite a big complex. - [steven] and there's an island in the middle, around which the chariots would race. you can see right in the middle of that, the large obelisk. - [bernie] this is one of the first two very tall obelisks brought from egypt to rome by the first emperor augustus. it symbolized to the egyptians, and the romans knew this, a sunbeam, and the romans thought this was appropriate for the circus because the circus itself had a temple of the sun god. - [steven] and this temple to the sun is placed directly across from the imperial box and just to the left of the stadium is the palace. - [bernie] the great imperial palace. at the end of the circus maximus is a triumphal arch. we know that was dedicated to the emperor titus and celebrated his victory over the province of judea. the reason that there's a triumphal arch of titus here is that the parade known as the triumphal procession went through the circus maximus and all along the triumphal procession there were temples, triumphal arches and other monuments. - [steven] and aligned with the arch of titus, we can see in the distance one of the great bath complexes of ancient rome. - [bernie] that's the baths of caracalla. now we're looking at the caelian hill, you can see the claudian aqueduct in the valley between the caelian hill and to our left the palatine hill, you see a plume of smoke going up from the imperial bath complex on the palatine hill. to our right we're passing by a great complex, a garden in the middle of which is a temple, and that's the temple of the divine claudius. claudius was made a god after his death and nero incorporated this piece of land into the golden house, which covered 120 acres. - [steven] what i find so fascinating is that so much of the ancient architecture that i associate with rome in the colosseum district is really a reaction against nero, as a reaction against his excesses. - [bernie] everywhere you look, the selfishly expropriated public land under nero is given back to the public, and the public was very happy. these are all public facilities, so think of the colosseum, beyond that where you have some smoke coming out, those are baths, the baths of trajan. it's open to the public. in front of that is the smaller bath complex, the baths of titus. - [steven] we're now flying just over the arch of constantine which is another landmark that survives into the modern era. - [bernie] yeah so another triumphal arch. in front of that you see that cone, that's the meta sudans, the great fountain, and to the right is the flavian amphitheater, also known as the colosseum. but you can see why it was called the colosseum in the middle ages, not in antiquity. because of that enormous 100 foot tall bronze statue, which is a statue of the sun god. now that was originally a statue of nero. after his death, the vespasian had the head taken off and had it converted to a statue of the sun god. we see just beyond the second arch of titus in the city. - [steven] and just to the right of that the basilica of maxentius and constantine. - [bernie] yes. - [steven] and these are all structures that remain. and now we're just veering off to the left, and at the top of the hill is the palace, we're seeing it from the other side. - [bernie] yeah this is the palace at the top of the palatine. because the emperors lived up there, the word palace became synonymous with where a leader would live. we're turning now away from the palace and looking over toward the roman forum. - [steven] in the ancient era the forum was a place for oratory, it was a place for government. - [bernie] in the republic, yes. it was a place for meetings of the assembly, as well as the senate. the senate had its own building, but the people would assemble in front of the speaker's roster or platform to listen to their leaders explain policy, propose laws, and debate each other when they were running for public office. - [steven] we seem to be flying through the smoke of the temple of vesta. - [bernie] the temple of vesta, famous for its eternal flame, and beyond that is the triple arch of augustus, it celebrates the restoration by the parthians in modern day iran of military standards. interestingly, if we're looking now at a rostra, a speaker's platform right ahead of us, that's a late antique rostra, dating to the end of the third century ad. - [steven] but we can see the original just a little further on. - [bernie] yes, bookending the forum plaza at the other end is another rostra, the augustan rostra originally built by julius caesar. - [steven] and in between the rostra, there's this beautiful equestrian sculpture. - [bernie] this was actually the early third century ad emperor septimius sevverus, and we know about the statue being there both archaeologically from the remains of the base, but also from coins that illustrate it. - [steven] we're surrounded by public buildings and by temples. - [bernie] we can see over the right the temple of castor and pollux. straight ahead is the temple of the divine julius caesar. if you look closely, you can see the colt statue inside. we know about that from a coin that illustrates it. caesar was shown as an augur, a priest. up in the pediment of the temple you see a star. it illustrates the comet that was seen in the sky over rome in the summer after caesar's assassination. - [steven] we're surrounded by columns, and these were honorary columns. - [bernie] yes, in front of the law court known as the basilica julia. and we know from pliny that to portray a human on top of a column was in effect, to make him a god, or make him god-like. what we see now in front of us is one of the two trajanic reliefs, that interestingly enough, in their backgrounds illustrates the roman forum as it appeared in the time of the emperors trajan and hadrian. a lot of people are surprised to see to see that set up here on the forum plaza. that's actually where they were found at the end of the 19th century. - [steven] but now they're in the senate. - [bernie] they were moved there in the 20th century to protect them from the elements. - [steven] when you go into the senate to see them, you don't see these blues, you don't see those yellows, you don't see these greens. almost all roman sculpture was painted. - [bernie] this is one of the great breakthroughs of the last 10 years or so, development of a number of noninvasive techniques to detect color, even little traces of pigment left on the surface of white marble. now we're seeing the so-called statue of phocas. it's called the statue of phocas because it was excavated at the beginning if the 19th century and they found an inscription to the byzantine emperor phocas. but we think that phocas' inscription was added on top of an older inscription to the tetrarch diocletian. and he is therefore the figure shown on top of the column. - [steven] we're now looking up the hill that leads to the capital line. - [bernie] masking the hill is the tabularium or the state record office in the background. in front of it are three temples. to the left the temple of saturn, in the center the temple of vespasian and titus, worshiped as gods after their deaths, and to the right, the temple of concordia that celebrated the harmony between the social classes of rome, and then during the empire it symbolizes the harmony between the imperial family and the roman senate. we're passing over the augustan rostra now, and just to the right is the arch septimius severus. he left a very big mark in the forum. - [steven] and his arch even today overshadows so much of the forum. - [bernie] yes, it's very well preserved. - [steven] let's move now to the imperial fora. as opposed to the roman forum, these are fora that individual emperors built to honor their own rule. - [bernie] fora is the plural of forum, so the roman forum and the imperial fora. starting from the time of julius caesar, it was recognized that the old roman forum was too crowded. if you were an emperor and you wanted to honor your favorite god, or eventually after you died have a temple to yourself, you needed to build a new public space. where better to do that than adjacent to the old roman forum? so julius caesar's forum which we're now over, uses the backside of the senate as a part and parcel of this new forum julium, the forum of julius caesar, which is dominated at the end of its main axis by the temple of venus genetrix, his favorite goddess. the other emperors followed suit, so across the way is the forum of augustus, dominated by the temple of his favorite god, the god mars, the war god. - [steven] the temple is actually flanked by two hemicycles. - [bernie] yes, and in those hemicycles were niches with some of rome's leading historic figures, and also the julian ancestors of augustus going all the way back to aeneas. - [steven] you can see other imperial fora that are squeezed in, especially the transitorium. - [bernie] yeah the transitorium is also called the forum of nerva. it's basically just a monumentalization of the argulatum the street that runs next to the senate house into the roman forum and then going into the other direction to the east into the subura, the slummy part of rome filled with tenements where lots of people lived. - [steven] but if the transitorium is squeezed in, you would never say that about the forum of trajan. - [bernie] no, the last one of these imperial fora is the forum of trajan it's the biggest by far, it's fairly well preserved at the end of it is a temple of the divine trajan which was built after trajan died but he actually started building this while he was still alive so in front of the temple is the column of trajan that celebrates his two victories over the dajians, the people in modern day romania. in flanking the column are two libraries. in front of the libraries in the column is a bigger building the basilica ulpia which probably served as a law court and had some other functions. it was a big multipurpose space. - [steven] just coming into view is one of the most famous extant roman monuments, the pantheon. - [bernie] now we're flying to the northern campus martius which was filled with funiary monuments, temples, ustrinai, places where emperor's bodies were cremated. the columns like the column of marcus orelius. - [steven] and the first roman emperor built his own mausoleum, the mausoleum of augustus. - [bernie] we can see this round structure in the northern most part of the campus martius. - [steven] now we've just swung around so we have a great view of the pantheon. - [bernie] we can really see the pantheon we have this hypothetical arch that a lot of people think was in front of the pantheon and to its left was the most prestigious shopping center of rome the saepta julia and next to that is this great egyptian temple of the goddess isis, you can see two obelisks. - [steven] so what we're seeing is a city that is filled with monuments to roman rulers. monuments that celebrate their achievements, their military victory, the wealth that they brought to the city. - [bernie] yes, but now as we turn and go back to the south and southern part of the campus martius we see that these emperors were not only selfish but they created a lot of public facilities and built up their popularity that way so we've just been flying through the entertainment part of the city of rome. - [steven] when you walk through rome now, this city that is so layered with history it's sometimes difficult to reconstruct in your mind how these ancient monuments fit together. this recreation provides such rich detail it allows us to see the city literally as if we had traveled back to the fourth century. - [bernie] the idea is to take all of the monographs and studies of the individual monuments and weave them together into something that gives us a synthetic view of the whole city. in the past we've been able to study just the pantheon or just the roman forum again it could take decades of your life. now thanks to this new 3d technology within a very short amount of time even just a day i would really say the average person can know more about the ancient city than even a phd in the field of roman archeology did five or 10 short years ago. (piano music)",t_e150f2ef6e7b,other,0
c_c7c0bddf9879,"leonardo da vinci, the virgin and child with st anne and st john the baptist (burlington house cartoon), 1499-1500, charcoal and chalk on paper, 55.7 × 41.2 inches c. 1499-1500 (national gallery, london)  [music playing] speaker 1: even in the renaissance, drawings were sometimes works of art unto themselves. they weren't always preparatory. and we think that's the case with the large scale drawing by leonardo that is usually given the title of the virgin and child with st. anne and st. john. and that's because it's not perforated. speaker 2: right although it's unfinished. so it's status is a little bit unclear. and it would have had tiny dots or perforations in it so that that would have allowed leonardo to trace the outlines of the figures so that you could transfer a drawing to a panel or a wall to paint on. speaker 1: although using leonardo's technique is so different from traditional, much more linear renaissance painting that that would be more problematic. you get the basic contours. but his construction of the figure is so often simply using chiaroscuro, or using light and shadow. speaker 2: sfumato. speaker 1: well, that's because it's so soft and because it's so smoky. that idea of just the line that would be traced by the perforations seems sort of absurd. speaker 2: right. yeah. he was much more interested in these, very slow gradations from dark to light and then moving back into dark again. so that is such a sense of three dimensionality and monumentality to these figures. speaker 1: and also an integration of the figures into a whole. the figures form a kind of pyramid. they are so stable. and that's one of the characteristics about renaissance. speaker 2: that stability that would suggest that kind of eternity that is appropriate for the subject of these divine figures, so, go ahead. did you want to say something? speaker 1: well, just wanted to say that it is such an interesting contrast. because on the one hand, you've got the sense of an ideal perfection. this notion of the eternal, and sort of the eternally spiritual. on the other hand, there's such a kind of intimacy between figures, between anne and mary, and between john and christ. speaker 2: that's very human. speaker 1: that's incredibly human and seems incredibly precious. and so sort of at odds with the notion of the eternal. speaker 2: yeah. it's both. that's what leonardo does, right? he combines the human and the divine. that's the definition to me of what leonardo accomplished in high renaissance. speaker 1: there are all these marvelous passages here. i mean, i just love the way that anne turns to mary, who sits on her lap. there's this kind of rhythm of needs of the two women, right? speaker 2: yeah. speaker 1: down, and up and down, and up again. it's almost musical as it moves across. speaker 2: it makes me feel that leonardo is certainly looking at classical sculpture. because that so much looks to me like drapery on ancient greek and roman figures. speaker 1: there is a sense of the varied age of the figures. and you get a real sense of leonardo's process, especially when you look at the contrast between anne's face and her hand, which is so much less finished and still so much more linear. speaker 2: and anne is pointing up to communicate this idea that this is part of god's plan, that christ and his future sacrifice is part of god's plan for the salvation of mankind. speaker 1: look at the way in which christ's arm bends around and his finger's up in blessing john. actually it's continued upward by anne's fingers. speaker 2: yeah. speaker 1: so that's one continuous movement. in a sense christ is literally drawn up in anne's gesture. speaker 2: well, and that begins with the line from mary's shoulder up through christ and then pointing up to god. speaker 1: in fact, you could actually begin that movement with anne's glance at-- speaker 2: right. speaker 1: mary continuing down her shoulders, as you said, around her elbow, and then up through christ's arm speaker 2: and actually what we just did is a really good example of what was so important to leonardo, which is that unification. like, you can start linking things together the longer you look at the image. i mean, we can look at st. john's glance up at christ and then move up there to mary's looking at the christ child. and then go back to anne, whose looking at mary. speaker 1: that's right. and it really does create a pathway for her eyes. but all of which lead toward heaven, which is, of course, the very point of the drawing. [music playing]",t_245e4b56100d,other,0
c_11bebc650d5c,"given a bunch of numbers, learn how to tell which are rational and which are irrational.  which of the following real numbers are irrational? well, irrational just means it's not rational. it means that you cannot express it as the ratio of two integers. so let's see what we have here. so we have the square root of 8 over 2. if you take the square root of a number that is not a perfect square, it is going to be irrational. and then if you just take that irrational number and you multiply it, and you divide it by any other numbers, you're still going to get an irrational number. so square root of 8 is irrational. you divide that by 2, it is still irrational. so this is not rational. or in other words, i'm saying it is irrational. now, you have pi, 3.14159-- it just keeps going on and on and on forever without ever repeating. so this is irrational, probably the most famous of all of the irrational numbers. 5.0-- well, i can represent 5.0 as 5/1. so 5.0 is rational. it is not irrational. 0.325-- well, this is the same thing as 325/1000. so i can clearly represent it as a ratio of integers. so this is rational. just as i could represent 5.0 as 5/1, both of these are rational. they are not irrational. here i have 7.777777, and it just keeps going on and on and on forever. and the way we denote that, you could just say these dots that say that the 7's keep going. or you could say 7.7. and this line shows that the 7 part, the second 7, just keeps repeating on forever. now, if you have a repeating decimal-- in other videos, we'll actually convert them into fractions-- but a repeating decimal can be represented as a ratio of two integers. just as 1/3 is equal to 0.333 on and on and on. or i could say it like this. i could say 3 repeating. we can also do the same thing for that. i won't do it here, but this is rational. so it's not irrational. 8 and 1/2? well, that's the same thing. 8 and 1/2 is the same thing as 17/2. so it's clearly rational. so the only two irrational numbers are the first two right over here.",t_9adc267917d0,other,0
c_32b345ea9a26,"section ""content list"" of the book on mongodb.mongodb mongodb notes for professionals  ®  notes for professionals  60+ pages  of professional hints and tricks  goalkicker.com  free programming books  disclaimer this is an unocial free book created for educational purposes and is not aliated with ocial mongodb® group(s) or company(s). all trademarks and registered trademarks are the property of their respective owners  contents about ................................................................................................................................................................................... 1 chapter 1: getting started with mongodb ....................................................................................................... 2 section 1.1: execution of a javascript ﬁle in mongodb ............................................................................................. 2 section 1.2: making the output of ﬁnd readable in shell ............................................................................................ 2 section 1.3: complementary terms ............................................................................................................................. 3 section 1.4: installation .................................................................................................................................................. 3 section 1.5: basic commands on mongo shell ............................................................................................................ 6 section 1.6: hello world ................................................................................................................................................. 6  chapter 2: crud operation ..................................................................................................................................... 7 section 2.1: create ......................................................................................................................................................... 7 section 2.2: update ....................................................................................................................................................... 7 section 2.3: delete ......................................................................................................................................................... 8 section 2.4: read ........................................................................................................................................................... 8 section 2.5: update of embedded documents .......................................................................................................... 9 section 2.6: more update operators .......................................................................................................................... 10 section 2.7: ""multi"" parameter while updating multiple documents ...................................................................... 10  chapter 3: getting database information ..................................................................................................... 11 section 3.1: list all collections in database ............................................................................................................... 11 section 3.2: list all databases .................................................................................................................................... 11  chapter 4: querying for data (getting started) ....................................................................................... 12 section 4.1: find() ......................................................................................................................................................... 12 section 4.2: findone() ................................................................................................................................................. 12 section 4.3: limit, skip, sort and count the results of the ﬁnd() method ................................................................ 12 section 4.4: query document - using and, or and in conditions ....................................................................... 14 section 4.5: ﬁnd() method with projection ................................................................................................................ 16 section 4.6: find() method with projection ............................................................................................................... 16  chapter 5: update operators .............................................................................................................................. 18 section 5.1: $set operator to update speciﬁed ﬁeld(s) in document(s) ................................................................. 18  chapter 6: upserts and inserts ............................................................................................................................ 20 section 6.1: insert a document ................................................................................................................................... 20  chapter 7: collections .............................................................................................................................................. 21 section 7.1: create a collection .................................................................................................................................. 21 section 7.2: drop collection ....................................................................................................................................... 22  chapter 8: aggregation ........................................................................................................................................... 23 section 8.1: count ........................................................................................................................................................ 23 section 8.2: sum .......................................................................................................................................................... 23 section 8.3: average ................................................................................................................................................... 24 section 8.4: operations with arrays .......................................................................................................................... 25 section 8.5: aggregate query examples useful for work and learning ................................................................. 25 section 8.6: match ....................................................................................................................................................... 29 section 8.7: get sample data ..................................................................................................................................... 30 section 8.8: remove docs that have a duplicate ﬁeld in a collection (dedupe) .................................................. 30 section 8.9: left outer join with aggregation ( $lookup) ..................................................................................... 30 section 8.10: server aggregation .............................................................................................................................. 31 section 8.11: aggregation in a server method .......................................................................................................... 31 section 8.12: java and spring example .................................................................................................................... 32  chapter 9: indexes ...................................................................................................................................................... 34 section 9.1: index creation basics .............................................................................................................................. 34 section 9.2: dropping/deleting an index .................................................................................................................. 36 section 9.3: sparse indexes and partial indexes ...................................................................................................... 36 section 9.4: get indices of a collection ..................................................................................................................... 37 section 9.5: compound ............................................................................................................................................... 38 section 9.6: unique index ........................................................................................................................................... 38 section 9.7: single ﬁeld ............................................................................................................................................... 38 section 9.8: delete ....................................................................................................................................................... 38 section 9.9: list ............................................................................................................................................................ 39  chapter 10: bulk operations ................................................................................................................................. 40 section 10.1: converting a ﬁeld to another type and updating the entire collection in bulk ............................... 40  chapter 11: 2dsphere index .................................................................................................................................... 43 section 11.1: create a 2dsphere index ........................................................................................................................ 43  chapter 12: pluggable storage engines .......................................................................................................... 44 section 12.1: wiredtiger .............................................................................................................................................. 44 section 12.2: mmap ...................................................................................................................................................... 44 section 12.3: in-memory ............................................................................................................................................. 44 section 12.4: mongo-rocks ......................................................................................................................................... 44 section 12.5: fusion-io ................................................................................................................................................. 44 section 12.6: tokumx ................................................................................................................................................... 45  chapter 13: java driver ........................................................................................................................................... 46 section 13.1: fetch collection data with condition .................................................................................................... 46 section 13.2: create a database user ........................................................................................................................ 46 section 13.3: create a tailable cursor ........................................................................................................................ 46  chapter 14: python driver ...................................................................................................................................... 48 section 14.1: connect to mongodb using pymongo ................................................................................................ 48 section 14.2: pymongo queries .................................................................................................................................. 48 section 14.3: update all documents in a collection using pymongo ...................................................................... 49  chapter 15: mongo as shards ............................................................................................................................... 50 section 15.1: sharding environment setup ................................................................................................................ 50  chapter 16: replication ............................................................................................................................................ 51 section 16.1: basic conﬁguration with three nodes .................................................................................................. 51  chapter 17: mongo as a replica set ................................................................................................................. 53 section 17.1: mongodb as a replica set .................................................................................................................... 53 section 17.2: check mongodb replica set states .................................................................................................... 54  chapter 18: mongodb - conﬁgure a replicaset to support tls/ssl ............................................. 56 section 18.1: how to conﬁgure a replicaset to support tls/ssl? ......................................................................... 56 section 18.2: how to connect your client (mongo shell) to a replicaset? ............................................................ 58  chapter 19: authentication mechanisms in mongodb .............................................................................. 60 section 19.1: authentication mechanisms .................................................................................................................. 60  chapter 20: mongodb authorization model ................................................................................................. 61 section 20.1: build-in roles ......................................................................................................................................... 61  chapter 21: conﬁguration ...................................................................................................................................... 62 section 21.1: starting mongo with a speciﬁc conﬁg ﬁle ........................................................................................... 63  chapter 22: backing up and restoring data ................................................................................................ 64 section 22.1: basic mongodump of local default mongod instance ...................................................................... 64 section 22.2: basic mongorestore of local default mongod dump ....................................................................... 64  section 22.3: mongoimport with json ..................................................................................................................... 64 section 22.4: mongoimport with csv ........................................................................................................................ 65  chapter 23: upgrading mongodb version ..................................................................................................... 66 section 23.1: upgrading to 3.4 on ubuntu 16.04 using apt ...................................................................................... 66  credits .............................................................................................................................................................................. 67 you may also like ........................................................................................................................................................ 69",t_f7ca0d87501e,other,0
c_5f23cfe24331,"example finding the minimum z-score and numerical threshold to be in a given percentile in a normal distribution.  - [instructor] the distribution of resting pulse rates of all students at santa maria high school was approximately normal with mean of 80 beats per minute and standard deviation of nine beats per minute. the school nurse plans to provide additional screening to students whose resting pulse rates are in the top 30% of the students who were tested. what is the minimum resting pulse rate at that school for students who will receive additional screening? round to the nearest whole number. if you feel like you know how to tackle this, i encourage you to pause this video and try to work it out. all right, now let's work this out together. they're telling us that the distribution of resting pulse rates are approximately normal. so we could use a normal distribution. and they tell us several things about this normal distribution. they tell us that the mean is 80 beats per minute. so that is the mean right over there. and they tell us that the standard deviation is nine beats per minute. so on this normal distribution, we have one standard deviation above the mean, two standard deviations above the mean, so this distance right over here is nine. so this would be 89. this one right over here would be 98. and you could also go standard deviations below the mean, this right over here would be 71, this would be 62, but what we're concerned about is the top 30% because that is who is going to be tested. so there's gonna be some value here, some threshold. let's say it is right over here, that if you are at that score, you have reached the minimum threshold to get an additional screening. you are in the top 30%. so that means that this area right over here is going to be 30% or 0.3. so what we can do, we can use a z-table to say for what z-score is 70% of the distribution less than that. and then we can take that z-score and use the mean and the standard deviation to come up with an actual value. in previous examples, we started with the z-score and were looking for the percentage. this time we're looking for the percentage. we want it to be at least 70% and then come up with the corresponding z-score. so let's see, immediately when we look at this, and we are to the right of the mean, and so we're gonna have a positive z-score. so we're starting at 50% here. we definitely want to get to the 67%, 68, 69, we're getting close and on our table this is the lowest z-score that gets us across that 70% threshold. it's at 0.7019. so it definitely crosses the threshold. and so that is a z-score of 0.53. 0.52 is too little. so we need a z-score of 0.53. let's write that down. 0.53, right over there, and we just now have to figure out what value gives us a z-score of 0.53. well, this just means 0.53 standard deviations above the mean. so to get the value, we would take our mean and we would add 0.53 standard deviation. so 0.53 times nine. and this will get us 0.53 times nine is equal to 4.77 plus 80 is equal to 84.77. 84.77 and they want us to round to the nearest whole number. so we will just round to 85 beats per minute. so that's the threshold. if you have that resting heartbeat, then the school nurse is going to give you some additional screening. you are in the top 30% of students who are tested.",t_f291fc0b5f6f,other,0
c_2aba5fe6e8f9,"a dependent system of equations has infinite solutions, and an independent system has a single solution. watch an example of analyzing a system to see if it's dependent or independent.  is the system of linear equations below dependent or independent? and they give us two equations right here. and before i tackle this specific problem, let's just do a little bit a review of what dependent or independent means. and actually, i'll compare that to consistent and inconsistent. so just to start off with, if we're dealing with systems of linear equations in two dimensions, there's only three possibilities that the lines or the equations can have relative to each other. so let me draw the three possibilities. so let me draw three coordinate axes. so that's my first x-axis and y-axis. let me draw another one. that is x and that is y. let me draw one more, because there's only three possibilities in two dimensions. x and y if we're dealing with linear equations. so you can have the situation where the lines just intersect in one point. let me do this. so you could have one line like that and maybe the other line does something like that and they intersect at one point. you could have the situation where the two lines are parallel. so you could have a situation-- actually let me draw it over here-- where you have one line that goes like that and the other line has the same slope but it's shifted. it has a different y-intercept, so maybe it looks like this. and you have no points of intersection. and then you could have the situation where they're actually the same line, so that both lines have the same slope and the same y-intercept. so really they are the same line. they intersect on an infinite number of points. every point on either of those lines is also a point on the other line. so just to give you a little bit of the terminology here, and we learned this in the last video, this type of system where they don't intersect, where you have no solutions, this is an inconsistent system. and by definition, or i guess just taking the opposite of inconsistent, both of these would be considered consistent. but then within consistent, there's obviously a difference. here we only have one solution. these are two different lines that intersect in one place. and here they're essentially the same exact line. and so we differentiate between these two scenarios by calling this one over here independent and this one over here dependent. so independent-- both lines are doing their own thing. they're not dependent on each other. they're not the same line. they will intersect at one place. dependent-- they're the exact same line. any point that satisfies one line will satisfy the other. any points that satisfies one equation will satisfy the other. so with that said, let's see if this system of linear equations right here is dependent or independent. so they're kind of having us assume that it's going to be consistent, that we're going to intersect in one place or going to intersect in an infinite number of places. and the easiest way to do this-- we already have this second equation here. it's already in slope-intercept form. we know the slope is negative 2, the y-intercept is 8. let's put this first equation up here in slope-intercept form and see if it has a different slope or a different intercept. or maybe it's the same line. so we have 4x plus 2y is equal to 16. we can subtract 4x from both sides. what we want to do is isolate the y on the left hand side. so let's subtract 4x from both sides. the left hand side-- we are just left with a 2y. and then the right hand side, we have a negative 4x plus 16. i just wrote the negative 4 in front of the 16, just so that we have it in the traditional slope-intercept form. and now we can divide both sides of this equation by 2, so that we can isolate the y on the left hand side. divide both sides by 2. we are left with y is equal to negative 4 divided by 2 is negative 2x plus 16 over 2 plus 8. so all i did is algebraically manipulate this top equation up here. and when i did that, when i solved essentially for y, i got this right over here, which is the exact same thing as the second equation. we have the exact same slope, negative 2, negative 2, and we have the exact same y-intercept, 8 and 8. if i were to graph these equations-- that's my x-axis, and that is my y-axis-- both of them have a y-intercept at 8 and then have a slope of negative 2. so they look something-- i'm just drawing an approximation of it-- but they would look something like that. so maybe this is the graph of this equation right here, this first equation. and then the second equation will be the exact same graph. it has the exact same y-intercept and the exact same slope. so clearly these two lines are dependent. they have an infinite number of points that are common to both of them, because they're the same line.",t_d7c8073ae32e,other,0
c_1add950dcdb6,"t-4 bacteriophage is a virulent bacteriophage that infects e. coli bacteria; virulent bacteriophages have a lytic life cycle.  learning objectives  summarize how the t4 life cycle serves as a model for viral virulence  key takeaways  key points  virulence is the degree of pathogenicity within a group or species of parasites as indicated by case fatality rates and/or the ability of the organism to invade the tissues of the host. the pathogenicity of an organism is determined by its virulence factors.  a key difference between the lytic and lysogenic phage cycles is that in the lytic phage, the viral dna exists as a separate molecule within the bacterial cell, and replicates separately from the host bacterial dna.  the t-4’s tail fibres allow attachment to a host cell, and the t4’s tail is hollow so that it can pass its nucleic acid to the cell it is infecting during attachment. t4 is capable of undergoing only a lytic lifecycle and not the lysogenic lifecycle.  key terms  lytic cycle: the normal process of viral reproduction involving penetration of the cell membrane, nucleic acid synthesis, and lysis of the host cell.  virulence: the degree of pathogenicity within a group or species of parasites as indicated by case fatality rates and/or the ability of the organism to invade the tissues of the host.  virulence is the degree of pathogenicity within a group or species of parasites as indicated by case fatality rates and/or the ability of the organism to invade the tissues of the host. the pathogenicity of an organism is determined by its virulence factors. virus virulence factors determine whether an infection will occur and how severe the resulting viral disease symptoms are. viruses often require receptor proteins on host cells to which they specifically bind. typically, these host cell proteins are endocytosed and the bound virus then enters the host cell. virulent viruses such as hiv, which causes aids, have mechanisms for evading host defenses.  some viral virulence factors confer ability to replicate during the defensive inflammation responses of the host such as during virus-induced fever. many viruses can exist inside a host for long periods during which little damage is done. extremely virulent strains can eventually evolve by mutation and natural selection within the virus population inside a host. the term “neurovirulent” is used for viruses such as rabies and herpes simplex which can invade the nervous system and cause disease there.  model organisms of virulent viruses that have been extensively studied include virus t4 and other t-even bacteriophages which infect escherichia coli and a number of related bacteria.  the lytic cycle is one of the two cycles of viral reproduction, the other being the lysogenic cycle. the lytic cycle is typically considered the main method of viral replication, since it results in the destruction of the infected cell. a key difference between the lytic and lysogenic phage cycles is that in the lytic phage, the viral dna exists as a separate molecule within the bacterial cell, and replicates separately from the host bacterial dna. the location of viral dna in the lysogenic phage cycle is within the host dna, therefore in both cases the virus/phage replicates using the host dna machinery, but in the lytic phage cycle, the phage is a free floating separate molecule to the host dna.  cycles of viral reproduction: comparison of the bacteriophage lysogenic and lytic cycles.  the lytic cycle is a six-stage cycle. in the first stage, called “penetration,” the virus injects its own nucleic acids into a host cell. then the viral acids form a circle in the center of the cell. the cell then mistakenly copies the viral acids instead of its own nucleic acids. then the viral dna organize themselves as viruses inside the cell. when the number of viruses inside becomes too much for the cell to hold, the membrane splits and the viruses are free to infect other cells. some viruses escape the host cell without bursting the cell membrane; instead, they bud off from it by taking a portion of the membrane with them. because it otherwise is characteristic of the lytic cycle in other steps, it still belongs to this category, although it is sometimes named the productive cycle. hiv, influenza and other viruses that infect eukaryotic organisms generally use this method.  t-4 bacteriophage is a bacteriophage that infects e. coli bacteria. its double-stranded dna genome is about 169 kbp long and is held in an icosahedral head, also known as a capsid. t4 is a relatively large phage, at approximately 90 nm wide and 200 nm long (most phages range from 25 to 200 nm in length). its tail fibres allow attachment to a host cell, and the t4’s tail is hollow so that it can pass its nucleic acid to the cell it is infecting during attachment. t4 is capable of undergoing only a lytic lifecycle and not the lysogenic lifecycle.  the t4 phage initiates an e. coli infection by recognizing cell surface receptors of the host with its long tail fibers (ltf). a recognition signal is sent through the ltfs to the baseplate. this unravels the short tail fibers (stf) that bind irreversibly to the e. coli cell surface. the baseplate changes conformation and the tail sheath contracts causing gp5 at the end of the tail tube to puncture the outer membrane of the cell. the lysozyme domain of gp5 is activated and degrades the periplasmic peptidoglycan layer. the remaining part of the membrane is degraded and then dna from the head of the phage can travel through the tail tube and enter the e. coli.  the lytic lifecycle (from entering a bacterium to its destruction) takes approximately 30 minutes (at 37 °c) and consists of:  adsorption and penetration (starting immediately)  arrest of host gene expression (starting immediately)  enzyme synthesis (starting after 5 minutes)  dna replication (starting after 10 minutes)  formation of new virus particles (starting after 12 minutes)  after the life cycle is complete, the host cell bursts open and ejects the newly built viruses into the environment, destroying the host cell. t4 has a burst size of approximately 100-150 viral particles per infected host. complementation, deletion, and recombination tests can be used to map out the rii gene locus by using t4. these bacteriophage infect a host cell with their information and then blow up the host cell, thereby propagating themselves.  the t4 phage has some unique features, including:  eukaryote-like introns  high speed dna copying mechanism, with only 1 error in 300 copies  special dna repair mechanisms  it infects e. coli o157:h7",t_9c814695a0bd,other,0
c_6268e2c8679e,"example calculating induced current based on change in flux.  - so we have something interesting going on. i have this ring of conductor right here, this square ring, it has a resistance of two ohms, we see that it is two meters by two meters so the area of this ring would be four square meters and we see a magnetic field going through the surface defined by the ring and it's constant, it's a constant magnetic field of five teslas and it's going exactly perpendicularly to, perpendicularly to the surface of the ring. now what we're going to happen, what we're going to see happen is over the next four seconds, and this is going to happen at a linear rate, it's going to happen at a constant rate, we're going to see the magnetic field over four seconds go from five teslas to 10 teslas so it's going to double over those four seconds and by doing so we're going to have a change in flux. let's think about what the change in flux is over this four seconds. so our initial flux, let me write it over here, so flux, let me use a different color and at any time if you are so inspired i encourage you to pause the video and figure out what our change in flux is. so our flux, flux initial is going to be, well it's the it's going to be the constant magnetic field, you could say the average magnetic field over the surface but since it's constant that's just going to be five teslas, so five teslas and it helps for, it helps us in this problem that the magnetic field vectors are exactly perpendicular to the surface, to the surface defined by the ring, if they weren't we would have to find the component that is perpendicular but we have that right over there so we have the five teslas, that's the average magnetic field or the average component of the magnetic field that is perpendicular to the surface, so five teslas times the area of the surface. so times, well two meters times two meters is four square meters so that is going to be equal to, that is equal to 20 tesla meter squared, tesla meter squared, fair enough. now what's the final, what's the final flux? the final flux, flux final is going to be equal to, well now the average magnetic field or the average components of the magnetic field that are perpendicular in the way i've defined this magnetic field, the vectors are already perpendicular is 10 teslas, so 10 teslas. the area of our ring hasn't changed, it's still four square meters, so times four square meters, and so what is this going to be? so our final flux is going to be final flux is going to be 40, 40 tesla meters squared. so what is our, what is our change in flux? let me write this over here, our change in flux, change in flux, which is going to be our final flux minus our initial flux is going to be 40 tesla meters squared minus 20 tesla meters squared, which is just going to be 20 tesla meters squared. so we figured out the change in flux, we actually know the change in time is going to be four seconds and actually using that we can now figure out what the voltage induced is going to be, the voltage induced, or the voltage that's going to now induce, induce a current. and if you were to look up faraday's law on the internet, you were to look up for a formula for faraday's law you would see something that looks like this, you would see voltage generated is equal to negative and, at least if you're not using the calculus version of it, negative n times our change in flux, change in, let me write change in flux not just flux, change in flux, delta flux over change in time. so one way to think about this, and to do this problem right we're assuming we have a constant or the rate of change is constant in our flux so you have your average rate of change of your flux and then you're going to multiply it times n. n is actually the number of loops you have, or you can think of it as the number of surfaces defined by it. in this exact example, in this exact example n is just going to be one, we just have one loop so that simplifies it right over there and then, so this is going to be, and you might say what is this negative because it's a bit of a strange thing because you know, how are we defining direction, you know what's in the-- and all of that and that's why i'm a little bit, i'm not a huge fan of this negative sign. this is, you know if you look it up in a textbook they'll often say, and you're not using calculus, they'll say, oh this reminder to use lenz's law, they'll write literally lenz's law and i would say if they want a reminder to use lenz's law why don't they just remind you to use lenz's law instead of putting a kind of bizarre negative sign there. and the negative sign actually does make sense if you were, if you were doing kind of the using the vectors here and taking the, and using a little bit of the, well, doing more sophisticated mathematics but this is just saying that the voltage induced is going to be in a direction so to induce a current whose, whose induced magnetic field will go in the direction, will counteract the change in flux, so that's just lenz's law there. so the real key here, at least for this example is to find our change in flux over change in time or our average, our average rate of change in flux and what is this going to be? well this is going to be 20 tesla meters squared, 20 tesla meters squared, that was our change in flux right over there divided by our change in time, which is four seconds, over four seconds, which is going to be equal to, and i'll, i could throw that negative there if we want to, that negative 20 divided by four is five, five tesla meters squared or square meters per second and this actually turns out to be a volt, so we could say this is negative five volts, negative, negative five volts, negative five volts. so if you have a voltage of, well let's just say five volts, we can think about the negative later, if you have a voltage of five volts across a, across a circuit that has a resistance of two ohms what is the current, what is the current going to be? well we just have to remind ourselves v is equal to i-r or voltage is equal to the current divided by the resistance, or voltage is equal to the current times the resistance or you could say that the current, the current is equal to the voltage divided by the resistance. so in this case the current, the current induced is going to be the voltage and i'm just going to focus on its absolute value now, we can think about its direction in a second. it's going to be its voltage, five volts divided by the resistance, so two ohms, two ohms, which is going to be equal to, this is going to be equal to 2.5, 2.5 amperes, 2.5 amperes. so we now know the magnitude of the current that's going to be induced while we have this change in flux, remember this is going to happen while, over the course of those four seconds, as we have this rate of change of flux, this average rate of change of flux, which we'll assume is the actual rate of change of flux, we're assuming that it's changing at a constant rate and so while it is changing we were just able to figure out that it would induce a current of 2.5 amperes. now the next question we should ask ourselves and this is where this little negative comes in, is a reminder for us to use lenz's law is, well which direction is that current going to go in? is it going to go in, let me pick two orientations, is it going to go in a, is it going to go in a, in a clockwise direction, is it going to go that way over the course of this change in flux or is it going to go in a counterclockwise direction, is it going to go that way? and to think about that we just have to use the right hand rule, take our right hand, point our thumb in the direction of the proposed direction of the current and so if we went with this one, our right hand, our right hand would look like this, i'm literally taking my left hand out and-- i mean my right hand out and i'm drawing it and i'm looking at it to think about what would happen, so that's my right hand so if i use the right hand if the current went in this direction then it would induce a magnetic field that went, that went like this and so if the current went in this direction the magnetic field it induces inside the surface would only reinforce the change in flux so it would only add to the flux so, and it's going in the same direction as the change in flux, which would just keep us, you know as we talked about in the lenz's law video, that would turn into just this source of energy that comes out of nowhere and defies the law of conservation of energy so this absolutely not, is not going to be the direction and so we know that the direction is going to be in a clockwise one. so the current, the 2.5 ampere current is going to flow, is going to flow like that, and we're done! by thinking about our change in flux and how long it's taking us, we were able to figure out not only the magnitude of the current, we were able to figure out the orientation of the direction that it's actually going to flow in.",t_3aafbb4067b5,other,0
c_9b362f204f9e,"skills to develop  in this section, we strive to understand the ideas generated by the following important questions:  what are the critical numbers of a function f and how are they connected to identifying the most extreme values the function achieves?  how does the first derivative of a function reveal important information about the behavior of the function, including the function’s extreme values?  how can the second derivative of a function be used to help identify extreme values of the function?  in many different settings, we are interested in knowing where a function achieves its least and greatest values. these can be important in applications – say to identify a point at which maximum profit or minimum cost occurs – or in theory to understand how to characterize the behavior of a function or a family of related functions. consider the simple and familiar example of a parabolic function such as  \[s(t) = −16t^2 +32t +48\]  which is shown at left in figure \(\pageindex{1}\) and that represents the height of an object tossed vertically: its maximum value occurs at the vertex of the parabola and represents the highest value that the object reaches. moreover, this maximum value identifies an especially important point on the graph, the point at which the curve changes from increasing to decreasing. more generally, for any function we consider, we can investigate where its lowest  figure \(\pageindex{1}\): at left, \(s(t) = −16t^2 + 24t + 32\) whose vertex is \((3/4 , 41)\); at right, a function \(g\) that demonstrates several high and low points.  and highest points occur in comparison to points nearby or to all possible points on the graph. given a function \(f\), we say that \(f (c)\) is a global or absolute maximum provided that \(f (c) ≥ f (x)\) for all \(x\) in the domain of \(f\), and similarly call \(f(c)\) a global or absolute minimum whenever \(f (c) ≤ f (x)\) for all x in the domain of f . for instance, for the function g given at right in figure \(\pageindex{1}\), \(g\) has a global maximum of \(g(c)\), but \(g\) does not appear to have a global minimum, as the graph of g seems to decrease without bound. we note that the point \((c, g(c))\) marks a fundamental change in the behavior of \(g\), where \(g\) changes from increasing to decreasing; similar things happen at both \((a, g(a))\) and \((b, g(b))\), although these points are not global mins or maxes.  for any function \(f\), we say that \(f (c)\) is a local maximum or relative maximum provided that \(f (c) ≥ f (x)\) for all x near c, while f (c) is called a local or relative minimum whenever \(f (c) ≤ f (x)\) for all \(x\) near \(c\). any maximum or minimum may be called an extreme value of \(f\). for example, in figure \(\pageindex{1}\), g has a relative minimum of g(b) at the point \((b, g(b))\) and a relative maximum of \(g(a)\) at \((a, g(a))\). we have already identified the global maximum of \(g\) as \(g(c)\); this global maximum can also be considered a relative maximum.  we would like to use fundamental calculus ideas to help us identify and classify key function behavior, including the location of relative extremes. of course, if we are given a graph of a function, it is often straightforward to locate these important behaviors visually. we investigate this situation in the following preview activity.  preview activity \(\pageindex{1}\)  consider the function h given by the graph in figure \(\pageindex{2}\). use the graph to answer each of the following questions.  figure \(\pageindex{2}\): the graph of a function h on the interval [−3, 3].  identify all of the values of \(c\) for which \(h(c)\) is a local maximum of \(h\).  identify all of the values of \(c\) for which \(h(c)\) is a local minimum of \(h\).  does h have a global maximum on the interval \([3, 3]\)? if so, what is the value of this global maximum?  does h have a global minimum on the interval \([3, 3]\)? if so, what is its value?  identify all values of \(c\) for which \(h'(c) = 0\).  identify all values of \(c\) for which \(h'(c)\) does not exist.  true or false: every relative maximum and minimum of \(h\) occurs at a point where \(h'(c)\) is either zero or does not exist.  true or false: at every point where \(h'(c)\) is zero or does not exist, \(h\) has a relative maximum or minimum.  critical numbers and the first derivative test  if a function has a relative extreme value at a point \((c, f (c))\), the function must change its behavior at c regarding whether it is increasing or decreasing before or after the point. for example, if a continuous function has a relative maximum at \(c\), such as those pictured in the two leftmost functions in figure \(\pageindex{3}\), then it is both necessary and sufficient that the function change from being increasing just before \(c\) to decreasing just after \(c\). in the same way, a continuous function has a relative minimum at c if and only if the function changes from decreasing to increasing at \(c\). see, for instance, the two functions pictured at right in figure \(\pageindex{3}\). there are only two possible ways for these changes in behavior to occur: either \(f' (c) = 0\) or \(f'(c)\) is undefined.  figure \(\pageindex{3}\): from left to right, a function with a relative maximum where its derivative is zero; a function with a relative maximum where its derivative is undefined; a function with neither a maximum nor a minimum at a point where its derivative is zero; a function with a relative minimum where its derivative is zero; and a function with a relative minimum where its derivative is undefined.  because these values of \(c\) are so important, we call them critical numbers. more specifically, we say that a function \(f\) has a critical number at \(x = c\) provided that \(c\) is in the domain of \(f\) , and \(f'(c) = 0\) or \(f'(c)\) is undefined. critical numbers provide us with the only possible locations where the function f may have relative extremes. note that not every critical number produces a maximum or minimum; in the middle graph of figure \(\pageindex{3}\), the function pictured there has a horizontal tangent line at the noted point, but the function is increasing before and increasing after, so the critical number does not yield a location where the function is greater than every value nearby, nor less than every value nearby.  we also sometimes use the terminology that, when \(c\) is a critical number, that \((c, f (c))\) is a critical point of the function, or that \(f (c)\) is a critical value.  the first derivative test summarizes how sign changes in the first derivative indicate the presence of a local maximum or minimum for a given function.  first derivative test  if \(p\) is a critical number of a continuous function \(f\) that is differentiable near \(p\) (except possibly at \(x = p\)), then f has a relative maximum at \(p\) if and only if \(f'\) changes sign from positive to negative at \(p\), and \(f\) has a relative minimum at \(p\) if and only if \(f'\) changes sign from negative to positive at \(p\).  we consider an example to show one way the first derivative test can be used to identify the relative extreme values of a function.  example \(\pageindex{1}\):  let \(f\) be a function whose derivative is given by the formula \(f'(x) = e^{−2x} (3 − x)(x + 1)^2\). determine all critical numbers of \(f\) and decide whether a relative maximum, relative minimum, or neither occurs at each.  solution  since we already have \(f'(x)\) written in factored form, it is straightforward to find the critical numbers of \(f\). since f' (x) is defined for all values of x, we need only 165 determine where f' (x) = 0. from the equation  \[f'(x)= e^{−2x} (3 − x)(x + 1)^2 = 0\]  and the zero product property, it follows that \(x = 3\) and \(x = −1\) are critical numbers of \(f\). (note particularly that there is no value of \(x\) that makes \(e^{−2x} = 0\).)  next, to apply the first derivative test, we’d like to know the sign of \(f'(x)\) at inputs near the critical numbers. because the critical numbers are the only locations at which f' can change sign, it follows that the sign of the derivative is the same on each of the intervals created by the critical numbers: for instance, the sign of f' must be the same for every \(x < −1\). we create a first derivative sign chart to summarize the sign of f' on the relevant intervals along with the corresponding behavior of f .  figure \(\pageindex{4}\): the first derivative sign chart for a function f whose derivative is given by the formula f' (x) = e −2x (3 − x)(x + 1) 2 .  the first derivative sign chart in figure \(\pageindex{4}\) comes from thinking about the sign of each of the terms in the factored form of \(f' (x)\) at one selected point in the interval under consideration. for instance, for \(x < −1\), we could consider \(x = −2\) and determine the sign of \(e^{−2x}\), \((3 − x)\), and \((x + 1)^2\) at the value \(x = −2\). we note that both \(e^{−2x}\) and \((x + 1)^2\) are positive regardless of the value of x, while \((3 − x)\) is also positive at \(x = −2\). hence, each of the three terms in \(f'\) is positive, which we indicate by writing “+ + +.” taking the product of three positive terms obviously results in a value that is positive, which we denote by the “+” in the interval to the left of x = −1 indicating the overall sign of \(f'\). and, since \(f'\) is positive on that interval, we further know that \(f\) is increasing, which we summarize by writing “inc” to represent the corresponding behavior of \(f\). in a similar way, we find that \(f'\) is positive and \(f\) is increasing on \(−1 < x < 3\), and \(f'\) is negative and \(f\) is decreasing for \(x > 3\).  now, by the first derivative test, to find relative extremes of \(f\) we look for critical numbers at which \(f'\) changes sign. in this example, \(f'\) only changes sign at \(x = 3\), where \(f'\) changes from positive to negative, and thus \(f\) has a relative maximum at \(x = 3\). while f has a critical number at \(x = −1\), since \(f\) is increasing both before and after \(x = −1\), \(f\) has neither a minimum nor a maximum at x = −1.  activity \(\pageindex{1}\)  suppose that \(g(x)\) is a function continuous for every value of \(x \neq 2\) whose first derivative is  \[g' (x) = \dfrac{(x + 4)(x − 1)^2}{x − 2}. \nonumber\]  further, assume that it is known that g has a vertical asymptote at \(x = 2\).  determine all critical numbers of \(g\).  by developing a carefully labeled first derivative sign chart, decide whether \(g\) has as a local maximum, local minimum, or neither at each critical number.  does g have a global maximum? global minimum? justify your claims.  what is the value of \(\lim_{x→∞} g'(x)\)? what does the value of this limit tell you about the long-term behavior of \(g\)?  sketch a possible graph of \(y = g(x)\).  the second derivative test  recall that the second derivative of a function tells us several important things about the behavior of the function itself. for instance, if \(f''\) is positive on an interval, then we know that \(f'\) is increasing on that interval and, consequently, that f is concave up, which also tells us that throughout the interval the tangent line to \(y = f (x)\) lies below the curve at every point. in this situation where we know that \(f' (p) = 0\), it turns out that the sign of the second derivative determines whether \(f\) has a local minimum or local maximum at the critical number \(p\).  in figure \(\pageindex{5}\), we see the four possibilities for a function \(f\) that has a critical number \(p\) at which \(f' (p) = 0\), provided \(f''(p)\) is not zero on an interval including p (except possibly at \(p\)). on either side of the critical number, \(f'\)' can be either positive or negative, and hence \(f\) can be either concave up or concave down. in the first two graphs, \(f\) does not change concavity at \(p\), and in those situations, \(f\) has either a local minimum or local maximum. in particular, if \(f' (p) = 0\) and \(f''(p) < 0\), then we know f is concave down at \(p\) with a horizontal tangent line, and this guarantees \(f\) has a local maximum there. this fact, along with the corresponding statement for when \(f''(p)\) is positive, is stated in the second derivative test.  figure \(\pageindex{5}\): four possible graphs of a function \(f\) with a horizontal tangent line at a critical point.  second derivative test  if \(p\) is a critical number of a continuous function \(f\) such that \(f' (p) = 0\) and \(f''(p) \neq 0\), then \(f\) has a relative maximum at \(p\) if and only if \(f''(p) < 0\), and \(f\) has a relative minimum at \(p\) if and only if \(f''(p) > 0\).  in the event that \(f''(p) = 0\), the second derivative test is inconclusive. that is, the test doesn’t provide us any information. this is because if \(f''(p) = 0\), it is possible that f has a local minimum, local maximum, or neither.1 just as a first derivative sign chart reveals all of the increasing and decreasing behavior of a function, we can construct a second derivative sign chart that demonstrates all of the important information involving concavity.  example \(\pageindex{2}\):  let f (x) be a function whose first derivative is  \[f' (x) = 3x^4−9x^2 .\nonumber\]  construct both first and second derivative sign charts for \(f\), fully discuss where \(f\) is increasing and decreasing and concave up and concave down, identify all relative extreme values, and sketch a possible graph of \(f\).  solution  since we know \(f' (x) = 3x^4 − 9x^2\), we can find the critical numbers of f by solving \(3x^4 − 9x^2 = 0\). factoring, we observe that  \[0 = 3x^2 \left(x^2 − 3\right) = 3x^2 \left(x + \sqrt{3}\right) \left(x − \sqrt{3} \right),\]  so that \(x = 0, ± \sqrt{3}\) are the three critical numbers of \(f\). it then follows that the first derivative sign chart for f is given in figure \(\pageindex{6}\). thus, \(f\) is increasing on the intervals (−∞, − √ 3) and ( √ 3, ∞), while \(f\) is decreasing on (− √ 3, 0) and (0, √ 3). note particularly that by the first derivative test, this information tells us that f has a local maximum at 1consider the functions \(f (x) = x 4\), g(x) = −x 4 , and h(x) = x 3 at the critical point p = 0.  figure \(\pageindex{6}\): the first derivative sign chart for f when f' (x) = 3x 4 − 9x 2 = 3x 2 (x 2 − 3).  x = − √ 3 and a local minimum at x = √ 3. while f also has a critical number at x = 0, neither a maximum nor minimum occurs there since f' does not change sign at x = 0. next, we move on to investigate concavity. differentiating f' (x) = 3x 4 − 9x 2 , we see that f''(x) = 12x 3 − 18x. since we are interested in knowing the intervals on which f'' is positive and negative, we first find where f''(x) = 0. observe that 0 = 12x 3 − 18x = 12x x 2 − 3 2 = 12x * , x + r 3 2 + - * , x − r 3 2 + - , which implies that x = 0, ± q 3 2 . building a sign chart for f'' in the exact same way we do for f' , we see the result shown in figure \(\pageindex{7}\). therefore, f is concave down on the  figure \(\pageindex{7}\): the second derivative sign chart for f when f''(x) = 12x 3 − 18x = 12x 2 x 2 − q 3 2 .  intervals (−∞, − q 3 2 ) and (0, q 3 2 ), and concave up on (− q 3 2 , 0) and ( q 3 2 , ∞). putting all of the above information together, we now see a complete and accurate 169 possible graph of f in figure \(\pageindex{8}\). the point a = (− √ 3, f (− √ 3)) is a local maximum, as f is increasing prior to a and decreasing after; similarly, the point e = ( √ 3, f ( √ 3) is a local minimum.  figure \(\pageindex{8}\): a possible graph of the function f in example 3.2.  note, too, that f is concave down at a and concave up at b, which is consistent both with our second derivative sign chart and the second derivative test. at points b and d, concavity changes, as we saw in the results of the second derivative sign chart in figure \(\pageindex{7}\). finally, at point \(c\), \(f\) has a critical point with a horizontal tangent line, but neither a maximum nor a minimum occurs there since f is decreasing both before and after \(c\).  it is also the case that concavity changes at \(c\). while we completely understand where f is increasing and decreasing, where f is concave up and concave down, and where f has relative extremes, we do not know any specific information about the y-coordinates of points on the curve. for instance, while we know that f has a local maximum at x = − √ 3, we don’t know the value of that maximum because we do not know f (− √ 3). any vertical translation of our sketch of f in figure \(\pageindex{8}\) would satisfy the given criteria for \(f\). points b, c, and d in figure \(\pageindex{8}\) are locations at which the concavity of f changes. we give a special name to any such point: if p is a value in the domain of a continuous function \(f\) at which f changes concavity, then we say that \((p, f (p))\) is an inflection point of \(f\). just as we look for locations where f changes from increasing to decreasing at points where \(f' (p) = 0\) or \(f' (p)\) is undefined, so too we find where \(f''(p) = 0\) or \(f''(p)\) is undefined to see if there are points of inflection at these locations. it is important at this point in our study to remind ourselves of the big picture that derivatives help to paint: the sign of the first derivative f' tells us whether the function \(f\) is increasing or decreasing, while the sign of the second derivative \(f''\) tells us how the function f is increasing or decreasing.  activity \(\pageindex{2}\):  suppose that \(g\) is a function whose second derivative, \(g''\), is given by the following graph.  figure \(\pageindex{9}\): the graph of y = g 00(x).  find all points of inflection of \(g\).  fully describe the concavity of \(g\) by making an appropriate sign chart.  suppose you are given that \(g' (−1.67857351) = 0\). is there is a local maximum, local minimum, or neither (for the function \(g\)) at this critical point of \(g\), or is it impossible to say? why?  assuming that \(g''(x)\) is a polynomial (and that all important behavior of \(g''\) is seen in the graph above, what degree polynomial do you think \(g(x)\) is? why?  as we will see in more detail in the following section, derivatives also help us to understand families of functions that differ only by changing one or more parameters. for instance, we might be interested in understanding the behavior of all functions of the form \(f (x) = a(x − h)^2 + k\) where \(a\), \(h\), and \(k\) are numbers that may vary. in the following activity, we investigate a particular example where the value of a single parameter has considerable impact on how the graph appears.  activity \(\pageindex{3}\):  consider the family of functions given by  \[h(x) = x^2 + \cos(k x)\]  where \(k\) is an arbitrary positive real number.  use a graphing utility to sketch the graph of h for several different \(k\)-values, including k = 1, 3, 5, 10. plot \(h(x) = x^2 + \cos(3x)\) on the axes provided below. what is the smallest value of \(k\) at which you think you can see (just by looking at the graph) at least one inflection point on the graph of \(h\)?  figure \(\pageindex{10}\): axes for plotting y = h(x).  explain why the graph of h has no inflection points if \(k ≤ \sqrt{2}\), but infinitely many inflection points if \(k > \sqrt{2}\).  explain why, no matter the value of \(k\), \(h\) can only have finitely many critical numbers.  summary  in this section, we encountered the following important ideas:  the critical numbers of a continuous function \(f\) are the values of \(p\) for which \(f' (p) = 0\) or \(f' (p)\) does not exist. these values are important because they identify horizontal tangent lines or corner points on the graph, which are the only possible locations at which a local maximum or local minimum can occur.  given a differentiable function \(f\), whenever \(f'\) is positive, \(f\) is increasing; whenever \(f'\) is negative, \(f\) is decreasing. the first derivative test tells us that at any point where \(f\) changes from increasing to decreasing, \(f\) has a local maximum, while conversely at any point where \(f\) changes from decreasing to increasing \(f\) has a local minimum.  given a twice differentiable function \(f\), if we have a horizontal tangent line at \(x = p\) and \(f''(p)\) is nonzero, then the fact that \(f''\) tells us the concavity of \(f\) will determine whether f has a maximum or minimum at \(x = p\). in particular, if \(f' (p) = 0\) and \(f''(p) < 0\), then f is concave down at \(p\) and \(f\) has a local maximum there, while if \(f' (p) = 0\) and \(f''(p) > 0\), then \(f\) has a local minimum at \(p\). if \(f' (p) = 0\) and \(f''(p) = 0\), then the second derivative does not tell us whether \(f\) has a local extreme at \(p\) or not.  contributors  matt boelkins (grand valley state university (https://activecalculus.org/)), david austin (grand valley state university), steve schlicker (grand valley state university)",t_c2dca5cf9033,other,0
c_3dcfe4e9822d,"trained interviewers call potential respondents on the telephone, often through random / automated dialing, and ask them a set of survey questions.  advantages:  lower cost than face-to-face  publicdomainimages – cc0  non-response rate is relatively low because interviewers can keep calling back until the respondent is home  interviewers can collect a large amount of data in a short time.  disadvantages:  some portions of the population do not have access to a telephone  increasing numbers use a mobile phone exclusively and fcc rules say that automated dialing to mobile phones is illegal  many respondents are suspicious of telephone interviews, consider them a sales pitch  long or complicated questions are inappropriate over the phone  increasing numbers of people have put themselves on federal “do not call” lists that prohibit researchers from calling  evaluating telephone interview survey data:  were the questionnaire and individual questions appropriately brief?  were the telephone banks staffed in a central location? (telephone interviewers who work from home are subject to less supervision, obviously)  what instructions were the interviewers given about who in the household they should interview?",t_4ac000a8bc4e,other,0
c_97e09805d5b7,"learn how to make a dowel from a wooden branch in this video how to make a dowel in this video, we're going to learn how to make a dowel. a dowel is used to strengthen the joint between two pieces of wood caution, this task requires: gloves closed footwear to make a dowel, you'll need: a bow saw a knife an auger for wood or hand drill and a hammer you'll need: a tree branch of a similar diameter to the mortise. choose green wood - or one that's been cut very recently this project can be done in 3 steps which we will outline for you step 1: saw the branch start off by making a hole with the drill or auger in a halving joint, this will serve as a pilot hole to learn more, see our videos on making a mortise and making a halving joint saw the branch to the desired length adding the length of your handspan from the tips of your outstretched thumb and little finger - or approximately 20cm, to give ample margin when making your dowel step 2: size the wood use your knife to shave the wood down to size turn it regularly to maintain a uniform roundness saw the other end of the dowel to flatten it off check that the dowel is the same size as the diameter of the hole careful, the dowel shouldn't slip into the hole easily  once you have sized it down to the right diameter, plane down the entirety of the length of the dowel to this size. once the entire dowel is at the right diameter, you're ready to assemble step 3: assembly position dowel vertically, over the mortise use the hammer to gently tap the dowel into the hole once it is firmly in, you can start hitting a little harder if you are having difficultly getting the dowel in, you can size it down more using a chisel once the dowel sticks through the other side of the joint, saw off the exess for a flat surface turn the joint over and do the same with the excess on the other side now you know how to make a dowel!",t_3d601f5ddcb2,other,0
c_70bf43ea54fd,"six bears were required to create this necklace, meant to imbue the pawnee chief with protection and power. [see learning resources here.](https://smarthistory.org/seeing-america-2/bear-pawnee-2/)      bear claw necklace (pawnee), before 1870, grizzly bear claws and hide, otter pelt, beads, cedar, tobacco and other materials (denver art museum), a smarthistory seeing america video speakers: dr. jo(piano music) - [steven] we're in the denver art museum looking at this magnificent pawnee necklace. its most striking feature are 34 large bear claws. - [john] the bear claws come off of what people refer to as a plains grizzly, which some people consider a subspecies that no longer exists on the plains today. - these were massive bears, they hunted buffalo. thinking about what must have gone into the collection of these claws, the hunt of these bears. - bears are associated with power and that's specifically why they are being used here. only the middle three of each front paw of an individual bear is only six claws per bear were used in the creation of this. it required at least six bears to create this work. one of the interesting attributes of these claws is not only the size, but also their ivory appearance. - in addition to the bear claws, there is an otter pelt that wraps around over the shoulder and around the breast and then over the other shoulder. - and on the backside of this, you see head of the otter hanging down one side of the shoulder and on the other side you have the tail and on the tail and on the head, there are beaded elements. - there are parts of this necklace that are not visible. - our records state that it's formed from a bear hide that is rolled to create the u-shape that goes around the neck, but it's also incorporated with cedar and tobacco, which ceremonially brings the prayers and the power into the piece to activate it. - and the power is protective. - the wearer of this has the power of the bear to protect their community from enemies and warfare, as well as from sickness or disease. - so this is a potent spiritual object and that's one of the reasons that it was being worn by the pawnee chief, a man named sky chief. - in 1873, sky chief led his group of pawnee on what became the last large-scale buffalo hunt on the plains. - and the last great intertribal warfare on the plains. - while they were out, there was word that there was lakota people in the area. at some point, sky chief removed his bear claw necklace thinking that the lakota might attack, handed it to his younger brother and told him to take off with it so it did not fall into lakota hands. - the act of taking the necklace off is making him vulnerable and is putting the necklace above his own life. - that's completely true and soon after removing the necklace on the hunt, he was skinning a buffalo when the lakota attacked. in 1873 when this battle occurred, or massacre rather, which became known as the battle of massacre canyon, the pawnee and lakota had been at war for about 40 years. - the politics at this moment were complicated. the pawnee had decided to work with the united states government and what the government was seeking was protection as they were moving westward and specifically, as the transcontinental railroad was being built. - sky chief was one of the great supporters of what was known as the accommodation treaty with the us army. the pawnee provided scouts to the us army and also provided protection to the building of the transcontinental railroad. part of this accommodation treaty was that the us army, in exchange for the pawnee's help, would provide them protection. yet during this massive buffalo hunt, only one field agent went with them on the hunt and he immediately escaped as soon as he saw trouble coming. - and the result was horrifying. the historical accounts vary wildly but we're probably on safe ground when we state that at least a hundred people were killed. - the pawnee were massacred. 2/3 of those killed were women and children. - this moment after the civil war was the moment when manifest destiny, the idea that the united states was entitled to all of the land between the atlantic and the pacific, was being actualized. but of course the issue here was there were lots of people living in between. - the pawnee consist of four distinct political units. after this event, the pawnee were moved to oklahoma, or at the time was known as indian territory. - this is such an intimidating necklace. the power of the claw, these long forms that curve under that look really terrifying, along with the otter express for me the close relationship between pawnee's society and the animals that they lived amongst. - pawnee religion included an emphasis on what some people refer to as animal lodge ceremonialism. animals had particular attributes and powers that the pawnee drew upon for use in their own lives. - and the necklace remains important to the pawnee people, but it's also an incredible window into american history. - in february 1998, a group of pawnee people came to the denver art museum to visit this necklace and to speak to it. william riding in, a pawnee man, said the following prayer to the necklace, ""father, smoke, and take notice of this smoke. i have clothed you and placed you upon mother earth. now then, father, smoke with me. take pity upon me. hear my prayers and give long life to him who will hereafter keep you and place you in a prominent place in his home. once you were owned by sky chief, a prominent chief. it was through your power that he was great. i have placed new clothing upon you. another man will now care for you and be with you always. show your powers to him and make him a good, wise chief and a great man, as you did to the others. may the men of the bear society have long life."" (piano music)",t_d4c7e897f28d,other,0
c_b7e19acccb24,"in addition to solving the inequality, we'll graph the solution. remember to swap if you mutiply both sides of the inequality by a negative number.  solve for c and graph the solution. we have negative 5c is less than or equal to 15. so negative 5c is less than or equal to 15. i just rewrote it a little bit bigger. so if we want to solve for c, we just want to isolate the c right over here, maybe on the left-hand side. it's right now being multiplied by negative 5. so the best way to just have a c on the left-hand side is we can multiply both sides of this inequality by the inverse of negative 5, or by negative 1/5. so we want to multiply negative 1/5 times negative 5c. and we also want to multiply 15 times negative 1/5. i'm just multiplying both sides of the inequality by the inverse of negative 5, because this will cancel out with the negative 5 and leave me just with c. now i didn't draw the inequality here, because we have to remember, if we multiply or divide both sides of an inequality by a negative number, you have to flip the inequality. and we are doing that. we are multiplying both sides by negative 1/5, which is the equivalent of dividing both sides by negative 5. so we need to turn this from a less than or equal to a greater than or equal. and now we can proceed solving for c. so negative 1/5 times negative 5 is 1. so the left-hand side is just going to be c is greater than or equal to 15 times negative 1/5. that's the same thing as 15 divided by negative 5. and so that is negative 3. so our solution is c is greater than or equal to negative 3. and let's graph it. so that is my number line. let's say that is 0, negative 1, negative 2, negative 3. and then i could go above, 1, 2. and so c is greater than or equal to negative 3. so it can be equal to negative 3. so i'll fill that in right over there. let me do it in a different color. so i'll fill it in right over there. and then it's greater than as well. so it's all of these values i am filling in in green. and you can verify that it works in the original inequality. pick something that should work. well, 0 should work. 0 is one of the numbers that we filled in. negative 5 times 0 is 0, which is less than or equal to 15. it's less than 15. now let's try a number that's outside of it. and i haven't drawn it here. i could continue with the number line in this direction. we would have a negative 4 here. negative 4 should not be included. and let's verify that negative 4 doesn't work. negative 4 times negative 5 is positive 20. and positive 20 is not less than 15, so it's good that we did not include negative 4. so this is our solution. and this is that solution graphed. and i wanted to do that in that other green color. here you go. that's what it looks like.",t_0571e083416e,other,0
c_c3bf9062cc45,we rewrite log₅(x³) as 3log₅(x).  ,t_3d64018a46e7,other,0
c_9bcb85a44902,"a _**consistent**_ system of equations has at least one solution, and an _**inconsistent**_ system has no solution. watch an example of analyzing a system to see if it's consistent or inconsistent.  is the system of linear equations below consistent or inconsistent? and they give us x plus 2y is equal to 13 and 3x minus y is equal to negative 11. so to answer this question, we need to know what it means to be consistent or inconsistent. so a consistent system of equations. has at least one solution. and an inconsistent system of equations, as you can imagine, has no solutions. so if we think about it graphically, what would the graph of a consistent system look like? let me just draw a really rough graph. so that's my x-axis, and that is my y-axis. so if i have just two different lines that intersect, that would be consistent. so that's one line, and then that's another line. they clearly have that one solution where they both intersect, so that would be a consistent system. another consistent system would be if they're the same line, because then they would intersect at a ton of points, actually at an infinite number of points. so let's say one of the lines looks like that. and then the other line is actually the exact same line. so it's exactly right on top of it. so those two intersect at every point along those lines, so that also would be consistent. an inconsistent system would have no solutions. so let me again draw my axes. let me once again draw my axes. it will have no solutions. and so the only way that you're going to have two lines in two dimensions have no solutions is if they don't intersect, or if they are parallel. so one line could look like this. and then the other line would have the same slope, but it would be shifted over. it would have a different y-intercept, so it would look like this. so that's what an inconsistent system would look like. you have parallel lines. this right here is inconsistent. so what we could do is just do a rough graph of both of these lines and see if they intersect. another way to do it is, you could look at the slope. and if they have the same slope and different y-intercepts, then you'd also have an inconsistent system. but let's just graph them. so let me draw my x-axis and let me draw my y-axis. so this is x and then this is y. and then there's a couple of ways we could do it. the easiest way is really just find two points on each of these that satisfy each of these equations, and that's enough to define a line. so for this first one, let's just make a little table of x's and y's. when x is 0, you have 2y is equal to 13, or y is equal to 13/2, which is the same thing as 6 and 1/2. so when x is 0, y is 6 and 1/2. i'll just put it right over here. so this is 0 comma 13/2. and then let's just see what happens when y is 0. when y is 0, then 2 times y is 0. you have x equaling 13. x equals 13. so we have the point 13 comma 0. so this is 0, 6 and 1/2, so 13 comma 0 would be right about there. we're just trying to approximate-- 13 comma 0. and so this line right up here, this equation can be represented by this line. let me try my best to draw it. it would look something like that. now let's worry about this one. let's worry about that one. so once again, let's make a little table, x's and y's. i'm really just looking for two points on this graph. so when x is equal to 0, 3 times 0 is just 0. so you get negative y is equal to negative 11, or you get y is equal to 11. so you have the point 0, 11, so that's maybe right over there. 0 comma 11 is on that line. and then when y is 0, you have 3x minus 0 is equal to negative 11, or 3x is equal to negative 11. or if you divide both sides by 3, you get x is equal to negative 11/3. and this is the exact same thing as negative 3 and 2/3. so when y is 0, you have x being negative 3 and 2/3. so maybe this is about 6, so negative 3 and 2/3 would be right about here. so this is the point negative 11/3 comma 0. and so the second equation will look like something like this. will look something like that. now clearly-- and i might have not been completely precise when i did this hand-drawn graph-- clearly these two guys intersect. they intersect right over here. and to answer their question, you don't even have to find the point that they intersect at. we just have to see, very clearly, that these two lines intersect. so this is a consistent system of equations. it has one solution. you just have to have at least one in order to be consistent. so once again, consistent system of equations.",t_d70645014785,other,0
c_dbfbd542dddc,"skills to develop  describe and give an example of an acute viral infection, a late complication following an acute infection, a latent viral infection, a chronic viral infection, and a slow viral infection.  most viruses that infect humans, such as those that cause routine respiratory infections (e.g., cold viruses, influenza viruses) and gastrointestinal infections (e.g., rotaviruses, noroviruses), cause acute infections. acute infections are of relatively short duration with rapid recovery.  in persistent infections, the viruses are continually present in the body. some persistent infections are late complications following an acute infection and include subacute sclerosing panencephalitis (sspe) that can follow an acute measles infection and progressive encephalitis that can follow rubella. other persistent infections are known as latent viral infection. in a latent viral infection the virus remains in equilibrium with the host for long periods of time before symptoms again appear, but the actual viruses cannot be detected until reactivation of the disease occurs. examples include infections caused by hsv-1 (fever blisters), hsv-2 (genital herpes), and vzv (chickenpox-shingles). in the case of chronic virus infections, the virus can be demonstrated in the body at all times and the disease may be present or absent for an extended period of time. examples include hepatitis b (caused by hbv) and hepatitis c (caused by hcv). slow infections are ones in which the infectious agents gradually increase in number over a very long period of time during which no significant symptoms are seen. examples include aids (caused  by hiv-1 and hiv-2) and certain lentiviruses that cause tumors in animals. although not viruses, prions also cause slow infections.  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | medscape (http://www.emedicine.com/) article on infections associated with organisms mentioned in this learning object. registration to access this website is free.      adenoviruses (http://www.emedicine.com/med/topic57.htm) herpes simplex (http://www.emedicine.com/med/topic1006.htm) varicella-zoster virus (http://www.emedicine.com/med/topic2361.htm) cytomegalovirus (http://www.emedicine.com/med/topic504.htm) hepatitis b (http://www.emedicine.com/med/topic992.htm) enteroviruses (http://www.emedicine.com/med/topic992.htm) rhinoviruses (http://www.emedicine.com/med/topic2030.htm) rubella (http://www.emedicine.com/ped/topic2025.htm) hepatitis c (http://www.emedicine.com/med/topic993.htm) measles (http://www.emedicine.com/ped/topic1388.htm) influenza (http://www.emedicine.com/med/topic1170.htm) hiv infection and aids (http://www.emedicine.com/emerg/topic253.htm) |  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  summary  acute infections are of relatively short duration with rapid recovery.  persistent infections are where the viruses are continually present in the body.  in a latent viral infection the virus remains in equilibrium with the host for long periods of time before symptoms again appear, but the actual viruses cannot be detected until reactivation of the disease occurs.  in a chronic virus infection, the virus can be demonstrated in the body at all times and the disease may be present or absent for an extended period of time.  slow infections are ones in which the infectious agents gradually increase in number over a very long period of time during which no significant symptoms are seen.  contributors  dr. gary kaiser (http://faculty.ccbcmd.edu/%7egkaiser/goshp.html) (community college of baltimore county, catonsville campus)",t_1127f4f7759c,other,0
c_c369bd14006e,"skills to develop  by the end of this section, you will be able to:  explain why it’s difficult to learn about venus from earth-based observation alone  describe the history of our interest in mars before the space age  compare the basic physical properties of earth, mars, and venus, including their orbits  as you might expect from close neighbors, mars and venus are among the brightest objects in the night sky. the average distance of mars from the sun is 227 million kilometers (1.52 au), or about half again as far from the sun as earth. venus’ orbit is very nearly circular, at a distance of 108 million kilometers (0.72 au) from the sun. like mercury, venus sometimes appears as an “evening star” and sometimes as a “morning star.” venus approaches earth more closely than does any other planet: at its nearest, it is only 40 million kilometers from us. the closest mars ever gets to earth is about 56 million kilometers.  appearance  venus appears very bright, and even a small telescope reveals that it goes through phases like the moon. galileo discovered that venus displays a full range of phases, and he used this as an argument to show that venus must circle the sun and not earth. the planet’s actual surface is not visible because it is shrouded by dense clouds that reflect about 70% of the sunlight that falls on them, frustrating efforts to study the underlying surface, even with cameras in orbit around the planet (figure (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#osc_astro_10_01_venus)).  venus as photographed by the pioneer venus orbiter.  this ultraviolet image shows an upper-atmosphere cloud structure that would be invisible at visible wavelengths. note that there is not even a glimpse of the planet’s surface.  in contrast, mars is more tantalizing as seen through a telescope (figure (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#osc_astro_10_01_mars)). the planet is distinctly red, due (as we now know) to the presence of iron oxides in its soil. this color may account for its association with war (and blood) in the legends of early cultures. the best resolution obtainable from telescopes on the ground is about 100 kilometers, or about the same as what we can see on the moon with the unaided eye. at this resolution, no hint of topographic structure can be detected: no mountains, no valleys, not even impact craters. on the other hand, bright polar ice caps can be seen easily, together with dusky surface markings that sometimes change in outline and intensity from season to season.  mars as seen from earth’s surface.  these are among the best earth-based photos of mars, taken in 1988 when the planet was exceptionally close to earth. the polar caps and dark surface markings are evident, but not topographic features.  for a few decades around the turn of the twentieth century, some astronomers believed that they saw evidence of an intelligent civilization on mars. the controversy began in 1877, when italian astronomer giovanni schiaparelli (1835–1910) announced that he could see long, faint, straight lines on mars that he called canale, or channels. in english-speaking countries, the term was mistakenly translated as “canals,” implying an artificial origin.  even before schiaparelli’s observations, astronomers had watched the bright polar caps change size with the seasons and had seen variations in the dark surface features. with a little imagination, it was not difficult to picture the canals as long fields of crops bordering irrigation ditches that brought water from the melting polar ice to the parched deserts of the red planet. (they assumed the polar caps were composed of water ice, which isn’t exactly true, as we will see shortly.)  until has death in 1916, the most effective proponent of intelligent life on mars was percival lowell, a self-made american astronomer and member of the wealthy lowell family of boston (see the feature box on percival lowell: dreaming of an inhabited mars (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#fs-id1168048373241)). a skilled author and speaker, lowell made what seemed to the public to be a convincing case for intelligent martians, who had constructed the huge canals to preserve their civilization in the face of a deteriorating climate (figure (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#osc_astro_10_01_marsglobe)).  lowell’s mars globe.  one of the remarkable globes of mars prepared by percival lowell, showing a network of dozens of canals, oases, and triangular water reservoirs that he claimed were visible on the red planet.  the argument for a race of intelligent martians, however, hinged on the reality of the canals, a matter that remained in serious dispute among astronomers. the canal markings were always difficult to study, glimpsed only occasionally because atmospheric conditions caused the tiny image of mars to shimmer in the telescope. lowell saw canals everywhere (even a few on venus), but many other observers could not see them at all and remained unconvinced of their existence. when telescopes larger than lowell’s failed to confirm the presence of canals, the skeptics felt vindicated. now it is generally accepted that the straight lines were an optical illusion, the result of the human mind’s tendency to see order in random features that are glimpsed dimly at the limits of the eye’s resolution. when we see small, dim dots of surface markings, our minds tend to connect those dots into straight lines.  percival lowell: dreaming of an inhabited mars  percival lowell was born into the well-to-do massachusetts family about whom john bossidy made the famous toast:  the home of the bean and the cod,   where the lowells talk to the cabots   and the cabots talk only to god.  and this is good old boston,  percival’s brother lawrence became president of harvard university, and his sister, amy, became a distinguished poet. percival was already interested in astronomy as a boy: he made observations of mars at age 13. his undergraduate thesis at harvard dealt with the origin of the solar system, but he did not pursue this interest immediately. instead, he entered the family business and traveled extensively in asia. in 1892, however, he decided to dedicate himself to carrying on schiaparelli’s work and solving the mysteries of the martian canals.  in 1894, with the help of astronomers at harvard but using his own funds, lowell built an observatory on a high plateau in flagstaff, arizona, where he hoped the seeing would be clear enough to show him mars in unprecedented detail. he and his assistants quickly accumulated a tremendous number of drawings and maps, purporting to show a vast network of martian canals (see figure (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#osc_astro_10_01_marsglobe)). he elaborated his ideas about the inhabitants of the red planet in several books, including mars (1895) and mars and its canals (1906), and in hundreds of articles and speeches.  as lowell put it,  a mind of no mean order would seem to have presided over the system we see—a mind certainly of considerably more comprehensiveness than that which presides over the various departments of our own public works. party politics, at all events, have had no part in them; for the system is planet-wide. . . . certainly what we see hints at the existence of beings who are in advance of, not behind us, in the journey of life.  lowell’s views captured the public imagination and inspired many novels and stories, the most famous of which was h. g. wells’ war of the worlds (1897). in this famous “invasion” novel, the thirsty inhabitants of a dying planet mars (based entirely on lowell’s ideas) come to conquer earth with advanced technology.  although the lowell observatory first became famous for its work on the martian canals, both lowell and the observatory eventually turned to other projects as well. he became interested in the search for a ninth (and then undiscovered) planet in the solar system. in 1930, pluto was found at the lowell observatory, and it is not a coincidence that the name selected for the new planet starts with lowell’s initials. it was also at the lowell observatory that the first measurements were made of the great speed at which galaxies are moving away from us, observations that would ultimately lead to our modern view of an expanding universe.  lowell (figure (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#osc_astro_10_01_lowell)) continued to live at his observatory, marrying at age 53 and publishing extensively. he relished the debate his claims about mars caused far more than the astronomers on the other side, who often complained that lowell’s work was making planetary astronomy a less respectable field. at the same time, the public fascination with the planets fueled by lowell’s work (and its interpreters) may, several generations later, have helped fan support for the space program and the many missions whose results grace the pages of our text.  percival lowell (1855–1916).  this 1914 photograph shows percival lowell observing venus with his 24-inch telescope at flagstaff, arizona.  in october 1938, the mercury theater of the air on radio dramatized the war of the worlds as a series of radio news reports. this broadcast (https://openstax.org/l/30warofworlds) scared many people into thinking that lowell’s martians were really invading new jersey, and caused something of a panic. you can listen to the original radio broadcast if you scroll down to “war of the worlds.”  rotation of the planets  astronomers have determined the rotation period of mars with great accuracy by watching the motion of permanent surface markings; its sidereal day is 24 hours 37 minutes 23 seconds, just a little longer than the rotation period of earth. this high precision is not obtained by watching mars for a single rotation, but by noting how many turns it makes over a long period of time. good observations of mars date back more than 200 years, a period during which tens of thousands of martian days have passed. as a result, the rotation period can be calculated to within a few hundredths of a second.  the rotational axis of mars has a tilt of about 25°, similar to the tilt of earth’s axis. thus, mars experiences seasons very much like those on earth. because of the longer martian year (almost two earth years), however, each season there lasts about six of our months.  the situation with venus is different. since no surface detail can be seen through venus’ clouds, its rotation period can be found only by bouncing radar signals off the planet (as explained for mercury in the cratered worlds (http://cnx.org/contents/2e737be8-ea65-48c3-aa0a-9f35b4c6a966@9.1:f5930002-07c4-4bec-8e25-f3ad35de6963@3) chapter). the first radar observations of venus’ rotation were made in the early 1960s. later, topographical surface features were identified on the planet that showed up in the reflected radar signals. the rotation period of venus, precisely determined from the motion of such “radar features” across its disk, is 243 days. even more surprising than how long venus takes to rotate is the fact that it spins in a backward or retrograde direction (east to west).  stop for a moment and think about how odd this slow rotation makes the calendar on venus. the planet takes 225 earth days to orbit the sun and 243 earth days to spin on its axis. so the day on venus (as defined by its spinning once) is longer than the year! as a result, the time the sun takes to return to the same place in venus’ sky—another way we might define the meaning of a day—turns out to be 117 earth days. (if you say “see you tomorrow” on venus, you’ll have a long time to wait.) although we do not know the reason for venus’ slow backward rotation, we can guess that it may have suffered one or more extremely powerful collisions during the formation process of the solar system.  basic properties of venus and mars  before discussing each planet individually, let us compare some of their basic properties with each other and with earth (table (http://cnx.org/contents/lnn76opl@9.1:x2ommvk0@3/the-nearest-planets-an-overvie#fs-id1168048335165)). venus is in many ways earth’s twin, with a mass 0.82 times the mass of earth and an almost identical density. the average amount of geological activity has been also relatively high, almost as high as on earth. on the other hand, with a surface pressure nearly 100 times greater than ours, venus’ atmosphere is not at all like that of earth. the surface of venus is also remarkably hot, with a temperature of 730 k (over 850 °f), hotter than the self-cleaning cycle of your oven. one of the major challenges presented by venus is to understand why the atmosphere and surface environment of this twin have diverged so sharply from those of our own planet.  -------------------------------------------------------------- |                        property |  earth |  venus |   mars |  |             semimajor axis (au) |   1.00 |   0.72 |   1.52 |  |                   period (year) |   1.00 |   0.61 |   1.88 |  |                mass (earth = 1) |   1.00 |   0.82 |   0.11 |  |                   diameter (km) | 12,756 | 12,102 |  6,790 |  |                 density (g/cm3) |    5.5 |    5.3 |    3.9 |  |     surface gravity (earth = 1) |   1.00 |   0.91 |   0.38 |  |          escape velocity (km/s) |   11.2 |   10.4 |    5.0 |  | rotation period (hours or days) | 23.9 h |  243 d | 24.6 h |  |        surface area (earth = 1) |   1.00 |   0.90 |   0.28 |  |      atmospheric pressure (bar) |   1.00 |     90 |  0.007 |  --------------------------------------------------------------  mars, by contrast, is rather small, with a mass only 0.11 times the mass of earth. it is larger than either the moon or mercury, however, and, unlike them, it retains a thin atmosphere. mars is also large enough to have supported considerable geological activity in the distant past. but the most fascinating thing about mars is that long ago it probably had a thick atmosphere and seas of liquid water—the conditions we associate with development of life. there is even a chance that some form of life persists today in protected environments below the martian surface.  key concepts and summary  venus, the nearest planet, is a great disappointment through the telescope because of its impenetrable cloud cover. mars is more tantalizing, with dark markings and polar caps. early in the twentieth century, it was widely believed that the “canals” of mars indicated intelligent life there. mars has only 11% the mass of earth, but venus is nearly our twin in size and mass. mars rotates in 24 hours and has seasons like earth; venus has a retrograde rotation period of 243 days. both planets have been extensively explored by spacecraft.  contributors  parseerror: eof expected (click for details)  callstack:     at (bookshelves/astronomy_and_cosmology_textmaps/map:_astronomy_(openstax)/10:_earthlike_planets_-_venus_and_mars/10.1:_the_nearest_planets_-_an_overview), /content/body/section[5]/div/div/ul/li/span, line 1, column 33",t_7e74febbac21,other,0
c_e34ef7d5f61e,"claude monet, la gare saint-lazare, 1877, oil on canvas, 75 x 104 cm (musée d’orsay, paris). speakers: dr. steven zucker and dr. beth harris  [music] we're in the musée d'orsay looking at monet's canvas ""gare saint-lazare."" this is one of several large train stations in the city of paris, and it's really interesting that we're looking at it in the musée d'orsay which is a renovated train station itself. -we think about train stations as just an ordinary part of urban life, but in the late 19th century in paris, large train stations carrying masses of people out to the suburbs, out to vacation spots, these were new kinds of structures. -and they express their modernity not only through their function, but also through their architecture. trains, at this point, were powered by burning coal and creating steam, and that required large open sheds which were held aloft by iron all of which spoke of modernity. this was not the traditional architecture of wood or of stone. this is a completely modern subject. -so this space looked modern, and it's not just the train shed, but the apartment buildings that we see beyond it that looked new. during the second half of the 19th century, paris was rebuilt. the old winding, maze-like, congested streets were torn down and wide boulevards were built with apartment buildings housing cafes and department stores catering to a new middle class, an upper-middle class that had cash to spend and the time and leisure to shop and to enjoy themselves in paris. -and in a subtler way, the idea of transportation itself, the idea of a place where people of different classes mix is also itself modern. for so long, french society had been rigidly ranked, but that's unraveling in the modern era and perhaps nowhere more vividly expressed than in a public space like the train station. -we often think about impressionist painting as being about leisure, renoir's ""moulin de la galette,"" for example, where we see figures socializing and dancing. -this is a working space, but look at this surface of this canvas. it's absolutely luscious. it's so drenched with steam and light and smoke that it seems to almost dissolve before our eyes. -it's difficult in some places to make out the architecture of the train shed, because that steam hides it especially on the left where those blueish lilac puffs of steam obscure that iron framework. -light is pouring through the opening at the top of the shed creating this prism of color that is playing across the steam within. in fact, one critic humorously said, i can't really see the paintings for all the smoke that's emanating from these six canvases that monet exhibited together each a play on the subject. -and it's not only the architectural structure that's disappearing, but the forms of the trains themselves. i mean, these are big machines that dissolve into light and atmosphere. -well that's what monet is interested in: pure color and pure light in the optical play before him, rather than his empirical knowledge of the solidity of an iron engine. -we have to remember that the impressionists were positioning themselves outside of the academic establishment. this painting and the group of other paintings of the gare saint-lazare were exhibited at an impressionist exhibition which was independent of the official exhibitions called salons that were sponsored by the royal academy, and so monet is not giving us a painting that would be a view of the gare saint-lazare with a factual accounting of what was in this station and what one knows of it, but you're right, this optical experience of light and atmosphere, this very subjective experience. -and monet was not the only person in his group that was interested in this subject. manet had painted this subject although in a very different way, and another important artist, caillebotte, had painted a scene from the bridge that we see just beyond the smokestack of the locomotive. -what fascinates me too is the degree to which monet has reduced the figures themselves to quick brushstrokes, and we can't make our faces. we can make out a little bit of gestures or postures, but he's really reducing the human figure to these quick strokes of pain. the human figure was the centerpiece of academic painting, and yet here it becomes equal to the trains and to the architecture he’s painting. -and subservient to the main subject of this painting: light and color. -other impressionist artists, like renoir, will concern themselves with the human figure within the light and atmosphere, but for monet it is the landscape and here, an urban landscape that is most important to him. and critics like baudelaire had been calling for artists to paint the beauty of modern life, and i think with paintings like the gare saint-lazare, monet is taking up that challenge. artists didn't need to paint classical antiquity anymore. they didn't need to paint biblical and history paintings. -they were creating a new beauty that was true to the new modern world in which they lived. but for all our talk about the sense of spontaneity, if you look at the surface, this is a heavily worked canvas. monet seems to be weaving color across the surface. you can see the paint has built up over time. there's no atmospheric perspective. the atmosphere is in the foreground as well as in the background all of which makes it impossible for us to forget that we're looking at paint on canvas. -monet and the impressionists are creating a new visual language for a new modern world. [music]",t_98a2663f682e,other,0
c_9cf4d55e6518,"problem set 5 (covers same mathematical skill of percent increase/decrease, but in a different context--profit/loss--than is specified by indicator 1.14.3)nys common core mathematics curriculum  lesson 6  7•4  lesson 6: fluency with percents classwork opening exercise solve the following problem using mental math only. be prepared to discuss your method with your classmates. cory and everett have collected model cars since the third grade. cory has 80 model cars in his collection, which is 25% more than everett has. how many model cars does everett have?  example 1: mental math and percents a.  75% of the students in jesse’s class are 60 inches or taller. if there are 20 students in her class, how many students are 60 inches or taller?  b.  bobbie wants to leave a tip for her waitress equal to 15% of her bill. bobbie’s bill for her lunch is $18. how much money represents 15% of the bill?  lesson 6:  fluency with percents  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g7-m4-te-1.3.0-09.2015  s.34 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  lesson 6  7•4  exercises 1.  express 9 hours as a percentage of 3 days.  2.  richard works from 11:00 a.m. to 3:00 a.m. his dinner break is 75% of the way through his work shift. what time is richard’s dinner break?  3.  at a playoff basketball game, there were 370 fans cheering for school a and 555 fans cheering for school b. a.  express the number of fans cheering for school a as a percent of the number of fans cheering for school b.  lesson 6:  fluency with percents  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g7-m4-te-1.3.0-09.2015  s.35 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  4.  lesson 6  7•4  b.  express the number of fans cheering for school b as a percent of the number of fans cheering for school a.  c.  what percent more fans were there for school b than for school a?  rectangle a has a width of 8 cm and a length of 16 cm. rectangle b has the same area as the first, but its width is 62.5% of the width of the first rectangle. express the length of rectangle b as a percent of the length of rectangle a. what percent more or less is the length of rectangle b than the length of rectangle a?  lesson 6:  fluency with percents  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g7-m4-te-1.3.0-09.2015  s.36 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  lesson 6  7•4  5.  a plant in mikayla’s garden was 40 inches tall one day and was 4 feet tall one week later. by what percent did the plant’s height increase over one week?  6.  loren must obtain a minimum number of signatures on a petition before it can be submitted. she was able to obtain 672 signatures, which is 40% more than she needs. how many signatures does she need?  lesson 6:  fluency with percents  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g7-m4-te-1.3.0-09.2015  s.37 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  lesson 6  7•4  lesson summary   identify the type of percent problem that is being asked as a comparison of quantities or a part of a whole.    identify what numbers represent the part, the whole, and the percent, and use the representation quantity = percent × whole.    a strategy to solving percents using mental math is to rewrite a percent using 1%, 5%, or 10%. these percents can be solved mentally. for example: 13% = 10% + 3(1%). to find 13% of 70, find 10% of 70 as 7, 1% of 70 as 0.7, so 13% of 70 is 7 + 3(0.7) = 7 + 2.10 = 9.10.  problem set 1.  micah has 294 songs stored in his phone, which is 70% of the songs that jorge has stored in his phone. how many songs are stored on jorge’s phone?  2.  lisa sold 81 magazine subscriptions, which is 27% of her class’s fundraising goal. how many magazine subscriptions does her class hope to sell?  3.  theresa and isaiah are comparing the number of pages that they read for pleasure over the summer. theresa read 2,210 pages, which was 85% of the number of pages that isaiah read. how many pages did isaiah read?  4.  in a parking garage, the number of suvs is 40% greater than the number of non-suvs. gina counted 98 suvs in the parking garage. how many vehicles were parked in the garage?  5.  the price of a tent was decreased by 15% and sold for $76.49. what was the original price of the tent in dollars?  6.  40% of the students at rockledge middle school are musicians. 75% of those musicians have to read sheet music when they play their instruments. if 38 of the students can play their instruments without reading sheet music, how many students are there at rockledge middle school?  7.  at longbridge middle school, 240 students said that they are an only child, which is 48% of the school’s student enrollment. how many students attend longbridge middle school?  8.  grace and her father spent 4 hours over the weekend restoring their fishing boat. this time makes up 6% of the  1 2  time needed to fully restore the boat. how much total time is needed to fully restore the boat?  lesson 6:  fluency with percents  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g7-m4-te-1.3.0-09.2015  s.38 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  9.  lesson 6  7•4  bethany’s mother was upset with her because bethany’s text messages from the previous month were 218% of the amount allowed at no extra cost under her phone plan. her mother had to pay for each text message over the allowance. bethany had 5,450 text messages last month. how many text messages is she allowed under her phone plan at no extra cost?  10. harry used 84% of the money in his savings account to buy a used dirt bike that cost him $1,050. how much money is left in harry’s savings account? 11. 15% of the students in mr. riley’s social studies classes watch the local news every night. mr. riley found that 136 of his students do not watch the local news. how many students are in mr. riley’s social studies classes? 12. grandma bailey and her children represent about 9.1% of the bailey family. if grandma bailey has 12 children, how many members are there in the bailey family? 13. shelley earned 20% more money in tips waitressing this week than last week. this week she earned $72.00 in tips waitressing. how much money did shelley earn last week in tips? 14. lucy’s savings account has 35% more money than her sister edy’s. together, the girls have saved a total of $206.80. how much money has each girl saved? 15. bella spent 15% of her paycheck at the mall, and 40% of that was spent at the movie theater. bella spent a total of $13.74 at the movie theater for her movie ticket, popcorn, and a soft drink. how much money was in bella’s paycheck? 16. on a road trip, sara’s brother drove 47.5% of the trip, and sara drove 80% of the remainder. if sara drove for 4 hours and 12 minutes, how long was the road trip?  lesson 6:  fluency with percents  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g7-m4-te-1.3.0-09.2015  s.39 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.",t_27970cffcf11,other,0
c_e4c74f6be618,"sal writes decimal numbers and fractions greater than 1 shown on number lines. decimals are limited to tenths and hundredths.  - [instructor] we're told express the point on the number line as both a fraction and a decimal. so pause this video and have a go at that. all right, now let's do this together. so we can see that the point in question, it's at a higher value than four and it's less than five. so greater than four, less than five. and the space between four and five is divided into one, two, three, four, five, six, seven, eight, nine, 10 equal sections. so each of these hash marks represent an extra tenth. so this is four, then this is four and one tenth, and now this is four right over here and two tenths. so we could write this, if we wanted to write it as a fraction or as a mixed number, this would be four and two tenths. and if we wanted to write that as a decimal, that would be four, and then in the tenths place, well we have two tenths. and that's it, we're done. let's do another example. so here, we're once again asked to express the point on the number line as both a fraction and a decimal, but this one's a little bit different. let's see how you can, if you can identify how it is different and answer the question. so pause this video, and once again have a go at it. all right, so here, our point, it's not between two whole numbers. it's actually between two tenths. we're between three and two tenths and three and three tenths. so this is between three and two tenths and three and three tenths. so each of these hash marks, which are a tenth of a tenth. so they would actually be a hundredth. so one way to think about it, you could view 3.2 or three and two tenths as three and 20 hundredths. and you could view three and three tenths as three and 30 hundredths. and so this is three and 20 hundredths. this is three and 21 hundredths, three and 22 hundredths. so this point right over here is three and 22 hundredths, 22 hundredths, and of course, you could also write that as a mixed number. that is three and 22 over 100. now another way that you could've approached it is hey, i'm starting at 3.2 or three and two tenths, and so i'm starting here at 3.2. and then i'm going to add to that, not just one hundredth, but two hundredths, so it would be three, two tenths, and then two hundredths. and there you have it, we've expressed it as both a fraction and a decimal.",t_1e17228de12c,other,0
c_6fa94afac294,"7.1: introduction to conics (/textmaps/precalculus_textmaps/map%3a_precalculus_(stitz-zeager)/7%3a_hooked_on_conics/7.1%3a_introduction_to_conics)  in exercises \ref{circleeqnfirst} - \ref{circleeqnlast}, find the standard equation of the circle and then graph it.  \begin{multicols}{2}  \begin{enumerate}  \item center $(-1, -5)$, radius $10$ \label{circleeqnfirst}  \item center $(4,-2)$, radius $3$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item center $\left(-3, \frac{7}{13}\right)$, radius $\frac{1}{2}$  \item center $(5, -9)$, radius $\ln(8)$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item center $\left(-e, \sqrt{2}\right)$, radius $\pi$  \item center $(\pi, e^{2})$, radius $\sqrt[3]{91}$ \label{circleeqnlast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{ctscirclefirst} - \ref{ctscirclelast}, complete the square in order to put the equation into standard form. identify the center and the radius or explain why the equation does not represent a circle.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^{2} - 4x + y^{2} + 10y = -25$ \label{ctscirclefirst}  \item $-2x^{2} - 36x - 2y^{2} - 112 = 0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^2+y^2+8x-10y -1 =0$  \item $x^2+y^2+5x-y-1=0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $4x^{2} + 4y^{2} - 24y + 36 = 0$  \item $x^{2} + x + y^{2} - \frac{6}{5}y = 1$ \label{ctscirclelast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  7.2: circles (/textmaps/precalculus_textmaps/map%3a_precalculus_(stitz-zeager)/7%3a_hooked_on_conics/7.2%3a_circles)  in exercises \ref{buildcirclefirst} - \ref{buildcirclelast}, find the standard equation of the circle which satisfies the given criteria.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item center $(3, 5)$, passes through $(-1, -2)$ \label{buildcirclefirst}  \item center $(3, 6)$, passes through $(-1, 4)$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item endpoints of a diameter: $(3,6)$ and $(-1,4)$  \item endpoints of a diameter: $\left( \frac{1}{2}, 4\right)$, $\left(\frac{3}{2}, -1\right)$ \label{buildcirclelast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item the giant wheel at cedar point is a circle with diameter 128 feet which sits on an 8 foot tall platform making its overall height is 136 feet.\footnote{source: \href{http://www.cedarpoint.com/public/par...nderline{cedar (http://www.cedarpoint.com/public/park/rides/tranquil/giant_wheel.cfm}{\underline{cedar) point's webpage}}.} find an equation for the wheel assuming that its center lies on the $y$-axis.  \label{giantwheelcircle}  \item verify that the following points lie on the unit circle: $(\pm 1, 0)$, $(0, \pm 1)$, $\left(\pm \frac{\sqrt{2}}{2}, \pm \frac{\sqrt{2}}{2}\right)$, $\left(\pm \frac{1}{2}, \pm \frac{\sqrt{3}}{2}\right)$ and $\left(\pm \frac{\sqrt{3}}{2}, \pm \frac{1}{2}\right)$  \item \label{circletransunitcircleexercise} discuss with your classmates how to obtain the standard equation of a circle, equation \ref{standardcircle}, from the equation of the unit circle, $x^2+y^2=1$ using the transformations discussed in section \ref{transformations}. (thus every circle is just a few transformations away from the unit circle.)  \item find an equation for the function represented graphically by the top half of the unit circle. explain how the transformations is section \ref{transformations} can be used to produce a function whose graph is either the top or bottom of an arbitrary circle.  \item find a one-to-one function whose graph is half of a circle. (hint: think piecewise.)  answers  \begin{multicols}{2}  \begin{enumerate}  \item $(x + 1)^{2} + (y + 5)^{2} = 100$  \begin{mfpic}[8]{-12}{10}{-16}{6}  \axes  \circle{(-1,-5),10}  \plotsymbol[3pt]{cross}{(-1,-5)}  \xmarks{-11,-1,9}  \ymarks{-15,-5,5}  \tlabel(10,-0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \tlabel(0.5,-5.25){\tiny $-5$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-11 \hspace{6pt}$} -11, {$-1 \hspace{6pt}$} -1, {$9$} 9}  \axislabels {y}{{$-15$} -15, {$5$} 5}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $(x-4)^2+(y+2)^2 = 9$  \begin{mfpic}[20]{-1}{8}{-6}{2}  \axes  \circle{(4,-2),3}  \plotsymbol[3pt]{cross}{(4,-2)}  \xmarks{1,4,7}  \ymarks{-5,-2,1}  \tlabel(8,-0.5){\scriptsize $x$}  \tlabel(0.5,2){\scriptsize $y$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$1$} 1,{$4$} 4,{$7$} 7}  \axislabels {y}{{$-5$} -5, {$-2$} -2, {$1$} 1 }  \normalsize  \end{mfpic}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\left(x + 3\right)^{2} + \left(y - \frac{7}{13}\right)^{2} = \frac{1}{4}$  \begin{mfpic}[35]{-4}{1}{-0.75}{2}  \axes  \circle{(-3,0.53846),0.5}  \plotsymbol[3pt]{cross}{(-3,0.53846)}  \xmarks{-3.5,-3,-2.5}  \ymarks{0.03846, 0.53836, 1.03846}  \tlabel(1,-0.25){\scriptsize $x$}  \tlabel(0.25,2){\scriptsize $y$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-\frac{7}{2} \hspace{6pt}$} -3.5, {$-3 \hspace{6pt}$} -3, {$-\frac{5}{2} \hspace{6pt}$} -2.5}  \axislabels {y}{{$\frac{1}{26}$} 0.03846, {$\frac{7}{13}$} 0.53846, {$\frac{27}{26}$} 1.03846}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $(x - 5)^{2} + (y + 9)^{2} = (\ln(8))^{2}$  \begin{mfpic}[10]{-1}{8}{-12}{1}  \axes  \circle{(5, -9),2.0794}  \plotsymbol[3pt]{cross}{(5,-9)}  \xmarks{2.92055, 5, 7.07944}  \ymarks{-11.07944, -9, -6.92055}  \tlabel(8,0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$5 - \ln(8)$} 2.92055, {$5$} 5, {$5 + \ln(8)$} 7.07944}  \axislabels {y}{{$-9 - \ln(8)$} -11.07944, {$-9$} -9, {$-9 + \ln(8)$} -6.92055}  \normalsize  \end{mfpic}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x + e)^{2} + \left(y - \sqrt{2} \right)^{2} = \pi^{2}$  \begin{mfpic}[10]{-7}{3}{-3}{6}  \axes  \circle{(-2.71828, 1.41421),3.14159}  \plotsymbol[3pt]{cross}{(-2.71828, 1.41421)}  \xmarks{-5.85987, -2.71828, 0.42331}  \ymarks{-1.72738,1.41421, 4.55581}  \tlabel(3,0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-e-\pi$} -6.85987, {$-e$} -2.71828, {$-e+\pi$} 1.42331}  \tlabel(0.5,-2.22738){$\sqrt{2}-\pi$}  \tlabel(0.5,1.41421){$\sqrt{2}$}  \tlabel(0.5,4.55581){$\sqrt{2}+\pi$}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $\left(x - \pi \right)^{2} + \left(y - e^{2}\right)^{2} = 91^{\frac{2}{3}}$  \begin{mfpic}[15]{-2}{8.25}{-0.25}{13}  \axes  \circle{(3.14159,7.389),4.4979}  \plotsymbol[3pt]{cross}{(3.14159,7.389)}  \xmarks{-1.3563, 3.14159, 7.6395}  \ymarks{2.8911, 7.389, 11.88699}  \tlabel(8.25,0.5){\scriptsize $x$}  \tlabel(0.25,13){\scriptsize $y$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$\pi - \sqrt[3]{91}$} -1.3563, {$\pi$} 3.14159, {$\pi + \sqrt[3]{91}$} 7.6395}  \axislabels {y}{{$e^{2} - \sqrt[3]{91}$} 2.8911, {$e^{2}$} 7.389, {$e^{2} + \sqrt[3]{91}$} 11.88699}  \normalsize  \end{mfpic}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x - 2)^{2} + (y + 5)^{2} = 4$\\  center $(2, -5)$, radius $r = 2$  \item $(x + 9)^{2} + y^{2} = 25$\\  center $(-9, 0)$, radius $r = 5$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x+4)^2 + (y-5)^2 = 42$ \\  center $(-4,5)$, radius $r = \sqrt{42}$  \item $\left(x + \frac{5}{2}\right)^2 + \left(y - \frac{1}{2}\right)^2 = \frac{30}{4}$ \\  center $\left( -\frac{5}{2}, \frac{1}{2}\right)$, radius $r = \frac{\sqrt{30}}{2}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^{2} + (y - 3)^{2} = 0$\\  this is not a circle.  \item $\left(x + \frac{1}{2}\right)^{2} + \left(y - \frac{3}{5}\right)^{2} = \frac{161}{100}$\\  center $\left(-\frac{1}{2}, \frac{3}{5}\right)$, radius $r = \frac{\sqrt{161}}{10}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x - 3)^{2} + (y - 5)^{2} = 65$  \item $(x-3)^2+(y-6)^2 = 20$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x-1)^2 + (y-5)^2 = 5$  \item $(x-1)^2 + \left(y - \frac{3}{2}\right)^2 = \frac{13}{2}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^{2} + (y - 72)^{2} = 4096$  \end{enumerate}  7.3: parabolas (/textmaps/precalculus_textmaps/map%3a_precalculus_(stitz-zeager)/7%3a_hooked_on_conics/7.3%3a_parabolas)  in exercises \ref{parabolasketchfirst} - \ref{parabolasketchlast}, sketch the graph of the given parabola. find the vertex, focus and directrix. include the endpoints of the latus rectum in your sketch.  \begin{multicols}{2}  \begin{enumerate}  \item $(x - 3)^{2} = -16y$ \label{parabolasketchfirst}  \item $\left(x + \frac{7}{3}\right)^{2} = 2\left(y + \frac{5}{2}\right)$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(y - 2)^{2} = -12(x + 3)$  \item $(y + 4)^{2} = 4x$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x-1)^2 = 4(y+3)$  \item $(x+2)^2 = -20(y-5)$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(y-4)^2 = 18(x-2)$  \item $\left(y+ \frac{3}{2}\right)^2 = -7 \left(x+ \frac{9}{2}\right)$ \label{parabolasketchlast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{stdfrmparabolafirst} - \ref{stdfrmparabolalast}, put the equation into standard form and identify the vertex, focus and directrix.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $y^{2} - 10y - 27x + 133 = 0$ \label{stdfrmparabolafirst}  \item $25x^{2} + 20x + 5y - 1 = 0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^2 + 2x - 8y + 49 = 0$  \item $2y^2 + 4y +x - 8 = 0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^2-10x+12y+1=0$  \item $3y^2-27y+4x+\frac{211}{4} = 0$ \label{stdfrmparabolalast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{buildparafirst} - \ref{buildparalast}, find an equation for the parabola which fits the given criteria.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item vertex $(7, 0)$, focus $(0, 0)$ \label{buildparafirst}  \item focus $(10, 1)$, directrix $x = 5$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item vertex $(-8, -9)$; $(0, 0)$ and $(-16, 0)$ are points on the curve  \item the endpoints of latus rectum are $(-2, -7)$ and $(4, -7)$ \label{buildparalast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item the mirror in carl's flashlight is a paraboloid of revolution. if the mirror is 5 centimeters in diameter and 2.5 centimeters deep, where should the light bulb be placed so it is at the focus of the mirror?  \item a parabolic wi-fi antenna is constructed by taking a flat sheet of metal and bending it into a parabolic shape.\footnote{this shape is called a `parabolic cylinder.'} if the cross section of the antenna is a parabola which is 45 centimeters wide and 25 centimeters deep, where should the receiver be placed to maximize reception?  \item \label{parabolaarch} a parabolic arch is constructed which is 6 feet wide at the base and 9 feet tall in the middle. find the height of the arch exactly 1 foot in from the base of the arch.  \item a popular novelty item is the `mirage bowl.' follow this \href{http://spie.org/etop/2007/etop07meth...derline{link}} (http://spie.org/etop/2007/etop07methodsv.pdf}{\underline{link}}) to see another startling application of the reflective property of the parabola.  \item with the help of your classmates, research spinning liquid mirrors. to get you started, check out this \href{http://www.astro.ubc.ca/lmt/lzt/}{\u...line{website}} (http://www.astro.ubc.ca/lmt/lzt/}{\underline{website}}).  \end{enumerate}  \newpage  \subsection{answers}  \begin{enumerate}  \item \begin{multicols}{2}  {\small $(x - 3)^{2} = -16y$}\\  {\small vertex $(3, 0)$}\\  {\small focus $(3, -4)$}\\  {\small directrix $y = 4$}\\  {\small endpoints of latus rectum $(-5, -4)$, $(11, -4)$}\\  \vfill  \columnbreak  \begin{mfpic}[10]{-6}{12}{-5}{5}  \axes  \xmarks{-5 step 1 until 11}  \ymarks{-4 step 1 until 4}  \arrow \reverse \arrow \function{-5.5,11.5,0.1}{((x - 3)**2)/(-16)}  \arrow \reverse \arrow \polyline{(-6,4),(12,4)}  \plotsymbol[3pt]{asterisk}{(3,-4)}  \tlabel(12,-0.5){\scriptsize $x$}  \tlabel(0.5,5){\scriptsize $y$}  \point[3pt]{(3,0),(-5,-4),(11,-4)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-5 \hspace{7pt}$} -5, {$-4 \hspace{7pt}$} -4, {$-3 \hspace{7pt}$} -3, {$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9, {$10$} 10, {$11$} 11}  \axislabels {y}{{$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \normalsize  \end{mfpic}  \end{multicols}  \smallskip  \item \begin{multicols}{2}  {\small $\left(x + \frac{7}{3}\right)^{2} = 2\left(y + \frac{5}{2}\right)$}\\  {\small vertex $\left(-\frac{7}{3}, -\frac{5}{2} \right)$}\\  {\small focus $\left(-\frac{7}{3}, -2 \right)$}\\  {\small directrix $y = -3$}\\  {\small endpoints of latus rectum $\left(-\frac{10}{3}, -2 \right)$, $\left(-\frac{4}{3}, -2 \right)$}\\  \vfill  \columnbreak  \begin{mfpic}[15][20]{-6}{1}{-4}{3}  \axes  \xmarks{-5 step 1 until 0}  \ymarks{-3 step 1 until 2}  \arrow \reverse \arrow \function{-5.5,0.8,0.1}{((x + (7/3))**2)/2 - (5/2)}  \arrow \reverse \arrow \polyline{(-5,-3),(1,-3)}  \plotsymbol[3pt]{asterisk}{(-2.333,-2)}  \tlabel(1,-0.5){\scriptsize $x$}  \tlabel(0.5,3){\scriptsize $y$}  \point[3pt]{(-2.333,-2.5),(-3.333,-2),(-1.333,-2)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-5 \hspace{7pt}$} -5, {$-4 \hspace{7pt}$} -4, {$-3 \hspace{7pt}$} -3, {$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1}  \axislabels {y}{{$-3$} -3, {$-2$} -2, {$-1$} -1, {$1$} 1, {$2$} 2}  \normalsize  \end{mfpic}  \end{multicols}  \smallskip  \item \begin{multicols}{2}  {\small $(y - 2)^{2} = -12(x + 3)$} \\  {\small vertex $(-3, 2)$} \\  {\small focus $(-6, 2)$} \\  {\small directrix $x = 0$}\\  {\small endpoints of latus rectum $(-6, 8)$, $(-6, -4)$}\\  \vfill  \columnbreak  \begin{mfpic}[10]{-8}{1}{-5}{9}  \axes  \xmarks{-7 step 1 until 0}  \ymarks{-4 step 1 until 8}  \arrow \reverse \function{-6.8,-3,0.1}{2+sqrt((-12*x) - 36)}  \arrow \reverse \function{-6.8,-3,0.1}{2-sqrt((-12*x) - 36)}  \plotsymbol[3pt]{asterisk}{(-6,2)}  \tlabel(1,-0.5){\scriptsize $x$}  \tlabel(0.5,9){\scriptsize $y$}  \point[3pt]{(-3,2),(-6,-4),(-6,8)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-7 \hspace{7pt}$} -7, {$-6 \hspace{7pt}$} -6, {$-5 \hspace{7pt}$} -5, {$-4 \hspace{7pt}$} -4, {$-3 \hspace{7pt}$} -3, {$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1}  \axislabels {y}{{$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8}  \normalsize  \end{mfpic}  \end{multicols}  \pagebreak  \item \begin{multicols}{2}  {\small $(y + 4)^{2} = 4x$}\\  {\small vertex $(0,-4)$} \\  {\small focus $(1,-4)$} \\  {\small directrix $x = -1$}\\  {\small endpoints of latus rectum $(1, -2)$, $(1, -6)$}\\  \vfill  \columnbreak  \begin{mfpic}[15]{-2}{5}{-9}{1}  \axes  \xmarks{-1 step 1 until 4}  \ymarks{-8 step 1 until 0}  \arrow \function{0,5,0.1}{-4-(2*sqrt(x))}  \arrow \function{0,5,0.1}{-4+(2*sqrt(x))}  \arrow \reverse \arrow \polyline{(-1,-9),(-1,1)}  \plotsymbol[3pt]{asterisk}{(1,-4)}  \tlabel(5,-0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \point[3pt]{(0,-4),(1,-2),(1,-6)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-8$} -8, {$-7$} -7, {$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \end{multicols}  \smallskip  \item \begin{multicols}{2}  {\small $(x-1)^2 = 4(y+3)$}\\  {\small vertex $\left(1, -3\right)$}\\  {\small focus $\left(1, -2 \right)$}\\  {\small directrix $y = -4$}\\  {\small endpoints of latus rectum $\left(3, -2 \right)$, $\left(-1, -2 \right)$}\\  \vfill  \columnbreak  \begin{mfpic}[15]{-4}{5}{-5}{1}  \axes  \xmarks{-3 step 1 until 4}  \ymarks{-4 step 1 until 0}  \arrow \reverse \arrow \function{-3,5,0.1}{((x -1)**2)/4 - 3}  \arrow \reverse \arrow \polyline{(-5,-4),(5,-4)}  \plotsymbol[3pt]{asterisk}{(1,-2)}  \tlabel(5,-0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \point[3pt]{(3,-2),(1,-3),(-1,-2)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-3 \hspace{7pt}$} -3, {$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \end{multicols}  \smallskip  \item \begin{multicols}{2}  {\small $(x+2)^2 = -20(y-5)$}\\  {\small vertex $\left(-2, 5\right)$}\\  {\small focus $\left(-2, 0 \right)$}\\  {\small directrix $y = 10$}\\  {\small endpoints of latus rectum $\left(-12, 0 \right)$, $\left(8, 0 \right)$}\\  \vfill  \columnbreak  \begin{mfpic}[7.5][10]{-13}{9}{-1}{11}  \axes  \xmarks{-12 step 1 until 8}  \ymarks{1 step 1 until 10}  \arrow \reverse \arrow \function{-13,9,0.1}{((x +2)**2)/(0-20) + 5}  \arrow \reverse \arrow \polyline{(-13,10),(9,10)}  \plotsymbol[3pt]{asterisk}{(-2,0)}  \tlabel(9,-0.5){\scriptsize $x$}  \tlabel(0.5,11){\scriptsize $y$}  \point[3pt]{(-12,0),(-2,5),(8,0)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-12 \hspace{7pt}$} -12, {$-10 \hspace{7pt}$} -10, {$-8 \hspace{7pt}$} -8, {$-6 \hspace{7pt}$} -6, {$-4 \hspace{7pt}$} -4, {$-2 \hspace{7pt}$} -2, {$2$} 2, {$4$} 4, {$6$} 6, {$8$} 8}  \axislabels {y}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9, {$10$} 10}  \normalsize  \end{mfpic}  \end{multicols}  \smallskip  \item \begin{multicols}{2}  {\small $(y-4)^2 = 18(x-2)$}\\  {\small vertex $\left(2, 4\right)$}\\  {\small focus $\left( \frac{13}{2}, 4 \right)$}\\  {\small directrix $x = -\frac{5}{2}$}\\  {\small endpoints of latus rectum $\left(\frac{13}{2}, -5 \right)$, $\left(\frac{13}{2}, 13 \right)$}\\  \vfill  \columnbreak  \begin{mfpic}[15][7.5]{-3}{8}{-6}{14}  \axes  \xmarks{-2 step 1 until 7}  \ymarks{-5 step 1 until 13}  \arrow \function{2,8,0.1}{4+(sqrt(18*(x-2)))}  \arrow \function{2,8,0.1}{4-(sqrt(18*(x-2)))}  \arrow \reverse \arrow \polyline{(-2.5,-6),(-2.5,14)}  \plotsymbol[3pt]{asterisk}{(6.5,4)}  \tlabel(8,-0.5){\scriptsize $x$}  \tlabel(0.5,14){\scriptsize $y$}  \point[3pt]{(6.5,-5),(2,4),(6.5,13)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-1$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7}  \axislabels {y}{{$-5$} -5, {$-3$} -3, {$-1$} -1, {$1$} 1, {$3$} 3, {$5$} 5, {$7$} 7, {$9$} 9, {$11$} 11, {$13$} 13}  \normalsize  \end{mfpic}  \end{multicols}  \smallskip  \item \begin{multicols}{2}  {\small $\left(y+ \frac{3}{2}\right)^2 = -7 \left(x+ \frac{9}{2}\right)$}\\  {\small vertex $\left(-\frac{9}{2}, -\frac{3}{2}\right)$}\\  {\small focus $\left( -\frac{25}{4}, -\frac{3}{2} \right)$}\\  {\small directrix $x = -\frac{11}{4}$}\\  {\small endpoints of latus rectum $\left(-\frac{25}{4}, 2 \right)$, $\left(-\frac{25}{4}, -5 \right)$}\\  \vfill  \columnbreak  \begin{mfpic}[15]{-7}{1}{-6}{3}  \axes  \xmarks{-6 step 1 until -1}  \ymarks{-5 step 1 until 2}  \arrow \function{-4.5,-7,0.1}{0-1.5+(sqrt((0-7)*(x+4.5)))}  \arrow \function{-4.5,-7,0.1}{0-1.5-(sqrt((0-7)*(x+4.5)))}  \arrow \reverse \arrow \polyline{(-2.75,-6),(-2.75,3)}  \plotsymbol[3pt]{asterisk}{(-6.25,-1.5)}  \tlabel(1,-0.5){\scriptsize $x$}  \tlabel(0.5,3){\scriptsize $y$}  \point[3pt]{(-6.25,-5),(-4.5,-1.5),(-6.25,2)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-5 \hspace{7pt}$} -5,{$-4 \hspace{7pt}$} -4,{$-3 \hspace{7pt}$} -3,{$-2 \hspace{7pt}$} -2,{$-1 \hspace{7pt}$} -1}  \axislabels {y}{{$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1, {$1$} 1, {$2$} 2}  \normalsize  \end{mfpic}  \end{multicols}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(y - 5)^{2} = 27(x - 4)$\\  vertex $(4, 5)$\\  focus $\left( \frac{43}{4}, 5 \right)$\\  directrix $x = -\frac{11}{4}$  \item $\left(x + \frac{2}{5} \right)^{2} = -\frac{1}{5}(y - 1)$\\  vertex $\left( -\frac{2}{5}, 1 \right)$\\  focus $\left( -\frac{2}{5}, \frac{19}{20} \right)$\\  directrix $y = \frac{21}{20}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x+1)^2=8(y-6)$ \\  vertex $(-1,6)$\\  focus $(-1,8)$ \\  directrix $y=4$  \item $(y+1)^2=-\frac{1}{2}(x-10)$\\  vertex $(10,-1)$\\  focus $\left(\frac{79}{8}, -1 \right)$\\  directrix $x = \frac{81}{8}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x-5)^2 = -12(y-2)$\\  vertex $(5,2)$\\  focus $(5,-1)$ \\  directrix $y=5$  \item $\left(y-\frac{9}{2}\right)^2 = -\frac{4}{3} (x-2)$\\  vertex $\left(2, \frac{9}{2}\right)$\\  focus $\left(\frac{5}{3}, \frac{9}{2}\right)$\\  directrix $x = \frac{7}{3}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $y^{2} = -28(x - 7)$  \item $(y - 1)^{2} = 10\left(x - \frac{15}{2} \right)$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x + 8)^{2} = \frac{64}{9}(y + 9)$  \item $(x - 1)^{2} = 6\left(y + \frac{17}{2}\right)$ or\\  $(x - 1)^{2} = -6\left(y + \frac{11}{2}\right)$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item the bulb should be placed $0.625$ centimeters above the vertex of the mirror. (as verified by carl himself!)  \item the receiver should be placed $5.0625$ centimeters from the vertex of the cross section of the antenna.  \item the arch can be modeled by $x^2=-(y-9)$ or $y=9-x^2$. one foot in from the base of the arch corresponds to either $x = \pm 2$, so the height is $y=9-(\pm 2)^2=5$ feet.  \end{enumerate}  \closegraphsfile  7.4: ellipses (/textmaps/precalculus_textmaps/map%3a_precalculus_(stitz-zeager)/7%3a_hooked_on_conics/7.4%3a_ellipses)  \subsection{exercises}  in exercises \ref{graphellipseexfirst} - \ref{graphellipseexlast}, graph the ellipse. find the center, the lines which contain the major and minor axes, the vertices, the endpoints of the minor axis, the foci and the eccentricity.  \begin{multicols}{2}  \begin{enumerate}  \item $\dfrac{x^{2}}{169} + \dfrac{y^{2}}{25} = 1$ \label{graphellipseexfirst}  \item $\dfrac{x^2}{9} + \dfrac{y^2}{25} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 2)^{2}}{4} + \dfrac{(y + 3)^{2}}{9} = 1$  \item $\dfrac{(x + 5)^{2}}{16} + \dfrac{(y - 4)^{2}}{1} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 1)^{2}}{10} + \dfrac{(y - 3)^{2}}{11} = 1$  \item $\dfrac{(x-1)^2}{9}+\dfrac{(y+3)^2}{4} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x+2)^2}{16}+\dfrac{(y-5)^2}{20} = 1$  \item $\dfrac{(x-4)^2}{8} + \dfrac{(y-2)^2}{18} = 1$ \label{graphellipseexlast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{stdformellipseexfirst} - \ref{stdformellipseexlast}, put the equation in standard form. find the center, the lines which contain the major and minor axes, the vertices, the endpoints of the minor axis, the foci and the eccentricity.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $9x^2+25y^2-54x-50y-119=0$ \label{stdformellipseexfirst}  \item $12x^{2} + 3y^{2} - 30y + 39 = 0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $5x^{2} + 18y^{2} - 30x + 72y + 27 = 0$  \item $x^2 - 2x + 2y^2 - 12y + 3 = 0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $9x^2 + 4y^2 - 4y - 8 = 0$  \item $6x^2+5y^2-24x+20y+14=0$ \label{stdformellipseexlast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{buildellipsefirst} - \ref{buildellipselast}, find the standard form of the equation of the ellipse which has the given properties.  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item center $(3, 7)$, vertex $(3, 2)$, focus $(3, 3)$ \label{buildellipsefirst}  \item foci $(0, \pm 5)$, vertices $(0, \pm 8)$.  \item foci $(\pm 3, 0)$, length of the minor axis $10$  \item vertices $(3,2)$, $(13,2)$; endpoints of the minor axis $(8,4)$, $(8,0)$  \item center $(5,2)$, vertex $(0,2)$, eccentricity $\frac{1}{2}$  \item all points on the ellipse are in quadrant iv except $(0, -9)$ and $(8, 0)$. (one might also say that the ellipse is ``tangent to the axes'' at those two points.) \label{buildellipselast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item repeat example \ref{whisgalleryex} for a whispering gallery 200 feet wide and 75 feet tall.  \item \label{ellipsearchex} an elliptical arch is constructed which is 6 feet wide at the base and 9 feet tall in the middle. find the height of the arch exactly 1 foot in from the base of the arch. compare your result with your answer to exercise \ref{parabolaarch} in section \ref{parabolas}.  \item the earth's orbit around the sun is an ellipse with the sun at one focus and eccentricity $e \approx 0.0167$. the length of the semimajor axis (that is, half of the major axis) is defined to be $1$ astronomical unit (au). the vertices of the elliptical orbit are given special names: `aphelion' is the vertex farthest from the sun, and `perihelion' is the vertex closest to the sun. find the distance in au between the sun and aphelion and the distance in au between the sun and perihelion.  \item the graph of an ellipse clearly fails the vertical line test, theorem \ref{vlt}, so the equation of an ellipse does not define $y$ as a function of $x$. however, much like with circles and horizontal parabolas, we can split an ellipse into a top half and a bottom half, each of which would indeed represent $y$ as a function of $x$. with the help of your classmates, use your calculator to graph the ellipses given in exercises \ref{graphellipseexfirst} - \ref{graphellipseexlast} above. what difficulties arise when you plot them on the calculator?  \item some famous examples of whispering galleries include \href{http://www.stpauls.co.uk/}{\underline{st (http://www.stpauls.co.uk/}{\underline{st). paul's cathedral}} in london, england, \href{http://www.aoc.gov/cc/capitol/nat_st...rline{national (http://www.aoc.gov/cc/capitol/nat_stat_hall.cfm}{\underline{national) statuary hall}} in washington, d.c., and \href{http://www.cincymuseum.org/}{\underline{the (http://www.cincymuseum.org/}{\underline{the) cincinnati museum center}}. with the help of your classmates, research these whispering galleries. how does the whispering effect compare and contrast with the scenario in example \ref{whisgalleryex}?  \item with the help of your classmates, research ``extracorporeal shock-wave lithotripsy''. it uses the reflective property of the ellipsoid to dissolve kidney stones.  \end{enumerate}  \newpage  \subsection{answers}  \begin{enumerate}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{x^{2}}{169} + \dfrac{y^{2}}{25} = 1$  center $(0, 0)$\\  major axis along $y = 0$\\  minor axis along $x = 0$\\  vertices $(13, 0), \, (-13, 0)$\\  endpoints of minor axis $(0,-5)$, $(0,5)$ \\  foci $(12, 0), \, (-12, 0)$\\  $e = \frac{12}{13}$\\  \begin{mfpic}[7][10]{-14}{14}{-6}{6}  \axes  \tlabel(14,-0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \xmarks{-13 step 1 until 13}  \ymarks{-5 step 1 until 5}  \ellipse{(0,0),13,5}  \plotsymbol[3pt]{asterisk}{(-12,0), (12,0)}  \plotsymbol[3pt]{cross}{(0,0)}  \point[3pt]{(-13,0), (13,0), (0,5), (0,-5)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-13 \hspace{6pt}$} -13, {$-1 \hspace{6pt}$} -1, {$1$} 1, {$13$} 13}  \axislabels {y}{{$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{x^{2}}{9} + \dfrac{y^{2}}{25} = 1$  center $(0, 0)$\\  major axis along $x = 0$\\  minor axis along $y = 0$\\  vertices $(0,5), \, (0,-5)$\\  endpoints of minor axis $(-3,0)$, $(3,0)$ \\  foci $(0,-4), \, (0,4)$\\  $e = \frac{4}{5}$\\  \begin{mfpic}[10]{-4}{4}{-6}{6}  \axes  \tlabel(4,-0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \xmarks{-3 step 1 until 3}  \ymarks{-5 step 1 until 5}  \ellipse{(0,0),3,5}  \plotsymbol[3pt]{asterisk}{(0,-4), (0,4)}  \plotsymbol[3pt]{cross}{(0,0)}  \point[3pt]{(-3,0), (3,0), (0,5), (0,-5)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$} -1,{$1$} 1, {$2$} 2, {$3$} 3}  \axislabels {y}{{$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x - 2)^{2}}{4} + \dfrac{(y + 3)^{2}}{9} = 1$  center $(2, -3)$\\  major axis along $x = 2$\\  minor axis along $y = -3$\\  vertices $(2, 0), \, (2, -6)$\\  endpoints of minor axis $(0,-3)$, $(4,-3)$\\  foci $(2, -3 + \sqrt{5}), \, (2, -3 - \sqrt{5})$\\  $e = \frac{\sqrt{5}}{3}$\\  \begin{mfpic}[15]{-1}{5}{-7}{1}  \axes  \tlabel(5,-0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \xmarks{1 step 1 until 4}  \ymarks{-6 step 1 until 0}  \ellipse{(2,-3),2,3}  \plotsymbol[3pt]{asterisk}{(2, -0.7639), (2,-5.23606)}  \plotsymbol[3pt]{cross}{(2,-3)}  \point[3pt]{(2,0), (2,-6), (0,-3), (4,-3)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x + 5)^{2}}{16} + \dfrac{(y - 4)^{2}}{1} = 1$  center $(-5, 4)$\\  major axis along $y = 4$\\  minor axis along $x = -5$\\  vertices $(-9, 4), \, (-1, 4)$\\  endpoints of minor axis $(-5,3)$, $(-5,5)$\\  foci $(-5 + \sqrt{15}, 4), \, (-5 - \sqrt{15}, 4)$\\  $e = \frac{\sqrt{15}}{4}$\\  \begin{mfpic}[16]{-10}{1}{-.5}{6}  \axes  \tlabel(1,-0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \xmarks{-9 step 1 until -1}  \ymarks{1 step 1 until 5}  \ellipse{(-5,4),4,1}  \plotsymbol[3pt]{asterisk}{(-8.873,4), (-1.127,4)}  \plotsymbol[3pt]{cross}{(-5,4)}  \point[3pt]{(-9,4), (-1,4), (-5,5), (-5,3)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$-9 \hspace{7pt}$} -9, {$-8 \hspace{7pt}$} -8, {$-7 \hspace{7pt}$} -7, {$-6 \hspace{7pt}$} -6, {$-5 \hspace{7pt}$} -5, {$-4 \hspace{7pt}$} -4, {$-3 \hspace{7pt}$} -3, {$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1}  \axislabels {y}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x - 1)^{2}}{10} + \dfrac{(y - 3)^{2}}{11} = 1$  center $(1, 3)$\\  major axis along $x = 1$\\  minor axis along $y = 3$\\  vertices $(1, 3 + \sqrt{11}), \, (1, 3 - \sqrt{11})$\\  endpoints of the minor axis \\ $(1-\sqrt{10}, 3), \, (1+\sqrt{10}, 3)$\\  foci $(1, 2), \, (1, 4)$\\  $e = \frac{\sqrt{11}}{11}$\\  \begin{mfpic}[18]{-3}{5}{-1}{7}  \axes  \tlabel(5,-0.25){\scriptsize $x$}  \tlabel(0.25,7){\scriptsize $y$}  \xmarks{-2 step 1 until 4}  \ymarks{1 step 1 until 6}  \ellipse{(1,3),3.1623,3.3166}  \plotsymbol[3pt]{asterisk}{(1,2), (1,4)}  \plotsymbol[3pt]{cross}{(1,3)}  \point[3pt]{(1,6.3166), (1,-0.3166), (-2.1623, 3), (4.1623,3)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x-1)^2}{9}+\dfrac{(y+3)^2}{4} = 1$  center $(1, -3)$\\  major axis along $y = -3$\\  minor axis along $x = 1$\\  vertices $(4, -3), \, (-2, -3)$\\  endpoints of the minor axis $(1,-1)$, $(1,-5)$\\  foci $(1+\sqrt{5}, -3), \, (1-\sqrt{5}, -3)$\\  $e = \frac{\sqrt{5}}{3}$\\  \begin{mfpic}[18]{-3}{5}{-6}{1}  \axes  \tlabel(5,-0.25){\scriptsize $x$}  \tlabel(0.25,1){\scriptsize $y$}  \xmarks{-2 step 1 until 4}  \ymarks{-5 step 1 until -1}  \ellipse{(1,-3),3,2}  \plotsymbol[3pt]{asterisk}{(3.2361,-3), (-1.2361,-3)}  \plotsymbol[3pt]{cross}{(1,-3)}  \point[3pt]{(4,-3), (-2,-3), (1,-1), (1,-5)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x+2)^2}{16}+\dfrac{(y-5)^2}{20} = 1$  center $(-2, 5)$\\  major axis along $x = -2$\\  minor axis along $y = 5$\\  vertices $(-2, 5 + 2\sqrt{5}), \, (-2, 5 - 2\sqrt{5})$\\  endpoints of the minor axis $(-6,5)$, $(2,5)$  foci $(-2, 7), \, (-2, 3)$\\  $e = \frac{\sqrt{5}}{5}$\\  \begin{mfpic}[18]{-7}{3}{-1}{11}  \axes  \tlabel(3,-0.25){\scriptsize $x$}  \tlabel(0.25,11){\scriptsize $y$}  \xmarks{-6 step 1 until 2}  \ymarks{1 step 1 until 11}  \ellipse{(-2,5),4,4.4721}  \plotsymbol[3pt]{asterisk}{(-2,7), (-2,3)}  \plotsymbol[3pt]{cross}{(-2,5)}  \point[3pt]{(-2,9.4721), (-2,0.5279), (-6,5), (2,5)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$-6 \hspace{7pt}$} -6,{$-5 \hspace{7pt}$} -5,{$-4 \hspace{7pt}$} -4,{$-3 \hspace{7pt}$} -3,{$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2}  \axislabels {y}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9, {$10$} 10 }  \normalsize  \end{mfpic}  \end{multicols}  \pagebreak  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x-4)^2}{8}+\dfrac{(y-2)^2}{18} = 1$  center $(4, 2)$\\  major axis along $x = 4$\\  minor axis along $y = 2$\\  vertices $(4, 2 + 3\sqrt{2}), \, (4, 2 - 3\sqrt{2})$\\  endpoints of the minor axis \\  $(4-2\sqrt{2},2)$, $(4+2\sqrt{2},2)$\\  foci $(4, 2+\sqrt{10}), \, (4, 2-\sqrt{10})$\\  $e = \frac{\sqrt{5}}{3}$\\  \begin{mfpic}[18]{-1}{8}{-4}{8}  \axes  \tlabel(8,-0.25){\scriptsize $x$}  \tlabel(0.25,8){\scriptsize $y$}  \xmarks{1 step 1 until 7}  \ymarks{-3 step 1 until 7}  \ellipse{(4,2),2.8284,4.2426}  \plotsymbol[3pt]{asterisk}{(4,5.1623), (4,-1.1623)}  \plotsymbol[3pt]{cross}{(4,2)}  \point[3pt]{(4,6.2426), (4,-2.2426), (1.1716, 2), (6.828,2)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7}  \axislabels {y}{{$-3$} -3,{$-2$} -2,{$-1$} -1,{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7}  \normalsize  \end{mfpic}  \end{multicols}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x-3)^2}{25} + \dfrac{\left(y-1\right)^2}{9} = 1$\\  center $\left(3, 1 \right)$\\  major axis along $y=1$\\  minor axis along $x=3$\\  vertices $\left( 8, 1 \right)$, $(-2, 1)$\\  endpoints of minor axis $\left(3,4\right)$, $\left(3,-2\right)$\\  foci $\left(7,1 \right)$, $\left(-1, 1\right)$\\  $e = \frac{4}{5}$  \vfill  \columnbreak  \item $\dfrac{x^{2}}{3} + \dfrac{(y - 5)^{2}}{12} = 1$\\  center $(0, 5)$\\  major axis along $x = 0$\\  minor axis along $y = 5$\\  vertices $(0, 5 - 2\sqrt{3}), (0, 5 + 2\sqrt{3})$\\  endpoints of minor axis $(-\sqrt{3},5)$, $(\sqrt{3},5)$\\  foci $(0, 2), (0, 8)$\\  $e = \frac{\sqrt{3}}{2}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 3)^{2}}{18} + \dfrac{(y + 2)^{2}}{5} = 1$\\  center $(3, -2)$\\  major axis along $y = -2$\\  minor axis along $x = 3$\\  vertices $(3 - 3\sqrt{2}, -2), (3 + 3\sqrt{2}, -2)$\\  endpoints of minor axis $(3,-2+\sqrt{5})$, $(3,-2-\sqrt{5})$\\  foci $(3 - \sqrt{13}, -2), (3 + \sqrt{13}, -2)$\\  $e = \frac{\sqrt{26}}{6}$  \vfill  \columnbreak  \item $\dfrac{(x - 1)^{2}}{16} + \dfrac{(y - 3)^{2}}{8} = 1$\\  center $(1,3)$ \\  major axis along $y=3$\\  minor axis along $x=1$\\  vertices $(5, 3)$, $(-3,3)$\\  endpoints of minor axis $(1,3+2\sqrt{2})$, $(1,3-2\sqrt{2})$\\  foci $(1 + 2 \sqrt{2}, 3)$, $(1-2 \sqrt{2},3)$\\  $e = \frac{\sqrt{2}}{2}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \pagebreak  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{x^2}{1} + \dfrac{4\left(y-\frac{1}{2}\right)^2}{9} = 1$\\  center $\left(0, \frac{1}{2} \right)$\\  major axis along $x=0$ (the $y$-axis)\\  minor axis along $y=\frac{1}{2}$\\  vertices $\left( 0, 2 \right)$, $(0, -1)$\\  endpoints of minor axis $\left(-1, \frac{1}{2} \right)$, $\left(1, \frac{1}{2} \right)$\\  foci $\left(0, \frac{1+\sqrt{5}}{2}\right)$, $\left(0, \frac{1-\sqrt{5}}{2}\right)$\\  $e = \frac{\sqrt{5}}{3}$  \vfill  \columnbreak  \item $\dfrac{(x-2)^2}{5} + \dfrac{\left(y+2\right)^2}{6} = 1$\\  center $\left(2, -2 \right)$\\  major axis along $x=2$\\  minor axis along $y=-2$\\  vertices $\left( 2, -2+\sqrt{6} \right)$, $(2, -2-\sqrt{6})$\\  endpoints of minor axis $\left(2-\sqrt{5},-2 \right)$, $\left(2+\sqrt{5},-2\right)$\\  foci $\left(2,-1 \right)$, $\left(2, -3\right)$\\  $e = \frac{\sqrt{6}}{6}$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 3)^{2}}{9} + \dfrac{(y - 7)^{2}}{25} = 1$  \item $\dfrac{x^{2}}{39} + \dfrac{y^{2}}{64} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{x^{2}}{34} + \dfrac{y^{2}}{25} = 1$  \item $\dfrac{(x - 8)^{2}}{25} + \dfrac{(y - 2)^{2}}{4} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x-5)^{2}}{25} + \dfrac{4(y-2)^{2}}{75} = 1$  \item $\dfrac{(x - 8)^{2}}{64} + \dfrac{(y + 9)^{2}}{81} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item jamie and jason should stand $100-25\sqrt{7} \approx 33.86$ feet from opposite ends of the gallery.  \item the arch can be modeled by the top half of $\frac{x^2}{9} + \frac{y^2}{81} = 1$. one foot in from the base of the arch corresponds to either $x = \pm 2$. plugging in $x = \pm 2$ gives $y = \pm 3\sqrt{5}$ and since $y$ represents a height, we choose $y=3\sqrt{5} \approx 6.71$ feet.  \item distance from the sun to aphelion $\approx 1.0167$ au.\\  distance from the sun to perihelion $\approx 0.9833$ au.  \end{enumerate}  \closegraphsfile  7.5: hyperbolas (/textmaps/precalculus_textmaps/map%3a_precalculus_(stitz-zeager)/7%3a_hooked_on_conics/7.5%3a_hyperbolas)  \subsection{exercises}  in exercises \ref{graphhyperbolafirst} - \ref{graphhyperbolalast}, graph the hyperbola. find the center, the lines which contain the transverse and conjugate axes, the vertices, the foci and the equations of the asymptotes.  \begin{multicols}{2}  \begin{enumerate}  \item $\dfrac{x^{2}}{16} - \dfrac{y^{2}}{9} = 1$ \label{graphhyperbolafirst}  \item $\dfrac{y^{2}}{9} - \dfrac{x^{2}}{16} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 2)^{2}}{4} - \dfrac{(y + 3)^{2}}{9} = 1$  \item $\dfrac{(y - 3)^{2}}{11} - \dfrac{(x - 1)^{2}}{10} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x + 4)^{2}}{16} - \dfrac{(y - 4)^{2}}{1} = 1$  \item $\dfrac{(x+1)^2}{9} - \dfrac{(y-3)^2}{4} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(y+2)^2}{16} - \dfrac{(x-5)^2}{20} = 1$  \item $\dfrac{(x-4)^2}{8} - \dfrac{(y-2)^2}{18} = 1$ \label{graphhyperbolalast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{stdfrmhypfirst} - \ref{stdfrmhyplast}, put the equation in standard form. find the center, the lines which contain the transverse and conjugate axes, the vertices, the foci and the equations of the asymptotes.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $12x^{2} - 3y^{2} + 30y - 111 = 0$ \label{stdfrmhypfirst}  \item $18y^{2} - 5x^{2} + 72y + 30x - 63= 0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $9x^2-25y^2-54x-50y-169 = 0$  \item $-6x^2+5y^2-24x+40y+26=0$ \label{stdfrmhyplast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  in exercises \ref{buildhypfirst} - \ref{buildhyplast}, find the standard form of the equation of the hyperbola which has the given properties.  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item center $(3, 7)$, vertex $(3, 3)$, focus $(3, 2)$ \label{buildhypfirst}  \item vertex $(0, 1)$, vertex $(8, 1)$, focus $(-3, 1)$  \item foci $(0, \pm 8)$, vertices $(0, \pm 5)$.  \item foci $(\pm 5, 0)$, length of the conjugate axis $6$  \item vertices $(3,2)$, $(13,2)$; endpoints of the conjugate axis $(8,4)$, $(8,0)$  \item vertex $(-10, 5)$, asymptotes $y = \pm \frac{1}{2}(x - 6) + 5$ \label{buildhyplast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  in exercises \ref{generalconicfirst} - \ref{generalconiclast}, find the standard form of the equation using the guidelines on page \pageref{idconocsrulesofthumb} and then graph the conic section.  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $x^2-2x-4y-11=0$ \label{generalconicfirst}  \item $x^2 + y^2-8x+4y+11=0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $9x^2 + 4y^2-36x+24y + 36=0$  \item $9x^2-4y^2-36x-24y-36=0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $y^2+8y-4x+16=0$  \item $4x^2+y^2-8x+4=0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $4x^2+9y^2-8x+54y+49=0$  \item $x^2 + y^2-6x+4y+14=0$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $2x^2+ 4y^2+12x-8y+25=0$  \item $4x^2-5y^2-40x-20y+160=0$ \label{generalconiclast}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item the graph of a vertical or horizontal hyperbola clearly fails the vertical line test, theorem \ref{vlt}, so the equation of a vertical of horizontal hyperbola does not define $y$ as a function of $x$.\footnote{we will see later in the text that the graphs of certain rotated hyperbolas pass the vertical line test.} however, much like with circles, horizontal parabolas and ellipses, we can split a hyperbola into pieces, each of which would indeed represent $y$ as a function of $x$. with the help of your classmates, use your calculator to graph the hyperbolas given in exercises \ref{graphhyperbolafirst} - \ref{graphhyperbolalast} above. how many pieces do you need for a vertical hyperbola? how many for a horizontal hyperbola?  \item the location of an earthquake's epicenter $-$ the point on the surface of the earth directly above where the earthquake actually occurred $-$ can be determined by a process similar to how we located sasquatch in example \ref{findthesasquatch}. (as we said back in exercise \ref{richterexercise} in section \ref{introexplogs}, earthquakes are complicated events and it is not our intent to provide a complete discussion of the science involved in them. instead, we refer the interested reader to a course in geology or the u.s. geological survey's earthquake hazards program found \href{http://earthquake.usgs.gov/}{\underline{here}}. (http://earthquake.usgs.gov/}{\underline{here}}.)) our technique works only for relatively small distances because we need to assume that the earth is flat in order to use hyperbolas in the plane.\footnote{back in the exercises in section \ref{cartesianplane} you were asked to research people who believe the world is flat. what did you discover?} the p-waves (``p'' stands for primary) of an earthquake in sasquatchia travel at 6 kilometers per second.\footnote{depending on the composition of the crust at a specific location, p-waves can travel between 5 kps and 8 kps.} station a records the waves first. then station b, which is 100 kilometers due north of station a, records the waves 2 seconds later. station c, which is 150 kilometers due west of station a records the waves 3 seconds after that (a total of 5 seconds after station a). where is the epicenter?  \item \label{hyperbolaeccentricity} the notion of eccentricity introduced for ellipses in definition \ref{ellipseeccentricity} in section \ref{ellipses} is the same for hyperbolas in that we can define the eccentricity $e$ of a hyperbola as  \[ e = \dfrac{\mbox{distance from the center to a focus}}{\mbox{distance from the center to a vertex}} \]  \begin{enumerate}  \item with the help of your classmates, explain why $e > 1$ for any hyperbola.  \item find the equation of the hyperbola with vertices $(\pm 3,0)$ and eccentricity $e = 2$.  \item with the help of your classmates, find the eccentricity of each of the hyperbolas in exercises \ref{graphhyperbolafirst} - \ref{graphhyperbolalast}. what role does eccentricity play in the shape of the graphs?  \end{enumerate}  \item on page \pageref{paraboloid} in section \ref{parabolas}, we discussed paraboloids of revolution when studying the design of satellite dishes and parabolic mirrors. in much the same way, `natural draft' cooling towers are often shaped as \index{hyperboloid} \textbf{hyperboloids of revolution}. each vertical cross section of these towers is a hyperbola. suppose the a natural draft cooling tower has the cross section below. suppose the tower is 450 feet wide at the base, 275 feet wide at the top, and 220 feet at its narrowest point (which occurs 330 feet above the ground.) determine the height of the tower to the nearest foot.  \begin{center}  \begin{mfpic}[20]{-3}{3}{0}{5}  \curve{(3,0), (1.5,3), (2,5)}  \curve{(-3,0), (-1.5,3), (-2,5)}  \point[3pt]{(3,0), (1.5,3), (2,5), (-3,0), (-1.5,3), (-2,5)}  \arrow \reverse \arrow \polyline{(-2.75,0), (2.75,0)}  \tlabel[cc](0,-0.5){\scriptsize $450$ ft}  \arrow \reverse \arrow \polyline{(-1.25,3), (1.25,3)}  \tlabel[cc](0,2.5){\scriptsize $220$ ft}  \arrow \reverse \arrow \polyline{(-1.75,5), (1.75,5)}  \tlabel[cc](0,5.5){\scriptsize $275$ ft}  \arrow \reverse \arrow \polyline{(5,0.25), (5,2.75)}  \dotted \polyline{(1.5,3), (5,3)}  \gclear \tlabelrect[cc]{(5,1.5)}{\scriptsize $330$ ft}  \end{mfpic}  \end{center}  \item with the help of your classmates, research the cassegrain telescope. it uses the reflective property of the hyperbola as well as that of the parabola to make an ingenious telescope.  \item \label{conicsclassificationnoxytermex} with the help of your classmates show that if $ax^2 + cy^2 + dx + ey + f = 0$ determines a non-degenerate conic\footnote{recall that this means its graph is either a circle, parabola, ellipse or hyperbola.} then  \begin{itemize}  \item $ac < 0$ means that the graph is a hyperbola  \item $ac = 0$ means that the graph is a parabola  \item $ac > 0$ means that the graph is an ellipse or circle  \end{itemize}  \textbf{note:} this result will be generalized in theorem \ref{conicclassification} in section \ref{rotationaxes}.  \end{enumerate}  \newpage  \subsection{answers}  \begin{enumerate}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{x^{2}}{16} - \dfrac{y^{2}}{9} = 1$  center $(0, 0)$\\  transverse axis on $y = 0$\\  conjugate axis on $x = 0$\\  vertices $(4, 0), (-4, 0)$\\  foci $(5, 0), (-5, 0)$\\  asymptotes $y = \pm \frac{3}{4} x$\\  \begin{mfpic}[12][9]{-7}{7}{-7}{7}  \axes  \tlabel(7,-0.5){\scriptsize $x$}  \tlabel(0.5,7){\scriptsize $y$}  \xmarks{-6 step 1 until 6}  \ymarks{-6 step 1 until 6}  \point[3pt]{(4,0),(-4,0)}  \dotted[1pt, 3pt] \polyline{(-4,3), (4,3), (4, -3), (-4,-3), (-4,3)}  \arrow \reverse \arrow \parafcn{-5,5,0.1}{(sqrt(16 + (1.778*(t**2))),t)}  \arrow \reverse \arrow \parafcn{-5,5,0.1}{(-sqrt(16 + (1.778*(t**2))),t)}  \arrow \reverse \arrow \dashed \function{-7,7,0.1}{0.75*x}  \arrow \reverse \arrow \dashed \function{-7,7,0.1}{-0.75*x}  \plotsymbol[3pt]{cross}{(0,0)}  \plotsymbol[3pt]{asterisk}{(5,0), (-5,0)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-6 \hspace{6pt}$} -6, {$-5 \hspace{6pt}$} -5, {$-4 \hspace{6pt}$} -4, {$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6}  \axislabels {y}{{$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{y^{2}}{9} - \dfrac{x^{2}}{16} = 1$  center $(0, 0)$\\  transverse axis on $x = 0$\\  conjugate axis on $y = 0$\\  vertices $(0, 3), (0, -3)$\\  foci $(0, 5), (0, -5)$\\  asymptotes $y = \pm \frac{3}{4} x$\\  \begin{mfpic}[12][9]{-7}{7}{-7}{7}  \axes  \tlabel(7,-0.5){\scriptsize $x$}  \tlabel(0.5,7){\scriptsize $y$}  \xmarks{-6 step 1 until 6}  \ymarks{-6 step 1 until 6}  \point[3pt]{(0,3),(0,-3)}  \dotted[1pt, 3pt] \polyline{(-4,3), (4,3), (4, -3), (-4,-3), (-4,3)}  \arrow \reverse \arrow \function{-7,7,0.1}{sqrt(9 + (0.5625*(x**2)))}  \arrow \reverse \arrow \function{-7,7,0.1}{-sqrt(9 + (0.5625*(x**2)))}  \arrow \reverse \arrow \dashed \function{-7,7,0.1}{0.75*x}  \arrow \reverse \arrow \dashed \function{-7,7,0.1}{-0.75*x}  \plotsymbol[3pt]{cross}{(0,0)}  \plotsymbol[3pt]{asterisk}{(0,5), (0,-5)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-6 \hspace{6pt}$} -6, {$-5 \hspace{6pt}$} -5, {$-4 \hspace{6pt}$} -4, {$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6}  \axislabels {y}{{$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x - 2)^{2}}{4} - \dfrac{(y + 3)^{2}}{9} = 1$  center $(2, -3)$\\  transverse axis on $y = -3$\\  conjugate axis on $x = 2$\\  vertices $(0, -3), (4, -3)$\\  foci $(2 + \sqrt{13}, -3), (2 - \sqrt{13}, -3)$\\  asymptotes $y = \pm \frac{3}{2}(x - 2) - 3$\\  \begin{mfpic}[12][9]{-4}{8}{-11}{5}  \axes  \tlabel(8,-0.5){\scriptsize $x$}  \tlabel(0.5,5){\scriptsize $y$}  \xmarks{-3 step 1 until 7}  \ymarks{-10 step 1 until 4}  \point[3pt]{(0,-3),(4,-3)}  \dotted[1pt, 3pt] \polyline{(0,0), (4,0), (4, -6), (0,-6), (0,0)}  \arrow \function{4,7,0.1}{-3 + sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \reverse \function{-3,0,0.1}{-3 + sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \function{4,7,0.1}{-3 - sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \reverse \function{-3,0,0.1}{-3 - sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \reverse \arrow \dashed \function{-3,7,0.1}{-1.5*x}  \arrow \reverse \arrow \dashed \function{-3,7,0.1}{(1.5*x) - 6}  \plotsymbol[3pt]{cross}{(2,-3)}  \plotsymbol[3pt]{asterisk}{(5.60555,-3), (-1.60555,-3)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7}  \axislabels {y}{{$-10$} -10, {$-9$} -9, {$-8$} -8, {$-7$} -7, {$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \normalsize  \end{mfpic}  \end{multicols}  \pagebreak  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(y - 3)^{2}}{11} - \dfrac{(x - 1)^{2}}{10} = 1$  center $(1, 3)$\\  transverse axis on $x = 1$\\  conjugate axis on $y = 3$\\  vertices $(1, 3 + \sqrt{11}), (1, 3 - \sqrt{11})$\\  foci $(1, 3 + \sqrt{21}), (1, 3 - \sqrt{21})$\\  asymptotes $y = \pm \frac{\sqrt{110}}{10}(x - 1) + 3$\\  \begin{mfpic}[12][9]{-6}{8}{-4}{10}  \axes  \tlabel(8,-0.5){\scriptsize $x$}  \tlabel(0.5,10){\scriptsize $y$}  \xmarks{-5 step 1 until 7}  \ymarks{-3 step 1 until 9}  \point[3pt]{(1,6.16228),(1,-0.16228)}  \dotted[1pt, 3pt] \polyline{(-2.3166,6.16228), (4.3166,6.16228), (4.3166,-0.16228), (-2.3166,-0.16228), (-2.3166,6.16228)}  \arrow \reverse \arrow \function{-5.5,7.5,0.1}{3 + sqrt(10 + (0.90909*((x-1)**2)))}  \arrow \reverse \arrow \function{-5.5,7.5,0.1}{3 - sqrt(10 + (0.90909*((x-1)**2)))}  \arrow \reverse \arrow \dashed \function{-6,8,0.1}{0.95346*(x - 1) + 3}  \arrow \reverse \arrow \dashed \function{-6,8,0.1}{-0.95346*(x - 1) + 3}  \plotsymbol[3pt]{cross}{(1,3)}  \plotsymbol[3pt]{asterisk}{(1,7.58258), (1,-1.58258)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-5 \hspace{6pt}$} -5, {$-4 \hspace{6pt}$} -4, {$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7}  \axislabels {y}{{$-3$} -3, {$-2$} -2, {$-1$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x + 4)^{2}}{16} - \dfrac{(y - 4)^{2}}{1} = 1$  center $(-4, 4)$\\  transverse axis on $y = 4$\\  conjugate axis on $x = -4$\\  vertices $(-8, 4), (0, 4)$\\  foci $(-4 + \sqrt{17}, 4), (-4 - \sqrt{17}, 4)$\\  asymptotes $y = \pm \frac{1}{4}(x +4) +4$\\  \begin{mfpic}[12][9]{-12}{4}{-1}{6}  \axes  \tlabel(4,-0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \xmarks{-11 step 1 until 3}  \ymarks{1 step 1 until 5}  \point[3pt]{(-8,4),(0,4)}  \dotted[1pt, 3pt] \polyline{(-8,5), (0,5), (0,3), (-8,3), (-8,5)}  \arrow \function{0,4,0.1}{4 + sqrt((0.0625*((x + 4)**2)) - 1)}  \arrow \reverse \function{-12,-8,0.1}{4 + sqrt((0.0625*((x + 4)**2)) - 1)}  \arrow \function{0,4,0.1}{4 - sqrt((0.0625*((x + 4)**2)) - 1)}  \arrow \reverse \function{-12,-8,0.1}{4 - sqrt((0.0625*((x + 4)**2)) - 1)}  \arrow \reverse \arrow \dashed \function{-12,4,0.1}{0.25*x + 5}  \arrow \reverse \arrow \dashed \function{-12,4,0.1}{-0.25*x + 3}  \plotsymbol[3pt]{cross}{(-4,4)}  \plotsymbol[3pt]{asterisk}{(0.123106,4), (-8.123106,4)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-11 \hspace{6pt}$} -11, {$-10 \hspace{6pt}$} -10, {$-9 \hspace{6pt}$} -9, {$-8 \hspace{6pt}$} -8, {$-7 \hspace{6pt}$} -7, {$-6 \hspace{6pt}$} -6, {$-5 \hspace{6pt}$} -5, {$-4 \hspace{6pt}$} -4, {$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3}  \axislabels {y}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x+1)^2}{9} - \dfrac{(y-3)^2}{4} = 1$  center $(-1, 3)$\\  transverse axis on $y=3$\\  conjugate axis on $x=-1$\\  vertices $(2, 3), (-4, 3)$\\  foci $\left(-1+\sqrt{13}, 3\right), \left(-1-\sqrt{13}, 3\right)$\\  asymptotes $y = \pm \frac{2}{3} (x+1)+3$\\  \begin{mfpic}[12]{-8}{6}{-1}{6}  \axes  \tlabel(6,-0.5){\scriptsize $x$}  \tlabel(0.5,6){\scriptsize $y$}  \xmarks{-7 step 1 until 5}  \ymarks{1 step 1 until 5}  \point[3pt]{(2,3),(-4,3)}  \dotted \polyline{(-4,1), (-4,5), (2, 5), (2,1),(-4,1)}  \arrow \reverse \arrow \parafcn{-1.4,1.4,0.1}{(3*cosh(t)-1,2*sinh(t)+3)}  \arrow \reverse \arrow \parafcn{-1.4,1.4,0.1}{(-3*cosh(t)-1,2*sinh(t)+3)}  \arrow \reverse \arrow \dashed \function{-7,5,0.1}{(2/3)*(x+1)+3}  \arrow \reverse \arrow \dashed \function{-7,5,0.1}{3-(2/3)*(x+1)}  \plotsymbol[3pt]{cross}{(-1,3)}  \plotsymbol[3pt]{asterisk}{(2.6056,3), (-4.6056,3)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-7 \hspace{6pt}$} -7,{$-6 \hspace{6pt}$} -6,{$-5 \hspace{6pt}$} -5, {$-4 \hspace{6pt}$} -4, {$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5}  \axislabels {y}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5}  \normalsize  \end{mfpic}  \end{multicols}  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(y+2)^2}{16} - \dfrac{(x-5)^2}{20} = 1$  center $(5, -2)$\\  transverse axis on $x=5$\\  conjugate axis on $y=-2$\\  vertices $(5,2), (5,-6)$\\  foci $\left(5,4 \right), \left(5,-8\right)$\\  asymptotes $y = \pm \frac{2\sqrt{5}}{5} (x-5)-2$\\  \begin{mfpic}[10]{-2}{12}{-9}{5}  \axes  \tlabel(12,-0.5){\scriptsize $x$}  \tlabel(0.5,5){\scriptsize $y$}  \xmarks{-1 step 1 until 11}  \ymarks{-8 step 1 until 4}  \point[3pt]{(5,2),(5,-6)}  \dotted \polyline{(0.5279,-6), (0.5279,2), (9.4721, 2), (9.4721,-6),(0.5279,-6)}  \arrow \reverse \arrow \parafcn{-1.25,1.25,0.1}{(4.4721*sinh(t)+5,4*cosh(t)-2)}  \arrow \reverse \arrow \parafcn{-1.25,1.25,0.1}{(4.4721*sinh(t)+5,0-4*cosh(t)-2)}  \arrow \reverse \arrow \dashed \function{-2,12,0.1}{0.89442*(x-5)-2}  \arrow \reverse \arrow \dashed \function{-2,12,0.1}{0-2-0.89442*(x-5)}  \plotsymbol[3pt]{cross}{(5,-2)}  \plotsymbol[3pt]{asterisk}{(5,4), (5,-8)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9, {$10$} 10, {$11$} 11}  \axislabels {y}{{$-8$} -8,{$-7$} -7,{$-6$} -6,{$-5$} -5,{$-4$} -4,{$-3$} -3,{$-2$} -2,{$-1$} -1,{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \normalsize  \end{mfpic}  \end{multicols}  \pagebreak  \item \begin{multicols}{2} \raggedcolumns  $\dfrac{(x-4)^2}{8} - \dfrac{(y-2)^2}{18} = 1$  center $(4, 2)$\\  transverse axis on $y=2$\\  conjugate axis on $x=4$\\  vertices $\left(4+2\sqrt{2},2\right), \left(4-2\sqrt{2},2\right)$\\  foci $\left(4+\sqrt{26},2 \right), \left(4-\sqrt{26},2\right)$\\  asymptotes $y = \pm \frac{3}{2} (x-4)+2$\\  \begin{mfpic}[10]{-3}{11}{-4}{10}  \axes  \tlabel(9,-0.5){\scriptsize $x$}  \tlabel(0.5,10){\scriptsize $y$}  \xmarks{-2 step 1 until 10}  \ymarks{-3 step 1 until 9}  \point[3pt]{(6.8284,2),(1.1716,2)}  \dotted \polyline{(1.1716,-2.2426), (1.1716,6.2426), (6.8284, 6.2426), (6.8284,-2.2426),(1.1716,-2.2426)}  \arrow \reverse \arrow \parafcn{-1.2,1.2,0.1}{(2.8284*cosh(t)+4,4.2426*sinh(t)+2)}  \arrow \reverse \arrow \parafcn{-1.2,1.2,0.1}{(0-2.8284*cosh(t)+4,4.2426*sinh(t)+2)}  \arrow \reverse \arrow \dashed \function{-1,9,0.1}{1.5*(x-4)+2}  \arrow \reverse \arrow \dashed \function{-1,9,0.1}{2-1.5*(x-4)}  \plotsymbol[3pt]{cross}{(4,2)}  \plotsymbol[3pt]{asterisk}{(9.0990,2), (-1.0990,2)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9, {$10$} 10}  \axislabels {y}{ -3,{$-2$} -2,{$-1$} -1,{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9}  \normalsize  \end{mfpic}  \end{multicols}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{x^{2}}{3} - \dfrac{(y - 5)^{2}}{12} = 1$  center $(0, 5)$\\  transverse axis on $y = 5$\\  conjugate axis on $x = 0$\\  vertices $(\sqrt{3}, 5), (-\sqrt{3}, 5)$\\  foci $(\sqrt{15}, 5), (-\sqrt{15}, 5)$\\  asymptotes $y = \pm 2x + 5$  \item $\dfrac{(y + 2)^{2}}{5} - \dfrac{(x - 3)^{2}}{18} = 1$  center $(3, -2)$\\  transverse axis on $x = 3$\\  conjugate axis on $y = -2$\\  vertices $(3, -2 + \sqrt{5}), (3, -2 - \sqrt{5})$\\  foci $(3, -2 + \sqrt{23}), (3, -2 - \sqrt{23})$\\  asymptotes $y = \pm \frac{\sqrt{10}}{6}(x - 3) - 2$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x-3)^{2}}{25} - \dfrac{(y+1)^{2}}{9} = 1$  center $(3, -1)$\\  transverse axis on $y=-1$\\  conjugate axis on $x=3$\\  vertices $(8, -1), (-2, -1)$\\  foci $\left(3+\sqrt{34}, -1 \right), \left(3-\sqrt{34}, -1 \right)$\\  asymptotes $y = \pm \frac{3}{5}(x - 3) - 1$  \item $\dfrac{(y+4)^{2}}{6} - \dfrac{(x+2)^{2}}{5} = 1$  center $(-2, -4)$\\  transverse axis on $x=-2$\\  conjugate axis on $y=-4$\\  vertices $\left(-2,-4+\sqrt{6} \right), \left(-2,-4-\sqrt{6} \right)$\\  foci $\left(-2, -4+\sqrt{11} \right), \left(-2, -4-\sqrt{11} \right)$\\  asymptotes $y = \pm \frac{\sqrt{30}}{5}(x + 2) - 4$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(y - 7)^{2}}{16} - \dfrac{(x - 3)^{2}}{9} = 1$  \item $\dfrac{(x - 4)^{2}}{16} - \dfrac{(y - 1)^{2}}{33} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{y^{2}}{25} - \dfrac{x^{2}}{39} = 1$  \item $\dfrac{x^{2}}{16} - \dfrac{y^{2}}{9} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 8)^{2}}{25} - \dfrac{(y - 2)^{2}}{4} = 1$  \item $\dfrac{(x - 6)^{2}}{256} - \dfrac{(y - 5)^{2}}{64} = 1$  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \pagebreak  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(x-1)^2 = 4(y+3)$ \\  \begin{mfpic}[15]{-4}{5}{-5}{1}  \axes  \xmarks{-3 step 1 until 4}  \ymarks{-4 step 1 until 0}  \arrow \reverse \arrow \function{-3,5,0.1}{((x -1)**2)/4 - 3}  \arrow \reverse \arrow \polyline{(-5,-4),(5,-4)}  \plotsymbol[3pt]{asterisk}{(1,-2)}  \tlabel(5,-0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \point[3pt]{(3,-2),(1,-3),(-1,-2)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-3 \hspace{7pt}$} -3, {$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $(x-4)^2+(y+2)^2 = 9$ \\  \begin{mfpic}[20]{-1}{8}{-6}{2}  \axes  \circle{(4,-2),3}  \plotsymbol[3pt]{cross}{(4,-2)}  \xmarks{1,4,7}  \ymarks{-5,-2,1}  \tlabel(8,-0.5){\scriptsize $x$}  \tlabel(0.5,2){\scriptsize $y$}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$1$} 1,{$4$} 4,{$7$} 7}  \axislabels {y}{{$-5$} -5, {$-2$} -2, {$1$} 1 }  \normalsize  \end{mfpic}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x - 2)^{2}}{4} + \dfrac{(y + 3)^{2}}{9} = 1$\\  \begin{mfpic}[15]{-1}{5}{-7}{1}  \axes  \tlabel(5,-0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \xmarks{1 step 1 until 4}  \ymarks{-6 step 1 until 0}  \ellipse{(2,-3),2,3}  \plotsymbol[3pt]{asterisk}{(2, -0.7639), (2,-5.23606)}  \plotsymbol[3pt]{cross}{(2,-3)}  \point[3pt]{(2,0), (2,-6), (0,-3), (4,-3)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $\dfrac{(x - 2)^{2}}{4} - \dfrac{(y + 3)^{2}}{9} = 1$ \\  \begin{mfpic}[12][9]{-4}{8}{-11}{5}  \axes  \tlabel(8,-0.5){\scriptsize $x$}  \tlabel(0.5,5){\scriptsize $y$}  \xmarks{-3 step 1 until 7}  \ymarks{-10 step 1 until 4}  \point[3pt]{(0,-3),(4,-3)}  \dotted[1pt, 3pt] \polyline{(0,0), (4,0), (4, -6), (0,-6), (0,0)}  \arrow \function{4,7,0.1}{-3 + sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \reverse \function{-3,0,0.1}{-3 + sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \function{4,7,0.1}{-3 - sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \reverse \function{-3,0,0.1}{-3 - sqrt((2.25*((x - 2)**2)) - 9)}  \arrow \reverse \arrow \dashed \function{-3,7,0.1}{-1.5*x}  \arrow \reverse \arrow \dashed \function{-3,7,0.1}{(1.5*x) - 6}  \plotsymbol[3pt]{cross}{(2,-3)}  \plotsymbol[3pt]{asterisk}{(5.60555,-3), (-1.60555,-3)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-3 \hspace{6pt}$} -3, {$-2 \hspace{6pt}$} -2, {$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7}  \axislabels {y}{{$-10$} -10, {$-9$} -9, {$-8$} -8, {$-7$} -7, {$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \normalsize  \end{mfpic}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $(y + 4)^{2} = 4x$ \\  \begin{mfpic}[15]{-2}{5}{-9}{1}  \axes  \xmarks{-1 step 1 until 4}  \ymarks{-8 step 1 until 0}  \arrow \function{0,5,0.1}{-4-(2*sqrt(x))}  \arrow \function{0,5,0.1}{-4+(2*sqrt(x))}  \arrow \reverse \arrow \polyline{(-1,-9),(-1,1)}  \plotsymbol[3pt]{asterisk}{(1,-4)}  \tlabel(5,-0.5){\scriptsize $x$}  \tlabel(0.5,1){\scriptsize $y$}  \point[3pt]{(0,-4),(1,-2),(1,-6)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-8$} -8, {$-7$} -7, {$-6$} -6, {$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $\dfrac{(x-1)^2}{1}+\dfrac{y^2}{4}=0$ \\  the graph is the point $(1,0)$ only.  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x-1)^2}{9}+\dfrac{(y+3)^2}{4} = 1$ \\  \begin{mfpic}[18]{-3}{5}{-6}{1}  \axes  \tlabel(5,-0.25){\scriptsize $x$}  \tlabel(0.25,1){\scriptsize $y$}  \xmarks{-2 step 1 until 4}  \ymarks{-5 step 1 until -1}  \ellipse{(1,-3),3,2}  \plotsymbol[3pt]{asterisk}{(3.2361,-3), (-1.2361,-3)}  \plotsymbol[3pt]{cross}{(1,-3)}  \point[3pt]{(4,-3), (-2,-3), (1,-1), (1,-5)}  \tlpointsep{4pt}  \scriptsize  \axislabels {x}{{$-2 \hspace{7pt}$} -2, {$-1 \hspace{7pt}$} -1, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \axislabels {y}{{$-5$} -5, {$-4$} -4, {$-3$} -3, {$-2$} -2, {$-1$} -1}  \normalsize  \end{mfpic}  \vfill  \columnbreak  \item $(x-3)^2+(y+2)^2=-1$ \\  there is no graph.  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{multicols}{2}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \item $\dfrac{(x+3)^2}{2}+\dfrac{(y-1)^2}{1} = -\dfrac{3}{4}$ \\  there is no graph.  \vfill  \columnbreak  \item $\dfrac{(y+2)^2}{16} - \dfrac{(x-5)^2}{20} = 1$ \\  \begin{mfpic}[10]{-2}{12}{-9}{5}  \axes  \tlabel(12,-0.5){\scriptsize $x$}  \tlabel(0.5,5){\scriptsize $y$}  \xmarks{-1 step 1 until 11}  \ymarks{-8 step 1 until 4}  \point[3pt]{(5,2),(5,-6)}  \dotted \polyline{(0.5279,-6), (0.5279,2), (9.4721, 2), (9.4721,-6),(0.5279,-6)}  \arrow \reverse \arrow \parafcn{-1.25,1.25,0.1}{(4.4721*sinh(t)+5,4*cosh(t)-2)}  \arrow \reverse \arrow \parafcn{-1.25,1.25,0.1}{(4.4721*sinh(t)+5,0-4*cosh(t)-2)}  \arrow \reverse \arrow \dashed \function{-2,12,0.1}{0.89442*(x-5)-2}  \arrow \reverse \arrow \dashed \function{-2,12,0.1}{0-2-0.89442*(x-5)}  \plotsymbol[3pt]{cross}{(5,-2)}  \plotsymbol[3pt]{asterisk}{(5,4), (5,-8)}  \tlpointsep{4pt}  \tiny  \axislabels {x}{{$-1 \hspace{6pt}$}{-1}, {$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4, {$5$} 5, {$6$} 6, {$7$} 7, {$8$} 8, {$9$} 9, {$10$} 10, {$11$} 11}  \axislabels {y}{{$-8$} -8,{$-7$} -7,{$-6$} -6,{$-5$} -5,{$-4$} -4,{$-3$} -3,{$-2$} -2,{$-1$} -1,{$1$} 1, {$2$} 2, {$3$} 3, {$4$} 4}  \normalsize  \end{mfpic}  \setcounter{hw}{\value{enumi}}  \end{enumerate}  \end{multicols}  \begin{enumerate}  \setcounter{enumi}{\value{hw}}  \addtocounter{enumi}{1}  \item by placing station a at $(0, -50)$ and station b at $(0, 50)$, the two second time difference yields the hyperbola $\frac{y^{2}}{36} - \frac{x^{2}}{2464} = 1$ with foci a and b and center $(0, 0)$. placing station c at $(-150, -50)$ and using foci a and c gives us a center of $(-75, -50)$ and the hyperbola $\frac{(x + 75)^{2}}{225} - \frac{(y + 50)^{2}}{5400} = 1$. the point of intersection of these two hyperbolas which is closer to a than b and closer to a than c is $(-57.8444, -9.21336)$ so that is the epicenter.  \item \begin{enumerate} \setcounter{enumii}{1} \item $\dfrac{x^2}{9} - \dfrac{y^2}{27} = 1$. \end{enumerate}  \item the tower may be modeled (approximately)\footnote{the exact value underneath $(y - 330)^{2}$ is $\frac{52707600}{1541}$ in case you need more precision.} by $\frac{x^2}{12100} - \frac{(y-330)^2}{34203} = 1$. to find the height, we plug in $x = 137.5$ which yields $y \approx 191$ or $y \approx 469$. since the top of the tower is above the narrowest point, we get the tower is approximately 469 feet tall.  \end{enumerate}  \closegraphsfile",t_9c6e63aebb7e,other,0
c_7d1d1f15abf2,"sal solves -3x^2+10x-3=0 by plugging a=-3, b=10, c=-3 in the quadratic formula. then he multiplies everything by -1 and solves again. the results are the same!  we're asked to solve the quadratic equation, negative 3x squared plus 10x minus 3 is equal to 0. and it's already written in standard form. and there's many ways to solve this. but in particular, all solve it using the quadratic formula. so let me just rewrite it. we have negative 3x squared plus 10x minus 3 is equal to 0. and actually, i'll solve it twice using the quadratic formula to show you that as long as we manipulated this in the valid way, the quadratic formula will give us the exact same roots or the exact same solutions to this equation. so in this form right over here, what are our abcs? let's just remind ourselves what the quadratic formula even is actually. that's a good place to start. the quadratic formula tells us that if we have a quadratic equation in the form ax squared plus bx plus c is equal to 0, so in standard form, then the roots of this are x are equal to negative b plus or minus the square root of b squared minus 4ac, all of that over 2a. and this is derived from completing the square in a general way. so it's no magic here, and i've derived it in other videos. but this is the quadratic formula. this is actually giving you two solutions, because you have the positive square root here and the negative square root. so let's apply it here in the case where-- in this case, a is equal to negative 3, b is equal to 10, and c is equal to negative 3. so applying the quadratic formula right here, we get our solutions to be x is equal to negative b. b is 10. so negative b is negative 10 plus or minus the square root of b squared. b is 10. so b squared is 100 minus 4 times a times c. so minus 4 times negative 3 times negative 3. let me just write it down. minus 4 times negative 3 times negative 3. all of that's under the radical sign. and then all of that is over 2a. so 2 times a is negative 6. so this is going to be equal to negative 10 plus or minus the square root of 100 minus-- negative 3 times negative 3 is positive 9. positive 9 times 4 is positive 36. we have a minus sign out here. so minus 36. all of that over negative 6. this is equal to 100 minus 36 is 64. so negative 10 plus or minus the square root of 64. all of that over negative 6. the principal square root of 64 is 8. but we're taking the positive and negative square root. so this is negative 10 plus or minus 8 over negative 6. so if we take the positive version, we say x could be equal to-- negative 10 plus 8 is negative 2 over negative 6. so that was taking the plus version. that's this right over here. and negative 2 over negative 6 is equal to 1/3. if we take the negative square root, negative 10 minus 8-- so let's take negative 10 minus 8. that would be x is equal to-- negative 10 minus 8 is negative 18. and that's going to be over negative 6. negative 18 divided by negative 6 is positive 3. so the two roots for this quadratic equation are positive 1/3 and positive 3. and i want to show you the we'll get the same answer, even if we manipulate this. some people might not like the fact that our first coefficient here is a negative 3. maybe they want a positive 3. so to get rid of that negative 3, they can multiply both sides of this equation times negative 1. and then if you did that, you would get 3x squared minus 10x plus 3 is equal to 0 times negative 1, which is still equal to 0. so in this case, a is equal to 3, b is equal to negative 10, and c is equal to 3 again. and we could apply the quadratic formula. we get x is equal to negative b. b is negative 10. so negative negative 10 is positive 10, plus or minus the square root of b squared, which is negative 10 squared, which is 100, minus 4 times a times c. a times c is 9 times 4 is 36. so minus 36. all of that over 2 times a. all of that over 6. so this is equal to 10 plus or minus the square root of 64, or really that's just going to be 8. all of that over 6. if we add 8 here, we get 10 plus 8 is 18 over 6. we get x could be equal to 3. or if we take the negative square root or the negative 8 here, 10 minus 8 is 2. 2 over 6 is 1/3. so once again, you get the exact same solutions.",t_cea82fcbb487,other,0
c_58763e5e1dd9,"sal orders 5 decimals from least to greatest.  let's once again see if we can order now a different set of decimals from least to greatest, and once again i encourage you to pause this video and try to do this on your own. so let's go to the most significant place, the ones place here. none of these have any ones. so then we can go to the next most significant place, which is the tenths place. this has five tenths. this has six tenths. this has one tenth. this has five tenths. this has one tenth. so if we just look at the tenths place, the ones that have the fewest tenths-- this has only one tenth, this one only has one tenth, this one has five tenths, this one has five tenths, and then this one has six tenths. so i've ordered it by what's going on in the tenths place. now, both of these have the same number of tenths. let's move to the hundredths place to figure out which of these is larger. this one has six hundredths. this has five hundredths, so this one is larger. it has more hundredths. same number of tenths, more hundredths. and hundredths are obviously more significant than thousandths, so it doesn't matter which one has the more thousandths. it matters that this one has more tenths, and actually this one has more thousandths as well. but now let's go look at these two. these have the same number of tenths. they both have five tenths. but this one has six hundredths, while this one only has two hundredths, so this one is larger. and then finally, this one of course, had six tenths, so this one had the most tenths. so we don't even have to look at the other places here. and we're done.",t_fba05d4c5549,other,0
c_f4ac535bd078,"sal discusses the appropriate way to use the calculator in order to find an angle when its tangent value is given.  javier is calibrating sophisticated medical imaging equipment. the manual reports that the tangent of a particular angle is one. so that's saying that the tangent and let's say that that particular angle is theta is equal to one. what should javier do to find the angle? and i encourage you to pause this video and look at these choices and think about which of these should he do to find the angle? so let's look through each of them. so the first one... well, actually, instead of looking at the choices, let's think about what we would do to find the angle. so they're saying that the tangent of some angle is equal to one. well one thing that you might want to do is say okay, if we take the inverse tangent, if we take the inverse tangent, of the tangent of theta, so if we take the inverse tangent of both sides of this, we of course would get the inverse tangent of the tangent of theta. if the domain over here is restricted appropriately, is just going to be equal to theta, so we could say the theta is going to be the inverse tangent of one. so it might be tempting to just pick this one right over here. type inverse tangent of one into his calculator. so maybe this looks like the best choice. but remember, i said if we restrict the domain right over here. if we restrict the possible values of tangent, of theta here appropriately, then this is going to simplify to this. but there is a scenario where this does not happen. and that's if we pick thetas that are outside of the range of the inverse tangent function. what do i mean by that? well it's really just based on the idea that there are multiple angles that have... or multiple angles whose tangent is one. and let me draw that here with a unit circle here. so we draw a unit circle, so that's my x axis, that's my y axis, let me draw my unit circle here. actually you probably don't even have to draw the unit circle, because the tangent is really much more about the slope of the ray created by the angle, than where it intersects the unit circle as would be the case with sine and cosine. so if you have.. so you could have this angle right over here. so let's say this is a candidate theta, where the tangent of this theta is the slope of this line, and this terminal angle, the terminal ray, you could say of the angle. the other side, the initial ray, is along the positive x axis. and so you could say, okay the tangent of this theta, the tangent of this theta is one. because the slope of this line is one. let me scroll over a little bit. well, so let me write it this way. so tangent theta is equal to one. but i can construct another theta whose tangent is equal to one by going all the way over here and essentially going in the opposite direction but the slope of this line, so let's call this theta two, tangent of theta two is also going to be equal to one. and of course you could go another pi radiance and go back to the original angle, but that's functionally the same angle in terms of where it is relative to the positive x axis, or what direction it points into, but this one is fundamentally a different angle. so we do not know, we do not have enough information just given what we've been told to know exactly which theta we're talking about, whether we're talking about this orange theta or this mauve theta. so i would say the get more information, there are multiple angles which fit this description.",t_a65373868dcb,other,0
c_0126daa384fd,"magnetic properties of materials are often utilized in advance technological devices such as superconductive maglev trains, scanning electron microscopy, electron beam physical vapor deposition, and internal and external computer hard drives. there are five types of magnetism:  diamagnetism,  paramagnetism,  ferromagnetism,  antiferromagnetism, and  ferrimagnetism.  each type of magnetism differs from the others because of differences in the composition and crystal structures of the materials, and how electrons within these materials respond to a magnetic field.  introduction  ferrimagnetism can be thought of as a combination of ferromagnetism and antiferromagnetism (https://eng.libretexts.org/bookshelves/materials_science/supplemental_modules_(materials_science)/magnetic_properties/antiferromagnetism) because of the many similarities between them, but it has important points of difference also. similar to ferromagnets, ferrimagnets exhibit a spontaneous magnetic moment (i.e., a magnetic moment even in the absence of a magnetic field) and hysteresis below their curie temperature, \(t_c\), and behave paramagnetically above the curie temperature. on the other hand, similar to antiferromagnets, the magnetic moments of ferrimagnets align antiparallel to one another, the difference being that the net magnetic moment is non-zero. ferrimagnetic materials are thus differentiated from ferromagnetic and antiferromagnetic materials by the arrangement of their magnetic moments, and the dependence of the resulting magnetic properties on temperature, which depend on the types of elements in the material, its crystal structure, and microstructural processing.  ferrimagnetic materials are widely used in non-volatile memory devices such as hard drives, which utilize their ability to easily switch the spins of electrons and be magnetized. when a ferrimagnet inside a coil of conducting wire is rotate, current is generated, so they are also widely used in power motors and generators. because ferrimagnets are electrically insulating, they are also widely used in high-frequency devices because no eddy currents are induced under ac fields.  ferrimagnetic materials  unlike ferromagnetic materials, which are typically metals, ferrimagnetic materials are ceramics, in particular, ceramic oxides. the most widely used ferrimagnets in technological devices are materials known as ferrites. ferrites are electrically insulating  transitional-metal oxides with the general chemical formula mo·fe2·o3, where m is a divalent ion such as mn2+, fe2+, co2+, or ni2+.  ferrites are often prepared by standard ceramic processing techniques. in the case of nio.fe2·o3 powders of nio and fe2o3 are mixed together and pressed into the desired shape before sintering (firing) at high temperature to form a dense ceramic of the desired composition. this method provides a reliable way of forming a wide variety of shapes and sizes of ferrimagnetic materials for embedding into technological devices.  magnetization of ferrimagnetic materials  ferrimagnetic materials contain magnetic moments aligned antiparallel to one another, as illustrated in the figure below, similar to antiferromagnetic materials. however, instead of having a zero net magnetic moment, different numbers of unpaired electrons in the component transition metals result do not cancel one another out, resulting in a spontaneous magnetization.  the figure below shows the ordering of magnetic ions in a ferrimagnetic lattice, with arrows pointing down being longer than those pointing up to indicate the relative size of the spin-up and spin-down moments. the result is a net magnetic moment in the down spin direction.  figure 1: magnetic ordering in a ferrimagnetic material.  the antiparallel magnetic moments in both ferrimagnetic and antiferromagnetic materials can be explained by the superexchange behavior that occurs in oxide materials. using manganese oxide, mno, as an example, in its crystal oxygen ions, o2-, sit between manganese ions, mn2+, as shown schematically in the figure below. due to the different energy levels of the mn and o orbitals, in order for bonding between the two ions to occur, the spin direction of one electron in mn2+ is flipped to match that of the electron in the oxygen ion, thus forcing magnetic moments on either side of the molecule to be antiparallel to each other.  figure 2: initial transition of superexchange behavior in mno where the magnetic moment of one electron of the left-side mn3+ is flipped due to the down-spin of the electron in the leftmost orbital of the o2- ion to which it bonds.  figure 3: the result of superexchange behavior whereby all electrons of the left-side mn3+ are rotated to be antiparallel to the right-side mn3+, so that both match the spins of the bonding orbitals of the o2- ion.  the spontaneous magnetization of ferrimagnetic materials originates from the non-zero net magnetic moments when filling up the d orbitals of transition metal ions according to hund’s rule. in the case of ferrites, which have what is known as an inverse spinel structure, the crystal structure can be thought of as consisting of two sublattices. ions on sublattice a are tetrahedrally coordinated to neighboring oxide ions, while those on sublattice b are octahedrally coordinated (figure 4). ions on each sublattice have their spins aligned in the same direction as one another. the magnetic moments of fe3+ ions cancel each other out because there is the same number of ions on the a and b sublattices, but with their moments aligned in opposite directions.  in order for there to be magnetization in the material, the numbers of magnetic ions on each of the sublattices have to be different, so that not all magnetic moments are canceled out. specifically, in order to create features of ferrimagnetism from a site and b site, interactions involving both sublattices must be considered: a-a, b-b, and a-b site interactions. since a sites and b sites in the inverse spinel structure have different environments, the magnetization and the weiss molecular fields are also not identical in magnitude.  the total magnetization of the crystal can be expressed as the sum of magnetization on the a and b sublattices:  \[m_{total} = m_a+m_b \tag{1}\]  where  \[m_a = \alpha n \mu_a \tag{2a}\]  and  \[m_b = \alpha n \mu_b \tag{2b}\]  here n is the number of magnetic ions per unit volume, α is the faction of a ions, beta is the fraction of b ions, and µa and µb are the average magnetic moment of an a ion and b ion, respectively, in the direction of the field at temperature t.  similarly, the weiss molecular field, which is the internal interaction between localized moments, can be expressed in terms of the molecular field strengths from of a site ions and b site ions according to  \[h_{w-total} = h_{w-a}+h_{w-b} \tag{3}\]  where  \[h_{w-a} = −\gamma_bm_b + γ_{aa}m_a \tag{4a}\]  and  \[h_{w-b} = −\gamma_{ab}m_a + \gamma_{bb}m_b \tag{4b}\]  where γ is the molecular field constant, which can be calculated using the curie temperature tc, magnetic moment µm, magnetization of each sublattice m, permeability of free space µ0, and the boltzmann's constant kb:  \[\gamma = \dfrac{3k_bt_c}{\mu_m\mu_0m} \tag{5}\]  figure 4: (a) a tetrahedrally coordinated atom, and (b) an octahedrally coordinated atom. in both structures the black dot represents the transitional metal ion and the white circles represent oxygen ions in a ferrite.  an example of ferrimagnetic material is nickel ferrite, nio·fe2o3. the fe3+ ions are evenly distributed across both a and b sublattices, and thus their magnetic moments cancel out, while ni2+ ions sit on b sites only. the electron configuration of nickel is 3d84s2 (figure 5), from which two electrons are taken from 4s2  to form ni2+, giving an electron configuration of 3d8. the electron spins of the ion are arranged according to hund’s rule. first, all five states are filled with one spin-up electron, leaving three electrons with down spin to be added. adding these electrons in accordance to hund’s rule results in two unpaired spin-up electrons. these two unpaired electrons produce a net magnetic moment on ni2+ ions; since these all sit on the same sublattice they are parallel and produce a net magnetic moment in the crystal.  figure 5:the electron configurations of \(ni^{2+}\) and \(fe^{3+}\)  the arrangement of magnetic moments in the inverse spinel structure of a ferrite can be summarized as shown in figure 6, metal cations on a site all have up-spin magnetic moments, and those on b sites all have down-spin moments. five of the upwards pointing arrows are canceled by an arrow pointing down, leaving two remaining up arrows corresponding to a net magnetic moment of two.  figure 6: separation of magnetic moments into those on a sites and those on b sites: a site atoms all have spin-up unpaired electrons, and b site atoms all have spin-down unpaired electrons. the difference in the number of up and down arrows represents the net magnetic moment of the material.  temperature dependence  the temperature dependence of ferrimagnetic materials is similar to that of ferromagnetic materials. there is a curie temperature at which the magnetic moments become randomized, causing ferrimagnetic materials to begin to behave paramagnetically. before the curie temperature, the saturation magnetization of a ferrimagnetic material decreases with increasing termpature until it vanishes completely at the curie temperature, as illustrated in figure 7. above the curie temperature, there is a 1/χ relationship with temperature, which also indicates a further decrease in magnetization.  figure 7: the temperature dependence of magnetization in ferrimagnetic materials magnetization. in the region below the curie temperature magnetization decreases as temperature increases. above the curie temperature, the ferrimagnetic material becomes paramagnetic.  questions  show how the electrons fill the available 3d orbitals in co3+ in its high-spin state.  what are the major similarities and differences between ferrimagnetism and antiferromagnetism?  what is the net magnetic moment in iron oxide feo·fe2o3?  answers  the major similarity between ferri- and antiferromagnetism is that they both experience superexchange behavior between ions that causes their magnetic moments to be antiparallel. the major difference between the two is that the net magnetic moment of the former is non-zero while in the latter it is zero. antiferromagnetic materials thus do not exhibit spontaneous magnetization, while ferrimagnetic materials do.  fe2o3 consists of fe3+ and o2- and has a net magnetic moment of zero. feo consists of fe2+ and o2- ions; taking two electrons from the 4s orbital of fe leaves fe2+ with 6 electrons in its 3d orbital, and, according to hund's rule, each fe2+ ion will have 4 unpaired electrons (in its high-spin state).  references  hummel, rolf e. (2005). electronic properties of materials, fourth edition. chapter 15, pages 347-371. springer  spaldin, nicola a. (2003) magnetic materials: fundamentals and applications, second edition. chapter 9, pages 113-129.      cambridge university press  contributors  alan wu (university of california, davis, materials science and engineering)  template:contribfisher",t_02ea430ecca3,other,0
c_a626f5dc9d8f,"def showstartscreen():     titlefont = pygame.font.font('freesansbold.ttf', 100)     titlesurf1 = titlefont.render('wormy!', true, white, darkgreen)     titlesurf2 = titlefont.render('wormy!', true, green)      degrees1 = 0     degrees2 = 0     while true:         displaysurf.fill(bgcolor)  when the wormy game program first begins running, the player doesn’t automatically begin playing the game. instead, a start screen appears which tells the player what program they are running. a start screen also gives the player a chance to prepare for the game to begin (otherwise the player might not be ready and crash on their first game).  the wormy start screen requires two surface objects with the ""wormy!"" text drawn on them. these are what the render() method calls create on lines 3 [130] and 4 [131]. the text will be large: the font() constructor function call on line 2 [129] creates a font object that is 100 points in size. the first ""wormy!"" text will have white text with a dark green background, and the other will have green text with a transparent background.  line 8 [135] begins the animation loop for the start screen. during this animation, the two pieces of text will be rotated and drawn to the display surface object.",t_7e66ace73380,other,0
c_6d1fd5c4175b,the use of modules has become increasingly important in microwave engineering. a wide variety of passive modules were introduced but there are many more. some microwave modules use unusual effects such as the response of magnetic materials to magnetic fields. many others use the characteristics of propagating em fields. the next chapter completes the discussion of modules by covering active modules. a successful microwave designer must have a good knowledge of the types and limitations of available modules.,t_793ff2218f50,other,0
c_01346ea78854,"this video will teach you all about the different ways you can use the sound of words for effect. alliteration is when you use a bunch of similar consonants in a row; assonance is when you use a bunch of similar vowel sounds in a row; onomatopoeia is basically sound effects. you'll see.  - [david] hello grammarians, hello rosie! - [rosie] hi david! - [david] so, you've caught me mid-scribble in the greatest challenge of my career. will i be able to write the word ono-mato-poeia? - [rosie] you can do it. - [david] did i get it? - [rosie] you did it. - [david] yes! this is one of my least favorite words to spell but one of my favorite things to talk about. because what we're talking about today is alliteration, assonance, and onomatopoeia. and these are all words that are related to the way language sounds. but let's begin with alliteration. rosie, what is alliteration? - [rosie] alliteration is when a series of words all start with the same consonant. - [david] so what's a good example of that? - [rosie] robert park swam swiftly, surely, and straight ahead. - [david] so you can see that all these pink words here, swam, swiftly, surely, straight ahead, all begin with ""s."" and so this is why we call this alliteration because ""s"" is a consonant and all of these things share a similar consonant sound. now i want to contrast that with assonance, which is what, rosie? - [rosie] assonance is when a series of words all start with the same vowel. althea abolished all anguish. - [david] so you can see, all of these words in the sentence in the same vowel neighborhood. - [rosie] right. - [david] but my favorite of all is onomatopoeia, which comes from greek, and it basically means, like, onom, onomat, means a name resulting from doing. so really, this is, this word just means sounds like what it does. so any, really anything that you would conceive of as a sound effect, like a word that comes from a sound effect. so, the bees buzzed, for example. like, what is buzzed? well, it's the sound that a bee makes. it's what it does. but that word is derived from the buzz sound. but that's not the only example of onomatopoeia. we've compiled here a list. what have we got, rosie? - [rosie] okay, we've got splat. that's kind of the sound of something hitting pavement. - [david] splat. - [rosie] yep. we've got clang, which is like the clanging of a bell. we've got bang, which sounds like something exploding. whoosh, which sounds like air or wind. beep. - [david] yeah. - [rosie] beep sounds like a beeping. (laughs) - [david] like that is literally, so if you, if you are trying to summon up the actual sound of a thing and transcribe it and use it as a noun or a verb, you're using onomatopoeia. i know it's a terrifying looking word, right? like, no one word should have this many vowels in front of the other. i get it, i get it. i'm, i'm terrified of spelling this word, but i managed to do it, apparently, and now you know what it means, and that should take away some of its scariness and impart to you some of its power. because here at khan academy, we want you to have the power to harness language, and specifically, today, to harness these three different language styles. so, alliteration, repeating the same consonant a bunch of times in a row, so swimming, swiftly, surely, and straight ahead. - [rosie] assonance, where you repeat the same vowel, like abolished all anguish. - [david] and onomatopoeia, where you make a word that sounds like what the word's effect is. so the bees buzzed, the pudding cup went splat, the boxing bell fell to the floor with a clang, the firework went off with a bang, a flight of bats whooshed past my head, and the robot, the little baby robot beeped at me, insistently. - [rosie] i like those. - [david] how can a robot be a baby? - [rosie] i think it's just the size, right? - [david] okay, sure. - [rosie] not the age. - [david] okay, sure, yeah that's legitimate. so okay, i guess the question is now you know what these things are, but rosie, why would a person want to use these techniques in language, whether written or spoken? - [rosie] that's a great question. writers can use some of these techniques to basically use the sound. to get across a pattern. - [david] um-hum. - [rosie] like if your going to use words that all sound the same at the beginning, with a bunch of ""ss"" that kind of, could potentially build some momentum to your sentence. like, it kind of makes the reader sit up and pay attention, too, like oh, this is an interesting pattern. so that could be one reason why a writer might use, for example, alliteration. - [david] yeah, so it's a way to express a pattern and to build on what you were saying, you can also, it's just a good attention grabber, and it's also useful for it's own sake, just as a technique for writing prose or poetry. like, it's something, it's a useful property of language to be able to sometimes access. - [rosie] right, and a good example with onomatopoeia, ono-mato-poeia, is you're really capturing, you're really capturing the sound, so the reader is really able to be emersed in the experience even more fully. you can hear the sounds that are happening. the buzzing of the bees, or, yeah. it just puts you even more in the story that the writer's telling. - [david] that's why you would want to learn how to use assonance, alliteration, and onomatopoeia. you can learn anything. david out. - [rosie] rosie out.",t_a596d115bb5c,other,0
c_13ec5f950a7d,"as human habitation expands, new viral hemorrhagic fevers are infecting humans.  learning objectives  generalize the characteristics and implications of an emergent virus  key takeaways  key points  there are several types of viruses that cause hemorrhagic fevers they are typified by high fever and bleeding.  emergent viruses are newly discovered viruses, often coming from other animal species. many emergent viruses are uncovered by human activity such as deforestation.  new sequencing technologies allow the identification of emergent viruses.  no other rhabdovirus is known to cause the acute, rapid and deadly hemorrhagic fever seen in the three cases in the congo.  key terms  rhabdovirus: rhabdoviruses are viruses belonging to the family rhabdoviridae,that infect a broad range of hosts throughout the animal and plant kingdoms.  an emergent virus is a virus that has adapted and emerged as a new disease/pathogenic strain, with attributes facilitating pathogenicity in a field not normally associated with that virus. this includes viruses that are the cause of a disease that has notably increased in incidence; this is often a result of a wide variety of causes from both the influence of man and nature. most emergent viruses can be categorized as zoonotic; an animal disease that can be transmitted to humans. the virus thus has the advantage of possibly having several natural reservoirs to propagate in. as human development increases, and we move into areas not previously inhabited a reservoir of a virus can be uncovered and infections of humans ensues. this is especially worse in tropical areas of the world with high levels of biodiversity such as africa, south america, and south asia. many newly discovered viruses come from these parts of the world as human habitation expands.  the viral hemorrhagic fevers (vhfs) are a diverse group of animal and human illnesses that may be caused by five distinct families of rna viruses: the families arenaviridae, filoviridae, bunyaviridae, flaviviridae, and rhabdoviridae. all types of vhf are characterized by fever and bleeding disorders and all can progress to high fever, shock and death in many cases. some of the vhf agents cause relatively mild illnesses, such as the scandinavian nephropathia epidemica, while others, such as the african ebola virus, can cause severe, life-threatening disease.  indeed the advent of deep sequencing technologies and other methods are identifying emergent viral hemorrhagic fevers. a recent study using deep sequencing, discovered a novel rhabdovirus (bas-congo virus, or basv) associated with a 2009 outbreak of three human cases of acute hemorrhagic fever in mangala village, democratic republic of congo (drc), africa. the cases, presenting over a three-week period, were characterized by abrupt disease onset, high fever, bloody vomiting, and diarrhea, and, in two patients, death within three days. basv was present in the blood of the lone survivor at a concentration of over a million copies per milliliter. the genome of basv, assembled from over 140 million sequence reads, reveals that it is very different from any other rhabdovirus. the lone survivor and a nurse caring for him (with no symptoms), both health care workers, were found to have high levels of antibodies to basv, indicating that they both had been infected by the virus. although the source of the virus remains unclear, the study findings suggest that basv may be spread by human-to-human contact and is an emerging pathogen associated with acute hemorrhagic fever in africa.  countries affected by viral hemorrhagic fever (vhf) outbreaks: mangala village, located in the bas-congo province in drc, is represented by a red star.  licenses and attributions  cc licensed content, shared previously  curation and revision. provided by: boundless.com. license:  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  cc licensed content, specific attribution  burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/burkitt's_lymphoma (http://en.wikipedia.org/wiki/burkitt's_lymphoma)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  lymph. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/lymph (http://en.wiktionary.org/wiki/lymph)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  non-hodgkin's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/non-hodgkin's%20lymphoma (http://en.wikipedia.org/wiki/non-hodgkin's%20lymphoma)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  lymphoma. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/lymphoma (http://en.wiktionary.org/wiki/lymphoma)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  epstein-barr virus (ebv). provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein-barr%20virus%20(ebv) (http://en.wikipedia.org/wiki/epstein-barr%20virus%20(ebv))  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/infectious%20mononucleosis (http://en.wikipedia.org/wiki/infectious%20mononucleosis)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  public domain: no known copyright (https://creativecommons.org/about/pdm)  teach cough hygiene everywhere/basic info on viruses. provided by: wikibooks. located at: . license:  http://en.wikibooks.org/wiki/teach_cough_hygiene_everywhere/basic_info_on_viruses (http://en.wikibooks.org/wiki/teach_cough_hygiene_everywhere/basic_info_on_viruses)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  epsteinu2013barr virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus (http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  epithelial cells. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epithelial%20cells (http://en.wikipedia.org/wiki/epithelial%20cells)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  lytic cycle. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/lytic_cycle (http://en.wiktionary.org/wiki/lytic_cycle)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  b cell. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/b_cell (http://en.wiktionary.org/wiki/b_cell)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  public domain: no known copyright (https://creativecommons.org/about/pdm)  epsteinu2013barr virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus (http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus)  public domain: no known copyright (https://creativecommons.org/about/pdm)  human cytomegalovirus. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/human_cytomegalovirus (https://en.wikipedia.org/wiki/human_cytomegalovirus)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  major histocompatibility complex. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/major+histocompatibility+complex (http://en.wiktionary.org/wiki/major+histocompatibility+complex)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  cytomegalovirus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/cytomegalovirus (http://en.wikipedia.org/wiki/cytomegalovirus)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  seroprevalence. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/seroprevalence (http://en.wikipedia.org/wiki/seroprevalence)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  immunocompromised. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/immunocompromised (http://en.wiktionary.org/wiki/immunocompromised)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  public domain: no known copyright (https://creativecommons.org/about/pdm)  epsteinu2013barr virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus (http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus)  public domain: no known copyright (https://creativecommons.org/about/pdm)  hcmvdrugs.pdf. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:hcmvdrugs.pdf  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  chikungunya outbreaks. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/chikungunya_outbreaks (http://en.wikipedia.org/wiki/chikungunya_outbreaks)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  chikungunya. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/chikungunya (http://en.wikipedia.org/wiki/chikungunya)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  chikungunya. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/chikungunya (http://en.wiktionary.org/wiki/chikungunya)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  aedes. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/aedes (http://en.wikipedia.org/wiki/aedes)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  dengue. provided by: wiktionary. located at: . license:  http://en.wiktionary.org/wiki/dengue (http://en.wiktionary.org/wiki/dengue)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  public domain: no known copyright (https://creativecommons.org/about/pdm)  epsteinu2013barr virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus (http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus)  public domain: no known copyright (https://creativecommons.org/about/pdm)  hcmvdrugs.pdf. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:hcmvdrugs.pdf  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  aedes aegypti mosquito | flickr - photo sharing!. provided by: flickr. located at: . license:  http://www.flickr.com/photos/sanofi-pasteur/5283441969/ (http://www.flickr.com/photos/sanofi-pasteur/5283441969/)  cc by: attribution (https://creativecommons.org/licenses/by/4.0/)  viral hemorrhagic fever. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/viral_hemorrhagic_fever (http://en.wikipedia.org/wiki/viral_hemorrhagic_fever)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  hemorrhagic. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/hemorrhagic (http://en.wikipedia.org/wiki/hemorrhagic)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  public domain: no known copyright (https://creativecommons.org/about/pdm)  epsteinu2013barr virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus (http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus)  public domain: no known copyright (https://creativecommons.org/about/pdm)  hcmvdrugs.pdf. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:hcmvdrugs.pdf  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  aedes aegypti mosquito | flickr - photo sharing!. provided by: flickr. located at: . license:  http://www.flickr.com/photos/sanofi-pasteur/5283441969/ (http://www.flickr.com/photos/sanofi-pasteur/5283441969/)  cc by: attribution (https://creativecommons.org/licenses/by/4.0/)  plos pathogens: a novel rhabdovirus associated with acute hemorrhagic fever in central africa. provided by: plos pathogens. located at: . license:  http://www.plospathogens.org/article/info:doi/10.1371/journal.ppat.1002924 (http://www.plospathogens.org/article/info:doi/10.1371/journal.ppat.1002924)  cc by: attribution (https://creativecommons.org/licenses/by/4.0/)  bas-congo virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/bas-congo_virus (http://en.wikipedia.org/wiki/bas-congo_virus)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  viral hemorrhagic fever. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/viral_hemorrhagic_fever (http://en.wikipedia.org/wiki/viral_hemorrhagic_fever)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  emerging viruses, the concept. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/emerging_viruses,_the_concept (http://en.wikipedia.org/wiki/emerging_viruses,_the_concept)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  rhabdoviridae. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/rhabdoviridae (http://en.wikipedia.org/wiki/rhabdoviridae)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  rhabdovirus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/rhabdovirus (http://en.wikipedia.org/wiki/rhabdovirus)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  large facial burkitt's lymphoma. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg (http://en.wikipedia.org/wiki/file:large_facial_burkitt's_lymphoma.jpg)  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  infectious mononucleosis. provided by: wikipedia. located at: . license:  https://en.wikipedia.org/wiki/infectious_mononucleosis (https://en.wikipedia.org/wiki/infectious_mononucleosis)  public domain: no known copyright (https://creativecommons.org/about/pdm)  epsteinu2013barr virus. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus (http://en.wikipedia.org/wiki/epstein%e2%80%93barr_virus)  public domain: no known copyright (https://creativecommons.org/about/pdm)  hcmvdrugs.pdf. provided by: wikipedia. located at: . license:  http://en.wikipedia.org/wiki/file:hcmvdrugs.pdf  cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  aedes aegypti mosquito | flickr - photo sharing!. provided by: flickr. located at: . license:  http://www.flickr.com/photos/sanofi-pasteur/5283441969/ (http://www.flickr.com/photos/sanofi-pasteur/5283441969/)  cc by: attribution (https://creativecommons.org/licenses/by/4.0/)  plos pathogens: a novel rhabdovirus associated with acute hemorrhagic fever in central africa. provided by: plos pathogens. located at: . license:  http://www.plospathogens.org/article/info:doi/10.1371/journal.ppat.1002924?imageuri=info:doi/10.1371/journal.ppat.1002924.g001 (http://www.plospathogens.org/article/info:doi/10.1371/journal.ppat.1002924?imageuri=info:doi/10.1371/journal.ppat.1002924.g001)  cc by: attribution (https://creativecommons.org/licenses/by/4.0/)",t_cc07d69c55f1,other,0
c_85cf52446eca,"the most common way to traverse the elements of a list is with a for loop. the syntax is the same as for strings:  for cheese in cheeses:     print cheese  this works well if you only need to read the elements of the list. but if you want to write or update the elements, you need the indices. a common way to do that is to combine the functions range and len:  for i in range(len(numbers)):     numbers[i] = numbers[i] * 2  this loop traverses the list and updates each element. len returns the number of elements in the list. range returns a list of indices from 0 to n−1, where n is the length of the list. each time through the loop i gets the index of the next element. the assignment statement in the body uses i to read the old value of the element and to assign the new value.  a for loop over an empty list never executes the body:  for x in []:     print 'this never happens.'  although a list can contain another list, the nested list still counts as a single element. the length of this list is four:  ['spam', 1, ['brie', 'roquefort', 'pol le veq'], [1, 2, 3]]",t_090ad32e7b1a,other,0
c_87c63298fd5c,"chapter 39 | the respiratory system  1135  39 | the respiratory system  figure 39.1 lungs, which appear as nearly transparent tissue surrounding the heart in this x-ray of a dog (left), are the central organs of the respiratory system. the left lung is smaller than the right lung to accommodate space for the heart. a dog’s nose (right) has a slit on the side of each nostril. when tracking a scent, the slits open, blocking the front of the nostrils. this allows the dog to exhale though the now-open area on the side of the nostrils without losing the scent that is being followed. (credit a: modification of work by geoff stearns; credit b: modification of work by cory zanker)  chapter outline 39.1: systems of gas exchange 39.2: gas exchange across respiratory surfaces 39.3: breathing 39.4: transport of gases in human bodily fluids  introduction breathing is an involuntary event. how often a breath is taken and how much air is inhaled or exhaled are tightly regulated by the respiratory center in the brain. humans, when they aren’t exerting themselves, breathe approximately 15 times per minute on average. canines, like the dog in figure 39.1, have a respiratory rate of about 15–30 breaths per minute. with every inhalation, air fills the lungs, and with every exhalation, air rushes back out. that air is doing more than just inflating and deflating the lungs in the chest cavity. the air contains oxygen that crosses the lung tissue, enters the bloodstream, and travels to organs and tissues. oxygen (o2) enters the cells where it is used for metabolic reactions that produce atp, a high-energy compound. at the same time, these reactions release carbon dioxide (co2) as a by-product. co2 is toxic and must be eliminated. carbon dioxide exits the cells, enters the bloodstream, travels back to the lungs, and is expired out of the body during exhalation.  1136  chapter 39 | the respiratory system  39.1 | systems of gas exchange by the end of this section, you will be able to: • describe the passage of air from the outside environment to the lungs • explain how the lungs are protected from particulate matter the primary function of the respiratory system is to deliver oxygen to the cells of the body’s tissues and remove carbon dioxide, a cell waste product. the main structures of the human respiratory system are the nasal cavity, the trachea, and lungs. all aerobic organisms require oxygen to carry out their metabolic functions. along the evolutionary tree, different organisms have devised different means of obtaining oxygen from the surrounding atmosphere. the environment in which the animal lives greatly determines how an animal respires. the complexity of the respiratory system is correlated with the size of the organism. as animal size increases, diffusion distances increase and the ratio of surface area to volume drops. in unicellular organisms, diffusion across the cell membrane is sufficient for supplying oxygen to the cell (figure 39.2). diffusion is a slow, passive transport process. in order for diffusion to be a feasible means of providing oxygen to the cell, the rate of oxygen uptake must match the rate of diffusion across the membrane. in other words, if the cell were very large or thick, diffusion would not be able to provide oxygen quickly enough to the inside of the cell. therefore, dependence on diffusion as a means of obtaining oxygen and removing carbon dioxide remains feasible only for small organisms or those with highly-flattened bodies, such as many flatworms (platyhelminthes). larger organisms had to evolve specialized respiratory tissues, such as gills, lungs, and respiratory passages accompanied by complex circulatory systems, to transport oxygen throughout their entire body.  figure 39.2 the cell of the unicellular algae ventricaria ventricosa is one of the largest known, reaching one to five centimeters in diameter. like all single-celled organisms, v. ventricosa exchanges gases across the cell membrane.  direct diffusion for small multicellular organisms, diffusion across the outer membrane is sufficient to meet their oxygen needs. gas exchange by direct diffusion across surface membranes is efficient for organisms less than 1 mm in diameter. in simple organisms, such as cnidarians and flatworms, every cell in the body is close to the external environment. their cells are kept moist and gases diffuse quickly via direct diffusion. flatworms are small, literally flat worms, which ‘breathe’ through diffusion across the outer membrane (figure 39.3). the flat shape of these organisms increases the surface area for diffusion, ensuring that each cell within the body is close to the outer membrane surface and has access to oxygen. if the flatworm had a cylindrical body, then the cells in the center would not be able to get oxygen.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1137  figure 39.3 this flatworm’s process of respiration works by diffusion across the outer membrane. (credit: stephen childs)  skin and gills earthworms and amphibians use their skin (integument) as a respiratory organ. a dense network of capillaries lies just below the skin and facilitates gas exchange between the external environment and the circulatory system. the respiratory surface must be kept moist in order for the gases to dissolve and diffuse across cell membranes. organisms that live in water need to obtain oxygen from the water. oxygen dissolves in water but at a lower concentration than in the atmosphere. the atmosphere has roughly 21 percent oxygen. in water, the oxygen concentration is much smaller than that. fish and many other aquatic organisms have evolved gills to take up the dissolved oxygen from water (figure 39.4). gills are thin tissue filaments that are highly branched and folded. when water passes over the gills, the dissolved oxygen in water rapidly diffuses across the gills into the bloodstream. the circulatory system can then carry the oxygenated blood to the other parts of the body. in animals that contain coelomic fluid instead of blood, oxygen diffuses across the gill surfaces into the coelomic fluid. gills are found in mollusks, annelids, and crustaceans.  figure 39.4 this common carp, like many other aquatic organisms, has gills that allow it to obtain oxygen from water. (credit: ""guitardude012""/wikimedia commons)  the folded surfaces of the gills provide a large surface area to ensure that the fish gets sufficient oxygen. diffusion is a process in which material travels from regions of high concentration to low concentration until equilibrium is reached. in this case, blood with a low concentration of oxygen molecules circulates through the gills. the concentration of oxygen molecules in water is higher than the concentration of oxygen molecules in gills. as a result, oxygen molecules diffuse from water (high concentration) to blood (low concentration), as shown in figure 39.5. similarly, carbon dioxide molecules in the blood diffuse from the blood (high concentration) to water (low concentration).  1138  chapter 39 | the respiratory system  figure 39.5 as water flows over the gills, oxygen is transferred to blood via the veins. (credit ""fish"": modification of work by duane raver, noaa)  tracheal systems insect respiration is independent of its circulatory system; therefore, the blood does not play a direct role in oxygen transport. insects have a highly specialized type of respiratory system called the tracheal system, which consists of a network of small tubes that carries oxygen to the entire body. the tracheal system is the most direct and efficient respiratory system in active animals. the tubes in the tracheal system are made of a polymeric material called chitin. insect bodies have openings, called spiracles, along the thorax and abdomen. these openings connect to the tubular network, allowing oxygen to pass into the body (figure 39.6) and regulating the diffusion of co2 and water vapor. air enters and leaves the tracheal system through the spiracles. some insects can ventilate the tracheal system with body movements.  figure 39.6 insects perform respiration via a tracheal system.  mammalian systems in mammals, pulmonary ventilation occurs via inhalation (breathing). during inhalation, air enters the body through the nasal cavity located just inside the nose (figure 39.7). as air passes through the nasal cavity, the air is warmed to body temperature and humidified. the respiratory tract is coated with mucus to seal the tissues from direct contact with air. mucus is high in water. as air crosses these surfaces of the mucous membranes, it picks up water. these processes help equilibrate the air to the body conditions, reducing any damage that cold, dry air can cause. particulate matter that is floating in the air is removed in the nasal passages via mucus and cilia. the processes of warming, humidifying, and removing particles are important protective mechanisms that prevent damage to the trachea and lungs. thus, inhalation serves several purposes in addition to bringing oxygen into the respiratory system.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1139  figure 39.7 air enters the respiratory system through the nasal cavity and pharynx, and then passes through the trachea and into the bronchi, which bring air into the lungs. (credit: modification of work by nci)  which of the following statements about the mammalian respiratory system is false? a. when we breathe in, air travels from the pharynx to the trachea. b. the bronchioles branch into bronchi. c. alveolar ducts connect to alveolar sacs. d. gas exchange between the lung and blood takes place in the alveolus. from the nasal cavity, air passes through the pharynx (throat) and the larynx (voice box), as it makes its way to the trachea (figure 39.7). the main function of the trachea is to funnel the inhaled air to the lungs and the exhaled air back out of the body. the human trachea is a cylinder about 10 to 12 cm long and 2 cm in diameter that sits in front of the esophagus and extends from the larynx into the chest cavity where it divides into the two primary bronchi at the midthorax. it is made of incomplete rings of hyaline cartilage and smooth muscle (figure 39.8). the trachea is lined with mucus-producing goblet cells and ciliated epithelia. the cilia propel foreign particles trapped in the mucus toward the pharynx. the cartilage provides strength and support to the trachea to keep the passage open. the smooth muscle can contract, decreasing the trachea’s diameter, which causes expired air to rush upwards from the lungs at a great force. the forced exhalation helps expel mucus when we cough. smooth muscle can contract or relax, depending on stimuli from the external environment or the body’s nervous system.  1140  chapter 39 | the respiratory system  figure 39.8 the trachea and bronchi are made of incomplete rings of cartilage. (credit: modification of work by gray's anatomy)  lungs: bronchi and alveoli the end of the trachea bifurcates (divides) to the right and left lungs. the lungs are not identical. the right lung is larger and contains three lobes, whereas the smaller left lung contains two lobes (figure 39.9). the muscular diaphragm, which facilitates breathing, is inferior to (below) the lungs and marks the end of the thoracic cavity.  figure 39.9 the trachea bifurcates into the right and left bronchi in the lungs. the right lung is made of three lobes and is larger. to accommodate the heart, the left lung is smaller and has only two lobes.  in the lungs, air is diverted into smaller and smaller passages, or bronchi. air enters the lungs through the two primary (main) bronchi (singular: bronchus). each bronchus divides into secondary bronchi, then into tertiary bronchi, which in turn divide, creating smaller and smaller diameter bronchioles as they split and spread through the lung. like the trachea, the bronchi are made of cartilage and smooth muscle. at the bronchioles, the cartilage is replaced with elastic fibers. bronchi are innervated by nerves of both the parasympathetic and sympathetic nervous systems that control muscle contraction (parasympathetic) or relaxation (sympathetic) in the bronchi and bronchioles, depending on the nervous system’s cues. in humans, bronchioles with a diameter smaller than 0.5 mm are the respiratory bronchioles. they lack cartilage and therefore rely on inhaled air to support their shape. as the passageways decrease in diameter, the relative amount of smooth muscle increases. the terminal bronchioles subdivide into microscopic branches called respiratory bronchioles. the respiratory bronchioles subdivide into several alveolar ducts. numerous alveoli and alveolar sacs surround the alveolar ducts. the alveolar sacs resemble bunches of grapes tethered to the end of the bronchioles (figure 39.10). in the acinar region, the alveolar ducts  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1141  are attached to the end of each bronchiole. at the end of each duct are approximately 100 alveolar sacs, each containing 20 to 30 alveoli that are 200 to 300 microns in diameter. gas exchange occurs only in alveoli. alveoli are made of thin-walled parenchymal cells, typically one-cell thick, that look like tiny bubbles within the sacs. alveoli are in direct contact with capillaries (one-cell thick) of the circulatory system. such intimate contact ensures that oxygen will diffuse from alveoli into the blood and be distributed to the cells of the body. in addition, the carbon dioxide that was produced by cells as a waste product will diffuse from the blood into alveoli to be exhaled. the anatomical arrangement of capillaries and alveoli emphasizes the structural and functional relationship of the respiratory and circulatory systems. because there are so many alveoli (~300 million per lung) within each alveolar sac and so many sacs at the end of each alveolar duct, the lungs have a sponge-like consistency. this organization produces a very large surface area that is available for gas exchange. the surface area of alveoli in the lungs is approximately 75 m2. this large surface area, combined with the thin-walled nature of the alveolar parenchymal cells, allows gases to easily diffuse across the cells.  figure 39.10 terminal bronchioles are connected by respiratory bronchioles to alveolar ducts and alveolar sacs. each alveolar sac contains 20 to 30 spherical alveoli and has the appearance of a bunch of grapes. air flows into the atrium of the alveolar sac, then circulates into alveoli where gas exchange occurs with the capillaries. mucous glands secrete mucous into the airways, keeping them moist and flexible. (credit: modification of work by mariana ruiz villareal)  watch the following video (http://openstaxcollege.org/l/lungs_pulmonary) to review the respiratory system.  protective mechanisms the air that organisms breathe contains particulate matter such as dust, dirt, viral particles, and bacteria that can damage the lungs or trigger allergic immune responses. the respiratory system contains several protective mechanisms to avoid problems or tissue damage. in the nasal cavity, hairs and mucus trap small particles, viruses, bacteria, dust, and dirt to prevent their entry.  1142  chapter 39 | the respiratory system  if particulates do make it beyond the nose, or enter through the mouth, the bronchi and bronchioles of the lungs also contain several protective devices. the lungs produce mucus—a sticky substance made of mucin, a complex glycoprotein, as well as salts and water—that traps particulates. the bronchi and bronchioles contain cilia, small hair-like projections that line the walls of the bronchi and bronchioles (figure 39.11). these cilia beat in unison and move mucus and particles out of the bronchi and bronchioles back up to the throat where it is swallowed and eliminated via the esophagus. in humans, for example, tar and other substances in cigarette smoke destroy or paralyze the cilia, making the removal of particles more difficult. in addition, smoking causes the lungs to produce more mucus, which the damaged cilia are not able to move. this causes a persistent cough, as the lungs try to rid themselves of particulate matter, and makes smokers more susceptible to respiratory ailments.  figure 39.11 the bronchi and bronchioles contain cilia that help move mucus and other particles out of the lungs. (credit: louisa howard, modification of work by dartmouth electron microscope facility)  39.2 | gas exchange across respiratory surfaces by the end of this section, you will be able to: • name and describe lung volumes and capacities • understand how gas pressure influences how gases move into and out of the body the structure of the lung maximizes its surface area to increase gas diffusion. because of the enormous number of alveoli (approximately 300 million in each human lung), the surface area of the lung is very large (75 m2). having such a large surface area increases the amount of gas that can diffuse into and out of the lungs.  basic principles of gas exchange gas exchange during respiration occurs primarily through diffusion. diffusion is a process in which transport is driven by a concentration gradient. gas molecules move from a region of high concentration to a region of low concentration. blood that is low in oxygen concentration and high in carbon dioxide concentration undergoes gas exchange with air in the lungs. the air in the lungs has a higher concentration of oxygen than that of oxygen-depleted blood and a lower concentration of carbon dioxide. this concentration gradient allows for gas exchange during respiration. partial pressure is a measure of the concentration of the individual components in a mixture of gases. the total pressure exerted by the mixture is the sum of the partial pressures of the components in the mixture. the rate of diffusion of a gas is proportional to its partial pressure within the total gas mixture. this concept is discussed further in detail below.  lung volumes and capacities different animals have different lung capacities based on their activities. cheetahs have evolved a much higher lung capacity than humans; it helps provide oxygen to all the muscles in the body and allows them to run very fast. elephants  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1143  also have a high lung capacity. in this case, it is not because they run fast but because they have a large body and must be able to take up oxygen in accordance with their body size. human lung size is determined by genetics, gender, and height. at maximal capacity, an average lung can hold almost six liters of air, but lungs do not usually operate at maximal capacity. air in the lungs is measured in terms of lung volumes and lung capacities (figure 39.12 and table 39.1). volume measures the amount of air for one function (such as inhalation or exhalation). capacity is any two or more volumes (for example, how much can be inhaled from the end of a maximal exhalation).  figure 39.12 human lung volumes and capacities are shown. the total lung capacity of the adult male is six liters. tidal volume is the volume of air inhaled in a single, normal breath. inspiratory capacity is the amount of air taken in during a deep breath, and residual volume is the amount of air left in the lungs after forceful respiration.  lung volumes and capacities (avg adult male) volume/ capacity  definition  volume (liters)  equations  tidal volume (tv)  amount of air inhaled during a normal breath  0.5  -  expiratory reserve volume (erv)  amount of air that can be exhaled after a normal exhalation  1.2  -  inspiratory reserve volume (irv)  amount of air that can be further inhaled after a normal 3.1 inhalation  -  residual volume (rv)  air left in the lungs after a forced exhalation  1.2  -  vital capacity (vc)  maximum amount of air that can be moved in or out of the lungs in a single respiratory cycle  4.8  erv+tv+irv  inspiratory capacity (ic)  volume of air that can be inhaled in addition to a normal exhalation  3.6  tv+irv  functional residual capacity (frc)  volume of air remaining after a normal exhalation  2.4  erv+rv  total lung capacity (tlc)  total volume of air in the lungs after a maximal inspiration  6.0  rv+erv+tv+irv  forced expiratory volume (fev1)  how much air can be forced out of the lungs over a specific time period, usually one second  ~4.1 to 5.5  -  table 39.1  1144  chapter 39 | the respiratory system  the volume in the lung can be divided into four units: tidal volume, expiratory reserve volume, inspiratory reserve volume, and residual volume. tidal volume (tv) measures the amount of air that is inspired and expired during a normal breath. on average, this volume is around one-half liter, which is a little less than the capacity of a 20-ounce drink bottle. the expiratory reserve volume (erv) is the additional amount of air that can be exhaled after a normal exhalation. it is the reserve amount that can be exhaled beyond what is normal. conversely, the inspiratory reserve volume (irv) is the additional amount of air that can be inhaled after a normal inhalation. the residual volume (rv) is the amount of air that is left after expiratory reserve volume is exhaled. the lungs are never completely empty: there is always some air left in the lungs after a maximal exhalation. if this residual volume did not exist and the lungs emptied completely, the lung tissues would stick together and the energy necessary to re-inflate the lung could be too great to overcome. therefore, there is always some air remaining in the lungs. residual volume is also important for preventing large fluctuations in respiratory gases (o2 and co2). the residual volume is the only lung volume that cannot be measured directly because it is impossible to completely empty the lung of air. this volume can only be calculated rather than measured. capacities are measurements of two or more volumes. the vital capacity (vc) measures the maximum amount of air that can be inhaled or exhaled during a respiratory cycle. it is the sum of the expiratory reserve volume, tidal volume, and inspiratory reserve volume. the inspiratory capacity (ic) is the amount of air that can be inhaled after the end of a normal expiration. it is, therefore, the sum of the tidal volume and inspiratory reserve volume. the functional residual capacity (frc) includes the expiratory reserve volume and the residual volume. the frc measures the amount of additional air that can be exhaled after a normal exhalation. lastly, the total lung capacity (tlc) is a measurement of the total amount of air that the lung can hold. it is the sum of the residual volume, expiratory reserve volume, tidal volume, and inspiratory reserve volume. lung volumes are measured by a technique called spirometry. an important measurement taken during spirometry is the forced expiratory volume (fev), which measures how much air can be forced out of the lung over a specific period, usually one second (fev1). in addition, the forced vital capacity (fvc), which is the total amount of air that can be forcibly exhaled, is measured. the ratio of these values ( fev1/fvc ratio) is used to diagnose lung diseases including asthma, emphysema, and fibrosis. if the fev1/fvc ratio is high, the lungs are not compliant (meaning they are stiff and unable to bend properly), and the patient most likely has lung fibrosis. patients exhale most of the lung volume very quickly. conversely, when the fev1/fvc ratio is low, there is resistance in the lung that is characteristic of asthma. in this instance, it is hard for the patient to get the air out of his or her lungs, and it takes a long time to reach the maximal exhalation volume. in either case, breathing is difficult and complications arise.  respiratory therapist respiratory therapists or respiratory practitioners evaluate and treat patients with lung and cardiovascular diseases. they work as part of a medical team to develop treatment plans for patients. respiratory therapists may treat premature babies with underdeveloped lungs, patients with chronic conditions such as asthma, or older patients suffering from lung disease such as emphysema and chronic obstructive pulmonary disease (copd). they may operate advanced equipment such as compressed gas delivery systems, ventilators, blood gas analyzers, and resuscitators. specialized programs to become a respiratory therapist generally lead to a bachelor’s degree with a respiratory therapist specialty. because of a growing aging population, career opportunities as a respiratory therapist are expected to remain strong.  gas pressure and respiration the respiratory process can be better understood by examining the properties of gases. gases move freely, but gas particles are constantly hitting the walls of their vessel, thereby producing gas pressure. air is a mixture of gases, primarily nitrogen (n2; 78.6 percent), oxygen (o2; 20.9 percent), water vapor (h2o; 0.5 percent), and carbon dioxide (co2; 0.04 percent). each gas component of that mixture exerts a pressure. the pressure for an individual gas in the mixture is the partial pressure of that gas. approximately 21 percent of atmospheric gas is oxygen. carbon dioxide, however, is found in relatively small amounts, 0.04 percent. the partial pressure for oxygen is much greater than that of carbon dioxide. the partial pressure of any gas can be calculated by:  p = (p atm ) × (percent content in mixture). patm, the atmospheric pressure, is the sum of all of the partial pressures of the atmospheric gases added together,  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1145  p atm = p n + p o + p h 2  2  2o  + p co = 760 mm hg 2  × (percent content in mixture). the pressure of the atmosphere at sea level is 760 mm hg. therefore, the partial pressure of oxygen is:  p o = (760 mm hg) (0.21) = 160 mm hg 2  and for carbon dioxide:  p co = (760 mm hg) (0.0004) = 0.3 mm hg. 2  at high altitudes, patm decreases but concentration does not change; the partial pressure decrease is due to the reduction in patm. when the air mixture reaches the lung, it has been humidified. the pressure of the water vapor in the lung does not change the pressure of the air, but it must be included in the partial pressure equation. for this calculation, the water pressure (47 mm hg) is subtracted from the atmospheric pressure:  760 mm hg − 47 mm hg = 713 mm hg and the partial pressure of oxygen is:  (760 mm hg − 47 mm hg) × 0.21 = 150 mm hg. these pressures determine the gas exchange, or the flow of gas, in the system. oxygen and carbon dioxide will flow according to their pressure gradient from high to low. therefore, understanding the partial pressure of each gas will aid in understanding how gases move in the respiratory system.  gas exchange across the alveoli in the body, oxygen is used by cells of the body’s tissues and carbon dioxide is produced as a waste product. the ratio of carbon dioxide production to oxygen consumption is the respiratory quotient (rq). rq varies between 0.7 and 1.0. if just glucose were used to fuel the body, the rq would equal one. one mole of carbon dioxide would be produced for every mole of oxygen consumed. glucose, however, is not the only fuel for the body. protein and fat are also used as fuels for the body. because of this, less carbon dioxide is produced than oxygen is consumed and the rq is, on average, about 0.7 for fat and about 0.8 for protein. the rq is used to calculate the partial pressure of oxygen in the alveolar spaces within the lung, the alveolar po above, 2 the partial pressure of oxygen in the lungs was calculated to be 150 mm hg. however, lungs never fully deflate with an exhalation; therefore, the inspired air mixes with this residual air and lowers the partial pressure of oxygen within the alveoli. this means that there is a lower concentration of oxygen in the lungs than is found in the air outside the body. knowing the rq, the partial pressure of oxygen in the alveoli can be calculated:  alveolar p o = inspired p o − ( 2  2  alveolar p o 2) rq  with an rq of 0.8 and a p co in the alveoli of 40 mm hg, the alveolar p o is equal to: 2 2  alveolar p o = 150 mm hg − ( 2  40 mm hg ) = mm hg. 0.8  notice that this pressure is less than the external air. therefore, the oxygen will flow from the inspired air in the lung ( p o  2  = 150 mm hg) into the bloodstream ( p o = 100 mm hg) (figure 39.13). 2  in the lungs, oxygen diffuses out of the alveoli and into the capillaries surrounding the alveoli. oxygen (about 98 percent) binds reversibly to the respiratory pigment hemoglobin found in red blood cells (rbcs). rbcs carry oxygen to the tissues where oxygen dissociates from the hemoglobin and diffuses into the cells of the tissues. more specifically, alveolar p o 2  is higher in the alveoli ( p alvo = 100 mm hg) than blood p o (40 mm hg) in the capillaries. because this pressure 2 2 gradient exists, oxygen diffuses down its pressure gradient, moving out of the alveoli and entering the blood of the  1146  chapter 39 | the respiratory system  capillaries where o2 binds to hemoglobin. at the same time, alveolar p co is lower p alvo = 40 mm hg than blood 2 2  p co = (45 mm hg). co2 diffuses down its pressure gradient, moving out of the capillaries and entering the alveoli. 2  oxygen and carbon dioxide move independently of each other; they diffuse down their own pressure gradients. as blood leaves the lungs through the pulmonary veins, the venous po = 100 mm hg, whereas the venous pco = 40 mm hg. as 2  2  blood enters the systemic capillaries, the blood will lose oxygen and gain carbon dioxide because of the pressure difference of the tissues and blood. in systemic capillaries, p o = 100 mm hg, but in the tissue cells, p o = 40 mm hg. this pressure 2  2  gradient drives the diffusion of oxygen out of the capillaries and into the tissue cells. at the same time, blood p co = 40 2  mm hg and systemic tissue p co = 45 mm hg. the pressure gradient drives co2 out of tissue cells and into the capillaries. 2  the blood returning to the lungs through the pulmonary arteries has a venous p o = 40 mm hg and a p co = 45 mm hg. 2 2 the blood enters the lung capillaries where the process of exchanging gases between the capillaries and alveoli begins again (figure 39.13).  figure 39.13 the partial pressures of oxygen and carbon dioxide change as blood moves through the body.  which of the following statements is false? a. in the tissues, p o drops as blood passes from the arteries to the veins, while p co increases. 2 2 b. blood travels from the lungs to the heart to body tissues, then back to the heart, then the lungs. c. blood travels from the lungs to the heart to body tissues, then back to the lungs, then the heart. d.  p o is higher in air than in the lungs. 2  in short, the change in partial pressure from the alveoli to the capillaries drives the oxygen into the tissues and the carbon dioxide into the blood from the tissues. the blood is then transported to the lungs where differences in pressure in the alveoli result in the movement of carbon dioxide out of the blood into the lungs, and oxygen into the blood.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1147  watch this video (http://openstaxcollege.org/l/spirometry) to learn how to carry out spirometry.  39.3 | breathing by the end of this section, you will be able to: • describe how the structures of the lungs and thoracic cavity control the mechanics of breathing • explain the importance of compliance and resistance in the lungs • discuss problems that may arise due to a v/q mismatch mammalian lungs are located in the thoracic cavity where they are surrounded and protected by the rib cage, intercostal muscles, and bound by the chest wall. the bottom of the lungs is contained by the diaphragm, a skeletal muscle that facilitates breathing. breathing requires the coordination of the lungs, the chest wall, and most importantly, the diaphragm.  types of breathing amphibians have evolved multiple ways of breathing. young amphibians, like tadpoles, use gills to breathe, and they don’t leave the water. some amphibians retain gills for life. as the tadpole grows, the gills disappear and lungs grow. these lungs are primitive and not as evolved as mammalian lungs. adult amphibians are lacking or have a reduced diaphragm, so breathing via lungs is forced. the other means of breathing for amphibians is diffusion across the skin. to aid this diffusion, amphibian skin must remain moist. birds face a unique challenge with respect to breathing: they fly. flying consumes a great amount of energy; therefore, birds require a lot of oxygen to aid their metabolic processes. birds have evolved a respiratory system that supplies them with the oxygen needed to enable flying. similar to mammals, birds have lungs, which are organs specialized for gas exchange. oxygenated air, taken in during inhalation, diffuses across the surface of the lungs into the bloodstream, and carbon dioxide diffuses from the blood into the lungs and expelled during exhalation. the details of breathing between birds and mammals differ substantially. in addition to lungs, birds have air sacs inside their body. air flows in one direction from the posterior air sacs to the lungs and out of the anterior air sacs. the flow of air is in the opposite direction from blood flow, and gas exchange takes place much more efficiently. this type of breathing enables birds to obtain the requisite oxygen, even at higher altitudes where the oxygen concentration is low. this directionality of airflow requires two cycles of air intake and exhalation to completely get the air out of the lungs.  1148  chapter 39 | the respiratory system  avian respiration birds have evolved a respiratory system that enables them to fly. flying is a high-energy process and requires a lot of oxygen. furthermore, many birds fly in high altitudes where the concentration of oxygen in low. how did birds evolve a respiratory system that is so unique? decades of research by paleontologists have shown that birds evolved from therapods, meat-eating dinosaurs (figure 39.14). in fact, fossil evidence shows that meat-eating dinosaurs that lived more than 100 million years ago had a similar flow-through respiratory system with lungs and air sacs. archaeopteryx and xiaotingia, for example, were flying dinosaurs and are believed to be early precursors of birds.  figure 39.14 (a) birds have a flow-through respiratory system in which air flows unidirectionally from the posterior sacs into the lungs, then into the anterior air sacs. the air sacs connect to openings in hollow bones. (b) dinosaurs, from which birds descended, have similar hollow bones and are believed to have had a similar respiratory system. (credit b: modification of work by zina deretsky, national science foundation)  most of us consider that dinosaurs are extinct. however, modern birds are descendants of avian dinosaurs. the respiratory system of modern birds has been evolving for hundreds of millions of years.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1149  all mammals have lungs that are the main organs for breathing. lung capacity has evolved to support the animal’s activities. during inhalation, the lungs expand with air, and oxygen diffuses across the lung’s surface and enters the bloodstream. during exhalation, the lungs expel air and lung volume decreases. in the next few sections, the process of human breathing will be explained.  the mechanics of human breathing boyle’s law is the gas law that states that in a closed space, pressure and volume are inversely related. as volume decreases, pressure increases and vice versa (figure 39.15). the relationship between gas pressure and volume helps to explain the mechanics of breathing.  figure 39.15 this graph shows data from boyle’s original 1662 experiment, which shows that pressure and volume are inversely related. no units are given as boyle used arbitrary units in his experiments.  there is always a slightly negative pressure within the thoracic cavity, which aids in keeping the airways of the lungs open. during inhalation, volume increases as a result of contraction of the diaphragm, and pressure decreases (according to boyle’s law). this decrease of pressure in the thoracic cavity relative to the environment makes the cavity less than the atmosphere (figure 39.16a). because of this drop in pressure, air rushes into the respiratory passages. to increase the volume of the lungs, the chest wall expands. this results from the contraction of the intercostal muscles, the muscles that are connected to the rib cage. lung volume expands because the diaphragm contracts and the intercostals muscles contract, thus expanding the thoracic cavity. this increase in the volume of the thoracic cavity lowers pressure compared to the atmosphere, so air rushes into the lungs, thus increasing its volume. the resulting increase in volume is largely attributed to an increase in alveolar space, because the bronchioles and bronchi are stiff structures that do not change in size.  figure 39.16 the lungs, chest wall, and diaphragm are all involved in respiration, both (a) inhalation and (b) expiration. (credit: modification of work by mariana ruiz villareal)  the chest wall expands out and away from the lungs. the lungs are elastic; therefore, when air fills the lungs, the elastic recoil within the tissues of the lung exerts pressure back toward the interior of the lungs. these outward and inward forces  1150  chapter 39 | the respiratory system  compete to inflate and deflate the lung with every breath. upon exhalation, the lungs recoil to force the air out of the lungs, and the intercostal muscles relax, returning the chest wall back to its original position (figure 39.16b). the diaphragm also relaxes and moves higher into the thoracic cavity. this increases the pressure within the thoracic cavity relative to the environment, and air rushes out of the lungs. the movement of air out of the lungs is a passive event. no muscles are contracting to expel the air. each lung is surrounded by an invaginated sac. the layer of tissue that covers the lung and dips into spaces is called the visceral pleura. a second layer of parietal pleura lines the interior of the thorax (figure 39.17). the space between these layers, the intrapleural space, contains a small amount of fluid that protects the tissue and reduces the friction generated from rubbing the tissue layers together as the lungs contract and relax. pleurisy results when these layers of tissue become inflamed; it is painful because the inflammation increases the pressure within the thoracic cavity and reduces the volume of the lung.  figure 39.17 a tissue layer called pleura surrounds the lung and interior of the thoracic cavity. (credit: modification of work by nci)  view (http://openstaxcollege.org/l/boyle_breathing) how boyle’s law is related to breathing and watch this video (http://openstaxcollege.org/l/boyles_law) on boyle’s law.  the work of breathing the number of breaths per minute is the respiratory rate. on average, under non-exertion conditions, the human respiratory rate is 12–15 breaths/minute. the respiratory rate contributes to the alveolar ventilation, or how much air moves into and out of the alveoli. alveolar ventilation prevents carbon dioxide buildup in the alveoli. there are two ways to keep the alveolar ventilation constant: increase the respiratory rate while decreasing the tidal volume of air per breath (shallow breathing), or decrease the respiratory rate while increasing the tidal volume per breath. in either case, the ventilation  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1151  remains the same, but the work done and type of work needed are quite different. both tidal volume and respiratory rate are closely regulated when oxygen demand increases. there are two types of work conducted during respiration, flow-resistive and elastic work. flow-resistive refers to the work of the alveoli and tissues in the lung, whereas elastic work refers to the work of the intercostal muscles, chest wall, and diaphragm. increasing the respiration rate increases the flow-resistive work of the airways and decreases the elastic work of the muscles. decreasing the respiratory rate reverses the type of work required. surfactant the air-tissue/water interface of the alveoli has a high surface tension. this surface tension is similar to the surface tension of water at the liquid-air interface of a water droplet that results in the bonding of the water molecules together. surfactant is a complex mixture of phospholipids and lipoproteins that works to reduce the surface tension that exists between the alveoli tissue and the air found within the alveoli. by lowering the surface tension of the alveolar fluid, it reduces the tendency of alveoli to collapse. surfactant works like a detergent to reduce the surface tension and allows for easier inflation of the airways. when a balloon is first inflated, it takes a large amount of effort to stretch the plastic and start to inflate the balloon. if a little bit of detergent was applied to the interior of the balloon, then the amount of effort or work needed to begin to inflate the balloon would decrease, and it would become much easier to start blowing up the balloon. this same principle applies to the airways. a small amount of surfactant to the airway tissues reduces the effort or work needed to inflate those airways. babies born prematurely sometimes do not produce enough surfactant. as a result, they suffer from respiratory distress syndrome, because it requires more effort to inflate their lungs. surfactant is also important for preventing collapse of small alveoli relative to large alveoli. lung resistance and compliance pulmonary diseases reduce the rate of gas exchange into and out of the lungs. two main causes of decreased gas exchange are compliance (how elastic the lung is) and resistance (how much obstruction exists in the airways). a change in either can dramatically alter breathing and the ability to take in oxygen and release carbon dioxide. examples of restrictive diseases are respiratory distress syndrome and pulmonary fibrosis. in both diseases, the airways are less compliant and they are stiff or fibrotic. there is a decrease in compliance because the lung tissue cannot bend and move. in these types of restrictive diseases, the intrapleural pressure is more positive and the airways collapse upon exhalation, which traps air in the lungs. forced or functional vital capacity (fvc), which is the amount of air that can be forcibly exhaled after taking the deepest breath possible, is much lower than in normal patients, and the time it takes to exhale most of the air is greatly prolonged (figure 39.18). a patient suffering from these diseases cannot exhale the normal amount of air. obstructive diseases and conditions include emphysema, asthma, and pulmonary edema. in emphysema, which mostly arises from smoking tobacco, the walls of the alveoli are destroyed, decreasing the surface area for gas exchange. the overall compliance of the lungs is increased, because as the alveolar walls are damaged, lung elastic recoil decreases due to a loss of elastic fibers, and more air is trapped in the lungs at the end of exhalation. asthma is a disease in which inflammation is triggered by environmental factors. inflammation obstructs the airways. the obstruction may be due to edema (fluid accumulation), smooth muscle spasms in the walls of the bronchioles, increased mucus secretion, damage to the epithelia of the airways, or a combination of these events. those with asthma or edema experience increased occlusion from increased inflammation of the airways. this tends to block the airways, preventing the proper movement of gases (figure 39.18). those with obstructive diseases have large volumes of air trapped after exhalation and breathe at a very high lung volume to compensate for the lack of airway recruitment.  1152  chapter 39 | the respiratory system  figure 39.18 the ratio of fev1 (the amount of air that can be forcibly exhaled in one second after taking a deep breath) to fvc (the total amount of air that can be forcibly exhaled) can be used to diagnose whether a person has restrictive or obstructive lung disease. in restrictive lung disease, fvc is reduced but airways are not obstructed, so the person is able to expel air reasonably fast. in obstructive lung disease, airway obstruction results in slow exhalation as well as reduced fvc. thus, the fev1/fvc ratio is lower in persons with obstructive lung disease (less than 69 percent) than in persons with restrictive disease (88 to 90 percent).  dead space: v/q mismatch pulmonary circulation pressure is very low compared to that of the systemic circulation. it is also independent of cardiac output. this is because of a phenomenon called recruitment, which is the process of opening airways that normally remain closed when cardiac output increases. as cardiac output increases, the number of capillaries and arteries that are perfused (filled with blood) increases. these capillaries and arteries are not always in use but are ready if needed. at times, however, there is a mismatch between the amount of air (ventilation, v) and the amount of blood (perfusion, q) in the lungs. this is referred to as ventilation/perfusion (v/q) mismatch. there are two types of v/q mismatch. both produce dead space, regions of broken down or blocked lung tissue. dead spaces can severely impact breathing, because they reduce the surface area available for gas diffusion. as a result, the amount of oxygen in the blood decreases, whereas the carbon dioxide level increases. dead space is created when no ventilation and/or perfusion takes place. anatomical dead space or anatomical shunt, arises from an anatomical failure, while physiological dead space or physiological shunt, arises from a functional impairment of the lung or arteries. an example of an anatomical shunt is the effect of gravity on the lungs. the lung is particularly susceptible to changes in the magnitude and direction of gravitational forces. when someone is standing or sitting upright, the pleural pressure gradient leads to increased ventilation further down in the lung. as a result, the intrapleural pressure is more negative at the base of the lung than at the top, and more air fills the bottom of the lung than the top. likewise, it takes less energy to pump blood to the bottom of the lung than to the top when in a prone position. perfusion of the lung is not uniform while standing or sitting. this is a result of hydrostatic forces combined with the effect of airway pressure. an anatomical shunt develops because the ventilation of the airways does not match the perfusion of the arteries surrounding those airways. as a result, the rate of gas exchange is reduced. note that this does not occur when lying down, because in this position, gravity does not preferentially pull the bottom of the lung down. a physiological shunt can develop if there is infection or edema in the lung that obstructs an area. this will decrease ventilation but not affect perfusion; therefore, the v/q ratio changes and gas exchange is affected. the lung can compensate for these mismatches in ventilation and perfusion. if ventilation is greater than perfusion, the arterioles dilate and the bronchioles constrict. this increases perfusion and reduces ventilation. likewise, if ventilation is less than perfusion, the arterioles constrict and the bronchioles dilate to correct the imbalance.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1153  visit this site (http://openstaxcollege.org/l/breathing) to view the mechanics of breathing.  39.4 | transport of gases in human bodily fluids by the end of this section, you will be able to: • describe how oxygen is bound to hemoglobin and transported to body tissues • explain how carbon dioxide is transported from body tissues to the lungs once the oxygen diffuses across the alveoli, it enters the bloodstream and is transported to the tissues where it is unloaded, and carbon dioxide diffuses out of the blood and into the alveoli to be expelled from the body. although gas exchange is a continuous process, the oxygen and carbon dioxide are transported by different mechanisms.  transport of oxygen in the blood although oxygen dissolves in blood, only a small amount of oxygen is transported this way. only 1.5 percent of oxygen in the blood is dissolved directly into the blood itself. most oxygen—98.5 percent—is bound to a protein called hemoglobin and carried to the tissues. hemoglobin hemoglobin, or hb, is a protein molecule found in red blood cells (erythrocytes) made of four subunits: two alpha subunits and two beta subunits (figure 39.19). each subunit surrounds a central heme group that contains iron and binds one oxygen molecule, allowing each hemoglobin molecule to bind four oxygen molecules. molecules with more oxygen bound to the heme groups are brighter red. as a result, oxygenated arterial blood where the hb is carrying four oxygen molecules is bright red, while venous blood that is deoxygenated is darker red.  figure 39.19 the protein inside (a) red blood cells that carries oxygen to cells and carbon dioxide to the lungs is (b) hemoglobin. hemoglobin is made up of four symmetrical subunits and four heme groups. iron associated with the heme binds oxygen. it is the iron in hemoglobin that gives blood its red color.  it is easier to bind a second and third oxygen molecule to hb than the first molecule. this is because the hemoglobin molecule changes its shape, or conformation, as oxygen binds. the fourth oxygen is then more difficult to bind. the binding of oxygen to hemoglobin can be plotted as a function of the partial pressure of oxygen in the blood (x-axis) versus the  1154  chapter 39 | the respiratory system  relative hb-oxygen saturation (y-axis). the resulting graph—an oxygen dissociation curve—is sigmoidal, or s-shaped (figure 39.20). as the partial pressure of oxygen increases, the hemoglobin becomes increasingly saturated with oxygen.  figure 39.20 the oxygen dissociation curve demonstrates that, as the partial pressure of oxygen increases, more oxygen binds hemoglobin. however, the affinity of hemoglobin for oxygen may shift to the left or the right depending on environmental conditions.  the kidneys are responsible for removing excess h+ ions from the blood. if the kidneys fail, what would happen to blood ph and to hemoglobin affinity for oxygen? factors that affect oxygen binding the oxygen-carrying capacity of hemoglobin determines how much oxygen is carried in the blood. in addition to p o , 2 other environmental factors and diseases can affect oxygen carrying capacity and delivery. carbon dioxide levels, blood ph, and body temperature affect oxygen-carrying capacity (figure 39.20). when carbon + dioxide is in the blood, it reacts with water to form bicarbonate (hco− 3 ) and hydrogen ions (h ). as the level of carbon dioxide in the blood increases, more h+ is produced and the ph decreases. this increase in carbon dioxide and subsequent decrease in ph reduce the affinity of hemoglobin for oxygen. the oxygen dissociates from the hb molecule, shifting the oxygen dissociation curve to the right. therefore, more oxygen is needed to reach the same hemoglobin saturation level as when the ph was higher. a similar shift in the curve also results from an increase in body temperature. increased temperature, such as from increased activity of skeletal muscle, causes the affinity of hemoglobin for oxygen to be reduced. diseases like sickle cell anemia and thalassemia decrease the blood’s ability to deliver oxygen to tissues and its oxygencarrying capacity. in sickle cell anemia, the shape of the red blood cell is crescent-shaped, elongated, and stiffened, reducing its ability to deliver oxygen (figure 39.21). in this form, red blood cells cannot pass through the capillaries. this is painful when it occurs. thalassemia is a rare genetic disease caused by a defect in either the alpha or the beta subunit of hb. patients with thalassemia produce a high number of red blood cells, but these cells have lower-than-normal levels of hemoglobin. therefore, the oxygen-carrying capacity is diminished.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1155  figure 39.21 individuals with sickle cell anemia have crescent-shaped red blood cells. (credit: modification of work by ed uthman; scale-bar data from matt russell)  transport of carbon dioxide in the blood carbon dioxide molecules are transported in the blood from body tissues to the lungs by one of three methods: dissolution directly into the blood, binding to hemoglobin, or carried as a bicarbonate ion. several properties of carbon dioxide in the blood affect its transport. first, carbon dioxide is more soluble in blood than oxygen. about 5 to 7 percent of all carbon dioxide is dissolved in the plasma. second, carbon dioxide can bind to plasma proteins or can enter red blood cells and bind to hemoglobin. this form transports about 10 percent of the carbon dioxide. when carbon dioxide binds to hemoglobin, a molecule called carbaminohemoglobin is formed. binding of carbon dioxide to hemoglobin is reversible. therefore, when it reaches the lungs, the carbon dioxide can freely dissociate from the hemoglobin and be expelled from the body. third, the majority of carbon dioxide molecules (85 percent) are carried as part of the bicarbonate buffer system. in this system, carbon dioxide diffuses into the red blood cells. carbonic anhydrase (ca) within the red blood cells quickly converts the carbon dioxide into carbonic acid (h2co3). carbonic acid is an unstable intermediate molecule + that immediately dissociates into bicarbonate ions (hco− 3 ) and hydrogen (h ) ions. since carbon dioxide is quickly  converted into bicarbonate ions, this reaction allows for the continued uptake of carbon dioxide into the blood down its concentration gradient. it also results in the production of h+ ions. if too much h+ is produced, it can alter blood ph. however, hemoglobin binds to the free h+ ions and thus limits shifts in ph. the newly synthesized bicarbonate ion is transported out of the red blood cell into the liquid component of the blood in exchange for a chloride ion (cl-); this is called the chloride shift. when the blood reaches the lungs, the bicarbonate ion is transported back into the red blood cell in exchange for the chloride ion. the h+ ion dissociates from the hemoglobin and binds to the bicarbonate ion. this produces the carbonic acid intermediate, which is converted back into carbon dioxide through the enzymatic action of ca. the carbon dioxide produced is expelled through the lungs during exhalation.  co 2 + h 2 o ↔  h 2 co 3 hco 3 + h+ ↔ (carbonic acid) (bicarbonate)  the benefit of the bicarbonate buffer system is that carbon dioxide is “soaked up” into the blood with little change to the ph of the system. this is important because it takes only a small change in the overall ph of the body for severe injury or death to result. the presence of this bicarbonate buffer system also allows for people to travel and live at high altitudes: when the partial pressure of oxygen and carbon dioxide change at high altitudes, the bicarbonate buffer system adjusts to regulate carbon dioxide while maintaining the correct ph in the body. carbon monoxide poisoning while carbon dioxide can readily associate and dissociate from hemoglobin, other molecules such as carbon monoxide (co) cannot. carbon monoxide has a greater affinity for hemoglobin than oxygen. therefore, when carbon monoxide is present, it binds to hemoglobin preferentially over oxygen. as a result, oxygen cannot bind to hemoglobin, so very little oxygen is transported through the body (figure 39.22). carbon monoxide is a colorless, odorless gas and is therefore difficult to detect. it is produced by gas-powered vehicles and tools. carbon monoxide can cause headaches, confusion, and nausea; long-term exposure can cause brain damage or death. administering 100 percent (pure) oxygen is the usual treatment for carbon monoxide poisoning. administration of pure oxygen speeds up the separation of carbon monoxide from hemoglobin.  1156  figure 39.22 as percent co increases, the oxygen saturation of hemoglobin decreases.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  chapter 39 | the respiratory system  1157  key terms alveolar po partial pressure of oxygen in the alveoli (usually around 100 mmhg) 2 alveolar duct duct that extends from the terminal bronchiole to the alveolar sac alveolar sac structure consisting of two or more alveoli that share a common opening alveolar ventilation how much air is in the alveoli alveolus (plural: alveoli) (also, air sac) terminal region of the lung where gas exchange occurs anatomical dead space (also, anatomical shunt) region of the lung that lacks proper ventilation/perfusion due to an anatomical block − + bicarbonate (hco− 3 ) ion ion created when carbonic acid dissociates into h and (hco 3 )  bicarbonate buffer system system in the blood that absorbs carbon dioxide and regulates ph levels bronchiole airway that extends from the main tertiary bronchi to the alveolar sac bronchus (plural: bronchi) smaller branch of cartilaginous tissue that stems off of the trachea; air is funneled through the bronchi to the region where gas exchange occurs in alveoli carbaminohemoglobin molecule that forms when carbon dioxide binds to hemoglobin carbonic anhydrase (ca) enzyme that catalyzes carbon dioxide and water into carbonic acid chloride shift chloride shift exchange of chloride for bicarbonate into or out of the red blood cell compliance measurement of the elasticity of the lung dead space area in the lung that lacks proper ventilation or perfusion diaphragm domed-shaped skeletal muscle located under lungs that separates the thoracic cavity from the abdominal cavity elastic recoil property of the lung that drives the lung tissue inward elastic work work conducted by the intercostal muscles, chest wall, and diaphragm expiratory reserve volume (erv) amount of additional air that can be exhaled after a normal exhalation fev1/fvc ratio ratio of how much air can be forced out of the lung in one second to the total amount that is forced out of the lung; a measurement of lung function that can be used to detect disease states flow-resistive work of breathing performed by the alveoli and tissues in the lung forced expiratory volume (fev) (also, forced vital capacity) measure of how much air can be forced out of the lung from maximal inspiration over a specific amount of time functional residual capacity (frc) expiratory reserve volume plus residual volume functional vital capacity (fvc) amount of air that can be forcibly exhaled after taking the deepest breath possible heme group centralized iron-containing group that is surrounded by the alpha and beta subunits of hemoglobin hemoglobin molecule in red blood cells that can bind oxygen, carbon dioxide, and carbon monoxide inspiratory capacity (ic) tidal volume plus inspiratory reserve volume inspiratory reserve volume (irv) amount of additional air that can be inspired after a normal inhalation  1158  chapter 39 | the respiratory system  intercostal muscle muscle connected to the rib cage that contracts upon inspiration intrapleural space space between the layers of pleura larynx voice box, a short passageway connecting the pharynx and the trachea lung capacity measurement of two or more lung volumes (how much air can be inhaled from the end of an expiration to maximal capacity) lung volume measurement of air for one lung function (normal inhalation or exhalation) mucin complex glycoprotein found in mucus mucus sticky protein-containing fluid secretion in the lung that traps particulate matter to be expelled from the body nasal cavity opening of the respiratory system to the outside environment obstructive disease disease (such as emphysema and asthma) that arises from obstruction of the airways; compliance increases in these diseases oxygen dissociation curve curve depicting the affinity of oxygen for hemoglobin oxygen-carrying capacity amount of oxygen that can be transported in the blood partial pressure amount of pressure exerted by one gas within a mixture of gases particulate matter small particle such as dust, dirt, viral particles, and bacteria that are in the air pharynx throat; a tube that starts in the internal nares and runs partway down the neck, where it opens into the esophagus and the larynx physiological dead space (also, physiological shunt) region of the lung that lacks proper ventilation/perfusion due to a physiological change in the lung (like inflammation or edema) pleura tissue layer that surrounds the lungs and lines the interior of the thoracic cavity pleurisy painful inflammation of the pleural tissue layers primary bronchus (also, main bronchus) region of the airway within the lung that attaches to the trachea and bifurcates to each lung where it branches into secondary bronchi recruitment process of opening airways that normally remain closed when the cardiac output increases residual volume (rv) amount of air remaining in the lung after a maximal expiration resistance measurement of lung obstruction respiratory bronchiole terminal portion of the bronchiole tree that is attached to the terminal bronchioles and alveoli ducts, alveolar sacs, and alveoli respiratory distress syndrome disease that arises from a deficient amount of surfactant respiratory quotient (rq) ratio of carbon dioxide production to each oxygen molecule consumed respiratory rate number of breaths per minute restrictive disease disease that results from a restriction and decreased compliance of the alveoli; respiratory distress syndrome and pulmonary fibrosis are examples sickle cell anemia genetic disorder that affects the shape of red blood cells, and their ability to transport oxygen and move through capillaries spirometry method to measure lung volumes and to diagnose lung diseases  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  1159  surfactant detergent-like liquid in the airways that lowers the surface tension of the alveoli to allow for expansion terminal bronchiole region of bronchiole that attaches to the respiratory bronchioles thalassemia rare genetic disorder that results in mutation of the alpha or beta subunits of hemoglobin, creating smaller red blood cells with less hemoglobin tidal volume (tv) amount of air that is inspired and expired during normal breathing total lung capacity (tlc) sum of the residual volume, expiratory reserve volume, tidal volume, and inspiratory reserve volume trachea cartilaginous tube that transports air from the larynx to the primary bronchi venous pco partial pressure of carbon dioxide in the veins (40 mm hg in the pulmonary veins) 2 venous po partial pressure of oxygen in the veins (100 mm hg in the pulmonary veins) 2 ventilation/perfusion (v/q) mismatch region of the lung that lacks proper alveolar ventilation (v) and/or arterial perfusion (q) vital capacity (vc) sum of the expiratory reserve volume, tidal volume, and inspiratory reserve volume  chapter summary 39.1 systems of gas exchange animal respiratory systems are designed to facilitate gas exchange. in mammals, air is warmed and humidified in the nasal cavity. air then travels down the pharynx, through the trachea, and into the lungs. in the lungs, air passes through the branching bronchi, reaching the respiratory bronchioles, which house the first site of gas exchange. the respiratory bronchioles open into the alveolar ducts, alveolar sacs, and alveoli. because there are so many alveoli and alveolar sacs in the lung, the surface area for gas exchange is very large. several protective mechanisms are in place to prevent damage or infection. these include the hair and mucus in the nasal cavity that trap dust, dirt, and other particulate matter before they can enter the system. in the lungs, particles are trapped in a mucus layer and transported via cilia up to the esophageal opening at the top of the trachea to be swallowed.  39.2 gas exchange across respiratory surfaces the lungs can hold a large volume of air, but they are not usually filled to maximal capacity. lung volume measurements include tidal volume, expiratory reserve volume, inspiratory reserve volume, and residual volume. the sum of these equals the total lung capacity. gas movement into or out of the lungs is dependent on the pressure of the gas. air is a mixture of gases; therefore, the partial pressure of each gas can be calculated to determine how the gas will flow in the lung. the difference between the partial pressure of the gas in the air drives oxygen into the tissues and carbon dioxide out of the body.  39.3 breathing the structure of the lungs and thoracic cavity control the mechanics of breathing. upon inspiration, the diaphragm contracts and lowers. the intercostal muscles contract and expand the chest wall outward. the intrapleural pressure drops, the lungs expand, and air is drawn into the airways. when exhaling, the intercostal muscles and diaphragm relax, returning the intrapleural pressure back to the resting state. the lungs recoil and airways close. the air passively exits the lung. there is high surface tension at the air-airway interface in the lung. surfactant, a mixture of phospholipids and lipoproteins, acts like a detergent in the airways to reduce surface tension and allow for opening of the alveoli. breathing and gas exchange are both altered by changes in the compliance and resistance of the lung. if the compliance of the lung decreases, as occurs in restrictive diseases like fibrosis, the airways stiffen and collapse upon exhalation. air becomes trapped in the lungs, making breathing more difficult. if resistance increases, as happens with asthma or emphysema, the airways become obstructed, trapping air in the lungs and causing breathing to become difficult. alterations in the ventilation of the airways or perfusion of the arteries can affect gas exchange. these changes in ventilation and perfusion, called v/q mismatch, can arise from anatomical or physiological changes.  1160  chapter 39 | the respiratory system  39.4 transport of gases in human bodily fluids hemoglobin is a protein found in red blood cells that is comprised of two alpha and two beta subunits that surround an iron-containing heme group. oxygen readily binds this heme group. the ability of oxygen to bind increases as more oxygen molecules are bound to heme. disease states and altered conditions in the body can affect the binding ability of oxygen, and increase or decrease its ability to dissociate from hemoglobin. carbon dioxide can be transported through the blood via three methods. it is dissolved directly in the blood, bound to plasma proteins or hemoglobin, or converted into bicarbonate. the majority of carbon dioxide is transported as part of the bicarbonate system. carbon dioxide diffuses into red blood cells. inside, carbonic anhydrase converts carbon dioxide into + + carbonic acid (h2co3), which is subsequently hydrolyzed into bicarbonate (hco− 3 ) and h . the h ion binds to hemoglobin in red blood cells, and bicarbonate is transported out of the red blood cells in exchange for a chloride ion. this is called the chloride shift. bicarbonate leaves the red blood cells and enters the blood plasma. in the lungs, bicarbonate is transported back into the red blood cells in exchange for chloride. the h+ dissociates from hemoglobin and combines with bicarbonate to form carbonic acid with the help of carbonic anhydrase, which further catalyzes the reaction to convert carbonic acid back into carbon dioxide and water. the carbon dioxide is then expelled from the lungs.  art connection questions 1. figure 39.7 which of the following statements about the mammalian respiratory system is false? a. when we breathe in, air travels from the pharynx to the trachea. b. the bronchioles branch into bronchi. c. alveolar ducts connect to alveolar sacs. d. gas exchange between the lung and blood takes place in the alveolus. 2. figure 39.13 which of the following statements is false? a. in the tissues, p o drops as blood passes from  b. blood travels from the lungs to the heart to body tissues, then back to the heart, then the lungs. c. blood travels from the lungs to the heart to body tissues, then back to the lungs, then the heart. d. p o is higher in air than in the lungs. 2  3. figure 39.20 the kidneys are responsible for removing excess h+ ions from the blood. if the kidneys fail, what would happen to blood ph and to hemoglobin affinity for oxygen?  2  the arteries to the veins, while p co increases. 2  review questions 4. the respiratory system ________. a. provides body tissues with oxygen b. provides body tissues with oxygen and carbon dioxide c. establishes how many breaths are taken per minute d. provides the body with carbon dioxide 5. air is warmed and humidified in the nasal passages. this helps to ________. a. ward off infection b. decrease sensitivity during breathing c. prevent damage to the lungs d. all of the above 6. which is the order of airflow during inhalation? a. nasal cavity, trachea, larynx, bronchi, bronchioles, alveoli b. nasal cavity, larynx, trachea, bronchi, bronchioles, alveoli c. nasal cavity, larynx, trachea, bronchioles, bronchi, alveoli  d. nasal cavity, trachea, larynx, bronchi, bronchioles, alveoli 7. the inspiratory reserve volume measures the ________. a. amount of air remaining in the lung after a maximal exhalation b. amount of air that the lung holds c. amount of air the can be further exhaled after a normal breath d. amount of air that can be further inhaled after a normal breath 8. of the following, which does not explain why the partial pressure of oxygen is lower in the lung than in the external air? a. air in the lung is humidified; therefore, water vapor pressure alters the pressure. b. carbon dioxide mixes with oxygen. c. oxygen is moved into the blood and is headed to the tissues. d. lungs exert a pressure on the air to reduce the oxygen pressure.  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system  9. the total lung capacity is calculated using which of the following formulas? a. residual volume + tidal volume + inspiratory reserve volume b. residual volume + expiratory reserve volume + inspiratory reserve volume c. expiratory reserve volume + tidal volume + inspiratory reserve volume d. residual volume + expiratory reserve volume + tidal volume + inspiratory reserve volume 10. how would paralysis of the diaphragm alter inspiration? a. it would prevent contraction of the intercostal muscles. b. it would prevent inhalation because the intrapleural pressure would not change. c. it would decrease the intrapleural pressure and allow more air to enter the lungs. d. it would slow expiration because the lung would not relax. 11. restrictive airway diseases ________. a. increase the compliance of the lung b. decrease the compliance of the lung c. increase the lung volume d. decrease the work of breathing  1161  a. the respiratory rate is increased while the volume of air per breath is decreased b. the respiratory rate and the volume of air per breath are increased c. the respiratory rate is decreased while increasing the volume per breath d. both a and c 13. which of the following will not facilitate the transfer of oxygen to tissues? a. decreased body temperature b. decreased ph of the blood c. increased carbon dioxide d. increased exercise 14. the majority of carbon dioxide in the blood is transported by ________. a. binding to hemoglobin b. dissolution in the blood c. conversion to bicarbonate d. binding to plasma proteins 15. the majority of oxygen in the blood is transported by ________. a. dissolution in the blood b. being carried as bicarbonate ions c. binding to blood plasma d. binding to hemoglobin  12. alveolar ventilation remains constant when ________.  critical thinking questions 16. describe the function of these terms and describe where they are located: main bronchus, trachea, alveoli, and acinus. 17. how does the structure of alveoli maximize gas exchange? 18. what does fev1/fvc measure? what factors may affect fev1/fvc? 19. what is the reason for having residual volume in the lung? 20. how can a decrease in the percent of oxygen in the air affect the movement of oxygen in the body? 21. if a patient has increased resistance in his or her lungs, how can this detected by a doctor? what does this mean?  22. how would increased airway resistance affect intrapleural pressure during inhalation? 23. explain how a puncture to the thoracic cavity (from a knife wound, for instance) could alter the ability to inhale. 24. when someone is standing, gravity stretches the bottom of the lung down toward the floor to a greater extent than the top of the lung. what implication could this have on the flow of air in the lungs? where does gas exchange occur in the lungs? 25. what would happen if no carbonic anhydrase were present in red blood cells? 26. how does the administration of 100 percent oxygen save a patient from carbon monoxide poisoning? why wouldn’t giving carbon dioxide work?  1162  this openstax book is available for free at http://cnx.org/content/col11448/1.10  chapter 39 | the respiratory system",t_93fbc5d2590a,other,0
c_b872af2da7ec,"septic shock occurs when a body’s response to an infection (sepsis) leads to life-threatening low blood pressure.  learning objectives  compare and contrast the symptoms of: sepsis, severe sepsis, septic shock  key takeaways  key points  sepsis results from certain bacterial infections, often acquired in a hospital. having certain conditions, such as a weakened immune system, certain chronic disorders, an artificial joint, or heart valve increases the risk.  symptoms of sepsis include either fever or low body temperature, rapid breathing, chills and shaking, rapid heartbeat, decreased urine output, and confusion or delirium.  severe sepsis often causes extremely low blood pressure, which limits blood flow to the body and can result in organ failure and death. this is known as septic shock.  sepsis is treated with antibiotics, fluids, and medicines to support blood pressure and prevent organ damage.  key terms  septic shock: a life-threatening condition caused by infection and sepsis, often after surgery or trauma.  sepsis: a life-threatening medical condition caused by a severe inflammatory response of the human body triggered by the presence of an infectious agent.  mortality rate: the number of deaths per given unit of population over a given period of time  sepsis is a potentially deadly medical condition characterized by a whole-body inflammatory state (called a systemic inflammatory response syndrome or sirs) that is triggered by an infection. septic shock is a medical condition as a result of severe infection and sepsis, though the microbe may be systemic or localized to a particular site. its most common victims are children, immuno-compromised individuals, and the elderly, as their immune systems cannot deal with the infection as effectively as those of healthy adults. frequently, patients suffering from septic shock are cared for in intensive care units. the mortality rate from septic shock is approximately 25–50%.  sepsis  sepsis is an illness in which the body has a severe response to bacteria or other germs. the body may develop this inflammatory response by the immune system to microbes in the blood, urine, lungs, skin, or other tissues. a popular term for sepsis is blood poisoning. severe sepsis is the systemic inflammatory response, infection, and the presence of organ dysfunction.  a bacterial infection anywhere in the body may set off the response that leads to sepsis. common places where an infection might start include:  the bloodstream  bones (common in children)  the bowel (usually seen with peritonitis)  the kidneys (upper urinary tract infection or pyelonephritis )  the lining of the brain ( meningitis )  the liver or gallbladder  the lungs (bacterial pneumonia )  the skin (cellulitis)  for patients in the hospital, common sites of infection include intravenous lines, surgical wounds, surgical drains, and sites of skin breakdown known as bedsores (decubitus ulcers).  the therapy of sepsis rests on intravenous fluids, antibiotics, surgical drainage of infected fluid collections, and appropriate support for organ dysfunction. this may include hemodialysis in kidney failure, mechanical ventilation in pulmonary dysfunction, transfusion of blood products, and drug and fluid therapy for circulatory failure. ensuring adequate nutrition—preferably by enteral feeding, but if necessary by parenteral nutrition—is important during prolonged illness.  septic shock  in sepsis, blood pressure drops, resulting in septic shock. major organs and body systems, including the kidneys, liver, lungs, and central nervous system, stop working properly because of poor blood flow.  most cases of septic shock are caused by gram-positive bacteria, followed by endotoxin-producing gram-negative bacteria. endotoxins are bacterial membrane lipopolysaccharides (lps) consisting of a toxic fatty acid (lipid a) core common to all gram-negative bacteria, and a complex polysaccharide coat (including o antigen) unique for each species. analogous molecules in the walls of gram-positive bacteria and fungi can also elicit septic shock. in gram-negative sepsis, free lps attaches to a circulating lps-binding protein, and the complex then binds to a specific receptor (cd14) on monocytes, macrophages, and neutrophils.  if sepsis worsens to the point of end-organ dysfunction (renal failure, liver dysfunction, altered mental status, or heart damage) then the condition is called severe sepsis. once severe sepsis worsens to the point where blood pressure can no longer be maintained with intravenous fluids alone, then the criteria have been met for septic shock. the precipitating infections which may lead to septic shock if severe enough include appendicitis, pneumonia, bacteremia, diverticulitis, pyelonephritis, meningitis, pancreatitis, and necrotizing fasciitis.  sepsis: sepsis due to meningococcal disease.  treatment primarily consists of the following:  volume resuscitation  early antibiotic administration  early goal directed thearpy  rapid source identification and control.  support of major organ dysfunction.  there are new drugs that act against the extreme inflammatory response seen in septic shock. these may help limit organ damage.  the mortality rate from sepsis is approximately 40% in adults, and 25% in children, and is significantly greater when left untreated for more than seven days.",t_820d83224b89,other,0
c_7da887213a23,default text  /**/,t_f4e6cc174377,other,0
c_dc735e30b782,"there is a second form of the principle of mathematical induction which is useful in some cases. to apply the first form of induction, we assume p(k) for an arbitrary natural number k and show that p(k + 1) follows from that assumption. in the second form of induction, the assumption is that p(x) holds for all x between 0 and k inclusive, and we show that p(k + 1) follows from this. this gives us a lot more to work with when deducing p(k + 1). we will need this second, stronger form of induction in the next two sections. a proof will be given in the next chapter.  theorem 3.9.  let p be a one-place predicate whose domain of discourse includes the natural numbers. suppose that p(0) is true and that  \((p(0) \wedge p(1) \wedge \cdots \wedge p(k)) \rightarrow p(k+1)\)  is true for each natural number k ≥ 0. then p(n) is true for every natural number n.  for example, we can use this theorem to prove that every integer greater than one can be written as a product of prime numbers (where a number that is itself prime is considered to be a product of one prime number). the proof illustrates an important point about applications of this theorem: when proving p(k + 1), you don’t necessarily have to use the assumptions that p(0), p(1), ..., and p(k) are true. if p(k + 1) is proved by any means—possibly including the assumptions—then the statement (p(0) ∧ p(1) ∧ · · · ∧ p(k)) → p(k + 1) has been shown to be true. it follows from this observation that several numbers, not just zero, can be ‘base cases’ in the sense that p(x + 1) can be proved independently of p(0) through p(x). in this sense, 0, 1, and every prime number are base cases in the following theorem.  theorem 3.10.  every natural number greater than one can be written as a product of prime numbers.  proof. let p(n) be the statement “if n &gt; 1, then n can be written as a product of prime numbers”. we will prove that p(n) is true for all n by applying the second form of the principle of induction.  note that p(0) and p(1) are both automatically true, since n = 0 and n = 1 do not satisfy the condition that n &gt; 1, and p(2) is true since 2 is the product of the single prime number 2. suppose that k is an arbitrary natural number with k &gt; 1, and suppose thatp(0), p(1), ..., p(k) are already known to be true; we want to show that p(k + 1) is true. in the case where k + 1 is a prime number, then k + 1 is a product of one prime number, so p(k + 1) is true.  consider the case where k + 1 is not prime. then, according to the definition of prime number, it is possible to write k + 1 = ab where a and b are numbers in the range from 2 to k inclusive. since p(0) through p(k) are known to be true, a and b can each be written as a product of prime numbers. since k + 1 = ab, k + 1 can also be written as a product of prime numbers. we have shown that p(k + 1) follows from p(0) ∧ p(1) ∧ · · · ∧ p(k), and this completes the induction.  in two of the pencasts of this course, we treat two flawed induction proofs and examine what mistakes have been made. you can find them here: youtu. be/m0eigqyukdq and youtu.be/2c-zw-ennss.  exercises  1. use induction to prove that \(n^{3}+3 n^{2}+2 n\) is divisible by 3 for all natural numbers \(n\)  2. use induction to prove that  \(\sum_{i=0}^{n} r^{i}=\frac{1-r^{n+1}}{1-r}\)  for any natural number n and for any real number r such that r \(\neq\) 1.  3. use induction to prove that for any natural number n,  \(\sum_{i=0}^{n} \frac{1}{2^{i}}=2-\frac{1}{2^{n}}\)  in addition to proving this by induction, show that it follows as a corollary of exercise 2.  use induction to prove that for any natural number n,  \(\sum_{i=0}^{n} 2^{i}=2^{n+1}-1\)  in addition to proving this by induction, show that it follows as a corollary of exercise 2.  5. use induction to prove that for any positive integer n,  \(\sum_{i=1}^{n} i^{2}=\frac{n(n+1)(2 n+1)}{6}\)  use induction to prove that for any positive integer n,  \(\sum_{i=1}^{n}(2 i-1)=n^{2}\)  7. evaluate the following sums, using results proved in this section and in the previous exercises:  a) 1 + 3 + 5 + 7 + 9 + 11 + 13 + 15 + 17 + 19  b) \(1+\frac{1}{3}+\frac{1}{3^{2}}+\frac{1}{3^{3}}+\frac{1}{3^{4}}+\frac{1}{3^{5}}+\frac{1}{3^{6}}\)  c) 50 + 51 + 52 + 53 + · · · + 99 + 100  d)1 + 4 + 9 + 16 + 25 + 36 + 49 + 81 + 100  e)\(\frac{1}{2^{2}}+\frac{1}{2^{3}}+\dots+\frac{1}{2^{99}}\)  write each of the sums in the preceding problem using summation notation.  rewrite the proof of theorem 3.8 without using summation notation.  use induction to prove the following generalized distributive laws for propositional logic: for any natural number \(n>1\) and any propositions \(q, p_{1}, p_{2}, \ldots, p_{n}\)  a) \(q \wedge\left(p_{1} \vee p_{2} \vee \cdots \vee p_{n}\right)=\left(q \wedge p_{n}\right) \vee\left(q \wedge p_{2}\right) \vee \cdots \vee\left(q \wedge p_{n}\right)\)  b) \(q \vee\left(p_{1} \wedge p_{2} \wedge \cdots \wedge p_{n}\right)=\left(q \vee p_{1}\right) \wedge\left(q \vee p_{2}\right) \wedge \cdots \wedge\left(q \vee p_{n}\right)\)",t_256dbda0d467,other,0
c_62d287159fb0,"learn how to build a nesting box to welcome barn owls into your garden- it's easier than you think! building a nesting box for barn owls welcoming biodiversity into your home building a nesting box for barn owls in this video, you will learn how to build a nesting box for barn owls. you will need: seven planks of untreated wood, screws or nails, a metal hinge at least 20 cm (7.9 inches) long, and dried leaves. you will also need: a clamp, a tape measure, a pencil, a try square, a saw, and a drill or a hammer. we will construct a nesting box measuring 60 by 40 cm (23.6 by 15.7 inches), with an interior chamber and an entrance. measure, cut and assemble the seven different planks to the desired dimensions. you will need: two planks, 49 by 40 cm (19.3 by 15.7 inches) for the sides, one plank measuring 44 by 64 cm (17.3 by 25.2 inches) for the roof, a plank measuring 64 by 51 cm (25.2 by 20 inches) for the front side, a plank measuring 60 by 51 cm (23.6 by 20 inches) for the back side, a plank measuring 60 by 40 cm (23.6 by 15.7 inches) for the bottom, and finally a plank measuring 49 by 30 (19.3 by 11.8 inches) for the interior wall. cut out the entrance on the right side of the front plank. it should be 18 cm high and 13 cm long (7 inches high and 5.1 inches long.) leave the untreated wood as is: barn owls are sensitive to paints and varnishes. attach the sides of the box to the base of the nest box. you can then put in the back side. place your interior wall and fix it to the base. make sure you leave a 20 cm (7.9 inch) space from the right wall, where the  entrance is, to facilitate the owls moving around. attach the front wall. you can now screw in the roof with the metal hinge. you should be able to open it up to clean the box after it's been nested in! place the dried and clean leaves on the floor of the nesting box and make a 3 to 4 cm (1.2 to 1.5 inches) deep carpet with them. this will make the nesting box a welcoming and suitable environment for nesting. your barn owl nesting box is finished! now all that remains is to place it outside on the ground or on a large wooden beam in the attic of a barn making sure the entrance leads directly outside.",t_89d90e196d0c,other,0
c_75320ffb5fc9,"sal solves another system of equations using elimination.  everyone in the kingdom is very impressed with your ability to help with the party planning, everyone except for this gentlemen right over here. this is arbegla. and he is the king's top adviser, and also chief party planner. and he seems somewhat threatened by your ability to solve these otherwise unsolvable problems, or at least from his point of view, because he keeps over-ordering or under-ordering things like cupcakes. and he says, king, that cupcake problem was easy. ask them about the potato chip issue, because we could never get the potato chips right. and so the king says, arbegla, that's a good idea. we need to get the potato chips right. so he comes to you and says, how do we figure out, on average, how many potato chips we need to order? and to do that, we have to figure out how much, on average, does each man eat and how much each woman eats. you say, well, what about the children? the king says, in our kingdom, we forbid potato chips for children. you say, oh, well, that's all and good. tell me what happened at the previous parties. and so the king says, you might remember, at the last party, in fact, the last two parties, we had 500 adults. at the last party, 200 of them were men, and 300 of them were women. and in total, they ate 1,200 bags of potato chips. and you say, what about the party before that? he says, that one, we had a bigger skew towards women. we only had 100 men, and we have 400 women. and that time, we actually had fewer bags consumed-- 1,100 bags of potato chips. so you say, ok, king and arbegla, this seems like a fairly straightforward thing. let me define some variables to represent our unknowns. so you go ahead and you say, well, let's let m equal the number of bags eaten by each man. and you could think of it on average, or maybe all the men in that kingdom are completely identical. or maybe it's the average number of bags eaten by each man. and let's let w equal the number of bags eaten by each woman. and so with these definitions of our variables, let's think about how we can represent this first piece of information, this piece of information in green. well, let's think about the total number of bags that the men ate. you had 200 men. let me scroll over a little bit. you had 200 men, and they each ate m bags, m bags per man. so the men at this first party collectively ate 200 times m bags. if m is 10 bags per man, then this would be 2,000. if m was 5 bags per man, then this would be 5,000. we don't know what m is, but 200 times m is the total eaten by the men. same logic-- total eaten by the women is 300 women times the number of bags eaten by each woman. and so if you add the total to eaten by the men and the women, you get the 1,200 bags. so this is information, written algebraically, given these variable definitions. now, let's do the same thing with the second part of the information that they gave us right over here. let's think about how we can represent this algebraically. well, similar logic-- what was a total that the men ate at that party? it was 100 men times m bags per man. and we're assuming that m is the same across parties, that men, on average, always eat the same number of bags. and how many did the women eat at that second party? well, you had 400 women. and on average, they ate w bags per woman. so this is 400 times w is the total number that the women ate. you add those two together, you get the total number that all the adults ate. so this is going to be 1,100 bags. so it looks pretty similar now. you have a system of two equations with two unknowns. and so you try your best to solve it. but when you solve it, you see something interesting. last time, it was very convenient. you had a, i think it was a 500 here, for 500 adults, and you had another 500. and so it seemed like it was pretty easy to cancel out one of the variables. here it seems a little bit more difficult. what's multiplying by the m's, it's different here. the coefficient on the w is different over here. you say, well, maybe i can change one of these equations so it makes it a little bit easier to cancel out with the other equation. so what if, for example, i were to take this blue equation right over here and multiply it by negative 2? and you might say, well, sal, why are we multiplying it by negative 2? well, if were to multiply it by negative 2, this 100m would become a negative 200m. and if it was a negative 200m, then that would cancel out with a positive 200m when we add the two. so let's see what happens. so let's multiply this blue equation by negative 2. we're going to multiply by negative 2. let me scroll over to the left a little bit. so what happens? remember, when we multiply an equation, we can't just do one side of the equation. we have to do the entire equation in order for the equality to hold true. so negative 2 times 100m is negative 200m. negative 2 times 400w-- there's a positive right over there. so it becomes negative 800w. and then negative 2-- now, we did the left hand side, but we also have to do the right hand side. negative 2 times 1,100 is negative 2,200. so just to be clear, this equation that i just wrote here essentially has the same information we just manipulated. we just changed this equation, multiplied both sides by negative 2. but it's kind of the same constraint. but what makes this interesting is, now, we can rewrite this green equation. let me do it over here, this first one. 200m plus 300w is equal to 1,200. and the whole reason why i multiplied by negative 2 is, so that if i were to add these two things, i might be able to get rid of that variable over there. and so let's do that. let's add the left hand sides, and let's add the right hand sides. and you could literally view it as, we're starting with this blue equation. we're adding this quantity, the left hand side of the yellow equation to the left hand side of the blue. and then 1,200 is the exact same thing that we're adding to the right hand side. we know that this is equal to this. so we can add this to the left hand side and this to the right hand side. so let's see what happens. so the good thing is, the whole reason we multiplied it by negative 2, so that these two characters cancel out. you add those two together. you just get 0m or just 0. you have negative 800w plus 300w. well, that's negative 500w. and then on the right hand side, you have negative 2,200 plus 1,200. so that's negative 1,000. and now this is pretty straightforward-- one equation, one unknown, a fairly straightforward equation. we divide both sides by the coefficient of w, multiplying w. so divide by negative 500 on the left, divide by negative 500 on the right. and we are left with w is equal to 2. on average, women ate two bags of potato chips at these parties. we're assuming that's constant across the parties. so let's think about how you would then figure out how many bags, on average, each man ate. well, to do that, we just go back to either one of these equations. in the last set of videos, i went to the first equation. i'll show that the second equation should also work. either one should work. so let's substitute back into the second equation. and you could either pick this version of it or this one. but i'll pick the original one. so you have 100 times m, which we're trying to figure out, plus 400 times-- well, we now know that w is equal to 2-- 400 times 2 is equal to 1,100. so you have 100m plus 800 is equal to 1,100. and now, to solve for m, we could subtract 800 from both sides. and we are left with 100m is equal to 300. and now, divide both sides by 100. and we are left with m, which is, on average, the number of bags of chips each man eats is equal to 3. so you have solved arbegla's problem, what he thought was a difficult problem, using the magical, mystical powers of algebra. you were able to tell the king in his party planning process that, on average, the men will eat three bags of potato chips each. and on average, the women will eat two bags of potato chips each.",t_6cb41e03dbd6,other,0
c_9ca3a750ede7,"pessimism bias  you overestimate the likelihood of negative outcomes.  pessimism is often a defense mechanism against disappointment, or it can be the result of depression and anxiety disorders. pessimists often justify their attitude by saying that they'll either be vindicated or pleasantly surprised, however a pessimistic attitude may also limit potential positive outcomes. it should also be noted that pessimism is something very different to skepticism: the latter is a rational approach that seeks to remain impartial, while the former is an expectation of bad outcomes.  perhaps the worst aspect of pessimism is that even if something good happens, you'll probably feel pessimistic about it anyway.  your free poster is downloading now.  pay it forward by helping to spread the rational word on facebook:",t_dc8fe1fdb261,other,0
c_724836372410,"the chain rule states that the derivative of f(g(x)) is f'(g(x))⋅g'(x). in other words, it helps us differentiate *composite functions*. for example, sin(x²) is a composite function because it can be constructed as f(g(x)) for f(x)=sin(x) and g(x)=x². using the chain rule and the derivatives of sin(x) and x², we can then find the derivative of sin(x²).  - [instructor] what we're going to go over in this video is one of the core principles in calculus, and you're going to use it any time you take the derivative, anything even reasonably complex. and it's called the chain rule. and when you're first exposed to it, it can seem a little daunting and a little bit convoluted. but as you see more and more examples, it'll start to make sense, and hopefully it'd even start to seem a little bit simple and intuitive over time. so let's say that i had a function. let's say i have a function h of x, and it is equal to, just for example, let's say it's equal to sine of x, let's say it's equal to sine of x squared. now, i could've written that, i could've written it like this, sine squared of x, but it'll be a little bit clearer using that type of notation. so let me make it so i have h of x. and what i'm curious about is what is h prime of x? so i want to know h prime of x, which another way of writing it is the derivative of h with respect to x. these are just different notations. and to do this, i'm going to use the chain rule. i'm going to use the chain rule, and the chain rule comes into play every time, any time your function can be used as a composition of more than one function. and as that might not seem obvious right now, but it will hopefully, maybe by the end of this video or the next one. now, what i want to do is a little bit of a thought experiment, a little bit of a thought experiment. if i were to ask you what is the derivative with respect to x, if i were to just apply the derivative operator to x squared with respect to x, what do i get? well, this gives me two x. we've seen that many, many, many, many times. now, what if i were to take the derivative with respect to a of a squared? well, it's the exact same thing. i just swapped an a for the x's. this is still going to be equal to two a. now i will do something that might be a little bit more bizarre. what if i were to take the derivative with respect to sine of x, with respect to sine of x of, of sine of x, sine of x squared? well, wherever i had the x's up here, the a's over here, i just replace it with a sine of x. so this is just going to be two times the thing that i had, so whatever i'm taking the derivative with respect to. here it was with respect to x. here with respect to a. here's with respect to sine of x. so it's going to be two times sine of x. now, so the chain rule tells us that this derivative is going to be the derivative of our whole function with respect, or the derivative of this outer function, x squared, the derivative of x squared, the derivative of this outer function with respect to sine of x. so that's going to be two sine of x, two sine of x. so we could view it as the derivative of the outer function with respect to the inner, two sine of x. we could just treat sine of x like it's kind of an x. and it would've been just two x, but instead it's a sine of x. we say two sine of x times, times the derivative, do this is green, times the derivative of sine of x with respect to x. times the derivative of sine of x with respect to x, well, that's more straightforward, a little bit more intuitive. the derivative of sine of x with respect to x, we've seen multiple times, is cosine of x, so times cosine of x. and so there we've applied the chain rule. it was the derivative of the outer function with respect to the inner. so derivative of sine of x squared with respect to sine of x is two sine of x, and then we multiply that times the derivative of sine of x with respect to x. so let me make it clear. this right over here is the derivative. we're taking the derivative of, we're taking the derivative of sine of x squared. so let me make it clear. that's what we were taking the derivative of with respect to sine of x, with respect to sine of x. and then we're multiplying that times the derivative of sine of x, the derivative of sine of x with respect to, with respect to x. and this is where it might start making a little bit of intuition. you can't really treat these differentials, this d whatever, this dx, this d sine of x, as a number. and you really can't, this notation makes it look like a fraction because intuitively that's what we're doing. but if you were to treat 'em like fractions, then you could think about canceling that and that. and once again, this isn't a rigorous thing to do, but it can help with the intuition. and then what you're left with is the derivative of this whole sine of x squared with respect to x. so you're left with, you're left with the derivative of essentially our original function, sine of x squared with respect to x, with respect to x, which is exactly what dh/dx is. this right over here, this right over here is our original function h. that's our original function h. so it might seem a little bit daunting now. what i'll do in the next video is another several examples, and then we'll try to abstract this a little bit.",t_dbbc1d5c0690,other,0
c_b8cde2668243,"energy budgets and life history strategies determine the type of reproductive capacity displayed by a population.  learning objectives  describe the energy budgets of, and the life history strategies used in, reproduction  key takeaways  key points  the amount of parental care given to an individual offspring is inversely related to the reproductive capacity of an animal species.  animal species that produce many small, vulnerable offspring tend to provide little or no care for them due to their energy budget constraints; just enough offspring survive to maintain the species.  animal species that have few offspring expend large amounts of their energy budgets on caring for helpless offspring that need to develop before being on their own.  plants with low fecundity produce few energy-rich seeds with high germination rates, while plants with high fecundity usually have many small, energy-poor seeds with poor survival rates.  species that reproduce early ensure a greater chance of having surviving offspring than do those that must survive to a later reproductive age.  semelparous species use all of their reproductive budgets on one single reproductive event, while iteroparous species spend it on multiple mating seasons.  key terms  iteroparous: reproducing more than once in a lifetime  semelparous: reproducing only once in a lifetime  fecundity: number, rate, or capacity of offspring production  life history patterns and energy budgets  energy is required by all living organisms for their growth, maintenance, and reproduction. at the same time, energy is often a major limiting factor in determining an organism’s survival. plants, for example, acquire energy from the sun via photosynthesis, but must expend this energy to grow, maintain health, and produce energy-rich seeds to produce the next generation. animals also have the additional burden of using some of their energy reserves to acquire food. in addition, some animals must expend energy caring for their offspring. thus, all species have an energy budget in which they must balance energy intake with their use of energy for metabolism, reproduction, parental care, and energy storage, as when bears build up body fat for winter hibernation.  parental care and fecundity  fecundity is the potential reproductive capacity of an individual within a population. in other words, it describes how many offspring could ideally be produced if an individual has as many offspring as possible, repeating the reproductive cycle as soon as possible after the birth of the offspring. in animals, fecundity is inversely related to the amount of parental care given to an individual offspring. species that produce a large number of offspring, such as many marine invertebrates, usually provide little if any care for those offspring, as they would not have the energy or the ability to do so. most of their energy budget is used to produce many tiny offspring. animals with this strategy are often self-sufficient at a very early age. this is because of the energy trade-off these organisms have made to maximize their evolutionary fitness. since their energy is used for producing offspring instead of parental care, it makes sense that these offspring have some ability to be able to move within their environment to find food and perhaps shelter. even with these abilities, their small size makes them extremely vulnerable to predation, so the production of many offspring allows enough of them to survive to maintain the species.  animal species that have few offspring during a reproductive event usually give extensive parental care, devoting much of their energy budget to these activities, sometimes at the expense of their own health. this is the case with many mammals, such as humans, kangaroos, and pandas. the offspring of these species are relatively helpless at birth, needing to develop before they achieve self-sufficiency.  plants with low fecundity produce few energy-rich seeds (such as coconuts and chestnuts) that have a good chance to germinate into a new organism. plants with high fecundity usually have many small, energy-poor seeds (as do orchids) that have a relatively-poor chance of surviving. although it may seem that coconuts and chestnuts have a better chance of surviving, the energy trade-off of the orchid is also very effective. it is a matter of where the energy is used: for large numbers of seeds or for fewer seeds with more energy.  early versus late reproduction  semelparous species: chinook salmon are an example of a population that uses its energy budget in one major reproductive event, dying shortly thereafter.  the timing of reproduction in a life history also affects species survival. organisms that reproduce at an early age have a greater chance of producing offspring, but this is usually at the expense of their growth and the maintenance of their health. conversely, organisms that start reproducing later in life often have greater fecundity or are better able to provide parental care, but they risk not surviving to reproductive age. examples of this can be seen in fish. small fish, such as guppies, use their energy to reproduce rapidly, but never attain the size that would give them defense against some predators. larger fish, such as bluefin tuna and mako sharks, use their energy to attain a large size, but do so with the risk that they will die before they can reproduce or reproduce to their maximum. these different energy strategies and trade-offs are key to understanding the evolution of each species as it maximizes its fitness and fills its niche.  single versus multiple reproductive events  some life history traits, such as fecundity, timing of reproduction, and parental care, can be grouped together into general strategies that are used by multiple species. semelparous species are those that only reproduce once during their lifetime and then die. such species use most of their resource budget during a single reproductive event, sacrificing their health to the point that they do not survive. examples of semelparity are bamboo, which flowers once and then dies, and the chinook salmon, which uses most of its energy reserves to migrate from the ocean to its freshwater nesting area, where it reproduces and then dies. in contrast, iteroparous species reproduce repeatedly during their lives. some animals are able to mate only once per year, but survive multiple mating seasons. primates, including humans and chimpanzees, are examples of animals that display iteroparity.",t_4426e0d5145d,other,0
c_5364ad9c9ec7,"the discussion in this section follows the description by max born [11] (who was instrumental in the development of quantum mechanics). extensions are made to relates quantum descriptions to effects important to microwave engineering. in particular the descriptions here relate phenomena at the discrete particle level to continuum properties such as permittivity, \(\epsilon\).  1.7.1 electromagnetic fields in a dielectric  a dielectric has no electrons that are free to move through a material under the influence of an electric field. when an em field is incident on a dielectric the electric field moves charge centers. for a crystal these charge centers are at the scale of the lattice, and for composite materials like plastics the centers are at the molecular scale. with some materials, which we know as materials having high permittivity, the charge centers are normally separated but by less than the intra-atom spacing. with all dielectric materials, the major impact of an applied electric field is movement of the charge centers, alternately moving them apart and moving them together as the applied electric field alternates. now being a dielectric, the charges cannot move freely through the material and the energy that is transferred to the charges is stored as electric potential energy in stretched bonds or, sometimes, as a distorted lattice (such as with the piezoelectric effect). this energy storage is much like storing mechanical energy in a spring. now the charges move and thus excite an electric field of their own. however the charges move sluggishly and so the phase of the em signal they produce is out of phase with respect to an externally applied alternating em field. the charge centers are moving the fastest at the peak of the applied sinusoidal field and the net effect is a \(90^{\circ}\) phase lag.  another phenomenon is that the combined effect of the reradiated fields from the moving charge centers produces an em wave with the same frequency as the applied field but with a smaller phase velocity (smaller because the phase velocity is averaged over many paths). the oscillating charge centers radiate in all directions (which is called scattering) and so some of the em energy will be scattered in the direction from which the applied em wave came.  an ideal dielectric has no loss. that is, there is no dielectric relaxation loss associated with heating as the charge centers move, and there is no conductivity due to moving free charges in the dielectric.  1.7.2 refractive index  dielectrics were first characterized by their refractive index long before the concept of em waves and permittivity were developed. the refractive index, \(n\), of a medium is defined as the ratio of the speed of light (i.e., of an em wave) in a vacuum, \(c\), of an em wave to the phase velocity, \(v_{p}\), of the wave in the medium:  \[\label{eq:1}n=\frac{c}{v_{p}}=\frac{1}{\sqrt{\epsilon_{0}\mu_{0}}}\frac{\sqrt{\epsilon\mu}}{1}\]  for a loss-free medium  \[\label{eq:2}n=\sqrt{\varepsilon_{r}\mu_{r}}\]  for a lossy medium the complex index of refraction is  \[\label{eq:3}\overline{n}=n+\jmath\kappa\]  where \(n\) is called the refractive index and is directly related to the phase velocity, \(v_{p}\), and \(\kappa\) is called the extinction coefficient, which describes loss when the em wave propagates through the material.  conversion between refractive index and permittivity is as follows [12, 13]; the complex permittivity  \[\label{eq:4}\varepsilon =\epsilon_{1}+\jmath\epsilon_{2}=(n+\jmath\kappa)^{2}\]  where  \[\label{eq:5}\varepsilon_{1}=n^{2}-\kappa^{2}\quad\text{and}\quad\varepsilon_{2}=2n\kappa\]  the components of the complex index of refraction are then  \[\label{eq:6}n=\sqrt{\frac{\sqrt{\varepsilon_{1}^{2}+\varepsilon_{2}^{2}}+\varepsilon_{1}}{2}}\quad\text{and}\quad\kappa =\sqrt{\frac{\sqrt{\varepsilon_{1}^{2}+\varepsilon_{2}^{2}}-\epsilon_{1}}{2}}\]  the permittivity is just the square of the (complex) refractive index in a nonmagnetic medium \((\mu_{r} = 1)\). the refractive index is used with optics and the permittivity is used when working with maxwell’s equations and with electronics.  the refractive index, and thus permittivity, of a dielectric can vary significantly between microwave and optical frequencies, a result of how quickly different types of charge centers can move. for water at \(20^{\circ}\text{c}\) and at the standard optical wavelength of \(589\text{ nm}\) (the yellow doublet sodium d-line), \(n = 1.333\) (\(\epsilon_{r} = 1.78\)) [14]. at \(1\text{ ghz}\) \(n = 8.94\) (\(\epsilon_{r} = 80\)) [15].  1.7.3 electromagnetic fields in a metal  the discussion here refers to the behavior of em fields in metals at frequencies from dc to \(10\text{ thz}\). above these frequencies the em wave changes direction much faster than electrons can move. metals have a large number of free charges that can move through a metal under the influence of an electric field. on transmission lines the energy is contained in the em fields between metal guides, and electric and magnetic fields are present at the surface of the metal. the main effect of the em fields at the surface of the metal is to accelerate the free electrons at the surface, with the electrons accelerating in the direction opposite to that of the electric field. while some of the em energy propagates into the metal, the overwhelming effect is transfer of energy from the em photons to kinetic energy of the free electrons. there is also some transfer of energy to the bound electrons, however, this effect is smaller as the bound electrons are shielded by the sea of free electrons. electrons have mass and accelerate relatively slowly. even when the electric field is reversed, the electrons will continue moving considerably in the same direction as the electric field before reversing. the moving and accelerating electrons also produce electric fields of their own that in turn influence the movement of other electrons. electrons are sluggish and their position is almost \(180^{\circ}\) out of phase with the applied \(e\) field. the net effect is that the electric field produced by the electrons almost completely cancels  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |    metal | photon energy \((\text{ev})\) | wavelength \(\lambda\:(\mu\text{m})\) | frequency \(f\:(\text{thz})\) |      \(n\) | \(\kappa\) | \(\varepsilon_{1}\) | \(\varepsilon_{2}\) |  |     gold |                       \(0.1\) |                            \(12.398\) |                    \(24.197\) |   \(8.17\) |  \(82.83\) |           \(-6794\) |            \(1353\) |  |   copper |                       \(0.1\) |                            \(12.398\) |                    \(24.197\) |  \(29.69\) |  \(71.57\) |           \(-4240\) |            \(4250\) |  | aluminum |                       \(0.1\) |                            \(12.398\) |                    \(24.197\) | \(98.595\) |  \(203.7\) |          \(-31663\) |           \(40168\) |  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  table \(\pageindex{1}\): electromagnetic properties of metals at optical frequencies. (\(n\) and \(\kappa\) are measured, \(\varepsilon_{1}\) and \(\varepsilon_{2}\) are derived using equation \(\eqref{eq:5}\).  the incoming electric field. it is therefore almost meaningless to talk about the (group or phase) velocity of the em fields in the metal. the overriding effect is transfer of energy to moving electrons that eventually make the lattice move and transfer their energy to the lattice, producing heat.  the accelerating electrons radiate electric field in all directions and in turn this field accelerates other electrons. there is also a damping force as the free electrons collide with atoms. so there is a rapidly diminishing component of the em field that travels through the metal at the speed of light. rather than energy being stored in the electric field through the movement of charge centers as in dielectrics, electric energy in the forward-propagating field is almost entirely lost in the scattering and collision processes. so at microwave frequencies the effective permittivity of a metal is almost entirely imaginary (corresponding to loss), and this imaginary component of the relative permittivity is \(8–10\) orders of magnitude greater than the real component, which is believed to be \(1\) [16]. the real component of the relative permittivity is \(1\) because the charge centers are masked by the sea of free electrons. it is not possible to directly measure the real part of the permittivity of metals at microwave frequencies. an ideal conductor has infinite conductivity, so there are no em fields inside the metal and net charges are confined to the surface of the conductor. at optical frequencies metals are known to have a negative permittivity (see table \(\pageindex{1}\)).",t_421ae7072b65,other,0
c_96b1936d17b4,"entire lesson (in conjunction with indicators 2.2.3 and 2.2.4)nys common core mathematics curriculum  lesson 34  6•4  lesson 34: writing and graphing inequalities in real-world problems classwork example 1 statement  inequality  a.  caleb has at least $5.  b.  tarek has more than $5.  c.  vanessa has at most $5.  d.  li chen has less than $5.  graph  example 2 kelly works for quick oil change. if customers have to wait longer than 20 minutes for the oil change, the company does not charge for the service. the fastest oil change that kelly has ever done took 6 minutes. show the possible customer wait times in which the company charges the customer.  example 3 gurnaz has been mowing lawns to save money for a concert. gurnaz will need to work for at least six hours to save enough money, but he must work fewer than 16 hours this week. write an inequality to represent this situation, and then graph the solution.  lesson 34:  writing and graphing inequalities in real-world problems  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g6-m4-te-1.3.0-09.2015  s.170 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  lesson 34  6•4  exercises 1–5 write an inequality to represent each situation. then, graph the solution. 1.  blayton is at most 2 meters above sea level.  2.  edith must read for a minimum of 20 minutes.  3.  travis milks his cows each morning. he has never gotten fewer than 3 gallons of milk; however, he always gets fewer than 9 gallons of milk.  4.  rita can make 8 cakes for a bakery each day. so far, she has orders for more than 32 cakes. right now, rita needs more than four days to make all 32 cakes.  5.  rita must have all the orders placed right now done in 7 days or fewer. how will this change your inequality and your graph?  lesson 34:  writing and graphing inequalities in real-world problems  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g6-m4-te-1.3.0-09.2015  s.171 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  lesson 34  6•4  possible extension exercises 6–10 6.  kasey has been mowing lawns to save up money for a concert. he earns $15 per hour and needs at least $90 to go to the concert. how many hours should he mow?  7.  rachel can make 8 cakes for a bakery each day. so far, she has orders for more than 32 cakes. how many days will it take her to complete the orders?  8.  ranger saves $70 each week. he needs to save at least $2,800 to go on a trip to europe. how many weeks will he need to save?  9.  clara has less than $75. she wants to buy 3 pairs of shoes. what price shoes can clara afford if all the shoes are the same price?  10. a gym charges $25 per month plus $4 extra to swim in the pool for an hour. if a member only has $45 to spend each month, at most how many hours can the member swim?  lesson 34:  writing and graphing inequalities in real-world problems  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g6-m4-te-1.3.0-09.2015  s.172 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.  nys common core mathematics curriculum  lesson 34  6•4  problem set write and graph an inequality for each problem. 1.  at least 13  2.  less than 7  3.  chad will need at least 24 minutes to complete the 5k race. however, he wants to finish in under 30 minutes.  4.  eva saves $60 each week. since she needs to save at least $2,400 to go on a trip to europe, she will need to save for at least 40 weeks.  5.  clara has $100. she wants to buy 4 pairs of the same pants. due to tax, clara can afford pants that are less than $25.  6.  a gym charges $30 per month plus $4 extra to swim in the pool for an hour. because a member has just $50 to spend at the gym each month, the member can swim at most 5 hours.  lesson 34:  writing and graphing inequalities in real-world problems  this work is derived from eureka math ™ and licensed by great minds. ©2015 great minds. eureka-math.org this file derived from g6-m4-te-1.3.0-09.2015  s.173 this work is licensed under a creative commons attribution-noncommercial-sharealike 3.0 unported license.",t_8fcc225e3c6b,other,0
c_b3676714a9c1,"4.3 field technique tips for counting whorls:  because each whorl represents one year of growth, one can estimate age on young trees with determinate height growth by counting the whorls.  1. on most trees, the lowest tree branches are systematically dropped as the tree grows and the sun no longer hits the base of the tree. therefore, when estimating age using this method, it is important to include the bottom-most stubs and/or knots where it is evident branches once existed.  2. two to four years should be added to most species to allow for the time between seedling germination and evidence of branch whorls on the trunk (figure 4.4).  3. small single branches between major branch whorls do not constitute a true whorl or year of growth. do not count these false whorls.  4. a very short increase in length between whorls that seems unlike the other years’ growth may indicate a “lammas” year, in which the tree flushed twice, often in response to extraordinary growing conditions. ignore those years unless it is evident that some injury is responsible for the very short internode (figure 4.4).  figure 4.4.  counting the whorls to determine age of a young conifer. lammas growth and false whorls are ignored. lower stem is examined for knots, and time to first visible knot is estimated and added in — generally 2-4 years.  this method of “counting the whorls” usually works very well up to fifteen years of age or so for conifers such as douglas-fir, spruces (picea spp.), pines (pinus spp.) and true firs (abies spp.).   it is more challenging for cedars (thuja spp., chamaecyparis spp.), hemlocks (tsuga spp.), and some hardwoods.  one really has to get close to the tree, look carefully for evidence of bud scars, and know the growth habits of the species.",t_45792dc6947e,other,0
c_a64a41525972,"sal introduces multiplying 2 fractions.  let's think about what it means to multiply 2 over 3, or 2/3, times 4/5. in a previous video, we've already seen how we can actually compute this. this is going to be equal to-- in the numerator, we just multiply the numerators. so it's going to be 2 times 4. and in the denominator, we just multiply the denominator. so it's going to be 3 times 5. and so the numerator is going to be 8, and the denominator is going to be 15. and this is about as simple as we can make it. 8 and 15 don't have any factors common to each other, than 1, so this is what it is. it's 8/15. but how, why does that actually makes sense? and to think about it, we'll think of two ways of visualizing it. so let's draw 2/3. i'll draw it relatively big. so i'm going to draw 2/3, and i'm going to take 4/5 of it. so 2/3, and i'm going to make it pretty big. just like this. so this is 1/3. and then this would be 2/3. which i could do a little bit better job making those equal, or at least closer to looking equal. so there you go. i have thirds. let me do it one more time. so here i have drawn thirds. 2/3 represents 2 of them. it represents 2 of them. one way to think about this is 2/3 times 4/5 is 4/5 of this 2/3. so how do we divide this 2/3 into fifths? well, what if we divided each of these sections into 5. so let's do that. so let's divide each into 5. 1, 2, 3, 4, 5. 1, 2, 3, 4, 5. and i could even divide this into 5 if i want. 1, 2, 3, 4, 5. and we want to take 4/5 of this section here. so how many fifths do we have here? we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. and we've got to be careful. these really aren't fifths. these are actually 15ths, because the whole is this thing over here. so i should really say how many 15ths do we have? and that's where we get this number from. but you see if 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. where did that come from? i had 3, i had thirds. and then i took each of those thirds, and i split them into fifths. so then i have five times as many sections. 3 times 5 is 15. but now we want 4/5 of this right over here. this is 10/15 right over here. notice it's the same thing as 2/3. now if we want to take 4/5 of that, if you have 10 of something, that's going to be 8 of them. so we're going to take 8 of them. so 1, 2, 3, 4, 5, 6, 7, 8. we took 8 of the 15, so that is 8/15. you could have thought about it the other way around. you could have started with fifths. so let me draw it that way. so let me draw a whole. so this is a whole. let me cut it into five equal pieces, or as close as i can draw five equal pieces. 1, 2, 3, 4, 5. 4/5, we're going to shade in 4 of them. 4 of the 5 equal pieces. 3, 4. and now we want to take 2/3 of that. well, how can we do that? well, let's split each of these 5 into 3 pieces. so now we have essentially 15ths again. so 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. we want to take 2/3 of this yellow area. we're not taking 2/3 of the whole section. we're taking 2/3 of the 4/5. so how many 15ths do we have here? we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12. so if you have 12 of something, and you want to take 2/3 of that, you're going to be taking 8 of it. so you're going to be taking 1, 2, 3, 4, 5, 6, 7, 8 or 8 of the fifteenths now. so either way, you get to the same result. one way, you're thinking of taking 4/5 of 2/3. another way you could think of it as you're taking 2/3 of 4/5.",t_a96449c10310,other,0
c_1a36e9904ada,"chapter 5 of the book on entity framework.chapter 5: entity framework code first migrations section 5.1: enable migrations to enable code first migrations in entity framework, use the command enable-migrations  on the package manager console. you need to have a valid dbcontext implementation containing your database objects managed by ef. in this example the database context will contain to objects blogpost and author: internal class databasecontext: dbcontext { public dbset<author> authors { get; set; } public dbset<blogpost> blogposts { get; set; } }  after executing the command, the following output should appear: pm> enable-migrations checking if the context targets an existing database... code first migrations enabled for project <yourprojectname>. pm>  in addition, a new folder migrations should appear with a single ﬁle configuration.cs inside:  the next step would be to create your ﬁrst database migration script which will create the initial database (see next example).  section 5.2: add your ﬁrst migration after you've enabled migrations (please refer to this example) you are now able to create your ﬁrst migration containing an initial creation of all database tables, indexes and connections. a migration can be created by using the command add-migration <migration-name>  this command will create a new class containing two methods up and down that are used to apply and remove the migration. now apply the command based on the example above to create a migration called initial: goalkicker.com – entity framework notes for professionals  23  pm> add-migration initial scaffolding migration 'initial'. the designer code for this migration file includes a snapshot of your current code first model. this snapshot is used to calculate the changes to your model when you scaffold the next migration. if you make additional changes to your model that you want to include in this migration, then you can re-scaffold it by running 'add-migration initial' again.  a new ﬁle timestamp_initial.cs is created (only the important stuﬀ is shown here): public override void up() { createtable( ""dbo.authors"", c => new { authorid = c.int(nullable: false, identity: true), name = c.string(maxlength: 128), }) .primarykey(t => t.authorid); createtable( ""dbo.blogposts"", c => new { id = c.int(nullable: false, identity: true), title = c.string(nullable: false, maxlength: 128), message = c.string(), author_authorid = c.int(), }) .primarykey(t => t.id) .foreignkey(""dbo.authors"", t => t.author_authorid) .index(t => t.author_authorid); } public override void down() { dropforeignkey(""dbo.blogposts"", ""author_authorid"", ""dbo.authors""); dropindex(""dbo.blogposts"", new[] { ""author_authorid"" }); droptable(""dbo.blogposts""); droptable(""dbo.authors""); }  as you can see, in method up() two tables authors and blogposts are created and the ﬁelds are created accordingly. in addition, the relation between the two tables is created by adding the ﬁeld author_authorid. on the other side the method down() tries to reverse the migration activities. if you feel conﬁdent with your migration, you can apply the migration to the database by using the command: update-database  all pending migrations (in this case the initial-migration) are applied to the database and afterwards the seed method is applied (the appropriate example) pm> update-database specify the '-verbose' flag to view the sql statements being applied to the target database. applying explicit migrations: [201609302203541_initial]. applying explicit migration: 201609302203541_initial.  goalkicker.com – entity framework notes for professionals  24  running seed method.  you can see the results of the activities in the sql explorer:  for the commands add-migration and update-database several options are available which can be used to tweak the activities. to see all options, please use get-help add-migration  and get-help update-database  section 5.3: doing ""update-database"" within your code applications running in non-development environments often require database updates. after using the addmigration command to create your database patches there's the need to run the updates on other environments,  and then the test environment as well. challenges commonly faced are: no visual studio installed on production environments, and no connections allowed to connection/customer environments in real life. a workaround is the following code sequence which checks for updates to be performed, and executes them in order. please ensure proper transactions & exception handling to ensure no data gets lost in case of errors. void updatedatabase(mydbconfiguration configuration) { dbmigrator dbmigrator = new dbmigrator( configuration); if ( dbmigrator.getpendingmigrations().any() ) { // there are pending migrations run the migration job dbmigrator.update(); } }  where mydbconfiguration is your migration setup somewhere in your sources: public class mydbconfiguration : dbmigrationsconfiguration<applicationdbcontext>  section 5.4: seeding data during migrations after enabling and creating migrations there might be a need to initially ﬁll or migrate data in your database. there are several possibilities but for simple migrations you can use the method 'seed()' in the ﬁle conﬁguration created after calling enable-migrations.  goalkicker.com – entity framework notes for professionals  25  the seed() function retrieves a database context as it's only parameter and you are able to perform ef operations inside this function: protected override void seed(model.databasecontext context);  you can perform all types of activities inside seed(). in case of any failure the complete transaction (even the applied patches) are being rolled back. an example function that creates data only if a table is empty might look like this: protected override void seed(model.databasecontext context) { if (!context.customers.any()) { customer c = new customer{ id = 1, name = ""demo"" }; context.customers.add(c); context.savedata(); } }  a nice feature provided by the ef developers is the extension method addorupdate(). this method allows to update data based on the primary key or to insert data if it does not exist already (the example is taken from the generated source code of conﬁguration.cs): protected override void seed(model.databasecontext context) { context.people.addorupdate( p => p.fullname, new person { fullname = ""andrew peters"" }, new person { fullname = ""brice lambson"" }, new person { fullname = ""rowan miller"" } ); }  please be aware that seed() is called after the last patch has been applied. if you need to migration or seed data during patches, other approaches need to be used.  section 5.5: initial entity framework code first migration step by step 1. create a console application. 2. install entityframework nuget package by running install-package entityframework in ""package manager console"" 3. add your connection string in app.conﬁg ﬁle , it's important to include providername=""system.data.sqlclient"" in your connection.  4. create a public class as you wish , some thing like ""blog"" 5. create your contextclass which inherit from dbcontext , some thing like ""blogcontext"" 6. deﬁne a property in your context of dbset type , some thing like this : public class blog { public int id { get; set; } public string name { get; set; } }  goalkicker.com – entity framework notes for professionals  26  public class blogcontext: dbcontext { public blogcontext(): base(""name=your_connection_name"") { } public virtual dbset<blog> blogs{ get; set; } }  7. it's important to pass the connection name in constructor ( here your_connection_name) 8. in package manager console run enable-migration command , this will create a migration folder in your project 9. run add-migration your_arbitrary_migraiton_name command , this will create a migration class in migrations folder with two method up() and down() 10. run update-database command in order to create a database with a blog table  section 5.6: using sql() during migrations for example: you are going to migrate an existing column from non-required to required. in this case you might need to ﬁll some default values in your migration for rows where the altered ﬁelds are actually null. in case the default value is simple (e.g. ""0"") you might use a default or defaultsql property in your column deﬁnition. in case it's not so easy, you may use the sql() function in up() or down() member functions of your migrations. here's an example. assuming a class author which contains an email-address as part of the data set. now we decide to have the email-address as a required ﬁeld. to migrate existing columns the business has the smart idea of creating dummy email-addresses like fullname@example.com, where full name is the authors full name without spaces. adding the [required] attribute to the ﬁeld email would create the following migration: public partial class authorsemailrequired : dbmigration { public override void up() { altercolumn(""dbo.authors"", ""email"", c => c.string(nullable: false, maxlength: 512)); } public override void down() { altercolumn(""dbo.authors"", ""email"", c => c.string(maxlength: 512)); } }  this would fail in case some null ﬁelds are inside the database: cannot insert the value null into column 'email', table 'app.model.databasecontext.dbo.authors'; column does not allow nulls. update fails. adding the following like before the altercolumn command will help: sql(@""update dbo.authors set email = replace(name, ' ', '') + n'@example.com' where email is null"");  the update-database call succeeds and the table looks like this (example data shown):  goalkicker.com – entity framework notes for professionals  27  other usage you may use the sql() function for all types of dml and ddl actibities in your database. it is executed as part of the migration transaction; if the sql fails, the complete migration fails and a rollback is done.  goalkicker.com – entity framework notes for professionals  28",t_82cedf72b65b,other,0
c_5873a097d81c,"examples of bias in surveys  - [instructor] we're told that david hosts a podcast and he is curious how much his listeners like his show. he decides to start with an online poll. he asks his listeners to visit his website and participate in the poll. the poll shows that 89% of about 200 respondents ""love"" his show. what is the most concerning source of bias in this scenario? and well, like always, pause this video and see if you can figure it out on your own and then we'll work through it together. let's think about what's going on. he has this population of listeners, right? i'll assume that the number of listeners is more than 200. and he says, ""hey i want to find a sample, ""and i can't ask all of my listeners."" who knows, maybe he has 10,000 listeners, they don't tell us that, but let's say there's 10,000 listeners here. and he says, ""well i want to get an indication ""of what percentage like my show. ""so i need a sample."" but instead of taking a truly random sample, he asks them to volunteer. he asks his listeners to visit his website. so that's classic volunteer response sampling. this is not random because who decides to go to his website and listen to what he just said, and maybe even has access to a computer. that's not random. in fact, the people more likely to do that, so these are the people out of the 10,000, these are the 200 responders here who decided to do it. these are more likely to be the people who already like david or like to listen to what he tells them to do. the people, the listeners who are not into david or don't want to do what he tells them to do, they're unlikely to say, ""oh, i'm not really into david ""and i don't like him telling me what to do, ""but hey, i'm gonna go to his website anyway, ""i'm gonna fill out that poll."" that's less likely. or you might get extremes, people who really don't like him, might say, ""i'm gonna definitely go there."" but in this case, i would say that it's more likely your fans are gonna do what you ask them to do and go to your website and spend time on your website. and because of that, that 89% is probably an overestimate. 89% is probably an overestimate of the number of listeners who really love his show. cause you're more likely to get the ones who love him to show up and fill out that actual survey. now these other forms of bias. response bias, this is when you're asking something that people don't necessarily want to answer truthfully, or the way that it's phrased, it might make someone respond, you see, in a biased way. classic examples of this are like, ""have you lied to your parents in the past week?"" or ""have you ever cheated on your spouse."" something, ""do you smoke?"" any of these things that people might not want to answer completely truthfully or they might be hiding from the world, they might not just want to answer that truthfully on a survey. and so you're going to have response bias. but that's not the case right over here. and undercoverage is when the way that you're sampling, you're definitely missing out on an important constituency. voluntary response we're likely missing out on some important constituencies, on some people who might not be into going to your website, but undercoverage is where it's a little bit more clear that that is happening. let's do another case, let's do another case, maybe an alternate reality where david's trying to figure this out again, he's still hosting a podcast, he's still curious how much his listeners like his show, but he tries to take a different sample. he decides in this case, to poll the next 100 listeners who send him fan emails. they don't all respond, but 94 out of the 97 listeners polled said they ""loved his show."" what is the most concerning source of bias in this scenario? well this is a classic, ""hey i have a group, ""i have a sample sitting in front of me, ""it's in my inbox in my email, let me just go to them."" isn't that convenient? so this is classic convenience sample. and this isn't just like, hey, these are the first 100 people to walk through the door and there's, a lot of times you can argue why that might be not so random, but these're the next 100 listeners who sent him fan emails. (laughing) so this is convenience sampling and the sample that you happen to use out of convenience is one that's going to be very skewed to liking you. so once again, this is overestimating, overestimating the percent, the percent that love his show. now nonresponse is when you ask a certain number of people to fill out a survey or to answer a questionnaire, and for some reason, some percent do not fill it out. and you're like, ""wow, who are those people? ""maybe they would have said something important ""and maybe their viewpoint ""is not properly represented in the overall number ""that actually did fill it out."" and there is some nonresponse going on here. he asks 100 people who sent fan emails to fill out the survey to say whether they love it or not, 97 fill it out. so there are three people who did not fill out the survey. so there is some nonresponse going on that would be a source of bias, but it's not the most concerning. right over here they're asking us, fill out the most concerning source of bias, and the convenience sampling is definitely the biggest deal here. there were three people who didn't respond, but that's not as big of a deal. voluntary response sampling. well, he didn't ask people, like in the last example, ""hey, if you can go here and fill it out?"" i guess, i take that back, there is a little bit of voluntary response here, where he goes to these 100 people and he asks them to respond. and so you have the 97 people who chose to respond. but once again, that could be a source of bias, but most of the 97 of the 100 are responding, and once again, the most concerning thing is the convenience sampling, which will once again, based on this sample that he's happening to use out of convenience, is going to be a very, a significant overestimate in terms of representing the entire population of his listeners.",t_44950a420485,other,0
c_d507e73a926a,"changes of state | matter |  physics | fuseschool  on earth, materials exist in one of three main states of matter: solid, liquid or gas.  materials can change between these states.  when a state change occurs, a substance’s properties will also change.  however, if the state change is reversed the substance will recover the properties it had to begin with.  matter can transition between the three states when heated or cooled. but why is heat key in all this? when a material is heated, it absorbs heat energy. this additional energy can cause attractive forces between molecules to break. this leads to rearrangements of the particles because the attractive forces no longer hold them together as tightly. the same happens when a liquid is heated. the attractive forces between the molecules break, leading them to become more widely dispersed and a gas to form.  do you know the difference between evaporation and boiling? both are when a substance transforms from a liquid to a gas. think of a boiling pan of water… all of the water bubbles. this is because all of the particles have enough energy to become gaseous.  but water standing in a pan that is not being heated by anything other than the environment, can also turn into a gas - this is evaporation. only the particles at the surface have enough energy to change from liquid to gas. hence, evaporation is a slower process than boiling even though it achieves the same state change. both are types of vaporisation.  the opposite of these vaporisation processes is condensation: the transition from gas to liquid. think of a cold can of soda on a hot day - those water droplets on the outside. or the dew on the grass in the morning. or the steamed-up mirror after a hot bath. even the clouds in the sky. or a foggy windscreen on a car. these are all examples of condensation. water vapour in the air has cooled down to form liquid droplets of water.  now let’s think about the transitions between solids and liquids: so, melting and freezing. think of the arctic sea ice. in the summer when air temperatures are warmer, more heat energy is absorbed by the ice. this causes bonds to break between the ice’s water molecules and the ice starts to melt. the solid ice becomes liquid water.  but in the winter, the air temperatures are colder and so seawater freezes and the ice starts to form again. there is less heat energy within the ice, and so more bonds can form, holding it together as solid ice . did you know that sometimes when solids are heated they can turn straight into gases? this is called sublimation. this is only demonstrated by particular materials such as solid carbon dioxide (aka ‘dry ice’). when subjected to a certain pressure it will turn straight into gaseous carbon dioxide. liquid carbon dioxide does exist but it only occurs under very high pressures. similarly, gases can turn straight into solids when cooled. this is called deposition.  our final thing to discover is that when a material changes states the mass stays the same.  the density changes - so the mass per unit volume. but the mass does not change. our glass of nice, cold coke weighs the same whether the ice is solid or when the ice has melted.  so, there we have the changes of state. just remember that the mass stays the same, whatever the state!    ",t_17b0df1709dc,other,0
c_1b070ddc37bd,"calculating the total final velocity for a projectile landing at a different altitude  in the last video, i told you that we would figure out the final velocity of when this thing lands. so let's do that. i forgot to do it in the last video. so let's figure out the final velocity-- the vertical and the horizontal components of that final velocity. and then we can reconstruct the total final velocity. so the horizontal component is easy, because we already know that the horizontal component of its velocity is this value right over here, which we-- this 30 cosine of 80 degrees. and that's not going to change at any point in time. so this is going to be the horizontal component of the projectile's velocity when it lands. but what we need to do is figure out the vertical component of its velocity. well, one thing we did figure out in the last video, we figured out what the time in the air is going to be. and we know a way of figuring out our final velocity from an initial velocity given our time in the air. we know that a change in velocity -- and we're only dealing in the vertical now-- we're only dealing with the vertical, because the horizontal velocity is not going to change. we've assumed that air resistance is negligible. so we're only dealing with the vertical component right over here. we know that the change in velocity-- or, we could say the horizontal-- the vertical component of the change in velocity, is equal to the vertical component of the acceleration times time. now, we know what the change in time is, we know it is-- i'll just write down times our time. and what is our change in velocity? well, our change in velocity is our final vertical velocity minus our initial vertical velocity. and we know what our initial vertical velocity is, we solved for it. our initial vertical velocity, we figured out, was 29.54 meters per second. that's 30 sine of 80 degrees, 29.54 meters per second. so this is going to be minus 29.54 meters per second, is equal to-- our acceleration in the vertical direction is negative, because it's accelerating us downwards, negative 9.8 meters per second squared. and our time in the air is 5.67 seconds. times 5.67 seconds. and so we can solve for the vertical component of our final velocity. so once again, this is the vertical component. this isn't the total one. so, the vertical component. let me-- well i wrote vertical up here. so there's the vertical component. so let's solve for this. so if you add 29.54 to both sides, you get the vertical component of your final velocity. well, this is a vertical component, i didn't mark it up here properly-- is equal to 29.54 meters per second plus 9.8 plus -- or i should say minus-- meters per second. minus 9.8 meters per second squared, times 5.67 seconds. the seconds cancel out with one of these seconds. so everything is meters per second. and so, get the calculator out again, we have 29.54 minus 9.8 times 5.67. so we get our change-- our final velocity is negative 26.03. so this is negative 26.03 meters per second. and you might say wait, wait sal , what is this negative 26.03 meters per second mean? remember, when we're dealing in the vertical dimension, positive means up, negative mean down. so it means we're going 26.03 meters per second downwards. downwards, right when we land. so what is our total velocity when we fall back to that landing? so the vertical component of our velocity is negative 29.06 times .03 in the downward direction. and the horizontal component of our velocity, we know, hadn't changed the entire time. that, we figured out, was 30 cosine of 80 degrees. so that over here, is 30 cosine of 80 degrees. i'll get the calculator out to calculate it. 30 cosine of 80 degrees, which is equal to 5.21. so this is 5.21 meters per second. these are both in meters per second. so what is the total velocity? well, i can do the head to tails. so i can shift this guy over so that its tail is at the head of the blue vector. so it would look like that. the length of this-- the magnitude of our vertical component, is 29.03. and then we could just use the pythagorean theorem to figure out the magnitude of the total velocity upon impact. so the length of that-- we could just use the pythagorean theorem. so the magnitude of our total velocity, that's this length right over here. the magnitude of our total velocity, our total final velocity i guess we can say, is going to be equal to-- well that's-- let me write it this way. the magnitude of our total velocity is going to be equal to square root-- this is just straight from the pythagorean theorem-- of 5.21 squared plus 29.03 squared. and we get it as being the second-- the square root of 5.21 squared plus 29.03 squared gives us 29.49 meters per second. this is equal to 29.49 meters per second. that is the magnitude of our final velocity, but we also need to figure out its direction. and so we need to figure out this angle. and now we're talking about an angle below the horizontal. or, if you wanted to view it in kind of pure terms, it would be a negative angle-- or we could say an angle below the horizontal. so what is this angle right over here? so if we view it as a positive angle just in the traditional trigonometric way, we could say that the-- we could use any of the trig functions, we could even use tangent. let's use tangent. we could say that the tangent of the angle, is equal to the opposite over the adjacent-- is equal to 29.03 over 5.21. or that theta is equal to the inverse tangent, or the arctangent of 29.03 over 5.21. and that gives us-- we take the inverse tangent of 29.03 divided by 5.21, and we get 79.8 degrees. but it's going to be 79.8 degrees south, or, i guess, below the horizontal. or you could view this as an angle of negative 79.8 degrees above the horizontal, either one of those work. what's neat about this, is we figured out our final velocity vector. the entire vector, we know what that entire vector is. it is 29.49 meters per second at 79.8 degrees below the horizontal.",t_6ede0ec5f167,other,0
c_3af45afad5fb,"def drawboard(board, message):     displaysurf.fill(bgcolor)     if message:         textsurf, textrect = maketext(message, messagecolor, bgcolor, 5, 5)         displaysurf.blit(textsurf, textrect)      for tilex in range(len(board)):         for tiley in range(len(board[0])):             if board[tilex][tiley]:                 drawtile(tilex, tiley, board[tilex][tiley])      left, top = getlefttopoftile(0, 0)     width = boardwidth * tilesize     height = boardheight * tilesize     pygame.draw.rect(displaysurf, bordercolor, (left - 5, top - 5, width + 11, height + 11), 4)  lines 12 [244] to 15 [247] draw a border around the tiles. the top left corner of the boarder will be 5 pixels to the left and 5 pixels above the top left corner of the tile at board coordinates (0, 0). the width and height of the border are calculated from the number of tiles wide and high the board is (stored in the boardwidth and boardheight constants) multiplied by the size of the tiles (stored in the tilesize constant).  the rectangle we draw on line 15 [247] will have a thickness of 4 pixels, so we will move the boarder 5 pixels to the left and above where the top and left variables point so the thickness of the line won’t overlap the tiles. we will also add 11 to the width and length (5 of those 11 pixels are to compensate for moving the rectangle to the left and up).",t_c9c9192dd6c4,other,0
c_e5ca52a9a7de,"tess-india (teacher education through school-based support) aims to improve the classroom practices of elementary and secondary teachers in india through the provision of open educational resources (oers) to support teachers in developing student-centred, participatory approaches. the tess-india oers provide teachers with a companion to the school textbook. they offer activities for teachers to try out in their classrooms with their students, together with case studies showing how other teachers have taught the topic and linked resources to support teachers in developing their lesson plans and subject knowledge. the tess- india oers are supported by a set of ten key resources. these key resources, which apply to all subjects and levels, offer teachers further practical guidance on key practices in the pedagogy modelled in tess-india oer and india policy. they include ways of organising students, learning activities and teacher– student and student–student interactions. excerpts from these key resources will be inserted into the oers. they will also be available on the website for teachers and teacher educators. tess-india is led by the open university uk and funded by the uk government.  version 2.0  kr03v1  except for third party materials and otherwise stated, this content is made available under a creative commons attribution-sharealike licence: http://creativecommons.org/licenses/by-sa/3.0/  key resource; talk for learning  talk for learning why talk for learning is important talk is a part of human development that helps us to think, learn and make sense of the world. people use language as a tool for developing reasoning, knowledge and understanding. therefore, encouraging students to talk as part of their learning experiences will mean that their educational progress is enhanced. talking about the ideas being learnt means that:     those ideas are explored reasoning is developed and organised as such, students learn more.  in a classroom there are different ways to use student talk, ranging from rote repetition to higher-order discussions. traditionally, teacher talk was dominant and was more valued than students’ talk or knowledge. however, using talk for learning involves planning lessons so that students can talk more and learn more in a way that makes connections with their prior experience. it is much more than a question and answer session between the teacher and their students, in that the students’ own language, ideas, reasoning and interests are given more time. most of us want to talk to someone about a difficult issue or in order to find out something, and teachers can build on this instinct with well-planned activities.  planning talk for learning activities in the classroom planning talking activities is not just for literacy and vocabulary lessons; it is also part of planning mathematics and science work and other topics. it can be planned into whole class, pair or groupwork, outdoor activities, role play-based activities, writing, reading, practical investigations, and creative work. even young students with limited literacy and numeracy skills can demonstrate higher-order thinking skills if the task is designed to build on their prior experience and is enjoyable. for example, students can make predictions about a story, an animal or a shape from photos, drawings or real objects. students can list suggestions and possible solutions about problems to a puppet or character in a role play. plan the lesson around what you want the students to learn and think about, as well as what type of talk you want students to develop. some types of talk are exploratory, for example: ‘what could happen next?’, ‘have we seen this before?’, ‘what could this be?’ or ‘why do you think that is?’ other types of talk are more analytical, for example weighing up ideas, evidence or suggestions. try to make it interesting, enjoyable and possible for all students to participate in dialogue. students need to be comfortable and feel safe in expressing views and exploring ideas without fear of ridicule or being made to feel they are getting it wrong.  www.tess-india.edu.in  1  key resource: talk for learning  building on students’ talk talk for learning gives teachers opportunities to:     listen to what students say appreciate and build on students’ ideas encourage the students to take it further.  not all responses have to be written or formally assessed, because developing ideas through talk is a valuable part of learning. you should use their experiences and ideas as much as possible to make their learning feel relevant. the best student talk is exploratory, which means that the students explore and challenge one another’s ideas so that they can become confident about their responses. groups talking together should be encouraged not to just accept an answer, whoever gives it. you can model challenging thinking in a whole class setting through your use of probing questions like ‘why?’, ‘how did you decide that?’ or ‘can you see any problems with that solution?’ you can walk around the classroom listening to groups of students and extending their thinking by asking such questions. your students will be encouraged if their talk, ideas and experiences are valued and appreciated. praise your students for their behaviour when talking, listening carefully, questioning one another, and learning not to interrupt. be aware of members of the class who are marginalised and think about how you can ensure that they are included. it may take some time to establish ways of working that allow all students to participate fully.  encourage students to ask questions themselves develop a climate in your classroom where good challenging questions are asked and where students’ ideas are respected and praised. students will not ask questions if they are afraid of how they will be received or if they think their ideas are not valued. inviting students to ask the questions encourages them to show curiosity, asks them to think in a different way about their learning and helps you to understand their point of view. you could plan some regular group or pair work, or perhaps a ‘student question time’ so that students can raise queries or ask for clarification. you could:         entitle a section of your lesson ‘hands up if you have a question’ put a student in the hot-seat and encourage the other students to question that student as if they were a character, e.g. pythagoras or mirabai play a ‘tell me more’ game in pairs or small groups give students a question grid with who/what/where/when/why questions to practise basic enquiry give the students some data (such as the data available from the world data bank, e.g. the percentage of children in full-time education or exclusive breastfeeding rates for different countries), and ask them to think of questions you could ask about this data design a question wall listing the students’ questions of the week.  you may be pleasantly surprised at the level of interest and thinking that you see when students are freer to ask and answer questions that come from them. as students learn how to communicate more clearly and accurately, they not only increase their oral and written vocabulary, but they also develop new knowledge and skills.  2  www.tess-india.edu.in  key resource; talk for learning  acknowledgements this content is made available under a creative commons attribution-sharealike licence (http://creativecommons.org/licenses/by-sa/3.0/), unless identified otherwise. the licence excludes the use of the tess-india, ou and ukaid logos, which may only be used unadapted within the tess-india project. every effort has been made to contact copyright owners. if any have been inadvertently overlooked the publishers will be pleased to make the necessary arrangements at the first opportunity. key resources include contributions from: deborah cooper, beth erling, jo mutlow, clare lee, kris stutchbury, freda wolfenden and sandhya paranjpe.  www.tess-india.edu.in  3",t_e403b7c5480e,other,0
c_f34693553653,"much has been written in this text regarding the efficiency of various power amplifier topologies. while class a is known for its circuit layout simplicity, it is also known for its very low efficiency. class b and class ab, while more complex than class a, present serious improvements in efficiency. in spite of these improvements, the family of class b amplifiers can hardly be considered as exhibiting high efficiency. although not explicitly covered in this text, class g and h topologies are variations on class b and attempt to increase efficiency through the use of multiple sets of power supply rails or output devices, and in the process, tick the complexity up to another level.  the class d amplifier is perhaps the last word in amplifier efficiency. theoretically with ideal devices, the efficiency of the output stage approaches 100%. unlike the other amplifier forms, the transistors used in class d amplifiers never operate in the linear region; the output devices only operate as a switch, in either saturation or cutoff. high switching speed turns out to be a huge plus as it plays a major role in efficiency.  the increase in efficiency comes at a considerable increase in circuit complexity, however, for some applications this turns out to be a very good trade-off. as odd as it might at first seem, the two areas where class d topologies have taken root are at the opposite ends of the power output spectrum. the first area is perhaps the most obvious, mainly, very high output power amplifiers. an example might be an amplifier used as part of a large public address system and capable of delivering in excess of 1000 watts into a loudspeaker. high efficiency does two things here: first, it reduces the waste heat in the amplifier itself, and second, it reduces the current draw from the ac mains. both of these are serious issues in a pa system used to fill a stadium or large concert hall as there may be dozens of such amplifiers comprising the system. as a bonus, improved efficiency also leads to a lighter and small enclosure because the need for heat sink area and mass will be reduced, as will the size of the ac power supply transformer. these traits will also reduce production costs and help offset the design complexity cost. the advantages have become so great that, in recent years, class d designs dominate the high end professional audio power amplifier market as well as the very high power automotive audio market (here there is another system limitation working in favor of class d, and that's the limited current capacity of the vehicle's alternator to deliver current).  the second area where class d has found acceptance is for low power portable devices. examples include personal music devices, cell phones and hearing aids. output powers for these applications might range from tens of milliwatts up to a few watts, so excess heat is generally not a big problem except in the most compact of enclosures. what is a problem, though, is the energy budget. unlike a large pa amplifier that might pump out in excess of two horsepower, these portable devices do not have the luxury of running off of the ac mains with tens or even hundreds of amps of current capacity. instead, these devices are restricted to battery power and batteries can only store so much energy. for a given battery capacity, higher efficiency directly translates into longer battery life. another way of thinking about this is that, given a higher efficiency, a smaller battery can be used to achieve the same battery life, and this means that the unit can be both smaller and less expensive. of course, nothing says that we can't opt for a little of each.",t_254a7afea6ed,other,0
c_55601517bbe9,"- [voiceover] so, what is sinusitis? before we can answer that question, we should talk a little bit about anatomy. so, here i've drawn a couple faces, and we're going to superimpose the sinuses on these faces. so, the largest sinuses that you have in your face are called the maxillary sinuses, and they live on the side of your nose here, right underneath your eye. if you tap on that bone right underneath your eye, your cheekbone, you're tapping on the frontal wall of the maxillary sinus. when you're looking at somebody from the front, this is what they look like, and maxillary sinuses from the side are located about right here. so, another set of sinuses lives at the top of your nasal cavity, and it's composed of multiple little air cells, multiple little bony chambers that are filled with air. these are a little bit irregular, and everybody's are a little bit different, but they kind of look about like this. there's usually two layers or so of them, and these are called the ethmoid sinuses. these are also known as the ethmoid air cells. right behind the ethmoid air cells, and deeper back in your head, is a pair of larger sinuses called the sphenoid sinuses, and they live about right here. and another set of sinuses lives in your forehead, about like right here. it's kind of variable in shape, but kind of looks about like this, and these are called your frontal sinuses. and altogether these are known as the paranasal sinuses. the reason for that is because they're located adjacent to your nasal cavity, and the nasal cavity, as you might guess, sits right in the middle of your face, right about here. now your paranasal sinuses and your nasal cavity are all lined by a layer of tissue called mucosa, and that mucosa is contiguous throughout your paranasal sinus and nasal system. in other words, the same mucosa lines everything, and because of this fact, sinusitis is probably more accurately termed rhinosinusitis. and in the medical literature, it's referred to in both ways. so, quickly i'd like to show a real example of this anatomy by using a cat scan. so, i'm going to label some of the structures here on these two images of an actual patient's cat scan. the first image is a coronal image, which means it's like we're looking at a patient's face directly on. the second one is an axial image, and that's like we're taking a slice through the patient's sinuses here and looking only at that slice. so, just like in our cartoon drawing, we have the maxillary sinuses here under your eyes. we have the ethmoid air cells. we have the nasal cavity. and on our axial image here, you can see the maxillary sinuses here and the nasal cavity here, and the nasal cavity extends all the way forward. so, you can see it going out towards the patient's nose. so, we'll go back to our cartoon. and now that we have a good grasp of the anatomy involved, we can talk about what exactly rhinosinusitis is. so, the definition of rhinosinusitis is inflammation in one or more of these cavities. let's say, for instance, that the sphenoid sinus in this patient in this cartoon is inflamed. so, that mucosal tissue that lines that sphenoid sinus is going to become red and irritated and inflamed. and the first thing that most patients notice is going to be pain. now, that pain can be localized to the sinus in question, but it can also produce general pain, particularly in the case of the deep sinuses, like the ethmoid air cells and the sphenoid sinuses. that may just cause headache. with maxillary sinusitis, you can actually feel the pain in that particular maxillary sinus. in fact, if you tapped on it with your finger, that could produce tenderness. and another thing that happens when you get inflammation of the mucosa is that mucosa produces mucus, as you might expect. so, going back to our sphenoid sinusitis here, we will draw in a fluid layer here of mucus that's being produced, and that mucus has to go somewhere. and all of these sinuses are connected by little holes to the nasal cavity, and the purpose of those connections is to actually allow things to drain out. so, that mucus that's produced is going to drain out into the nasal cavity. now, there's really only two things that it can do, once it's in the nasal cavity. the first thing is to come out of your nose. so, people will notice nasal discharge. so, the other place that mucus can go is down into your throat. so, the back of your nose is connected with the back of your throat, and as that mucus leaks down into the back of your throat, it's irritating there as well, and that will cause you to cough, and when you lie down, it's particularly bad, and so the cough is often worse at night when you're trying to sleep. now, sometimes the inflammation is bad enough that patients will get a fever. that's not always the case. you can certainly have sinusitis without having a fever, but it is one of the reported things, and it tends to happen more often in cases that are worse. and this inflammation in the mucosa can also alter the way your body smells and tastes things. let's move this down, to give ourselves a little bit of space to write here. so, what are the causes of sinusitis? in adults, the vast majority of cases are caused by viruses. in fact, more than 98 percent of them. the remaining two percent are usually caused by bacteria, the common types of bacteria being streptococcus pneumoniae, haemophilus influenza, often abbreviated h. flu, and moraxella catarrhalis. there's a small population of people that can get fungal disease. that's not as common and tends to only happen in people who are immunosuppressed. there are some predisposing factors that make it more likely that you'll get sinusitis. if you have allergic rhinitis, that could make it easier for an infection to take hold. if you're exposed to cigarette or cigar smoke, either firsthand or secondhand. and there's certain anatomic variants that make it harder for sinuses to drain. like if the hole to one of the sinuses that leads to the nasal cavity is a little bit small, or if it's blocked by an extra large air cell, that can be a set up to get an infection. so, let's go back to a cat scan. this one's a little bit different. this time, the patient has acute sinusitis. here you can see in the maxillary sinus this liquid that's layering at the bottom here. you can see the fluid, and you can see sitting in the top, these little round bubbles as well. so, this is kind of a frothy fluid sitting in here. that's a definite sign of acute sinusitis. you can also see some fluid up here, in the ethmoid air cells, and a little bit of fluid sitting in the nasal cavity as well, but not a lot. you can also see some mild mucosal edema. i'll outline that for you here and here. sometimes the mucosal edema can get so bad that it will fill up the entire cavity. this particular patient, it's not so bad. but the fact that you can see it at all, at least in the maxillary sinuses and ethmoid air cells, means that it's inflamed. so, we're going to move this picture up a little bit, and we're going to use it to illustrate some of the potential complications of sinusitis. now, most of the time sinusitis is a self-limiting disease. the viral type will go away on its own, after a period of time, but the bacterial type tends to be a little bit more aggressive. so, you can see these structures in your face are really located in a pretty central and important area, and the complications of sinusitis are all related to spreading infection. so, there's lots of important bones here. so, if this infection was to spread into the maxillary bone, here for instance, or if it was to spread into here, that complication is called osteomyelitis, and that just means infection of the bone, and that can be a very difficult infection to treat. let's say this infection traveled from the ethmoid air cell here, through this very thin bone, and then spread into this cavity here. of course, that's where your brain likes to live. that's inside your skull at this point. so, now we're talking about an intracranial abscess, and, of course, that's a very major complication. that can cause all sorts of problems with the brain, if it gets up into the brain. if the infection spreads out into the soft tissues here, or here, or basically anywhere else, that is termed cellulitis. if the infection spreads this way, through the ethmoid air cells, into this cavity, that's your orbit. that's where your eyeball lives. that can be a super severe complication too. that can cause an intraorbital abscess or an orbital cellulitis. and there's all sorts of important arteries and veins that run through your head and neck, and if infection gets into them, it can cause infected clots or septic clots, and it can also travel to other parts of the body, and those are called septic emboli. now, all of these complications are much more common in severe disease, and severe disease is usually, but not always, bacterial. so, most people will try and treat bacterial sinusitis pretty aggressively. similarly, if your immune system isn't working properly, you can develop severe disease and are more prone to get these complications. but keep in mind that complications are rare. in fact, something on the order of 30 million people in the united states alone get sinusitis in any given year. that's a huge number, and only a tiny minority of them actually get these complications. most of them don't need treatment at all, and those that do get treated, usually respond very well.",t_5defe3fd182f,other,0
c_317410f0608c,"this prestigious garment follows a traditional design passed down through generations of indigenous alaskans. [see learning resources here.](https://smarthistory.org/seeing-america-2/resilience-robe/)      clarissa rizal, resilience robe, 2014, merino wool, 64 x 53 inches (portland art museum). speakers: lily hope and beth harris  (light music) - [beth] i'm in the portland art museum with lily hope looking at a beautiful chilkat robe, woven by her mother. - [lilly] this resilience robe is a modern take on an ancient design. chilkat weaving originates from the northwest coast, so she has elements of traditional bird with wings and a tail, and the claws, and the feathers coming down on the points of these wings. and then within that body of the bird is modern influences. - [beth] so for example i notice the letters anb on the left and ans on the right. so the alaska native brotherhood and the alaska native sisterhood, - [lilly] key in bringing about sovereignty, if you can say that. bringing about power, to the indigenous peoples so that we had a unified voice. - [beth] and we also see the logo of sealaska, right in the center. - [lilly] this was the original sealaska corporation design and that corporation is one of the 13 corporations in alaska who organized to support the indigenous peoples of southeast alaska. so the tlingit people have been around for thousands of years, and here we have, just the last 100 to 200 years, of these influences. we even have, in the very tail of this design, sealaska heritage institute's original logo. they support arts, education, and all sorts of support for alaska native artists and scholars. - [beth] and that education is so important because these are traditional ways of creating that must be passed down to new generations so that they're not lost. - [lilly] sealaska heritage institute is dedicated to perpetuating endangered art forms, chilkat weaving is one of them. - [beth] and your mother, clarissa rizal, learned this technique from someone who had practiced it for decades. and you, yourself are a weaver, carrying on this tradition. - [lily] trained under my mother. - [beth] and she learned from jennie thlunaut. who was this very revered weaver. - [lilly] jennie thlunaut wove over 90 large weavings in her lifetime, which is phenomenal. when you think about weavers taking a year or even a half or four years to finish one robe, and jennie wove 90. - [beth] we're not just talking about going down to the corner and buying some yarn. - [lilly] it's three or four months of preparation. - [beth] gathering the bark, treating it, shredding it, spinning it together with the wool, traditionally goats hair. the spinning is done on the thigh, really labor intensive. requires an enormous amount of skill and patience, i imagine. - [lilly] it is months of work. before you even get to hang your warp on your loom. and we call it a loom, but it's more of a frame. - [beth] normally we think about a loom as having warp, the vertical threads, attached at the top and the bottom and here, they're only attached at the top, which means that the weaver has to have an enormous amount of skill to keep the tension even as you're winding the weft through the warp. - [lilly] how you hold your hands makes all the difference in whether you have a wonky little weaving or if you have a nice firm fiber that's danceable. and this chilkat weaving uses four colors, black, yellow, turquoise and white. they would be commissioned by clan leaders or heads of the communities, and still are. you have to have a deep pocketbook for these robes. they are some of the most prestigious pieces of art you can own from the northwest coast. - [beth] our historians refer to this kind of pattern as form line design these ovoid and circular shapes. these black lines that get thin and thick. so these are very similar to the designs that one would see in wood carving, but here, adjusted for weaving. these are made by women where traditionally, the carving would be done by men. - [lilly] chilkat robes often hold the crests and clan emblems of the people of the northwest coast. - [beth] and i know that this robe features an eagle and a raven. both important animals in tlingit culture. - [lilly] so this robe is an eagle and a raven. we say it's moiety, which is a french anthropological term which means half and in tlingit culture you are an eagle or you are a raven and traditionally, you would marry your opposite. - [beth] and there's something very balanced about the robe. - [lilly] it's kind of perfect that way. she is embodied both the anb and the ans, the eagle and the raven. we have elements of not just strength in the tlingit people, in the people of south east alaska, but we also have the outside influence on these outer panels the gold panning that happened, the museums and schools that came in and helped us to fit in in the western world - [beth] and we also see ships. - [lilly] so we have the influences of trade on the north west coast from the russians, from the english coming over on their ships and they would bring us not just disease right, but buttons and wool blankets, so we get those influences which weren't all bad. there are probably 100's of people who know to chilkat weave and most of us practice it as a hobby. there are probably less than 10 of us who have the time and expertise to weave a full size robe. - [beth] the time involved to make a robe of this size is not something that everyone can afford or know how to do. - [lilly] it's a huge commitment, i just put my second robe on the loom and the overwhelming feeling of that, of okay this is what i'm doing for the next year and a half it's terrifying, and it's also so gratifying. - [beth] it looks like it's heavy to wear. - [lilly] it's seven or eight pounds of marino wool with sidobark spun into it and it's like a hug when you put it on. when it drapes over your shoulders, you want to move because that fringe dances around you at your knees, down to your calves and you just want to shake your shoulders back and forth and feel what that's like to move and bring it alive. there is such a spiritual power in these robes that we don't fully understand even now and we protect not just the wearer, but we protect the teachings and how to pass this information on. (light music)",t_cc341d6b6852,other,0
c_80f499de7c07,"one common pattern when you are developing a python program to connect to an sqlite database will be to run a python program and check the results using the database browser for sqlite. the browser allows you to quickly check to see if your program is working properly.  you must be careful because sqlite takes care to keep two programs from changing the same data at the same time. for example, if you open a database in the browser and make a change to the database and have not yet pressed the ""save"" button in the browser, the browser ""locks"" the database file and keeps any other program from accessing the file. in particular, your python program will not be able to access the file if it is locked.  so a solution is to make sure to either close the database browser or use the file menu to close the database in the browser before you attempt to access the database from python to avoid the problem of your python code failing because the database is locked.",t_5d0d78cdf940,other,0
c_b1bfdc7037f8,"the neumann problem (second boundary value problem) is to find a solution \(u\in c^2(\omega)\cap c^1(\overline{\omega})\) of \begin{eqnarray} \label{n1}\tag{7.3.2.1} \triangle u&amp;=&amp;0\ \ \mbox{in}\ \omega\\ \label{n2} \tag{7.3.2.2} \frac{\partial u}{\partial n}&amp;=&amp;\phi\ \ \mbox{on}\ \partial\omega, \end{eqnarray} where \(\phi\) is given and continuous on \(\partial\omega\).  proposition 7.5. assume \(\omega\) is bounded, then a solution to the dirichlet problem is in the class \(u\in c^2(\overline{\omega})\) uniquely determined up to a constant.  proof. exercise. hint: multiply the differential equation \(\triangle w=0\) by \(w\) and integrate the result over \(\omega\). another proof under the weaker assumption \(u\in c^1(\overline{\omega})\cap c^2(\omega)\) follows from the hopf boundary point lemma, see lecture notes: linear elliptic equations of second order, for instance.  contributors  prof. dr. erich miersemann (http://www.math.uni-leipzig.de/~miersemann/) (universität leipzig (http://www.math.uni-leipzig.de/cms/en/startseite/))  integrated by justin marshall.",t_d3713961ad05,other,0
c_e6e664a85465,"james garfield's proof of the pythagorean theorem.  what we're going to do in this video is study a proof of the pythagorean theorem that was first discovered, or as far as we know first discovered, by james garfield in 1876, and what's exciting about this is he was not a professional mathematician. you might know james garfield as the 20th president of the united states. he was elected president. he was elected in 1880, and then he became president in 1881. and he did this proof while he was a sitting member of the united states house of representatives. and what's exciting about that is that it shows that abraham lincoln was not the only us politician or not the only us president who was really into geometry. and what garfield realized is, if you construct a right triangle-- so i'm going to do my best attempt to construct one. so let me construct one right here. so let's say this side right over here is length b. let's say this side is length a, and let's say that this side, the hypotenuse of my right triangle, has length c. so i've just constructed enough a right triangle, and let me make it clear. it is a right triangle. he essentially flipped and rotated this right triangle to construct another one that is congruent to the first one. so let me construct that. so we're going to have length b, and it's collinear with length a. it's along the same line, i should say. they don't overlap with each other. so this is side of length b, and then you have a side of length-- let me draw a it so this will be a little bit taller-- side of length b. and then, you have your side of length a at a right angle. your side of length a comes in at a right angle. and then, you have your side of length c. so the first thing we need to think about is what's the angle between these two sides? what's this mystery angle? what's that mystery angle going to be? well, it looks like something, but let's see if we can prove to ourselves that it really is what we think it looks like. if we look at this original triangle and we call this angle ""theta,"" what's this angle over here, the angle that's between sides of length a and length c? what's the measure of this angle going to be? well, theta plus this angle have to add up to 90. because you add those two together, they add up to 90. and then, you have another 90. you're going to get 180 degrees for the interior angles of this triangle. so these two have to add up to 90. this angle is going to be 90 minus theta. well, if this triangle appears congruent-- and we've constructed it so it is congruent-- the corresponding angle to this one is this angle right over here. so this is also going to be theta, and this right over here is going to be 90 minus theta. so given that this is theta, this is 90 minus theta, what is our angle going to be? well, they all collectively go 180 degrees. so you have theta, plus 90 minus theta, plus our mystery angle is going to be equal to 180 degrees. the thetas cancel out. theta minus theta. and you have 90 plus our mystery angle is 180 degrees. subtract 90 from both sides, and you are left with your mystery angle equaling 90 degrees. so that all worked out well. so let me make that clear, and that's going to be useful for us in a second. it's going to be useful. so we can now say definitively that this is 90 degrees. this is a right angle. now, what we are going to do is we are going to construct a trapezoid. this side a is parallel to side b down here, the way it's been constructed, and this is just one side right over here. this goes straight up, and now let's just connect these two sides right over there. so there's a couple of ways to think about the area of this trapezoid. one is we could just think of it as a trapezoid and come up with its area, and then we could think about it as the sum of the areas of its components. so let's just first think of it as a trapezoid so what do we know about the area of a trapezoid? well, the area of a trapezoid is going to be the height of the trapezoid, which is a plus b. that's the height of the trapezoid. times-- the way i think of it-- the mean of the top and the bottom, or the average of the top and the bottom. since that's this times one half times a plus a plus b. and the intuition there, you're taking the height times the average of this bottom and the top. the average of the bottom and the top gives you the area of the trapezoid. now, how could we also figure out the area with its component parts? regardless of how we calculate the area, as long as we do correct things, we should come up with the same result. so how else can we come up with this area? well, we could say it's the area of the two right triangles. the area of each of them is one half a times b, but there's two of them. let me do that b in that same blue color. but there's two of these right triangle. so let's multiply by two. so two times one half ab. that takes into consideration this bottom right triangle and this top one. and what's the area of this large one that i will color in in green? what's the area of this large one? well, that's pretty straightforward. it's just one half c times c. so plus one half c times c, which is one half c squared. now, let's simplify this thing and see what we come up with, and you might guess where all of this is going. so let's see what we get. so we can rearrange this. let me rearrange this. so one half times a plus b squared is going to be equal to 2 times one half. well, that's just going to be one. so it's going to be equal to a times b, plus one half c squared. well, i don't like these one halfs laying around, so let's multiply both sides of this equation by 2. i'm just going to multiply both sides of this equation by 2. on the left-hand side, i'm just left with a plus b squared. so let me write that. and on the right-hand side, i am left with 2ab. trying to keep the color coding right. and then, 2 times one half c squared, that's just going to be c squared plus c squared. well, what happens if you multiply out a plus b times a plus b? what is a plus b squared? well, it's going to be a squared plus 2ab plus 2ab plus b squared. and then, our right-hand side it's going to be equal to all of this business. and changing all the colors is difficult for me, so let me copy and let me paste it. so it's still going to be equal to the right-hand side. well, this is interesting. how can we simplify this? is there anything that we can subtract from both sides? well, sure there is. you have a 2ab on the left-hand side. you have a 2ab on the right-hand side. let's subtract 2ab from both sides. if you subtract 2ab from both sides, what are you left with? you are left with the pythagorean theorem. so you're left with a squared plus b squared is equal to c squared. very, very exciting. and for that, we have to thank the 20th president of the united states, james garfield. this is really exciting. the pythagorean theorem, it was around for thousands of years before james garfield, and he was able to contribute just kind of fiddling around while he was a member of the us house of representatives.",t_a84bf654e92c,other,0
c_9176de2f9f29,"washington allston, _elijah in the desert_ , 1818, oil on canvas, 125.09 x 184.78 cm / 49 1/4 x 72 3/4 inches (museum of fine arts, boston)  (piano music) &gt;&gt; dr. steven zucker: one of the most interesting paintings by an american artist early in the nation's history is washington allston's ""elijah in the desert."" it's dark, it's brooding, it's melancholic, and it seems to emphasize the supernatural. these are all traits that are so at odds with most of the american painting that we know of from this period. &gt;&gt; dr. beth harris: that's true, but they were things that especially interested washington allston. he was very much a romantic. he was interested in the gothic and the supernatural and the creepy in all of its forms. &gt;&gt; dr. zucker: this is really creepy (laughs). &gt;&gt; dr. harris: it is. like so many american artists at the end of the 18th and early 19th century, he went to london. he learned the european methods. in fact, he exhibited at the paris salon. &gt;&gt; dr. zucker: he actually went to rome and spent a good deal of time with coleridge, spent time with john vanderlyn, another american artist, but importantly focused on the ruins in ancient rome. &gt;&gt; dr. harris: right. you can imagine him strolling through the ruins of rome in the moonlight. that activity suited his romantic sensibility. &gt;&gt; dr. zucker: we know that he was interested in the supernatural. just take a look at this painting. most prominent is this wonderful gnarl tree. it looks like it has lived an enormously long life and suffered and has finally, perhaps by lightning, been blasted and is now dead. as if that wasn't enough, there is this raven in its bow and then another down close to the figure of elijah himself, and of course, this is central to the story of elijah. &gt;&gt; dr. harris: right, where elijah is sent into the wilderness by god but cared for by god there by ravens who feed the prophet. this is from the bible, from the book of kings. allston was interested in these biblical subjects and using landscape as a means to convey these biblical stories, so this is as much a landscape or more a landscape than it is the biblical story. &gt;&gt; dr. zucker: it anticipates some of the ideas that developed back in the united states. that is, this notion that the landscape in america could convey ideas of redemption, could convey ideas of the ancient, could convey spiritual themes. &gt;&gt; dr. harris: right. we didn't have cathedrals and palaces, but we had our untouched landscape. we had landscape which could be interpreted in these emotional and moral ways. one way of also elevating landscape to a higher position in the subject matter of art is to place something significant happening within that landscape, like a biblical story or something heroic. otherwise, landscapes were actually the lowest kind of art, according to the academy. allston is really making a very serious landscape painting. this isn't simply a view of a landscape. &gt;&gt; dr. zucker: but it's not just a serious landscape subject. it's also a serious attempt to elevate painting from the united states. this is critical because if you think back to the kinds of paintings that were being done either during the colonial period or soon thereafter in the federalist period, you have painting that is generally portraiture. but here is an attempt to create a real narrative, something that's serious but also informed by the european tradition quite strongly. &gt;&gt; dr. harris: and you can see that, i think, in the color and the way that allston's painted this. he learned a glazing technique while in london, a way of applying paint in thin layers that really makes the color rich. &gt;&gt; dr. zucker: he was also especially in love with the work of veronese and of titian, and you can see the influence of the venetians in this painting. the color really is much more subtle than what we see in most american painting of this time. &gt;&gt; dr. harris: we can see that really in the clouds, in the mountains in the distance, in the highlights of the sun on that blasted tree in the foreground. so i think you're right. this moral, serious, biblical subject in this wild imaginative landscape is something a little bit at odds with american culture, its emphasis on the practical and the material. i think for a lot of artists in america in the early 19th century and also in the late 18th century, there was this conflict between wanting to create something very serious and meaningful and in a european tradition but also the needs of a more practical american culture. &gt;&gt; dr. zucker: maybe that's one of the reasons that this painting remained unsold for so long. &gt;&gt; dr. harris: perhaps. (piano music)",t_fad897d5b643,other,0
c_fb196083d66e,"when you are doing a complicated calculation involving difficult equations connecting several physical quantities, you , routinely, check the dimensions of  line in your calculation. if the equation does not balance dimensionally, you know immediately that you have made a mistake, and the dimensional imbalance may even give you a hint as to what the mistake is. if the equation does balance dimensionally, this, of course, does not guarantee that it is correct - you may, for example, have missed a dimensionless constant in the equation.  must  every  suppose that you have deduced (or have read in a book) that the period of oscillations of a torsion pendulum is \( p = 2 \pi \sqrt{\frac{i}{c}} \) , where \(i\) is the rotational inertia and \(c\) is the torsion constant. you have to check to see whether the dimensions of the right hand side are indeed that of time. we have \( \left[\sqrt{\frac{i}{c}}\right] = \sqrt{\frac{\text{ml}^2}{\text{ml}^2 \text{t}^{-2}}} \) , which does indeed come to t, and so the equation balances dimensionally.  contributor  jeremy tatum (university of victoria, canada) (http://astrowww.phys.uvic.ca/faculty/tatum/jbt.html)",t_dd9673da1e02,other,0
c_3a7c6e5becc8,"what are giant chemical structures | properties of matter | chemistry | fuseschool  learn the basics about the differences between different chemical structures, including giant covalent, giant ionic and metallic structures.  there are numerous materials and substances that possess giant chemical structures. some are common: like the grains of sand on the beach; the microprocessors in our computers; the graphite in our pencils, the magnesium oxide found in the cement on our buildings; the salt we put on our food; the metals found almost everywhere; and the precious gemstone diamond.  these substances are vastly different and this is due to the bonding and the arrangements of chemicals atoms, or ions.  sand, graphite, and diamond are all examples of giant covalent structures. the bonding between the atoms is covalent, but the arrangements of the atoms can be different.  link to part 2: https://www.youtube.com/watch?v=-s9aggunmbw&feature=youtu.be    ",t_14e1749792e5,other,0
c_9c640e08853b,"the bank gets bailed out by an equity infusion from a sovereign wealth fund.  welcome back. and i've made this balance sheet so messy i think it would make sense to redraw it cleaned up a little bit. so what's our new balance sheet, after we've unloaded a lot of those assets? all i have now, i have a little bit of cash, let me write that down, i had $1 billion of cash. i'll write the 'b' there so you know. and just so you know, a bank needs cash to operate. it can't just use all of its cash to pay off things. because then it won't be able to even transact with its customers, or pay its rent, or send its executives on their learjets, whatever it needs to do. but anyway, you have $1 billion of cash. so you might have been thinking, why not just use its cash to unload some of that debt? well, you always have to keep some cash on line just to conduct business. and actually, that's called working capital. but anyway, back to the point of this video. so you have $1 billion in cash. and at least the management of this company thinks that it has $4 billion worth of residential cdos. and this is the toxic stuff that's the focus of this government bailout, which is really historic in its proportions. and i'll talk more about that later. and on the liabilities side, what was left? i think i had called it loan c. i'll write liabilities in red, just because they're bad. they're not bad, but they're something you owe, so they're not as pleasant. so loan c, we said was $3 billion. and then what is the equity? i'll do that in yellow. so the total assets were $5 billion in assets. total assets. you have $3 billion in liabilities. so if you believe what the accountants or the bank management has said about their assets, if you wanted to just liquidate everything. if you had $5 billion in assets, you liquidate them, got $5 billion, you paid off your $3 billion in loans, you'd be left with $2 billion. so that's the equity. and just as a reminder, how many shares where there? i think i originally set in the original video that we have 500 million shares. so each of those shares is one 500 millionth of this equity. so let's see, the book value per share is what? it's going to be the book value, $2 billion, divided by 500 million. so it's $4. remember, it was $6 not too long ago. but we had to take those commercial mortgages that we thought were worth $10 billion, actually ended up being worth $9 billion. so we lost $1 billion of our book value. and $1 billion translates to $2 of the share price. anyway, fair enough. and maybe at this point the market value of the share, so that's essentially the stock price if you were to look up this company's ticker price, let's say it's at $1. because they're like, boy, after all this bear stearns and lehman brothers, this is all getting a little nerve racking. and they have this shady thing over here. so we have to be careful. so if the market value is $1, what are they saying about the assets? or what are they saying about the equity? well, what's the market cap? it's the share price times the number of shares. so they're saying essentially that the market cap, and that's equivalent to the market value of the equity, or what the market thinks the equity is worth, that's $1 times 500 million shares. so it's worth $500 million. or $0.5 billion. so the market is actually saying, no, you don't have $2 billion of equity, you only have half a billion of equity. and it's probably because they think this is worth a billion and a half left. but anyway, we'll leave that aside for now. but now we're getting to the crux of the issue. two of those other loans, they came due, no-one was willing to renew the loans, or give them new loans. so the company had to liquidate some of their assets in order to pay those loans down. now, this is the endgame. we have loan c. and let's say loan c comes due. so they say, things are really shady, your assets they look very similar to lehman brothers and bear stearns, we're not going to renew your loan. you go out to the credit markets, you try to issue bonds, you try to do anything you can. no-one's willing to give you a loan, just because they're all a little bit scared. so what do you do? well, you have to pay $3 billion of loans. you just have to. because no-one's willing to give you $3 billion. well you say, out of this cash i can't use all of it. if i just wanted to operate bare-bones, maybe i could give $0.5 billion in cash. but that's not going to help my situation at all. because i still would have $2.5 billion left. so you're like, wow i'm in a situation where i have to sell these cdos. so now, all my models and all my assumptions are going to see if they were even vaguely accurate. if these things are really worth $4 billion. so i go out there and i try to sell my cdos. i try to sell them for whatever i can get for them, because i have to sell them. and one, there's no market for them. because there's a lot of people who want to unload them, but there's not really anybody who's keen on buying it. so there there might not even be any market. but you're like, no i want to sell them. so you broadcast it out to every hedge fund and private equity fund and every bank out there. and you say, who wants to buy my cdos? and some private equity firm comes and says, ok well, i think that those things are pretty toxic, but they're probably worth maybe something. i'm pretty optimistic about the real estate market. and maybe in 10 years they might come back. so i'm willing to give you $1 billion for those cdos. so essentially, what's the market price of something? it's the best price that someone's willing to give you for something. so the market price of this, because you've shopped it around, you've gone to the market, you've gone to everyone you can, the market price for this is, essentially, the market is offering you $1 billion for this cdo. so what do you do? well, if you sell it for $1 billion, does that help your situation? if you sell this for $1 billion, you get $1 billion here, you have $1 billion of cash, you have a total of $2 billion, that still won't pay your loan. you're still going to be bankrupt. and even more, the company management is very stubborn. they say, if i sell it i'm going to go bankrupt. and i think that that's some kind of fire sale price, quote-unquote. that's not the real price. all of a sudden for the first time in my career when i was getting $30 million a year bonuses, i heavily believed in the market. but now i'm in denial of the market. i say, the only reason why i'm only getting $1 billion for this is because everyone is afraid. and these things, if someone were to just hold them to maturity, if someone were to just hold these assets for the 30 years over which the underlying mortgages will just pay out, someone's going to collect roughly $4 billion. or maybe at worst, $3.5 billion. so i'm not going to do this. but really, you have no choice. so what you try to do is you say, well can someone give me some type of a loan? just lend me some money in the short term just so that i could get this paid off. and i'll be willing to give this as collateral. collateral on a loan is you give me a loan, and you take this as collateral, and if i don't pay the loan, you just keep the asset. and that's essentially what the fed was doing. the fed traditionally only gives loans if you give something really nice as a collateral, like treasuries, essentially just treasuries. and they'll still take a little discount of your collateral. like if you give the federal reserve $1 of treasuries, they might give you $0.80 of loans. but over this whole credit crunch, the fed has gotten looser and looser in terms of what it's willing to accept as collateral. so actually, the fed, i don't know the details of how toxic of an asset they were willing to take as collateral, but they started loosening it up to pretty toxic assets. so maybe you could get a loan. but let's just put that aside right now. but this is the situation we're facing. you have a bank, and it's essentially being forced, or it perceives it, forced into bankruptcy. even though, it thinks that it has positive equity. so you could get a loan from the fed or someone else if they're willing to take this kind of toxic stuff as collateral. let's assume that they're not for now. the other option is you can recapitalize. you can get someone to invest in the firm. you can sell equity in the firm and get some more cash to pay off this loan. if you can convince someone that no, your firm is really in the future going to be worth a lot more. this is just a stressful situation. so you go to some sovereign wealth fund, and that's just a way of saying some foreign government that's been collecting dollars because they've been selling us oil or cheap manufactured goods. so you go those and say, look, we are goldman brothers or we're lehman sachs. we are this great brand in the banking industry, wouldn't you like to have a piece of this thing that represents american capitalism? and they say sure, we'll be interested in investing. so they say, well the market price is $1 and i think that's probably a little distressed, so we'll be willing to pay $1.50 per share. and we'll buy, how much do you need? we'll buy 2 billion shares at $1.50 per share. so what happens? so let's say the sovereign wealth fund, they're going to buy 2 billion shares at $1.50 per share. so now what does the balance sheet look like? so 2 billion, $1.50 per share, that is equal to $3 billion. so now you get $3 billion more in cash, so this becomes $4 billion. but you can't get something for free, so what happened? are our liabilities increasing? well no, our liabilities didn't increase. they didn't give us a loan. they invested in us. they essentially bought shares of the company. they bought 2 billion shares. so how does that get accounted for? well instead of our share account being 500 million shares, this is how many shares we had before, the company essentially created 2 billion new shares. so now the company has 2.5 billion shares. and it's something interesting here. what is the new book value of the shares? so what are our total assets? $4 billion plus $4 billion, it's $8 billion of assets. our liabilities are still $3 billion. now the the value of our share after the investment, and you can kind of call this the post money valuation or book value, is $5 billion. $8 billion minus $3 billion. and now what's the book value of our shares? $5 billion divided by $2.5 billion, it's $2 per share. and that's interesting. it's someplace in between our old book value and the price that the company paid, or the sovereign wealth fund paid, $1.50 per share. but anyway, i just realized i'm out of time again, i'll continue this in the next video.",t_149082bfae17,other,0
c_820ebe2ec873,an appliation of linear systems involving two types of coins.,t_a2ba40c2b1db,other,0
c_0f91244ac5d4,"to get a better intuition about how much a consumer values a good in a market, we think of demand as a marginal benefit curve. in this video we look at the demand curve from a marginal benefit framework.  voiceover: in all of our conversations about demand curves so far, i've been generally talking about price driving quantities. so for example, we've been saying, using say this demand curve right here for a new car in terms of how many would be sold per day, we would say things like, ""well look, if we price it at $60,000 per car,"" this is in thousands of dollars. ""if we price it at $60,000 per car, ""we are going to sell one car. ""if we price it at $50,000 a car, ""we are going to sell two cars."" the way that i've been talking about it is given a price, how many are we actually going to sell? what i want to do in this video is think about it the other way around. we're going to look at the exact same demand curve, the exact same relationship between price and quantity, but we're going to conceptualize it in our heads in a slightly different way. we're going to think about it in terms of quantity driving price. to think of it that way, imagine that we are the producers of this given model of a new car. we go the other way. we don't say, ""how many will we sell ""at a price of $60,000?"" or, ""how much will we sell at a price of $50,000?"" we'll go from the point of view of what if we only produce one car a week? if we only produced one car a week, how much could we get for that car? let's say somehow you're able to figure that out. you're able to read people's minds or you have some type of a market study. when you ask that question you're like, ""look if you only allowed one car to be sold each week, ""you determine that in that week there ""is going to be somebody, ""somebody's going to think that it's worth ""$60,000 to buy that car."" that person, they're willingness to pay, that person is going to be willing to trade $60,000. they're going to be willing to forego what else they could have bought for that $60,000 and instead they want that car. then you would plot that point right over there. if you only had one unit, you could sell it for $60,000. now let's go, let's keeping asking ourselves for more units. let's say, what if we wanted to sell two units? well, if you wanted to sell two units, you could definitely sell one unit for $60,000, assuming that you could get that first person, but that second person, this might have been the person that just wants a car so badly it just resonated with them in some way. for that second unit, the second person who is going to need to buy your car, might not be as excited about it. that second person will only be willing to forego $50,000. that second person would be willing to forego 50. so if you wanted to sell two units, if you insist on selling two units, and if you're assuming you're going to give the same price for everyone. we'll talk about in the future how you might give different prices to different people. assuming you want to give the same price to everyone, you're going to have to sell your car for $50,000. now clearly that first person is definitely going to jump at it. they're going to be able to get the car for more than they were willing to pay. more than what it was worth to them. more than the benefit for them, but if you want two people, now you're going to have to set this up for $50,000. now the same logic. now what if we want to sell three cars? what if we want to sell three cars a week? well, if we price it at $50,000, we'll definitely get those first two, but the third person might not jump. the third person isn't going to be as excited about it or need it as much as these first two. so you do a market study or you're able to read people's minds. you're like, ""look the third person, ""for the market, the marginal benefit."" let me write this word down. the marginal benefit. the marginal benefit for the next unit, the next unit is going to be $40,000. to get that next buyer, and it could be multiple buyers buying each unit or it could be one buyer buying all of the units. maybe it's some type of a car rental company saying, ""oh, we don't need to get ... for three ""of these cars i'm not as excited about it anymore. ""my marginal benefit is lower."" this is really the same marginal benefit that we talked about when we talked about the ppf, the production possibilities frontier. in that, we talked about it very explicitly in terms of trade off, in terms of opportunity cost. here we're measuring the marginal benefit in terms of price, but price really can be viewed as a foregone opportunity. if you spend $40,000 on this car, you're making the decision not to spend $40,000 on something else. a down payment on a house or a nice boat, or whatever else it might be. so really what we're doing, is at any point in this curve, this really is the marginal benefit for that next buyer. that marginal benefit to the market of that next unit of whatever you are producing. this is a very different way of viewing the exact same demand curve. before we said, ""okay, if we want to price ""it at $50,000, how many are we going to sell?"" now we're saying, ""if we want to sell only two units, ""where can we price it?"" we can price it at $50,000. if we want to go from two to three units, we're going to have to price it at the marginal benefit of that third unit to the market and it could be the marginal benefit to that next consumer. convincing that next consumer to say, ""hey it is worth it to buy this car. ""let's price it at $40,000."" i'm going to leave you there in this video, but what i'm going to think about is depending on where you price it, let's say that we decide that we want to sell four units every week. so we say, ""well look, to get that fourth ""person to buy this car, we have to price the car ""at $30,000."" what we're going to talk about in the next video is if you did that, if this is where you decide to price it so that you can sell four units, these other people got really good deals. the first unit could have gone for much more. the second unit could have still also gone for a good bit, not as much as the first unit. the third unit could have gone for a little bit less than the second unit, but still more than what you ended up selling things for. we're going to talk about this idea right over here that some of these consumers are getting more for their money than what they have to pay, or at least in their own minds they are.",t_bd0747d2f45c,other,0
c_6146a60faa13,"deriving and using the expected value (mean) formula for binomial random variables  - [tutor] so i've got a binomial variable x and i'm gonna describe it in very general terms, it is the number of successes after n trials, after n trials, where the probability of success, success for each trial is p and this is a reasonable way to describe really any random, any binomial variable, we're assuming that each of these trials are independent, the probability stays constant, we have a finite number of trials right over here, each trial results in either a very clear success or a failure. so what we're gonna focus on in this video is well, what would be the expected value of this binomial variable? what would the expected value, expected value of x be equal to? and i will just cut to the chase and tell you the answer and then later in this video, we'll prove it to ourselves a little bit more mathematically. the expected value of x, it turns out, is just going to be equal to the number of trials times the probability of success for each of those trials and so if you wanted to make that a little bit more concrete, imagine if a trial is a free throw, taking a shot from the free throw line, success, success is made shot, so you actually make the shot, the ball went in the basket, your probability is, use this yellow color, your probability, this would be your free throw percentage, so let's say it's 30% or 0.3 and let's say for the sake of argument, that we're taking 10 free throws, so n is equal to 10, so this is making it all a lot more concrete, so in this particular scenario, your expected value, your expected value, if x is the number of made free throws, after taking 10 free throws with a free throw percentage of 30%, well, based on what i just told you, it would be n times p, it would be the number of trials times the probability of success in any one of those trials, times 0.3, which is just going to be, of course equal to three. now does that make intuitive sense? well, if you're taking 10 shots with a 30% free throw percentage, it actually does feel natural that i would expect to make three shots. now with that out of the way, let's make ourselves feel good about this mathematically and we're gonna leverage some of our expected value properties, in particular, we're gonna leverage the fact that if i have the expected value of the sum of two independent random variables, let's say x plus y, it's going to be equal to the expected value of x plus the expected value of y, that we talk about in other videos and so assuming this right over here, let's construct a new random variable, let's call our random variable y and we know the following things about y, the probability that y is equal to one is equal to p and the probability that y is equal to zero is equal to one minus p and these are the only two outcomes for this random variable and so you might be seeing where this is going, you could view this random variable, it's really representing one trial, it becomes one in its success, zero when you don't have a success and so you could view our original random variable, x right over here as being equal to y plus y and we're gonna have 10 of these, so we're gonna have 10 ys, in the concrete sense, you could view the random variable y as equaling one, if you make a free throw and equaling zero, if you don't make a free throw, it's really just representing one of those trials and you can view x as the sum of n of those trials, well now actually, let me be very clear here, i immediately went to the concrete, but i really should be saying n ys, 'cause i wanna stay general right over here, so there are n, n ys right over here, this was just a particular example, but i am going to try to stay general for the rest of the video, because now we are really trying to prove this result right over here, so let's just take the expected value of both sides, so what is it going to be? so we get the expected value of x, of x is equal to well, it's the expected value of all of this thing, but by that property right over here is going to be the expected value of y plus the expected value of y plus, and we're gonna do this n times, plus the expected value of y and we're gonna have n of these, so we have n and so you could rewrite this as being equal to, this is our n right over here, this is n times the expected value of y. now what is the expected value of y? well, this is pretty straightforward, we can actually just do it directly, the expected value of y, let me just write it over here, the expected value of y is just the probability-weighted outcome and since there's only two discrete outcomes here, it's pretty easy to calculate, we have a probability of p of getting a one, so it's p times one plus we have a probability of one minus p of getting a zero, well, what does this simplify to? well, zero times anything, that's zero and then you have one times p, this is just equal to p, so expected value of y is just equal to p and so there you have it, we get the expected value of x is 10 times the expected value, or the expected value of x is n times the expected value of y and the expected value of y is p, so the expected value of x is equal to np, hope you feel good about that.",t_18cbe65a1c2b,other,0
c_84ac9e3afd99,"a look at why the ""proof"" of the relation between changes in gibbs free energy and spontaneity is wrong in many textbooks.  in the video that i just did, where i try to more rigorously prove the gibbs free energy relation, and that if this relation is less than zero then this is spontaneous. i took great pains to make sure that we use the proper definition of entropy. that every time that we said, ok, a change in entropy from here to here is the heat absorbed by a reversible process divided by the temperature at which it was absorbed. and the change in entropy of the environment is the opposite of that and, of course, that is equal to zero. and i was very careful to use this definition. and so you might have been asking, hey sal, there's a much simpler definition or proof in my textbook. and i don't if it's in your textbook, but it's in some of the ones that i've seen and in some of the web pages i've looked at. where they use a much simpler argument that gets us eventually to this gibbs free energy relation. and i thought i would go over it because as far as i can tell, it's incorrect. and what the argument tends to go, is it says, look, the second law of thermodynamics tells us, that for any spontaneous process, that delta s is greater than zero. i agree with that completely right now. and in order for delta s, and that's delta s of the universe, is greater than zero. and that means that delta s of the system plus dealt s of the environment is going to be greater than zero. and then this is the step that you'll often see in a lot of textbooks and a lot of websites that i disagree with. they'll say delta s of the environment is equal to the heat or, let me say, the heat absorbed by the environment, divided by the temperature of the environment. and let's just say for simplicity that everything here it's in some type of temperature equilibrium. and it tends to be when we're dealing with stuff in our chemistry sets in our labs, whatever else. but the the reason why i disagree with this step right here, that you see in a lot of textbooks, is that this is not saying anything about the reversibility of the reaction. you can only use this thermodynamic definition of entropy if you know this heat transfer is reversible. and when we're doing it in general terms, we don't know whether it's reversal. in fact, if we're saying to begin with that the reaction is spontaneous, that means by definition that it's irreversible. so this is actually an irreversible transfer of heat, which is not the definition of entropy. the thermodynamic definition of entropy is a very delicate one. you have to make sure that it is a reversible reaction. obviously, in a lot of first year chemistry classes this doesn't matter. you're going to get the question right. in fact, the question might be dependent upon you making this incorrect assumption. so i don't want to confuse you too much. but i want to show you that this is not a right assumption. because if you're assuming something is spontaneous, and you're saying, ok, the change in entropy in the environment is equal to the amount of heat the environment absorbs, divided by t-- this is wrong because this is not an irreversible reaction. but let's just see how this argument tends to proceed. so they'll say, ok, this is equal to delta s of our system plus the change in heat of our environment, divided by the temperature of our environment. they'll call this for the environment, and that of course has to be equal to zero. and they'll say, look, the heat absorbed by the environment is equal to the minus of the heat absorbed by the system. right? it's either the system is giving energy to the environment or the environment is giving energy or heat to the system. so they are just going to be the minus of each other. so the argument would go, well this thing i can rewrite. this equation is the change in entropy of the system, instead of writing a plus q of the environment here, i could write a minus q of the system over t is greater than zero. and then they multiply both sides of this equation by t and you get t delta s of the system minus the heat absorbed by the system is greater than zero. you multiply both sides of this by negative one and you get the heat absorbed by the system minus the temperature times the change in entropy of the system is greater than zero-- i'm sorry, is less than zero when you multiply both sides by a negative, you switch the signs. and then if you assume constant pressure, this is the change in enthalpy of the system. so you get the change in enthalpy minus the temperature times delta s of the system is less than zero. and they say, see this shows that if you have a negative gibbs free energy or change in gibbs free energy, then you're spontaneous. but all of that was predicated on the idea that this could be rewritten like this. but it can't be rewritten like that, because this is not a reversible process. we're starting from the assumption that this is a spontaneous irreversible process. and so you can't make this substitution here. and that's why in the earlier video i was very careful not to make that substitution. i was very careful to say, oh, you know, the change in entropy of an irreversible system that goes from here to here is the same as the change in entropy as an irreversible system that goes from there to there. or let me say this differently. the change in entropy of a reversible system from there to there is the same as an irreversible system from there to there. although you don't know what goes on in between for the irreversible. and so that's why i made this comparison. this thing, and this thing are the same, but then we compared the heat absorbed by an irreversible system, and we showed that it's less than the heat absorbed by a reversible system because it's generating its own friction. and from that, we got this relation, which we were able to then go and get the gibbs free energy relation. so, anyway, i don't want to make a video that's too geeky or too particular, or kind of trying to really pick at the details. but i think it's an important point to make because so much of what we talk about, especially in thermodynamics, is our definition of entropy. and it's very important we use the correct one, and we don't take what i would argue are incorrect shortcuts, because this is not the definition of entropy right there.",t_bc52aeea0c10,other,0
c_0bc4dfc21164,"rectangular waveguides are used to route millimeter-wave signals and high power microwave signals. the rectangular waveguide, often called just waveguide, shown in figure \(\pageindex{1}\) has metal walls forming a rectangular pipe. charges and currents induced in the conductive walls guide propagating em fields in the \(+z\) and \(−z\) directions. the rectangular waveguide has very little loss compared to a coaxial line because the em field is away from the walls and there is little current in the walls, and what is there is spread out resulting in low current density. all of the waveguide loss, as with the loss of most transmission systems, is resistive loss so minimizing current density minimizes loss.  this chapter begins with section 6.2 where symmetries and restricting  figure \(\pageindex{1}\): rectangular waveguide.  figure \(\pageindex{2}\): parallel-plate waveguide.  propagation to only the \(±z\) direction are applied to maxwell’s equations to yield the rectangular wave equation. these are then used in section 6.3 to describe propagation between two metal planes forming what is called a parallel-plate waveguide, see figure \(\pageindex{2}\). then the rectangular wave equations are applied to a rectangular waveguide in section 6.4 to derive the field distribution inside a rectangular waveguide.",t_784b97f6418a,other,0
c_777ec59122fc,"how to write rate laws for unimolecular and bimolecular elementary reactions.  - [voiceover] let's say we have a simple elementary reaction where we have only one reactant, a, turning into our products. we can classify this reaction according to its molecularity, which refers to the number of participating molecules. so if we think about one molecule of a giving us our products, this would be a unimolecular reaction. we have only one molecule, so we call this a unimolecular reaction. next let's think about writing the rate law. so we know when we're writing rate laws, we write the rate of our reaction is equal to the rate constant k times the concentration of our reactants. and here we have only one reactant, so we say times the concentration of a. for the exponents, we can actually take the coefficient in our balanced equation and turn that into the exponent. so we have a one here for our coefficient, so we make that a one right here. so you can only do this for an elementary, one-step reaction. you can't do this for an overall equation with a detailed mechanism like we'll see in the next video. but for these elementary reactions, you can do this. so the rate of our reaction is equal to the rate constant k times the concentration of a to the first power. so for this unimolecular reaction, it's first order in a. next, let's look at another reaction. a, one molecule of a plus one molecule of b gives us our products. here we have two molecules, two participating molecules. so this is a bimolecular reaction. so i write bimolecular here. so we can think about these two molecules colliding in space. so molecule a is going to collide with molecule b to give us our products. and so it makes sense that the rate of the formation of our products depends on how frequently a and b collide. and that depends on the concentration of a and b. if you increase the concentration of a and b, you increase the frequency of collisions, and therefore you increase the overall rate of your reaction. so when you write your rate law, so the rate of our reaction is equal to the rate constant k times the concentration of a, and since this is an elementary, one-step reaction, we can take the coefficient and turn that into our exponent. so times the concentration of a to the first power, times the concentration of b, and once again, we can take our coefficient, which is a one, and turn that into our exponent. and so now we have the rate law for this bimolecular reaction. let's look at another bimolecular reaction. this time we have two molecules of a reacting to give us our products. so we could say that this is a plus a gives us our products or we could say that this is two a gives us our products. so either one. if we stick with the first version, we have a one for our coefficient here, and a one for our coefficient here, and so we write the rate law for this bimolecular reaction, the rate is equal to the rate constant k times the concentration of a and we look at our coefficient here which is a one so we make that to the first power, and then times the concentration of a again, and once again we look at our coefficient and we turn that into our exponent. and so that of course will become, this will just be the rate is equal to the rate constant k times the concentration of a, this will be to the second power. a to the first times a to the first is equal to a squared. or we could have looked at our other version of writing it, a two a, and once again our coefficient would become our exponent. so this is another example of a bimolecular reaction. finally, let's look at a reaction where we have three participating molecules. so one a plus one b plus one c gives us our products. so one molecule of a plus one molecule of b plus one molecule of c. there are three participating molecules here so we call this a termolecular reaction. and for this to occur in one step, these would all have to collide at the same time. so if we had a, b, and c, they would all have to collide at this point in space at the same time. and this is rare if you think about it, trying to get three molecules to collide at once is pretty difficult to do. so these termolecular reactions are rare, but we can write the rate law. so the rate of our reaction is equal to the rate constant k times the concentration of a and we have a coefficient of one here so this is to the first power, times the concentration of b and once again this would be to the first power, and times the concentration of c and this would also be to the first power. so for these elementary rate laws, for these elementary reactions, we can take the coefficients and turn them into the exponents in our rate laws. once again, in this next video, you'll see that we can't do that, we can't look at an overall balanced equation with a detailed mechanism and just take the exponents and figure out the rate law. the rate law needs to be determined experimentally.",t_f27ea2f8a57e,other,0
c_a548370ebbfb,"histograms let you see the frequency distribution of a data set. learn how and when to use histograms to visualize data.  in this video we're going to talk about another way of visualizing data called the histogram, which is a very fancy word for a not so fancy thing. i think it's probably fair to say that the histogram is the most used way of representing statistical data. let me just show you how to figure out a histogram for some data, and i think you're going to get the point pretty easily. so i have some data here and i want to represent it with a histogram. what we're going to see is how frequent are each of these numbers. and in order to figure that out, let me just write the numbers down, let me just categorize them in their respective buckets. so i have a 1 here. i have a 4, so i want to leave space for the 2, the 3, and put a 4 there. i have a 2. i have a 1. let me put that 1 on a stack right above that 1. i have a 0-- let me put the 0 to the left of the 1. i want to put them in order. i have a 2, another 2. let me stack that above my first 2. i have another 1. let me stack that above my other two 1's. i have another 0. let me stack it there. i have another 1. then i have another 2. another 1. i have two more 0's. 0, 0. i have two more 2's. i have a 3. i have two more 1's. another 3. and then i have a 6. so no 5's, and then i have a 6. and that space right there was unnecessary. but right here i've listed-- i've just rewritten those numbers and i've essentially categorized them. now what i want to do is calculate how many of each of these numbers we have. so let me go down here. so i want to look at the frequency of each of these numbers. so i have one, two, three, four 0's. i have one, two, three, four, five, six, seven 1's. i have one, two, three, four, five 2's. i have one, two 3's. i have one 4, and one 6. so we could write it this way. we could write the number, and then we can have the frequency. so i have the numbers 0, 1, 2, 3, 4-- we could even throw 5 in there, although 5 has a frequency of 0. and we have a 6. so the 0 showed up four times in this data set. 1 showed up seven times in this data set. 2 showed up five times, 3 showed up to two times, 4 showed up one time, 5 didn't show up, and 6 showed up one time. all i did is i counted this data set, and i did this first. but you could say how many times do i see a 0? i see it one, two, three, four times. how many times do i see a 1? one, two, three, four, five, six, seven times. that's what we mean by frequency. now a histogram is really just a plot, kind of a bar graph, plotting the frequency of each of these numbers. it's going to look a lot like this original thing that i drew. so let me draw some axes here. so the different buckets here are the numbers. and that worked out because we're dealing with very clean integers that tend to repeat. if you're dealing with things that the exact number doesn't repeat, oftentimes people will put the numbers into buckets or ranges. but here they fit into nice little buckets. you have the numbers 0, 1, 2, 3, 4, 5, and 6. this is the actual numbers. and then on the vertical axis we're going to plot the frequency. so one, two, three, four, five, six, seven. so that's 7, 6, 5, 4, 3, 2, 1. so 0 shows up four times. so we'll draw a little bar graph here. 0 shows up four times. draw it just like that. 0 shows up four times. that is that information right there. 1 shows up seven times. so i'll do a little bar graph. 1 shows up seven times. just like that. i want to make it a little bit straighter than that-- 1 shows up seven times. 2-- i'll do it in a different color-- 2 shows up five times. do a bar graph, go all the way up to five. 2 shows up five times. 3 shows up two times. we have one 3, two 3's. 4 shows up one time here. 5 doesn't show up at all. so it doesn't even get any height there. and then finally, 6 shows up one time. so i'll do 6 showing up one time. what i just plotted here, this is a histogram. this right here is a histogram. very fancy word, but i think you will agree it's a fairly simple idea. figure out the frequency of each of these numbers and then plot the frequency of each of these numbers and you get yourself a histogram.",t_e78e087649c3,other,0
c_de439c18439f,"quick questions  you should be able to answer these questions without too much difficulty after studying this tlp. if not, then you should go through it again!  which of these factors do not influence the angle of repose taken up by a pile of granular particles?  ---------------- | a |    shape |  | b | friction |  | c |  density |  | d | cohesion |  ----------------  answer  c. density. shape is important - the more 'angular' the particles, the more likely the angle of repose will be higher. conversely, the more rounded the particles, the lower the angle of repose, all other factors remaining unchanged. friction is vitally important - without friction, even a simple arrangement such as a regular tetrahedron on a flat surface is unstable. cohesion is also important, and is particularly important if there is a steep angle to be maintained by a pile of granular particles, e.g., when building a sandcastle.  which of the following systems of granular materials exhibit dilatancy?  --------------------------------------------------------------------- | a | soil which when picked up from the ground is dry to the touch |  | b |                                                tomato ketchup |  | c |                                           sparkly nail polish |  | d | soil which when picked up from the ground is wet to the touch |  ---------------------------------------------------------------------  answer  d. soil which when picked up is dry to the touch has too low a water content to be able to dilate. when packed together, this type of soil will take in water to fill the pores between the grains of soil. shearing this soil will enable grains to move relative to one another so that the packing efficiency is improved and so there is a decrease in the overall porosity of the soil aggregate. tomato ketchup is a suspension of edible solids within water at a level typically of 25% by volume. it is a shear-thinning fluid, meaning that its viscosity decreases as it is sheared, in contrast to shear-thickening fluids such as dense wet sand, the viscosity of which increases as it is sheared. sparkly nail polish has a suspension of particles such as mica, biocl (bismuth oxychloride) and aluminium powder, but the amount of solids per unit volume in the fluid is too low to cause the phenomenon of dilatancy - nail polish is in essence a liquid containing small granular particles, rather than being a wet assembly of granular material.  inspired by this tlp, you purchase some corn starch and mix it with water in the ratio by volume of 1 part water to 2 parts corn starch to make a thick paste of corn starch which you pour into a large plastic container. the surface of the corn starch is then hit quickly with a rubber mallet so that the time of contact with the surface is 100 milliseconds or so. what happens to the surface of the corn starch?  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | a |                                                                                                                                                                                                                                                                                                                               the rubber mallet bounces back from the surface. everything happens too quickly to work out what is going on! |  | b | water retreats from where the impact is made by the rubber mallet because of the phenomenon of dilatancy, so that in this region the surface goes from shiny to matt after the hammer has struck. the rubber mallet causes a small impression in the corn starch which over time gradually disappears as water returns. eventually, the surface returns to being shiny and it is difficult to determine where the rubber mallet had struck. |  | c |                                                                                                                                                                                                                            the rubber mallet causes a mess everywhere because it has gone deep into the paste initially, causing paste to be ejected from the surface into the surrounding environment, and has then been forcibly removed. |  | d |                                                                                                                                                                                                                                                      the surface of the cornstarch is lowered where the rubber mallet has struck, but it returns to its initial state quickly. there is no change to the shininess of the surface anywhere. |  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  answer  b. however, this answer will be heavily dependent on making a sufficiently dense paste of corn starch. if the paste is not dense enough, so that the density of corn starch particles per unit volume is not high enough, the rubber mallet will be able to go deep into the paste and it will splash (answer (c)). answers (a) and (d) would suggest that you have not paid enough attention when undertaking the experiment!  deeper questions  the following questions require some thought and reaching the answer may require you to think beyond the contents of this tlp.  ginkaku-ji ('the silver pavilion') is a zen temple in kyoto, japan renowned for its meticulously maintained raked dry sand garden called ginshadan known as the 'sea of silver sand' next to which there is a massive 1.8 m high sand cone platform called kogetsudai said to symbolise mount fuji.  the 'angle of repose' of kogetsudai is impressively high, as are the angles of repose in ginshadan. which of the following are the most likely explanations for how these angles of repose are maintained?  a   the sand is highly angular, very cohesive and has a high coefficient of friction because it is unusually rough to enable the sand particles to form such steep structures.  b   moisture, e.g., water, is added to the dry sand daily to enable the structures to be maintained, just like the shapes of sandcastles can be maintained by adhesive forces generated by capillarity between grains.  c   the dry sand contains some cementitious binding agent such as cement, gypsum mortar or lime mortar cunningly disguised in the white sand.  d   the custodians of such dry sand gardens have secrets handed down to them by their predecessors over the years which science has yet to establish.  answer  all of the above, apart from (d). a variety of special rakes are used by custodians of dry sand gardens and is it evident that water is used in the process of designing and maintaining these gardens - see www.japanesegardening.org/reference/sand/ and http://www.japanesegardening.org/site/pushing-the-line-a-theoretical-approach-to-raking-a-karesansui-garden/ (http://www.japanesegardening.org/site/pushing-the-line-a-theoretical-approach-to-raking-a-karesansui-garden/), so that areas which require raking need only be raked on a weekly basis. therefore, the term 'dry sand garden' is somewhat of a misnomer. where there are steep sides to dry sand garden features such as at ginkaku-ji and at the sand mounds at honen-in, it would make sense not to have to alter the underlying shape of the features, so that the underlying shape is a rigid assembly of sand and cement, i.e., concrete, on the surface of which there is a relatively thin dusting of moistened sand raked into shape. custodians of these dry sand gardens clearly have expertise in maintaining them which can take time to learn, but which is explicable in terms of the science behind the art.  soil in an embankment is made progressively more wet by unusually heavy rain. what measures should be in place during the construction of the embankment and its subsequent maintenance to reduce the risk of possible failure of this embankment?  answer  this is a question which is of direct relevance to the construction of the levees which broke when hurricane katrina struck new orleans in august 2005. in constructing and maintaining a soil embankment a number of engineering problems require attention: the foundations, the nature of the material used to construct the embankment and the degree of compaction, the need for adequate drainage, the monitoring of erosion and the monitoring of pore water pressure. a relevant research paper on the levees which failed in new orleans is g. l. sills, n. d. vroman, r. e. wahl and n. t. schwanz, overview of new orleans levee failures: lessons learned and their impact on national levee design and assessment, j. geotech. geoenv. engng. 134, 556-565 (2008).",t_1870042fbd3d,other,0
c_e3df4d39eceb,"attempting to comprehend the scale of the large  the purpose of this video is to just begin to appreciate how vast and enormous the universe is. and frankly, our brains really can't grasp it. what we'll see in this video is that we can't even grasp things that are actually super small compared to the size of the universe. and we actually don't even know what the entire size of the universe is. but with that said, let's actually just try to appreciate how small we are. so this is me right over here. i am 5 foot 9 inches, depending on whether i'm wearing shoes-- maybe 5 foot 10 with shoes. but for the sake of this video, let's just roughly approximate around 6 feet, or around roughly-- i'm not to go into the details of the math-- around 2 meters. now, if i were to lie down 10 times in a row, you'd get about the length of an 18-wheeler. that's about 60 feet long. so this is times 10. now, if you were to put an 18-wheeler-- if you were to make it tall, as opposed to long-- somehow stand it up-- and you were to do that 10 times in a row, you'll get to the height of roughly a 60-story skyscraper. so once again, if you took me and you piled me up 100 times, you'll get about a 60-story skyscraper. now, if you took that skyscraper and if you were to lie it down 10 times in a row, you'd get something of the length of the golden gate bridge. and once again, i'm not giving you the exact numbers. it's not always going to be exactly 10. but we're now getting to about something that's a little on the order of a mile long. so the golden gate bridge is actually longer than a mile. but if you go within the twin spans, it's roughly about a mile. it's actually a little longer than that. but that gives you a sense of a mile. now, if you multiply that by 10, you get to the size of a large city. and this right here is a satellite photograph of san francisco. this is the actual golden gate bridge here. and when i copy and pasted this picture, i tried to make it roughly 10 miles by 10 miles just so you appreciate the scale. and what's interesting here-- and this picture's interesting. because this is the first time we can relate to cities. but when you look at a city on this scale, it's starting to get larger than what we're used to processing on a daily basis. a bridge-- we've been on a bridge. we know what a bridge looks like. we know that a bridge is huge. but it doesn't feel like something that we can't comprehend. already, a city is something that we can't comprehend all at once. we can drive across a city. we can look at satellite imagery. but if i were to show a human on this, it would be unbelievably, unbelievably small. you wouldn't actually be able to see it. it would be less than a pixel on this image. a house is less than a pixel on this image. but let's keep multiplying by 10. if you multiply by 10 again, you get to something roughly the size of the san francisco bay area. this whole square over here is roughly that square right over there. let's multiply by 10 again. so this square is about 100 miles by 100 miles. so this one would be about 1,000 miles by 1,000 miles. and now you're including a big part of the western united states. you have california here. you nevada here. you have arizona and new mexico-- so a big chunk of a big continent we're already including. and frankly, this is beyond the scale that we're used to operating. we've seen maps, so maybe we're a little used to it. but if you ever had to walk across this type of distance, it would take you a while. to some degree, the fact that planes goes so fast-- almost unimaginably fast for us-- that it's made it feel like things like continents aren't as big. because you can fly across them in five or six hours. but these are already huge, huge, huge distances. but once again, you take this square that's about 1,000 miles by 1,000 miles, and you multiply that by 10. and you get pretty close-- a little bit over-- the diameter of the earth-- a little bit over the diameter of the earth. but once again, we're on the earth. we kind of relate to the earth. if you look carefully at the horizon, you might see a little bit of a curvature, especially if you were to get into the plane. so even though this is, frankly, larger than my brain can really grasp, we can kind of relate to the earth. now you multiply the diameter of earth times 10. and you get to the diameter of jupiter. and so if you were to sit earth right next to jupiter-- obviously, they're nowhere near that close. that would destroy both of the planets. actually, it would definitely destroy earth. it would probably just be merged into jupiter. so if you put earth next to jupiter, it would look something like that right over there. so i would say that jupiter is definitely-- on this diagram that i'm drawing here-- is definitely the first thing that i have i can't comprehend. the earth, itself, is so vastly huge. jupiter is-- it's 10 times bigger in diameter. it's much larger in terms of mass, and volume, and all the rest. but just in terms of diameter, it is 10 times bigger. but let's keep going. 10 times jupiter gets us to the sun. this is times 10. so if this is the sun-- and if i were to draw jupiter, it would look something like-- i'll do jupiter in pink-- jupiter would be around that big. and then the earth would be around that big if you were to put them all next to each other. so the sun, once again, is huge. even though we see it almost every day, it is unimaginably huge. even the earth is unimaginably huge. and the sun is 100 times more unimaginably bigger. now we're going to start getting really, really, really wacky. you multiply the diameter of the sun, which is already 100 times the diameter of the earth-- you multiply that times 100. and that is the distance from the earth to the sun. so i've drawn the sun here as a little pixel. and i didn't even draw the earth as a pixel. because a pixel would be way too large. it would have to be a hundredth of a pixel in order to draw the earth properly. so this is a unbelievable distance between the earth and the sun. it's 100 times the distance of the diameter of the sun itself. so it's massive, massive. but once again, these things are relatively close compared to where we're about to go. because if we want to get to the nearest star-- so remember, the sun is 100 times the diameter of the earth. the distance between the sun and the earth is 100 times that. or you could say it's 10,000 times the diameter of the earth. so these are unimaginable distances. but to get to the nearest star, which is 4.2 light years away, it's 200,000 times-- and once again, unimaginable. it's 200,000 times the distance between the earth and the sun. and to give you a rough sense of how far apart these things are, if the sun was roughly the size of a basketball-- if the average star was about the size of a basketball-- in our part of the galaxy in a volume the size of the earth-- so if you had a big volume the size of the earth, if the stars were the sizes of basketballs, in our part of the galaxy, you would only have a handful of basketballs per that volume. so unbelievably sparse. even though, when you look at the galaxy-- and this is just an artist's depiction of it-- it looks like something that has the spray of stars, and it looks reasonably dense, there is actually a huge amount of space that the great, great, great, great, great majority of the volume in the galaxy is just empty, empty space. there's no stars, no planets, no nothing. i mean, this is a huge jump that i'm talking about. and then if you really want to realize how large a galaxy, itself, can be, you take this distance between the sun, or between our solar system and the nearest star-- so that's 200,000 times the distance between the earth and the sun-- and you multiply that distance by 25,000. so if the sun is right here, our nearest star will be in that same pixel. they'll actually be within-- you'd actually get a ton of stars within that one pixel, even though they're so far apart. and then this whole thing is 100,000 light years. it's 25,000 times the distance than the distance between the sun and the nearest star. so we're talking about unimaginable, unfathomable distances, just for a galaxy. and now we're going to get our-- frankly, my brain is already well beyond anything that it can really process. at this point, it almost just becomes abstract thinking. it just becomes playing with numbers and mathematics. but to get a sense of the universe, itself, the observable universe-- and we have to be clear. because we can only observe light that started leaving from its source 13.7 billion years ago. because that's how old the universe is. the observable universe is about 93 billion light years across. and the reason why it's larger than 13.7 billion is that the points in space that emitted light 13.7 billion years ago, those have been going away from us. so now they're on the order of 40 billion light years away. but this isn't about cosmology. this is just about scale and appreciating how huge the universe is. just in the part of the universe that we can theoretically observe, you have to get-- and that we can observe, just because we're getting electromagnetic radiation from those parts of the universe-- you would have to multiply this number. so let me make this clear. 100,000 light years-- that's the diameter of the milky way. you would have to multiply not by 1,000. 1,000 would get you to 100 million light years. this is 100,000 times 1,000 is 100 million. you have to multiply by 1,000 again to get to 100 billion light years. and the universe, for all we know, might be much, much, much, much, larger. it might even be infinite. who knows? but to get from just the diameter of the milky way to the observable universe, you have to multiply by a million. and already, this is an unfathomable distance. so in the whole scheme of things, not only are we pretty small, and not only are the things we build pretty small, and not only is our planet ultra small, and not only is our sun ultra small, and our solar system ultra small, but our galaxy is really nothing compared to the vastness of the universe.",t_f8d33c006053,other,0
c_a0d4465d1c1f,"it should be mentioned that linear maps between vector spaces are also called vector space homomorphisms. instead of the notation \( \mathcal{l} (v,w) \), one often sees the convention  \[  \mathrm{hom}_\mathbb{f} (v,w) = \{ t:v \to w \mid \text{ t is linear} \}. \]  a homomorphism \(t:v \to w \) is also often called  monomorphism iff \(t \) is injective;  epimorphism iff \(t \) is surjective;  isomorphism iff \(t \) is bijective;  endomorphism iff \(v=w \);  automorphism iff \(v=w \) and \(t \) is bijective.  contributors  isaiah lankham,  (http://www.math.ucdavis.edu/%7eissy/contact_info.html)mathematics department at uc davis (http://www.math.ucdavis.edu/)  bruno nachtergaele,  (http://www.math.ucdavis.edu/%7ebxn/)mathematics department at uc davis (http://www.math.ucdavis.edu/)  anne schilling,  (http://www.math.ucdavis.edu/%7eanne/)mathematics department at uc davis (http://www.math.ucdavis.edu/)  both hardbound and softbound versions of this textbook are available online at worldscientific.com. (http://www.worldscientific.com/worldscibooks/10.1142/9808)",t_5880dd399363,other,0
c_96275b125848,"an overview of the different types of evidence that support evolution, including homologous and analogous features and vestigial structures.  - [voiceover] we've done many videos on khan academy on evolution and natural selection explaining them, but i thought i would do a video going a little bit more in depth in evidence for evolution and natural selection. and i started with this quote ""nothing in biology makes sense except in the light of evolution."" this is by theodus dobzhansky, who's a famous biologist, he's passed away now, and what he's saying is absolutely true and this is why it's so important to appreciate the evidence for evolution and natural selection and to understand them, because before the theory of evolution, biology was just about observation and classification without having a cohesive narrative for how all of this came about. and since darwin had come up with this theory in the mid-19th century, we've had far more tools to back it up beyond just the observations we had up until that point. we have our tools around dating and the fossil record, which gives us much more evidence. we have our tools of microbiology and genetics, which gives us even stronger evidence, so a lot of times people say ""oh, it's a theory, evolution ""is it just a theory?"" well, it's about as strong as theories get and without it, as theodus dobzhansky said, biology as we know it and all of the progress we've made in biology frankly wouldn't make any sense and probably would not have happened. now i'm going to broadly go into three types of evidence in this video for evolution and natural selection. the first is structural. and these are the types of things that folks like darwin would have observed, that people have been observing in biology for a long time but evolution and natural selection starts to make a lot more sense of it, and here we're talking about the macro structure, things that we can for the most part observe with our eyes or with a very simple microscope. the next level is what we've learned, really over the last 100 or so years, at the micro level, in microbiology. microbiology and especially in genetics. so this has really firmed up the theory of evolution. and then the last dimension we'll look at is direct observation, direct observation, and this is really where it goes beyond a theory. we are seeing it happen. a lot of times people say ""oh, it's a theory, ""you know, the theory says it happened over tens ""of millions of years but no one was around to really ""observe, even if we see a lot of evidence, no one ""knows if it for sure happened."" but if you're directly observing things, well you know it's for sure happening and as we'll see, evolution does not only occur over time scales of millions or tens of millions of years, it actually can occur and we see it occurring all the time on scales well within a human observational capacity, within just a matter of months or years. so let's go through each of these. so first let's talk about structural and this is a very high-level overview. i encourage you to do more research on it. you will find loads and loads and loads of any type of this evidence. so the first thing i want to talk about is homologous structures, homologous structures, that you see throughout the biological world. hom-ol-o-gous, homologous structures. and the word homologous means things that have similar structure, similar position, similar ancestry but not necessarily the exact same function. and here you see examples of a, well as a human, we would consider a forearm. you see the human forearm and wrist and then you see the homologous structures in dogs and birds and whales. and even though this part of those animals have very different functions, a human does not walk on its hands for the most part; a dog does walk on its front legs; a bird isn't walking at all, it's using them to flap its wings; and a whale, this is making up its actual fins, it's using them to propel or to control their movement inside of the water. and even though they have these very, very different functions and at first when you look at a human and a bird and a whale on the outside, they might look reasonably different, when you look at these bone structures, they are eerily similar, especially color-coded the way it is. so these are, this is a very strong hint that maybe humans, dogs, birds, and whales share a common ancestor, more recently in the past than say other animals or organisms, i should say, that don't have, whose structures aren't as homologous as these are right over here. and if you were independently trying to create structures for what each of these different species are doing, it's not obvious that you would have such homologous structures actually be involved. now these are all species that exist today, these are all species that exist on the planet at the same time, but we also see structural evidence by going into the fossil record. in the last few hundred years, or early in the last hundred years is where we've gotten really good at it, we've gotten good at looking at different layers of rock strata and being able to date them and say ""okay, that layer was laid down x-million ""years ago, that layer was laid down a little bit ""more recent, this one was even more recent,"" and then looking at fossils within that to say ""okay, 20 million years ago there were species ""around that looked something like that, ""and then 10 million years ago there were species ""that looked like that."" and one example is if you look at a horse-like animal. so this is right over here, we're talking about horses, zebras, donkeys, mules, things like that, the modern ones, well this is their bone structure but if you look at the fossil record from 12 to 5 million years ago, you see fossils that look like this and they're very close so you see, it's very believable that you could have evolution from this to that, but then you go further back and once again, it draws, it seems like a very gradual process. and once again, this happening over, these are from 12 to 5 million years ago, these are from 16 to 12 million years ago, these are from over 34 million years ago. and so you can see how this is happening at a very, very gradual pace and the mechanism, and we go into some depth in other videos in khan academy, you have variation in species, you have the environment selecting for it. the environment might change or different things happen so you have different forms of selection, different types of combinations sprout up, they're more suitable for the environment, they start to reproduce better, they become the dominant species or they take over certain parts of a niche or an ecosystem, and so you have this change, this heritable change of traits over time. and so when you look at the fossil record, it makes a lot of sense that, okay, this is strong evidence for evolution, that the animals that we see today weren't just put on, just created all of a sudden and haven't changed since then, but there's a constant change and we can see it directly through the fossil record. now the next point of evidence, i will put a bit of a caveat because the gentleman who first created this, his name was haeckel, he was a controversial figure, he had some spurious theories, and even this diagram that he created, it seems like he fudged a little bit of the drawings in order to make a stronger argument, but even with modern observations, these drawings are pretty close to being correct. and it's very, very compelling. it shows the embryonic development of a whole series of species, from a fish on the left to a reptile to birds to mammals and another mammal, to non-human mammals and, of course, to humans. and you can see at the early stages, they look eerily similar. in fact, you see proto gill slits in all of these animals, which later differentiate into things that are more suitable for what that animal actually becomes. and haeckel, he's the guy who claimed ontogeny recapitulates phylogeny, which is a very fancy way of saying that your embryonic development is telling the story of the evolutionary path, which isn't true, but you'll even hear people quote that today. but his drawings and his observations, this is compelling evidence for life sharing a common ancestry, coming from similar origins that got more and more different over time through the process of natural selection. so everything i've talked about so far has been kind of macro structure, things we can observe. the next thing i'm gonna talk about is, you can think about as micro structures or processes, and this is microbiology. microbiology... biolo, biology... microbiology. and the more we understand about microbiology the more compelling case of evolution because when we look at even one, all life forms that we know, they involve dna. how the dna gets replicated and translated and transcribed is very similar from one life form to another. the idea of dna going to, dna coding for proteins, proteins, that are made up of amino acids is something that we see throughout biology. amino acids, which once again hints at a common ancestry. and not only are those molecular and many of the very proteins are very, very similar, more similar than if you look at the macro level or even at the structural level between different species, and not just do they share these common microstructures and processes, but the actual information stored in things like dna also are very, very strong evidence for evolution. so this is a picture, i got this from, i got this from the site, i should give proper credit, 23andme.com. but this and you'll see other data like this that's very similar to this, which is how much genetic similarity do we have between different species, and these numbers tell us how much genetic similarity at a high level do we have with chimpanzees, mice, fruit flies, yeast, and plants. and the fact that we have 26% of our genes in common with yeast is mind-blowing because at a macro level it doesn't seem like there's a lot in common with yeast, but when you get at a microbiological level, there's a good bit that's in common with yeast. and chimpanzees, we do relate to them, their facial expressions often feel eerily human, their behaviors often feel eerily human, but their genes, so just how close to human beings they actually are. and this actually shows that even mice are way closer, if you look at the entire tree of life based on genetic evidence, things like mice and even fruit flies are awfully close to human beings, especially if you were to compare it to bacteria or a plant. but once again, you share all of these common processes and the fact that we can now measure how far things are away allows us to create a very accurate tree of life, and especially thinking about how far in the past we had evolutionary common ancestors. now the last thing that i promised i would talk about is direct evidence, direct evidence of evolution, and i talk about this in the first evolution video, but the direct evidence we see all the time with things like bacteria where you have bacteria, let's say growing around, and we have antibiotics that we use in our body to kill bacteria, but the reason why many physicians and scientists will tell you ""don't ""overuse antibiotics"" is because the more you use it, it causes a very strong natural selection process for bacteria that are going to be resistant to that antibiotic. so if you keep using an antibiotic and the bacterias keep changing, there's more and more variation, well you're gonna kill a lot of the bacteria but if even one of them is resistant to that antibiotic that you use, well then all of its competition is gonna get killed and so that drug-resistant superbug, it's often called, is going to be able to go nuts and that antibiotic isn't going to be able to do anything. and if you look at science today or you look at medicine today, this is kind of an arms race. you have this constant need to create new antibiotics because more and more bacteria are becoming drug-resistant, they're becoming what's often called superbugs, where they are resistant to the existing antibiotics. and this is evolution, natural selection, happening on a human scale. you could also think about the flu virus where every year that vaccine for the flu virus, you gotta get a new one every year because the virus is changing. your immune system's ability to recognize it can't recognize the next year's because it's changed so much.",t_7971d1431965,other,0
c_cbcdb84291ab,"why warren buffett called credit default swaps financial weapons of mass destruction  let's think a little bit about why credit default swaps, or famously referred to by warren buffett as financial weapons of mass destruction. at the center of it-- and there's not just one credit default swap writer, but i'll put one in the middle because each of them are writing many, many credit default swaps. aig is the most famous. but you have some writer here. they're given some good credit rating. maybe in the past that credit rating was actually earned by a credit rating agency. and then frankly, the credit rating agency got a little sloppy and really wasn't willing to downgrade them given all of the credit default swaps, all of the obligations they are taking on. and as you could tell, i kind of view these guys and these guys as the main culprits, and maybe a little bit of the regulatory agencies saying, hey, look, these guys are writing insurance. maybe we should actually regulate them. but with that said, you have companies over here. i'll do the companies in this pink color. and they want to borrow money from other parties, let's say, investors. i'll do the investors in this orange color. so the investors are lending them money. the companies give them interest. so investors lending money, giving interest, lending money, giving interest, lending money, giving interest. and then these investors-- it seems pretty reasonable-- say, hey, look, there's a guy over here with a double a rating. the people that we're lending to don't have a double a rating. maybe this guy has a b, maybe this guy has a double b, maybe this guy only has a single a. and so he says, look, i want to be completely safe here so i'm going to pay a little bit of a premium to aig or to the writer, whoever the writer is, and in exchange i will get insurance on this debt. and it seems pretty reasonable except for the fact that this player right over here did not put out any money aside or did not put the appropriate amount of money aside to properly account for all of these liabilities, all of this risk that its taking on. and also, all of these risks are correlated. you can imagine a situation where the economy goes bad. now, all of a sudden this company defaults on its debt and this company defaults on its debt. in fact, when the economy's good, it's likely that very few of these companies are going to default and when the economy goes bad, it's likely that many of them will default. but the real problem is is as soon as these defaults start happening, then the credit default swap writer is going to have to actually start paying for the defaults. they'll get the bad debt and in exchange they'll make the other side of the credit default swap, the holder of it, they will pay to make them whole. and so this could take them out of business. and all of a sudden, the people over here who thought that they had insurance no longer do. and they might actually say, wait, i can only hold double a debt and they might actually have to dump this debt on to the market. even worse, you have all of the people over here who didn't lend any money to anybody, but they really just wanted to make side bets. either the side bets might have been pure directional bets on the state of the economy saying, hey, i think a bunch of companies or i think this company in particular is going to default on its debt, and they too could get credit default swaps really as just side bets. so just for maybe this right here is $1 billion in debt, maybe all of these parties took side bets on this guy. so even though there's only $1 billion of debt here, there might be $4 or $5 or $10 billion worth of insurance on that $1 billion bet. so if all of a sudden this one company can't pay its $1 billion, now aig is on the line not for $1 billion, but for $4 or $5 or $6 billion, however much it insured it for. so it allows people to insure for things that they don't have the offsetting liability for. and so you can imagine, some of these people-- if this guy fails will just take a loss and that's bad and all of the rest because they were expecting that they wouldn't-- but some of these players might have had offsetting hedges. the only reason why they might have felt comfortable taking on some other liability is they said, look, if the economy goes really bad, i have this insurance over here. and they did that transaction with another third party. now all of a sudden, if the economy goes bad and these guys say, hey, look, i'm in a lot of trouble. good thing i have this credit default swap, but then it turns out that they don't because the counterparty here fails, the credit default swap writer, now all of a sudden this guy becomes insolvent. but this guy was dependent on this guy paying and he thought he was good because he even looked at this guy's books and said this guy had offsetting hedges, and now this guy might fail. and so you could have this entire cascade through the entire financial system.",t_7a6eeaf0ec8e,other,0
c_ee0e3dcccaf6,a word problem that involves a formula that contains a square root.,t_5259ba536eb6,other,0
c_6310efbca803,"voiceover: so we're gonna take a look at a branch of psychology called social psychology. so we're placed in different situations each and every day, so you can't dismiss the fact that these situations affect our behavior. this is a situational approach to behavior. and theorists place the situational approach to behavior under a branch of psychology called social psychology. so social psychology is a branch of psychology concerned with how social phenomena influences us, and how people interact with others. so it focuses on the interaction between an individual in his or her environment. so this is us in our environment, and this interaction is going to shape our behavior. so in many instances, people behave very differently, depending upon their situation. so behavior is seen as being influenced by external situational factors rather than internal traits or motivations. so, external is a very important word, external or situational factors. so in this theory, or explanation, so to say, it's hard to predict someone's behavior based off of just one situation. because, that one situation isn't going to be really predictive of how they'll act or be in another situation. that's the beauty of this situational approach, is that, depending on the situation, the behavior may change. that's the assumption we need to go in with. and as social creatures, we humans base judgments and ideas about others simply off the situation in which that person behaves. but we also acknowledge, and it's important to do this, that sometimes we behave in ways that deviate from our typical character in differing situations. it's kind of like saying, you can't judge a book by its cover. an attribution is the process of inferring the causes of events or behaviors. so attribution has two parts to it but we're going to focus on one part. so attribution can either be internal or it can be external and the external, is what we're going to be focusing on today. so, over the course of a day, or let me step back a bit. attribution, i said, is the process of inferring the causes of events and behaviors, and it's something that we do everyday without even really realizing that we're doing it. so, over the course of a day we probably make tons of attributions about our own behavior, as well as that of the people around us. so, the concept of attribution is actually much more complex, but since we're gonna focus on the external. we'll break that part down. so the external attribution is the inference that a person is behaving a certain way because of something about the situation he or she is in. so, external attribution has three main parts. and the first is consistency. so, now we're looking at external situational, circumstances, we're looking at consistency, so does the person usually behave this way in this situation? and the second is distinctiveness. now distinctiveness in this case is does the person behave differently in different situations or is this particular situation distinct. and the last is consensus. so, do others behave similarly in this situation? now, if we can confidently answer yes to this second two questions, so the ones that regard distinctiveness and consensus, so if we can say yes to does the person behaves differently in different situations. and do others behave similarly in the situation? then we can come to the conclusion that the person is behaving in a particular way due to their situation. so here we can say the situation is having an effect on their behavior. now if the person usually behaves the same in new situation, then you know that their behavior is not really affected by that situation, since they're consistent. so if we answer yes to this one, then we know that maybe their behavior isn't totally dependent on the situation. if it's going to be consistent from situation to the next situation to the next situation. maybe that is more of an internal attribution. so, pretend you're at the zoo with your very calm and reasonable best friend, and you head over to the snakes exhibit. and although your friend doesn't like snakes, she calmly takes the time to look at them and read about all the different kinds of snakes out there. now one day, you have this genius idea to decide to bring a pet cobra to her house. and the second she walks in the door, she screams and freaks out and runs out, and you are totally bewildered. you have no idea what to do. well, what can we conclude? i mean i wouldn't say your best friend is always frantic. but clearly based on the distinct situation she was placed in, she's going to behave differently. so, in the zoo, the snakes are all caged up. she's obviously comfortable, she knows the snakes are not going to come at her. but the second you brought it into her living room, in a different situation, she felt like her safety was being endangered. so she's going to act differently in that situation. so moral of the story: situational approaches teaches more about a person the more time we spend with them and see them in different circumstances. and also, don't ever bring a snake that close and in the open to your best friend's house.",t_1bdf6b992fb2,other,0
c_dc361265719b,"sal uses fractions to name parts of a whole.  i have a square here divided into one, two, three, four, five, six, seven, eight, nine equal sections. and we've already seen that if we were to shade in one of these sections, if we were to select one of these sections, let's say the middle one right over here, this is one out of the nine equal sections. so if someone said, what fraction of the whole does this purple square represent? well, you would say, well, that represents 1/9 of the whole. this thing right over here represents 1/9. now what would happen if we shaded in more than that? so let's say we shaded in this one and this one, let me shade it in a little bit better. and this one and this one right over here. now what fraction of the whole have we shaded in? well, each of these, we've already seen, each of these represent 1/9. so that's 1/9, that's 1/9. when i say 1/9, i could also say a ninth. so this is 1/9 or a ninth, so each of these represents a ninth. but how many of these ninths do we have shaded in? well we have one, two, three, four shaded in. so now we have a total of 4/9 shaded it. 4 of the 9 equal sections are shaded in. so 4/9 of the whole is shaded in. now let's make things a little bit more interesting. let's shade in. so here i have five equal sections. let me write this down. i have five equal sections. and let me shade in five of them. so one, two, three, four, five. we already know that each of these sections, each of these situated in sections represent 1/5. so 1/5, another way of saying that is a fifth, is 1/5. but now how much do i have shaded in? well i have five out of the five equal sections shaded, or i have 5/5 shaded in. and you might be saying, wait, wait, if i gave five out of the five equal sections shaded in, if i have 5/5 shaded in, i've got the whole thing shaded in. and you would be absolutely right. 5/5 is equal to the whole. now what i want you to do is pause this video and write down on a piece of paper or at least think in your head, what fraction of each of these wholes is shaded in? so let's go to this first one. we have one, two, three, four, five, six equal sections. and we see that one, two, three, four are shaded in. so 4/6 of this figure is shaded in. let's go over here. we have one, two, three, four, five equal sections. and one, two, three, four are shaded in. so here, 4/5 of this circle is shaded in. now in this figure, i have two equal sections and both of them are shaded in. and this we would say two halves of this figure are shaded in. and once again, if two halves are shaded in, that means everything is shaded in, that this represents a whole. now this one right over here it might be tempting to say, i have one, two, three, four sections and one, two, three have been shaded in so maybe the red represents 3/4 of the figure. but remember, the sections have to be equal sections. and this red section is way bigger. it actually looks like it's bigger than the other three combined. so you do not have four equal sections here. so at least based on how it's drawn, you can't say that 3/4 is actually filled in.",t_5825872145e6,other,0
c_b8f725201713,"learn the difference between lines, line segments, and rays.  what i want to do in this video is think about the difference between a line segment, a line, and a ray. and this is the pure geometrical versions of these things. and so, a line segment is actually probably what most of us associate with a line in our everyday lives. a line segment is something just like that. for lack of a better word, a straight line. but why we call it a segment is that it actually has a starting and a stopping point. so, most of the lines that we experience in our everyday reality are actually line segments when we think of it from a pure geometrical point of view. and i know i drew a little bit of a curve here, but this is supposed to be completely straight, but this is a line segment. the segment is based on the fact that it has an ending point and a starting point, or a starting point and an ending point. a line, if you're thinking about it in the pure geometric sense of a line, is essentially, it does not stop. it doesn't have a starting point and an ending point. it keeps going on forever in both directions. so a line would look like this. and to show that it keeps on going on forever in that direction right over there, we draw this arrow, and to keep showing that it goes on forever in kind of the down left direction, we draw this arrow right over here. so obviously, i've never encountered something that just keeps on going straight forever. but in math-- that's the neat thing about math-- we can think about these abstract notions. and so the mathematical purest geometric sense of a line is this straight thing that goes on forever. now, a ray is something in between. a ray has a well defined starting point. so that's its starting point, but then it just keeps on going on forever. so the ray might start over here, but then it just keeps on going. so that right over there is a ray. now, with that out of the way, let's actually try to do the khan academy module on recognizing the difference between line segments, lines, and rays. and i think you'll find it pretty straightforward based on our little classification right over here. so, let me get the module going. where did i put it? there you go. all right. so what is this thing right over here? well, it has two arrows on both ends, so it's implying that it goes on forever. so this is going to be a line. let's check our answer. yeah, it's a line. now it's taking some time, oh, correct, next question. all right, now what about this thing? well, once again, arrows on both sides. it means that this thing is going to go on forever in both directions. so once again, it is a line. fair enough. let's do another one. here we have one arrow, so it goes on forever in this direction, but it has a well-defined starting point. so it starts there, and then goes on forever. and if you remember, that's what a ray is. one starting point, but goes on forever. or one way to think about it, goes on forever in only one direction. so that is a ray. so let's do another question. this right over here, you have a starting point and an ending point, or you could call this the start point and the ending point, but it doesn't go on forever in either direction. so this right over here is a line segment. there you go. so hopefully that gives you enough to work your way through this module. and you might notice, when i did this module right here, there is no video. and that's exactly what this video is. it's the video for this module.",t_236b171b0a38,other,0
c_56947149ab23,"functions assign outputs to inputs. the domain of a function is the set of all possible inputs for the function. for example, the domain of f(x)=x² is all real numbers, and the domain of g(x)=1/x is all real numbers except for x=0. we can also define special functions whose domains are more limited.  let's have a little bit of a review of what a function is before we talk about what it means that what the domain of a function means. so function we can view as something -- so i put a function in this box here and it takes inputs, and for a given input, it's going to produce an output which we call f of x. so, for example, let's say that we have the function -- let's say we have the function f of x is equal to 2 over x. so in this case if -- let me see -- that's my function f. if i were to input the number 3. well, f of 3 that we're going to output -- we have, we know how to figure that out. we've defined it right over here. it's going to be equal to 2 over 3. it's going to be equal to 2 over 3. so we're able, for that input, we're able to find an output. if our input was pi, then we input into our function and then f of pi -- when x is pi, we're going to output f of pi, which is equal to 2 over pi. so we could write this as 2 over pi. we're able to find the output pretty easily. but i want to do something interesting. let's attempt to input 0 into the function. if we input 0 then the function tells us what we need to output. does this definition tell us what we need to output? so if i attempt to put x equal 0, then this definition would say f of 0 be 2 over 0, but 2 over 0 is undefined. rewrite this -- 2 over 0. this is undefined. this function definition does not tell us what to actually do with 0. it gives us an undefined answer. so this function is not defined here. it gives a question mark. so this gets to the essence of what domain is. domain is the set of all inputs over which the function is defined. so the domain of this function f would be all real numbers except for x equals 0. so we write down these, these big ideas. this is the domain -- the domain of a function -- actually let me write that out. the domain of a function a domain of a function is the set of all inputs -- inputs over which the function is defined -- over which the function is defined, or the function has defined outputs over which the function has defined outputs. so the domain for this f in particular -- so the domain for this one-- if i want to say its domain, i could say, look, it's going to be the set of these curly brackets. these are kind of typical mathy set notation. i said ok , it could be the set of -- i gonna put curly brackets like that. well, x can be a member so this little symbol means a member of the real numbers. but it can't be any real number. it could be most of the real numbers except it cannot be 0 because we don't know -- this definition is undefined when you put the input as 0 so x is a member of the real numbers, and we write real numbers -- we write it with this kind of double stroke right over here. that's the set of all real numbers such that -- we have to put the exception. 0 is not a -- x equals to 0 is not a member of that domain -- such that x does not -- does not equal 0. now let's make this a little bit more concrete by do some more examples so more examples we do, hopefully the clearer this will become. so let's say we have another function. just be clear, we don't always have to use f's and x's. we could say, let's say we have g of y is equal to the square root of y minus 6. so what is the domain here? what is the set of all inputs over which this function g is defined? so here we are in putting a y it to function g and we're gonna output g of y. well it's going to be defined as long as whatever we have under the radical right over here is non-negative. if this becomes a negative, our traditional principal root operator here is not defined. we need something that -- if this was a negative number, how would you take the principal root of a negative number? we just think this is kind of the the traditional principal root operator. so y minus 6, y minus 6 needs to be greater than or equal to 0, in order for, in order for g to be defined for that input y. or you could say add six to both sides. y is to be greater than or equal 6. or you could say g is defined for any inputs y that are greater than or equal to 6. so you could say the domain here, we could say the domain here is the set of all y's that are members of the real numbers such that y, such that they're also greater than or equal, such that they're also greater than or equal to 6. so hopefully this is starting to make some sense -- you're all used to a function that is defined this way. you could even see functions that are divided fairly exotic ways. you could see a function -- let me say h of x -- h of x could be defined as -- it literally could be defined as, well h of x is gonna be 1 if x is equal to pi and it's equal to 0 if, if, x is equal to 3. now what's the domain here? and i encourage you to pause the video and think about it. well, this function is actually only defined for two input. if you, we know h of -- we know h of pi -- if you input pi into it we know you're gonna output 1, and we know that if you input 3 into it h of 3, when x equals 3, you're going to -- you're going to -- put some commas here. you're gonna get 0. but if you input anything else, what's h of 4 going to be? well, it hasn't defined. it's undefined. what's h of negative 1 going to be? it hasn't defined. so the domain, the domain here, the domain of h is literally -- it's just literally going to be the the two valid inputs that x can be are 3 and pi. these are the only valid inputs. these are the only two numbers over which this function is actually defined. so this hopefully starts to give you a flavor of why we care about to the domain. it's not all functions are defined over all real numbers. some are definedfor only a small subset of real numbers, or for some other thing, or only whole numbers, or natural numbers, or positive numbers, and negative numbers. so they have exceptions. so we'll see that as we do more and more examples.",t_c8a36e9d662f,other,0
c_f57bcf25f192,"sal solves the equation -7q^2+2q+9=0 by using the quadratic formula.  use the quadratic formula to solve the equation, 0 is equal to negative 7q squared plus 2q plus 9. now, the quadratic formula, it applies to any quadratic equation of the form-- we could put the 0 on the left hand side. 0 is equal to ax squared plus bx plus c. and we generally deal with x's, in this problem we're dealing with q's. but the quadratic formula says, look, if you have a quadratic equation of this form, that the solutions of this equation are going to be x is going to be equal to negative b plus or minus the square root of b squared minus 4ac-- all of that over 2a. and this is actually two solutions here, because there's one solution where you take the positive square root and there's another solution where you take the negative root. so it gives you both roots of this. so if we look at the quadratic equation that we need to solve here, we can just pattern match. we're dealing with q's, not x's, but this is the same general idea. it could be x's if you like. and if we look at it, negative 7 corresponds to a. that is our a. it's the coefficient on the second degree term. 2 corresponds to b. it is the coefficient on the first degree term. and then 9 corresponds to c. it's the constant. so, let's just apply the quadratic formula. the quadratic formula will tell us that the solutions-- the q's that satisfy this equation-- q will be equal to negative b. b is 2. plus or minus the square root of b squared, of 2 squared, minus 4 times a times negative 7 times c, which is 9. and all of that over 2a. all of that over 2 times a, which is once again negative 7. and then we just have to evaluate this. so this is going to be equal to negative 2 plus or minus the square root of-- let's see, 2 squared is 4-- and then if we just take this part right here, if we just take the negative 4 times negative 7 times 9, this negative and that negative is going to cancel out. so it's just going to become a positive number. and 4 times 7 times 9. 4 times 9 is 36. 36 times 7. let's do it up here. 36 times 7. 7 times 6 is 42. 7 times 3, or 3 times 7 is 21. plus 4 is 25. 252. so this becomes 4 plus 252. remember, you have a negative 7 and you have a minus out front. those cancel out, that's why we have a positive 252 for that part right there. and then our denominator, 2 times negative 7 is negative 14. now what does this equal? well, we have this is equal to negative 2 plus or minus the square root of-- what's 4 plus 252? it's just 256. all of that over negative 14. and what's 256? what's the square root of 256? it's 16. you can try it out for yourself. this is 16 times 16. so the square root of 256 is 16. so we can rewrite this whole thing as being equal to negative 2 plus 16 over negative 14. or negative 2 minus-- right? this is plus 16 over negative 14. or minus 16 over negative 14. if you think of it as plus or minus, that plus is that plus right there. and if you have that minus, that minus is that minus right there. now we just have to evaluate these two numbers. negative 2 plus 16 is 14 divided by negative 14 is negative 1. so q could be equal to negative 1. or negative 2 minus 16 is negative 18 divided by negative 14 is equal to 18 over 14. the negatives cancel out, which is equal to 9 over 7. so q could be equal to negative 1, or it could be equal to 9 over 7. and you could try these out, substitute these q's back into this original equation, and verify for yourself that they satisfy it. we could even do it with the first one. so if you take q is equal to negative 1. negative 7 times negative 1 squared-- negative 1 squared is just 1-- so this would be negative 7 times 1, right? that's negative 1 squared. negative 1 times 2 is minus 2 plus 9. so it's negative 7 minus 2, which is negative 9, plus 9, does indeed equal 0. so this checks out. and i'll leave it up to you to verify that 9 over 7 also works out.",t_16e6b02dcd8f,other,0
c_2da42cacdeb2,"a statement is a unit of code that the python interpreter can execute. we have seen two kinds of statements: expression statement with ""print"" and assignment.  when you type a statement in interactive mode, the interpreter executes it and displays the result, if there is one.  a script usually contains a sequence of statements. if there is more than one statement, the results appear one at a time as the statements execute.  for the script below, notice that the assignment statement (in this case x = 2) produces no output.  code \(\pageindex{1}\) (python):  print(1) x = 2 print(x)",t_e2cb36f0cd06,other,0
c_d95fee35a442,"chapter 5 polynomials and polynomial functions  487  polynomials and polynomial functions  5  figure 5.1 there are many different kinds of coins in circulation, but a new type of coin exists only in the virtual world. it is the bitcoin.  chapter outline 5.1 add and subtract polynomials 5.2 properties of exponents and scientific notation 5.3 multiply polynomials 5.4 dividing polynomials  introduction you may have coins and paper money in your wallet, but you may soon want to acquire a type of currency called bitcoins. they exist only in a digital wallet on your computer. you can use bitcoins to pay for goods at some companies, or save them as an investment. although the future of bitcoins is uncertain, investment brokers are beginning to investigate ways to make business predictions using this digital currency. understanding how bitcoins are created and obtained requires an understanding of a type of function known as a polynomial function. in this chapter you will investigate polynomials and polynomial functions and learn how to perform mathematical operations on them. 5.1  add and subtract polynomials  learning objectives by the end of this section, you will be able to: determine the degree of polynomials add and subtract polynomials evaluate a polynomial function for a given value add and subtract polynomial functions be prepared! before you get started, take this readiness quiz. 1. simplify: 3x 2 + 3x + 1 + 8x 2 + 5x + 5. if you missed this problem, review example 1.7. 2. subtract:  (5n + 8) − (2n − 1).  if you missed this problem, review example 1.5. 3. evaluate:  4xy 2 when x = −2 and y = 5.  if you missed this problem, review example 1.21.  488  chapter 5 polynomials and polynomial functions  determine the degree of polynomials we have learned that a term is a constant or the product of a constant and one or more variables. a monomial is an algebraic expression with one term. when it is of the form ax m, where a is a constant and m is a whole number, it is called a monomial in one variable. some examples of monomial in one variable are. monomials can also have more than 3 one variable such as and −4a 2 b c 2. monomial a monomial is an algebraic expression with one term. a monomial in one variable is a term of the form ax m, where a is a constant and m is a whole number. a monomial, or two or more monomials combined by addition or subtraction, is a polynomial. some polynomials have special names, based on the number of terms. a monomial is a polynomial with exactly one term. a binomial has exactly two terms, and a trinomial has exactly three terms. there are no special names for polynomials with more than three terms. polynomials polynomial—a monomial, or two or more algebraic terms combined by addition or subtraction is a polynomial. monomial—a polynomial with exactly one term is called a monomial. binomial—a polynomial with exactly two terms is called a binomial. trinomial—a polynomial with exactly three terms is called a trinomial. here are some examples of polynomials.  polynomial  y+1  4a 2 − 7ab + 2b 2  4x 4 + x 3 + 8x 2 − 9x + 1  monomial  14  8y 2  −9x 3 y 5  −13a 3 b 2 c  binomial  a + 7b  4x 2 − y 2  y 2 − 16  3p 3 q − 9p 2 q  trinomial  x 2 − 7x + 12  9m 2 + 2mn − 8n 2  6k 4 − k 3 + 8k  z 4 + 3z 2 − 1  notice that every monomial, binomial, and trinomial is also a polynomial. they are just special members of the “family” of polynomials and so they have special names. we use the words monomial, binomial, and trinomial when referring to these special polynomials and just call all the rest polynomials. the degree of a polynomial and the degree of its terms are determined by the exponents of the variable. a monomial that has no variable, just a constant, is a special case. the degree of a constant is 0. degree of a polynomial the degree of a term is the sum of the exponents of its variables. the degree of a constant is 0. the degree of a polynomial is the highest degree of all its terms. let’s see how this works by looking at several polynomials. we’ll take it step by step, starting with monomials, and then progressing to polynomials with more terms. let's start by looking at a monomial. the monomial 8ab 2 has two variables a and b. to find the degree we need to find the sum of the exponents. the variable a doesn't have an exponent written, but remember that means the exponent is 1. the exponent of b is 2. the sum of the exponents, 1 + 2, is 3 so the degree is 3.  here are some additional examples.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  489  working with polynomials is easier when you list the terms in descending order of degrees. when a polynomial is written this way, it is said to be in standard form of a polynomial. get in the habit of writing the term with the highest degree first. example 5.1 determine whether each polynomial is a monomial, binomial, trinomial, or other polynomial. then, find the degree of each polynomial.  ⓐ 7y 2 − 5y + 3 ⓑ −2a 4 b 2 ⓒ 3x 5 − 4x 3 − 6x 2 + x − 8 ⓓ 2y − 8xy 3 ⓔ 15 solution polynomial  number of terms  type  degree of terms  degree of polynomial  ⓐ  7y 2 − 5y + 3  3  trinomial  2, 1, 0  2  ⓑ  −2a 4 b 2  1  monomial  4, 2  6  ⓒ  3x 5 − 4x 3 − 6x 2 + x − 8  5  polynomial  5, 3, 2, 1, 0  5  ⓓ  2y − 8xy 3  2  binomial  1, 4  4  ⓔ  15  1  monomial  0  0  try it : : 5.1 determine whether each polynomial is a monomial, binomial, trinomial, or other polynomial. then, find the degree of each polynomial.  ⓐ −5 ⓑ 8y 3 − 7y 2 − y − 3 ⓒ −3x 2 y − 5xy + 9xy 3 ⓓ 81m 2 − 4n 2 ⓔ −3x 6 y 3 z  490  chapter 5 polynomials and polynomial functions  try it : : 5.2 determine whether each polynomial is a monomial, binomial, trinomial, or other polynomial. then, find the degree of each polynomial.  ⓐ 64k 3 − 8 ⓑ 9m 3 + 4m 2 − 2 ⓒ 56 ⓓ 8a 4 − 7a 3 b − 6a 2 b 2 − 4ab 3 + 7b 4 ⓔ −p 4 q 3 add and subtract polynomials we have learned how to simplify expressions by combining like terms. remember, like terms must have the same variables with the same exponent. since monomials are terms, adding and subtracting monomials is the same as combining like terms. if the monomials are like terms, we just combine them by adding or subtracting the coefficients. example 5.2 add or subtract: ⓐ  25y 2 + 15y 2  ⓑ 16pq 3 − ⎛⎝−7pq 3⎞⎠.  solution  ⓐ  25y 2 + 15y 2 40y 2  combine like terms.  ⓑ  16pq 3 − ⎛⎝−7pq 3⎞⎠ 23pq 3  combine like terms.  ⓑ 8mn 3 − ⎛⎝−5mn 3⎞⎠.  try it : : 5.3  add or subtract: ⓐ  12q 2 + 9q 2  try it : : 5.4  add or subtract: ⓐ  −15c 2 + 8c 2  ⓑ −15y 2 z 3 − ⎛⎝−5y 2 z 3⎞⎠.  remember that like terms must have the same variables with the same exponents. example 5.3 simplify: ⓐ  a 2 + 7b 2 − 6a 2  ⓑ u 2 v + 5u 2 − 3v 2.  solution  ⓐ  a 2 + 7b 2 − 6a 2 −5a 2 + 7b 2  combine like terms.  ⓑ there are no like terms to combine. in this case, the polynomial is unchanged.  u 2 v + 5u 2 − 3v 2 u 2 v + 5u 2 − 3v 2  try it : : 5.5  add: ⓐ  8y 2 + 3z 2 − 3y 2  ⓑ m 2 n 2 − 8m 2 + 4n 2.  try it : : 5.6  add: ⓐ  3m 2 + n 2 − 7m 2  ⓑ pq 2 − 6p − 5q 2.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  491  we can think of adding and subtracting polynomials as just adding and subtracting a series of monomials. look for the like terms—those with the same variables and the same exponent. the commutative property allows us to rearrange the terms to put like terms together. example 5.4 ⎛  ⎞  ⎛  ⎞  find the sum: ⎝7y 2 − 2y + 9⎠ + ⎝4y 2 − 8y − 7⎠.  solution  ⎛ 7y 2 ⎝____  identify like terms. rewrite without the parentheses, rearranging to get the like terms together.  − ___ 2y + 9⎞⎠ + ⎛⎝____ 4y 2 − ___ 8y − 7⎞⎠  7y 2 + 4y 2 − _______ 2y − 8y + 9 − 7 _________ 11y 2 − 10y + 2  combine like terms. ⎛  ⎞  ⎛  ⎞  try it : : 5.7  find the sum: ⎝7x 2 − 4x + 5⎠ + ⎝x 2 − 7x + 3⎠.  try it : : 5.8  find the sum: ⎝14y 2 + 6y − 4⎠ + ⎝3y 2 + 8y + 5⎠.  ⎛  ⎞  ⎛  ⎞  be careful with the signs as you distribute while subtracting the polynomials in the next example. example 5.5 ⎛  ⎞  ⎛  ⎞  find the difference: ⎝9w 2 − 7w + 5⎠ − ⎝2w 2 − 4⎠.  solution  ⎛ 2 ⎝9w  − 7w + 5⎞⎠ − ⎛⎝2w 2 − 4⎞⎠  9w 2 − ___ 7w + 5 − ____ 2w 2 + 4 ____  distribute and identify like terms.  9w 2 − 2w 2 − ___ 7w + 5 + 4 __________  rearrange the terms.  7w 2 − 7w + 9  combine like terms. try it : : 5.9  try it : : 5.10  to subtract  ⎛  ⎞  ⎛  ⎞  ⎛  ⎞  find the difference: ⎝8x 2 + 3x − 19⎠ − ⎝7x 2 − 14⎠. ⎛  ⎞  find the difference: ⎝9b 2 − 5b − 4⎠ − ⎝3b 2 − 5b − 7⎠.  a from b, we write it as b − a, placing the b first.  example 5.6 ⎛  ⎞  ⎛  ⎞  subtract ⎝ p 2 + 10pq − 2q 2⎠ from ⎝ p 2 + q 2⎠.  solution distribute. rearrange the terms, to put like terms together. combine like terms.  ⎛ 2 ⎝p  + q 2⎞⎠ − ⎛⎝ p 2 + 10pq − 2q 2⎞⎠  p 2 + q 2 − p 2 − 10pq + 2q 2  p 2 − p 2 − 10pq + q 2 + 2q 2 −10pq 2 + 3q 2  492  chapter 5 polynomials and polynomial functions  ⎛  ⎞  ⎛  ⎞  try it : : 5.11  subtract ⎝a 2 + 5ab − 6b 2⎠ from ⎝a 2 + b 2⎠.  try it : : 5.12  subtract ⎝m 2 − 7mn − 3n 2⎠ from ⎝m 2 + n 2⎠.  ⎛  ⎛  ⎞  ⎞  example 5.7 ⎞  ⎛  ⎛  ⎞  find the sum: ⎝u 2 − 6uv + 5v 2⎠ + ⎝3u 2 + 2uv⎠.  solution  ⎛ 2 ⎝u  − 6uv + 5v 2⎞⎠ + ⎛⎝3u 2 + 2uv⎞⎠  distribute.  u 2 − 6uv + 5v 2 + 3u 2 + 2uv  rearrange the terms to put like terms together.  u 2 + 3u 2 − 6uv + 2uv + 5v 2 4u 2 − 4uv + 5v 2  combine like terms. ⎛  ⎞  ⎛  ⎛  ⎞  ⎛  ⎞  try it : : 5.13  find the sum: ⎝3x 2 − 4xy + 5y 2⎠ + ⎝2x 2 − xy⎠.  try it : : 5.14  find the sum: ⎝2x 2 − 3xy − 2y 2⎠ + ⎝5x 2 − 3xy⎠.  ⎞  when we add and subtract more than two polynomials, the process is the same. example 5.8 ⎛ 3  simplify: ⎝a  − a 2 b⎞⎠ − ⎛⎝ab 2 + b 3⎞⎠ + ⎛⎝a 2 b + ab 2⎞⎠.  solution  ⎛ 3 ⎝a  − a 2 b⎞⎠ − ⎛⎝ab 2 + b 3⎞⎠ + ⎛⎝a 2 b + ab 2⎞⎠  a 3 − a 2 b − ab 2 − b 3 + a 2 b + ab 2  distribute. rewrite without the parentheses, rearranging to get the like terms together.  a 3 − a 2 b + a 2 b − ab 2 + ab 2 − b 3 a3 − b3  combine like terms. ⎛ 3  − x 2 y⎞⎠ − ⎛⎝xy 2 + y 3⎞⎠ + ⎛⎝x 2 y + xy 2⎞⎠.  ⎛ 3  − p 2 q⎞⎠ + ⎛⎝ pq 2 + q 3⎞⎠ − ⎛⎝ p 2 q + pq 2⎞⎠.  try it : : 5.15  simplify: ⎝x  try it : : 5.16  simplify: ⎝ p  evaluate a polynomial function for a given value a polynomial function is a function defined by a polynomial. for example, polynomial functions, because  x 2 + 5x + 6 and 3x − 4 are polynomials.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  f (x) = x 2 + 5x + 6 and g(x) = 3x − 4 are  chapter 5 polynomials and polynomial functions  493  polynomial function a polynomial function is a function whose range values are defined by a polynomial. in graphs and functions, where we first introduced functions, we learned that evaluating a function means to find the value of f (x) for a given value of x. to evaluate a polynomial function, we will substitute the given value for the variable and then simplify using the order of operations. example 5.9 for the function  f (x) = 5x 2 − 8x + 4 find: ⓐ f (4)  ⓑ f (−2) ⓒ f (0).  solution  ⓐ  simplify the exponents. multiply. simplify.  ⓑ  simplify the exponents. multiply. simplify.  ⓒ  simplify the exponents. multiply. simplify.  try it : : 5.17  for the function  f (x) = 3x 2 + 2x − 15, find ⓐ f (3)  try it : : 5.18  for the function  g(x) = 5x 2 − x − 4, find ⓐ g(−2)  ⓑ f (−5) ⓒ f (0).  ⓑ g(−1) ⓒ g(0).  the polynomial functions similar to the one in the next example are used in many fields to determine the height of an object at some time after it is projected into the air. the polynomial in the next function is used specifically for dropping something from 250 ft.  494  chapter 5 polynomials and polynomial functions  example 5.10  h(t) = −16t 2 + 250 gives the height of a ball t seconds after it is dropped from a 250-foot tall building. find the height after t = 2 seconds. the polynomial function  solution h(t) = −16t 2 + 250 to fin h(2), substitute t = 2. simplify.  h(2) = −16(2) 2 + 250 h(2) = −16 · 4 + 250  simplify.  h(2) = −64 + 250  simplify.  h(2) = 186 after 2 seconds the height of the ball is 186 feet.  try it : : 5.19  h(t) = −16t 2 + 150 gives the height of a stone t seconds after it is dropped from a  the polynomial function  150-foot tall cliff. find the height after  t = 0 seconds (the initial height of the object).  try it : : 5.20  h(t) = −16t 2 + 175 gives the height of a ball t seconds after it is dropped from a  the polynomial function  175-foot tall bridge. find the height after  t = 3 seconds.  add and subtract polynomial functions just as polynomials can be added and subtracted, polynomial functions can also be added and subtracted. addition and subtraction of polynomial functions for functions  f (x) and g(x), ⎛ ⎝  f + g⎞⎠(x) = f (x) + g(x) ⎛ ⎞ ⎝ f − g⎠(x) = f (x) − g(x) example 5.11 for functions  f (x) = 3x 2 − 5x + 7 and g(x) = x 2 − 4x − 3, find:  ⓐ f + g (x) ⓑ f + g (3) ⓒ f − g (x) ⓓ f − g (−2). ⎛ ⎝  ⎞ ⎠  ⎛ ⎝  ⎞ ⎠  ⎛ ⎝  ⎞ ⎠  ⎛ ⎝  ⎞ ⎠  solution  ⓐ  rewrite without the parentheses. put like terms together. combine like terms.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  ⓑ in part (a) we found f + g (x) ⎛ ⎝  to fin  ⎛ ⎝  ⎞ ⎠  and now are asked to find  f + g⎞⎠(3), substitute x = 3.  notice that we could have found  ⎛ ⎝  find f (3).  find g(3).  find ⎛⎝ f + g⎞⎠(3).  ⓒ  rewrite without the parentheses.  combine like terms.  ⓓ  ⎛ ⎝  f + g⎞⎠(3).  ⎛ ⎝  f + g⎞⎠(x) = 4x 2 − 9x + 4  ⎛ ⎝  f + g⎞⎠(3) = 4(3) 2 − 9 · 3 + 4  ⎛ ⎝  f + g⎞⎠(3) = 4 · 9 − 9 · 3 + 4  ⎛ ⎝  f + g⎞⎠(3) = 36 − 27 + 4  f + g⎞⎠(3) by first finding the values of f (3) and g(3) separately and then adding the  results.  put like terms together.  495  496  chapter 5 polynomials and polynomial functions  try it : : 5.21 for functions ⎛ ⎝  f − g⎞⎠(−2).  f (x) = 2x 2 − 4x + 3 and g(x) = x 2 − 2x − 6, find: ⓐ ⎛⎝ f + g⎞⎠(x)  ⓑ f + g (3) ⓒ f − g (x) ⓓ  f (x) = 5x 2 − 4x − 1 and g(x) = x 2 + 3x + 8, find ⓐ ⎛⎝ f + g⎞⎠(x)  ⓑ f + g (3) ⓒ f − g (x) ⓓ  ⎛ ⎝  ⎞ ⎠  ⎛ ⎝  ⎞ ⎠  try it : : 5.22 for functions ⎛ ⎝  f − g⎞⎠(−2).  ⎛ ⎝  ⎞ ⎠  ⎛ ⎝  media : : access this online resource for additional instruction and practice with adding and subtracting polynomials. • adding and subtracting polynomials (https://openstax.org/l/37addsubtrpoly)  this openstax book is available for free at http://cnx.org/content/col12119/1.3  ⎞ ⎠  chapter 5 polynomials and polynomial functions  497  5.1 exercises practice makes perfect determine the degree of polynomials in the following exercises, determine if the polynomial is a monomial, binomial, trinomial, or other polynomial. 1.  ⓐ ⓑ ⓒ  2.  5c 3 + 11c 2 − c − 8 5 ab + 1 b 9 3  ⓓ4 ⓔ 4pq + 17 4.  ⓐ ⓑ ⓒ ⓓ ⓔ  11y  5.  ⓐ ⓑ ⓒ ⓓ ⓔ  2  −73  6x 2 − 3xy + 4x − 2y + y 2 4y 2 + 17z 2 5c 3 + 11c 2 − c − 8  7.  ⓐ ⓑ ⓒ ⓓ ⓔ  3.  ⓐ x2 − y2 ⓑ −13c 4 ⓒ a 2 + 2ab − 7b 2 ⓓ 4x 2 y 2 − 3xy + 8 ⓔ 19  47x 5 − 17x 2 y 3 + y 2  2  5a + 12ab − 7b  ⓐ ⓑ ⓒ ⓓ ⓔ  8y − 5x y 2 − 5yz − 6z 2 y 3 − 8y 2 + 2y − 16 81ab 4 − 24a 2 b 2 + 3b −18  6.  ⓐ 9y 3 − 10y 2 + 2y − 6 ⓑ −12p 3 q ⓒ a 2 + 9ab + 18b 2 ⓓ 20x 2 y 2 − 10a 2 b 2 + 30 ⓔ 17  2  18xy 2 z 5x + 2  y 3 − 8y 2 + 2y − 16  −24  8.  ⓐ 15xy ⓑ 15 ⓒ 6x 2 − 3xy + 4x − 2y + y 2 ⓓ 10p − 9q ⓔ m 4 + 4m 3 + 6m 2 + 4m + 1  14s − 29t 2  z − 5z − 6  y 3 − 8y 2 z + 2yz 2 − 16z 3  23ab 2 − 14 −3  add and subtract polynomials in the following exercises, add or subtract the monomials. 9.  ⓐ 7x + 5x ⓑ 4a − 9a 2  10.  ⓐ 4y + 6y ⓑ −y − 5y  2  12.  13.  ⓐ −3m + 9m ⓑ 15yz 2 − (−8yz 2) 15.  2  2  16.  3  11.  ⓐ −12w + 18w ⓑ 7x 2 y − (−12x 2 y)  3  7x 2 + 5x 2 + 4a − 9a  2  14.  2  4y 3 + 6y 3 − y − 5y  17.  −12w + 18w + 7x y − (−12x y)  −3m + 9m + 15yz − (−8yz )  ⓐ −5b − 17b ⓑ 3xy − (−8xy) + 5xy  18.  19.  20.  ⓐ −10x − 35x ⓑ 17mn 2 − (−9mn 2) + 3mn 2  ⓐ 12a + 5b − 22a ⓑ pq 2 − 4p − 3q 2  ⓐ 14x − 3y − 13x ⓑ a 2 b − 4a − 5ab 2  498  chapter 5 polynomials and polynomial functions  21.  22.  23.  24.  25.  26.  ⓐ 2a 2 + b 2 − 6a 2 ⓑ x 2 y − 3x + 7xy 2  ⓐ 5u 2 + 4v 2 − 6u 2 ⓑ 12a + 8b  ⓐ xy 2 − 5x − 5y 2 ⓑ 19y + 5z  12a + 5b − 22a + pq 2 − 4p − 3q 2 14x − 3y − 13x + a 2 b − 4a − 5ab 2 2a 2 + b 2 − 6a 2 + x 2 y − 3x + 7xy 2  27.  5u 2 + 4v 2 − 6u 2 + 12a + 8b  30. add:  28.  4x, 3y, −3x  xy 2 − 5x − 5y 2 + 19y + 5z  31. subtract  29. add:  5x 6 from −12x 6  4a, −3b, −8a  32. subtract  2p 4 from −7p 4  in the following exercises, add the polynomials. 33.  2  34.  2  2  2  (5y + 12y + 4) + (6y − 8y + 7)  (4y + 10y + 3) + (8y − 6y + 5)  36. (y 2 + 9y + 4) + (−2y 2 − 5y − 1)  37.  (8x 2 − 5x + 2) + (3x 2 + 3)  (5a 2 + 8) + (a 2 − 4a − 9)  40.  (p 2 − 6p − 18) + (2p 2 + 11)  39.  35. (x 2 + 6x + 8) + (−4x 2 + 11x − 9)  38.  (7x 2 − 9x + 2) + (6x 2 − 4)  in the following exercises, subtract the polynomials. 41.  42.  44. (b 2 − 7b + 5) − (b 2 − 2b + 9)  45.  (4m 2 − 6m − 3) − (2m 2 + m − 7)  (12s 2 − 15s) − (s − 9)  in the following exercises, subtract the polynomials. ⎛  ⎛  ⎞  ⎞  47. subtract ⎝9x 2 + 2⎠ from ⎝12x 2 − x + 6⎠ ⎞  ⎛  43. (a 2 + 8a + 5) − (a 2 − 3a + 2)  (3b 2 − 4b + 1) − (5b 2 − b − 2)  (10r 2 − 20r) − (r − 8)  ⎛  ⎞  ⎛  ⎛  ⎞  ⎛  49. subtract ⎝7w 2 − 4w + 2⎠ from ⎝8w 2 − w + 6⎠  ⎛ 2 ⎝w  the  − 10w +  difference  24⎞⎠  of  ⎛ 2 ⎝w  + w − 42⎞⎠  in the following exercises, add the polynomials. ⎛  ⎞  ⎛  ⎛  ⎞  ⎛  ⎞  53. ⎝7x 2 − 2xy + 6y 2⎠ + ⎝3x 2 − 5xy⎠  ⎞  50. subtract ⎝5x 2 − x + 12⎠ from ⎝9x 2 − 6x − 20⎠  in the following exercises, find the difference of the polynomials. 51. find  ⎞  48. subtract ⎝5y 2 − y + 12⎠ from ⎝10y 2 − 8y − 20⎠ ⎞  ⎛  46.  and  52. find  the  ⎛ 2 ⎝z  20⎞⎠  + 5z −  difference  ⎛  ⎞  of  ⎛ 2 ⎝z  ⎛  − 3z − 18⎞⎠  ⎞  54. ⎝−5x 2 − 4xy − 3y 2⎠ + ⎝2x 2 − 7xy⎠ ⎞  55. ⎝7m 2 + mn − 8n 2⎠ + ⎝3m 2 + 2mn⎠  ⎛  ⎞  ⎛  ⎞  56. ⎝2r 2 − 3rs − 2s 2⎠ + ⎝5r 2 − 3rs⎠  this openstax book is available for free at http://cnx.org/content/col12119/1.3  and  chapter 5 polynomials and polynomial functions  499  in the following exercises, add or subtract the polynomials. ⎛  ⎞  ⎛  ⎞  57. ⎝a 2 − b 2⎠ − ⎝a 2 + 3ab − 4b 2⎠  ⎛  ⎛ 3  − 3p 2 q⎞⎠ + ⎛⎝2pq 2 + 4q 3⎞⎠ − ⎛⎝3p 2 q + pq 2⎞⎠  60. ⎝a  ⎛ 3  − x 2 y⎞⎠ − ⎛⎝4xy 2 − y 3⎞⎠ + ⎛⎝3x 2 y − xy 2⎞⎠  62. ⎝x  59. ⎝ p 61. ⎝x  ⎞  ⎛  ⎞  58. ⎝m 2 + 2n 2⎠ − ⎝m 2 − 8mn − n 2⎠ ⎛ 3  − 2a 2 b⎞⎠ + ⎛⎝ab 2 + b 3⎞⎠ − ⎛⎝3a 2 b + 4ab 2⎞⎠  ⎛ 3  − 2x 2 y⎞⎠ − ⎛⎝xy 2 − 3y 3⎞⎠ − ⎛⎝x 2 y − 4xy 2⎞⎠  evaluate a polynomial function for a given value in the following exercises, find the function values for each polynomial function. 63. for the function  f (x) = 8x 2 − 3x + 2, find:  ⓐ f (5) ⓑ f (−2) ⓒ f (0) 65. for the function  64. for the function  f (x) = 5x 2 − x − 7, find:  ⓐ f (−4) ⓑ f (1) ⓒ f (0)  g(x) = 4 − 36x, find:  ⓐ g(3) ⓑ g(0) ⓒ g(−1)  66. for the function  g(x) = 16 − 36x 2, find:  ⓐ g(−1) ⓑ g(0) ⓒ g(2)  in the following exercises, find the height for each polynomial function. 67. a painter drops a brush from a platform 75 feet high. the polynomial function h(t) = −16t 2 + 75  68. a girl is throwing a ball off the cliff into the ocean. the polynomial h(t) = −16t 2 + 200 gives the height  gives the height of the brush t seconds after it was dropped. find the height after t = 2 seconds.  of a ball t seconds after it is dropped from a 250-foot tall cliff. find the height after t = 3 seconds.  69. a manufacturer of stereo sound speakers has found that the revenue received from selling the speakers at a cost of p dollars each is given by the polynomial function r(p) = −4p 2 + 420p. find the revenue  70. a manufacturer of the latest basketball shoes has found that the revenue received from selling the shoes at a cost of p dollars each is given by the polynomial r(p) = −4p 2 + 420p. find the revenue received  received when  when  p = 60 dollars.  71. the polynomial  c(x) = 6x 2 + 90x gives the cost,  in dollars, of producing a rectangular container whose top and bottom are squares with side x feet and height 6 feet. find the cost of producing a box with x = 4 feet.  p = 90 dollars.  72. the polynomial  c(x) = 6x 2 + 90x gives the cost,  in dollars, of producing a rectangular container whose top and bottom are squares with side x feet and height 4 feet. find the cost of producing a box with x = 6 feet.  add and subtract polynomial functions for each function, find ⓐ (f + g)(x)  ⓑ (f + g)(2) ⓒ (f − g)(x) ⓓ (f − g)(−3).  73.  f (x) = 2x 2 − 4x + 1 and g(x) = 5x 2 + 8x + 3  74.  f (x) = 4x 2 − 7x + 3 and g(x) = 4x 2 + 2x − 1  75.  f (x) = 3x 3 − x 2 − 2x + 3 and g(x) = 3x 3 − 7x  76.  f (x) = 5x 3 − x 2 + 3x + 4 and g(x) = 8x 3 − 1  writing exercises 77. using your own words, explain the difference between a monomial, a binomial, and a trinomial.  78. using your own words, explain the difference between a polynomial with five terms and a polynomial with a degree of 5.  6y 2 + 5y 4 is 11y 6. what is  80. is every trinomial a second degree polynomial? if not, give an example.  79. ariana thinks the sum  wrong with her reasoning?  500  chapter 5 polynomials and polynomial functions  self check  ⓐ after completing the exercises, use this checklist to evaluate your mastery of the objectives of this section.  ⓑ if most of your checks were: …confidently. congratulations! you have achieved the objectives in this section. reflect on the study skills you used so that you can continue to use them. what did you do to become confident of your ability to do these things? be specific. …with some help. this must be addressed quickly because topics you do not master become potholes in your road to success. in math every topic builds upon previous work. it is important to make sure you have a strong foundation before you move on. who can you ask for help? your fellow classmates and instructor are good resources. is there a place on campus where math tutors are available? can your study skills be improved? …no - i don’t get it! this is a warning sign and you must not ignore it. you should get help right away or you will quickly be overwhelmed. see your instructor as soon as you can to discuss your situation. together you can come up with a plan to get you the help you need.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  5.2  501  properties of exponents and scientific notation  learning objectives by the end of this section, you will be able to: simplify expressions using the properties for exponents use the definition of a negative exponent use scientific notation be prepared! before you get started, take this readiness quiz. 1. simplify:  (−2)(−2)(−2).  if you missed this problem, review example 1.19. 2. simplify:  8x . 24y  if you missed this problem, review example 1.24. 3. name the decimal  (−2.6)(4.21).  if you missed this problem, review example 1.36.  simplify expressions using the properties for exponents remember that an exponent indicates repeated multiplication of the same quantity. for example, in the expression  a m,  the exponent m tells us how many times we use the base a as a factor.  let’s review the vocabulary for expressions with exponents. exponential notation  this is read a to the in the expression  m th power.  a m, the exponent m tells us how many times we use the base a as a factor.  when we combine like terms by adding and subtracting, we need to have the same base with the same exponent. but when you multiply and divide, the exponents may be different, and sometimes the bases may be different, too. first, we will look at an example that leads to the product property.  what does this mean?  502  chapter 5 polynomials and polynomial functions  notice that 5 is the sum of the exponents, 2 and 3. we see  x 2 · x 3 is x 2 + 3 or x 5.  the base stayed the same and we added the exponents. this leads to the product property for exponents. product property for exponents if a is a real number and m and n are integers, then  am · an = am + n to multiply with like bases, add the exponents. example 5.12 simplify each expression: ⓐ  y5 · y6  ⓑ 2 x · 2 3x ⓒ 2a 7 · 3a.  solution  ⓐ use the product property, a m · a n = a m + n. simplify.  ⓑ  use the product property, a m · a n = a m + n. simplify.  ⓒ  rewrite, a = a 1. use the commutative property and use the product property, a m · a n = a m + n. simplify.  ⓓ  add the exponents, since bases are the same. simplify.  try it : : 5.23  simplify each expression:  ⓐ b 9 · b 8 ⓑ 4 2x · 4 x ⓒ 3p 5 · 4p ⓓ x 6 · x 4 · x 8.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  try it : : 5.24  503  simplify each expression:  ⓐ x 12 · x 4 ⓑ 10 · 10 x ⓒ 2z · 6z 7 ⓓ b 5 · b 9 · b 5. now we will look at an exponent property for division. as before, we’ll try to discover a property by looking at some examples.  consider  x2 x3  and  x5 x2  what do they mean?  x·x·x·x·x x·x  x·x x·x·x  use the equivalent fractions property.  x · x ·x·x·x x·x  x · x ·1 x · x ·x  x3  1 x  simplify.  notice, in each case the bases were the same and we subtracted exponents. we see is or  x 5 is x 5 − 2 or x 3 . we see x 2 x2 x3  1 . when the larger exponent was in the numerator, we were left with factors in the numerator. when the larger x  exponent was in the denominator, we were left with factors in the denominator--notice the numerator of 1. when all the factors in the numerator have been removed, remember this is really dividing the factors to one, and so we need a 1 in the numerator.  x = 1 . this leads to the quotient property for exponents. x  quotient property for exponents if a is a real number,  a ≠ 0, and m and n are integers, then a m = a m − n, m > n an  and  am = 1 , n > m an an − m  example 5.13 simplify each expression: ⓐ  x9 x7  10 8 3 ⓑ 3 2 ⓒ b12 ⓓ 7 5 .  3  b  7  solution to simplify an expression with a quotient, we need to first compare the exponents in the numerator and denominator.  ⓐ since 9 > 7, there are more factors of x in the numerator. m use quotient property, a n = a m − n. a  simplify.  ⓑ  504  chapter 5 polynomials and polynomial functions  since 10 > 2, there are more factors of 3 in the numerator. m use quotient property, a n = a m − n. a  simplify. notice that when the larger exponent is in the numerator, we are left with factors in the numerator.  ⓒ since 12 > 8, there are more factors of b in the denominator. m use quotient property, a n = n1− m . a a  simplify.  ⓓ since 5 > 3, there are more factors of 3 in the denominator. m use quotient property, a n = n1− m . a a  simplify. simplify. notice that when the larger exponent is in the denominator, we are left with factors in the denominator.  try it : : 5.25  try it : : 5.26  simplify each expression: ⓐ  x 15 x 10  18 14 15 ⓑ 6 5 ⓒ x 22 ⓓ 12 30 .  simplify each expression: ⓐ  y 43 y 37  8 15 7 ⓑ 10 7 ⓒ m15 ⓓ 919 .  6  10  x  12  m  9  a special case of the quotient property is when the exponents of the numerator and denominator are equal, such as an m expression like a m . we know , x x = 1, for any x (x ≠ 0) since any number divided by itself is 1. a the quotient property for exponents shows us how to simplify m  a m . when m > n and when n < m by subtracting am  m = n ? we will simplify a m in two ways to lead us to the definition of the zero exponent property. a in general, for a ≠ 0 : exponents. what if  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  we see  505  a m simplifies to a 0 and to 1. so a 0 = 1. any non-zero base raised to the power of zero equals 1. am  zero exponent property if a is a non-zero number, then  a 0 = 1.  if a is a non-zero number, then a to the power of zero equals 1. any non-zero number raised to the zero power is 1. in this text, we assume any variable that we raise to the zero power is not zero. example 5.14 simplify each expression: ⓐ  90  ⓑ n 0.  solution the definition says any non-zero number raised to the zero power is 1.  ⓐ use the definition of he zero exponent.  ⓑ use the definition of he zero exponent.  90 1 n0 1  to simplify the expression n raised to the zero power we just use the definition of the zero exponent. the result is 1.  try it : : 5.27  simplify each expression: ⓐ  11 0  ⓑ q 0.  try it : : 5.28  simplify each expression: ⓐ  23 0  ⓑ r 0.  use the definition of a negative exponent we saw that the quotient property for exponents has two forms depending on whether the exponent is larger in the numerator or the denominator. what if we just subtract exponents regardless of which is larger? let’s consider  x 2 . we subtract the exponent in the denominator from the exponent in the numerator. we see x 2 is x5 x5  x 2 − 5 or x −3. we can also simplify  x 2 by dividing out common factors: x5  506  chapter 5 polynomials and polynomial functions  this implies that  a −n = 1n . a  x −3 = 13 and it leads us to the definition of a negative exponent. if n is an integer and a ≠ 0, then x  let’s now look at what happens to a fraction whose numerator is one and whose denominator is an integer raised to a negative exponent.  1 a −n use the definition of a ne ative exponent, a −n = 1n . a  1  1 an n  1· a 1  simplify the complex fraction.  an  multiply. this implies  1 = a n and is another form of the definition of properties of negative exponents. a −n  properties of negative exponents if n is an integer and  a ≠ 0, then a −n = 1n or 1−n = a n. a a  the negative exponent tells us we can rewrite the expression by taking the reciprocal of the base and then changing the sign of the exponent. any expression that has negative exponents is not considered to be in simplest form. we will use the definition of a negative exponent and other properties of exponents to write the expression with only positive exponents. for example, if after simplifying an expression we end up with the expression  x −3, we will take one more step and write  1 . the answer is considered to be in simplest form when it has only positive exponents. x3 example 5.15 simplify each expression: ⓐ  x −5  ⓑ 10 −3 ⓒ 1−4 ⓓ 1−2 . y  3  solution  ⓐ use the definition of a ne ative exponent, a −n = 1n . a  ⓑ  this openstax book is available for free at http://cnx.org/content/col12119/1.3  x −5 1 x5  chapter 5 polynomials and polynomial functions  507  10 −3 1 10 3 1 1000  use the definition of a ne ative exponent, a −n = 1n . a simplify.  ⓒ  1 y −4  use the property of a negative exponent, 1−n = a n. a  y4  ⓓ  1 3 −2 32  use the property of a negative exponent, 1−n = a n. a simplify.  try it : : 5.29  try it : : 5.30  9  simplify each expression: ⓐ  z −3  ⓑ 10 −7 ⓒ 1−8 ⓓ 1−3 .  simplify each expression: ⓐ  n −2  ⓑ 10 −4 ⓒ 1−7 ⓓ 1−4 .  p  4  q  2  suppose now we have a fraction raised to a negative exponent. let’s use our definition of negative exponents to lead us to a new property.  ⎛3 ⎞ ⎝4 ⎠  1  use the definition of a ne ative exponent, a −n = 1n . a  ⎛3 ⎞ ⎝4 ⎠  2  1  simplify the denominator.  9 16  16 9  simplify the complex fraction. ⎛ ⎞  −2  2  but we know that 16 is ⎝4 ⎠ . 9 3 ⎛3 ⎞ ⎝4 ⎠  this tells us that  −2  ⎛ ⎞  = ⎝4 ⎠ 3  2  to get from the original fraction raised to a negative exponent to the final result, we took the reciprocal of the base—the fraction—and changed the sign of the exponent. this leads us to the quotient to a negative power property. quotient to a negative power property if a and b are real numbers,  a ≠ 0, b ≠ 0 and n is an integer, then ⎛ ⎞  and ⎝a ⎠ b  −n  ⎛ ⎞ = ⎝ba ⎠  n  508  chapter 5 polynomials and polynomial functions  example 5.16  ⎛ ⎞ simplify each expression: ⓐ ⎝5 ⎠ 7  −2  ⓑ ⎛⎝− xy ⎞⎠ . −3  solution  ⓐ ⎛ ⎞  use the quotient to a negative exponent property, ⎝a ⎠ b  −n  ⎛5 ⎞ ⎝7 ⎠  ⎛ ⎞ = ⎝ba ⎠ . n  take the reciprocal of the fraction and change the sign of the exponent. simplify.  ⓑ ⎛ ⎞  use the quotient to a negative exponent property, ⎝a ⎠ b  −n  ⎛ ⎞ = ⎝ba ⎠ . n  simplify.  try it : : 5.32  ⎛7 ⎞ ⎝5 ⎠  49 25  −4  ⎛ ⎞  simplify each expression: ⓐ ⎝3 ⎠ 5  −3  −3  ⎛ y⎞ ⎝− x ⎠  −  ⎛ ⎞ simplify each expression: ⓐ ⎝2 ⎠ 3  2  ⎛ x⎞ ⎝− y ⎠  take the reciprocal of the fraction and change the sign of the exponent.  try it : : 5.31  −2  3  y3 x3  −2  ⓑ ⎛⎝− mn ⎞⎠ . ⓑ ⎛⎝− ab ⎞⎠ . −4  now that we have negative exponents, we will use the product property with expressions that have negative exponents. example 5.17 simplify each expression: ⓐ  z −5 · z −3  ⓑ ⎛⎝m 4 n −3⎞⎠⎛⎝m −5 n −2⎞⎠ ⓒ ⎛⎝2x −6 y 8⎞⎠⎛⎝−5x 5 y −3⎞⎠.  solution  ⓐ add the exponents, since the bases are the same. simplify. use the definition of a ne ative exponent.  ⓑ  this openstax book is available for free at http://cnx.org/content/col12119/1.3  z −5 · z −3 z −5 − 3 z −8 1 z8  chapter 5 polynomials and polynomial functions  509  ⎛ 4 −3⎞⎛ −5 −2⎞ n ⎠ ⎝m n ⎠⎝m  use the commutative property to get like bases together.  m 4 m −5 · n −2 n −3 m −1 · n −5 1 · 1 m1 n5 1 mn 5  add the exponents for each base. take reciprocals and change the signs of the exponents. simplify.  ⓒ  ⎛ −6 8⎞⎛ y ⎠⎝−5x 5 y −3⎞⎠ ⎝2x  2(−5) · ⎛⎝x −6 x 5⎞⎠ · ⎛⎝y 8 y −3⎞⎠  rewrite with the like bases together. multiply the coefficients and add he exponents of each variable.  −10 · x −1 · y 5  use the definition of a ne ative exponent, a −n = 1n . a  −10 · 1x · y 5 −10y 5 x  simplify.  try it : : 5.33  simplify each expression:  ⓐ z −4 · z −5 ⓑ ⎛⎝p 6 q −2⎞⎠⎛⎝p −9 q −1⎞⎠ ⓒ ⎛⎝3u −5 v 7⎞⎠⎛⎝−4u 4 v −2⎞⎠. try it : : 5.34  simplify each expression:  ⓐ c −8 · c −7 ⓑ ⎛⎝r 5 s −3⎞⎠⎛⎝r −7 s −5⎞⎠ ⓒ ⎛⎝−6c −6 d 4⎞⎠⎛⎝−5c −2 d −1⎞⎠. now let’s look at an exponential expression that contains a power raised to a power. see if you can discover a general property.  (x 2) 3  what does this mean?  x2 · x2 · x2  how many factors altogether?  so we have  notice the 6 is the product of the exponents, 2 and 3. we see that  (x 2) 3 is x 2 · 3 or x 6.  we multiplied the exponents. this leads to the power property for exponents. power property for exponents if a is a real number and m and n are integers, then  (a m) n = a m · n to raise a power to a power, multiply the exponents.  510  chapter 5 polynomials and polynomial functions  example 5.18 simplify each expression: ⓐ  (y 5) 9  ⓑ (4 4) 7 ⓒ (y 3) 6 (y 5) 4.  solution  ⓐ use the power property, (a m) n = a m · n. simplify.  ⓑ  use the power property. simplify.  ⓒ  (y 3) 6 (y 5) 4 y 18 · y 20  use the power property.  y 38  add the exponents.  try it : : 5.35  simplify each expression: ⓐ  (b 7) 5  ⓑ (5 4) 3 ⓒ (a 4) 5 (a 7) 4.  try it : : 5.36  simplify each expression: ⓐ  (z 6) 9  ⓑ (3 7) 7 ⓒ (q 4) 5 (q 3) 3.  we will now look at an expression containing a product that is raised to a power. can you find this pattern?  what does this mean? we group the like factors together.  (2x) 3 2x · 2x · 2x 2·2·2·x·x·x 23 · x3  how many factors of 2 and of x  notice that each factor was raised to the power and  (2x) 3 is 2 3 · x 3.  the exponent applies to each of the factors! this leads to the product to a power property for exponents. product to a power property for exponents if a and b are real numbers and m is a whole number, then (ab) m =  am bm  to raise a product to a power, raise each factor to that power. example 5.19 simplify each expression: ⓐ  (−3mn) 3  0  ⓑ ⎛⎝−4a 2 b⎞⎠ ⓒ ⎛⎝6k 3⎞⎠  −2  2  ⓓ ⎛⎝5x −3⎞⎠ .  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  511  solution  ⓐ use power of a product property, (ab) m = a m b m. simplify.  ⓑ  ⎛ 2 ⎞ ⎝−4a b⎠  0  (−4) 0 ⎛⎝a 2⎞⎠ (b) 0  use power of a product property, (ab) m = a m b m. simplify. multiply.  1·1·1 1  ⓒ  ⎛ 3⎞ ⎝6k ⎠  use the product to a power property, (ab) m = a m b m.  −2  (6) −2 ⎛⎝k 3⎞⎠  use the definition of a ne ative exponent, a −n = 1n . a simplify.  ⓓ  ⎛ −3⎞ ⎝5x ⎠  2 2  use the product to a power property, (ab) m = a m b m.  5 2 ⎛⎝x −3⎞⎠  simplify.  25 · x −6 25 · 16 x 25 x6  rewrite x −6 using, a −n = 1n . a  simplify.  try it : : 5.38  −2  6 −2 k −6 1 · 1 62 k6 1 36k 6  use the power property, (a m) n = a m · n.  try it : : 5.37  0  0  −4  simplify each expression: ⓐ  (2wx) 5  ⓑ ⎛⎝−11pq 3⎞⎠ ⓒ ⎛⎝2b 3⎞⎠  simplify each expression: ⓐ  (−3y) 3  ⓑ (−8m 2 n 3) 0 ⓒ ⎛⎝−4x 4⎞⎠  now we will look at an example that will lead us to the quotient to a power property.  2  ⓓ ⎛⎝8a −4⎞⎠ . −2  3  ⓓ ⎛⎝2c −4⎞⎠ .  512  chapter 5 polynomials and polynomial functions  ⎛x ⎞ ⎝y ⎠  3  x·x·x y y y x·x·x y·y·y  this means multiply the fractions.  x3 y3  write with exponents.  notice that the exponent applies to both the numerator and the denominator. ⎛ ⎞ we see that ⎝ x y⎠  3  is  x3. y3  this leads to the quotient to a power property for exponents. quotient to a power property for exponents if  a and b are real numbers, b ≠ 0, and m is an integer, then ⎛a ⎞ ⎝b ⎠  m  m = am b  to raise a fraction to a power, raise the numerator and denominator to that power. example 5.20 simplify each expression:  ⓐ ⎛⎝b3 ⎞⎠ ⓑ ⎛⎝kj ⎞⎠ 4  −3  2⎞ ⎛4p −3 ⎞ ⎛ ⓒ ⎜ 2xy z ⎟ ⓓ ⎜ 2 ⎟ . 2  3  ⎝  ⎠  ⎝ q  ⎠  solution  ⓐ  m ⎛ ⎞ use quotient to a power property, ⎝a ⎠ = a m . b b m  simplify.  ⓑ  raise the numerator and denominator to the power. use the definition of negative exponent. multiply.  ⓒ  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  513  ⎛ 2xy 2 ⎞ ⎜ ⎟ ⎝ z ⎠  ⎛ ⎞ use quotient to a power property, ⎝a ⎠ b  m  =  ⎛ 2⎞ ⎝2xy ⎠  am. m  3  3  z3  b  8x 3 y 6 z3  use the product to a power property, (ab) m = a m b m.  ⓓ  ⎛4p −3 ⎞ ⎜ ⎟ ⎝ q2 ⎠  ⎛ ⎞ use quotient to a power property, ⎝a ⎠ b  m  ⎛ −3⎞ ⎝4p ⎠  m = am. b  m  ⎛ 2⎞ ⎝q ⎠  2  2  4 2 ⎛⎝ p −3⎞⎠  m m  use the product to a power property, (ab) = a b .  ⎛ 2⎞ ⎝q ⎠  2  2  16p −6 q4 16 · 1 q4 p6 16 p6 q4  simplify using the power property, (a m) n = a m · n. use the definition of ne ative exponent. simplify.  try it : : 5.39  2  simplify each expression:  ⎛ −2 ⎞ 3 −7 p ⎞4 ⎛m ⎞ ⓐ ⎛⎝10 ⓒ ⎛⎝3ab2 ⎞⎠ ⓓ ⎜3x 3 ⎟ . ⎠ ⓑ ⎝n⎠ ⎝ y ⎠ c 4  try it : : 5.40  3  simplify each expression: 3 ⎛ xy ⎞ −4 ⎛2m −2 ⎞ ⎞ ⎛w ⎞ ⓐ ⎛⎝−2 q ⎠ ⓑ ⎝ x ⎠ ⓒ ⎜⎝ 2 ⎟⎠ ⓓ ⎝ −2 ⎠ . 3z n 3 2  3  we now have several properties for exponents. let’s summarize them and then we’ll do some more examples that use more than one of the properties. summary of exponent properties if a and b are real numbers, and m and n are integers, then  514  chapter 5 polynomials and polynomial functions  property  description  product property  am · an = am + n  power property  (a m) n = a m · n  product to a power  (ab) n = a m b m  quotient property  a m = a m − n, a ≠ 0 an  zero exponent property  a 0 = 1, a ≠ 0  quotient to a power property  ⎛a ⎞ ⎝b ⎠  properties of negative exponents  a −n = 1n and 1−n = a n a a  quotient to a negative exponent  ⎛a ⎞ ⎝b ⎠  m  m = am, b ≠ 0 b  −n  ⎛ ⎞ = ⎝ba ⎠  n  example 5.21 simplify each expression by applying several properties:  ⓐ (3x y) (2xy ) ⓑ 2  4  2 3  (x 3) 4 (x −2) 5 (x 6) 5  ⓒ  ⎛ 2xy 2 ⎞ ⎛ 12xy 3 ⎞ ⎜ ⎟ ⎜ ⎟ ⎝ x 3 y −2 ⎠ ⎝ x 3 y −1 ⎠ 2  −1  .  solution  ⓐ use the product to a power property, (ab) m = a m b m. simplify. use the commutative property.  (3x 2 y) 4 (2xy 2) 3 (3 4 x 8 y 4)(2 3 x 3 y 6) (81x 8 y 4)(8x 3 y 6) 81 · 8 · x 8 · x 3 · y 4 · y 6  multiply the constants and add the exponents.  ⓑ  use the power property, (a m) n = a m · n. add the exponents in the numerator. m use the quotient property, a n = n1− m . a a  ⓒ  this openstax book is available for free at http://cnx.org/content/col12119/1.3  648x 11 y 10 (x 3) 4 (x −2) 5 (x 6) 5 (x 12)(x −10) (x 30) x2 x 30 1 x 28  chapter 5 polynomials and polynomial functions  515  ⎛ 2xy 2 ⎞ ⎛ 12xy 3 ⎞ ⎜ ⎟ ⎜ ⎟ ⎝ x 3 y −2 ⎠ ⎝ x 3 y −1 ⎠ 2  ⎛ 2y 4 ⎞ ⎛ 12y 4 ⎞ ⎜ ⎟ ⎜ ⎟ ⎝ x2 ⎠ ⎝ x2 ⎠ 2  simplify inside the parentheses fir t. ⎛ ⎞ use the quotient to a power property, ⎝a ⎠ b  m  2  ⎛ 4⎞ ⎛ 4⎞ ⎝2y ⎠ ⎝12y ⎠  m = am. b  ⎛ 2⎞ ⎝x ⎠  simplify. simplify.  −1  −1  simplify each expression:  ⓐ (c d ) (3cd ) ⓑ 4 2 5  try it : : 5.42  ⎛ 2⎞ ⎝x ⎠  −1  4y 8 12 −1 y −4 · x4 x −2 4 4y 12x 2 y4 3x 2  use the product to a power property, (ab) m = a m b m.  try it : : 5.41  2  −1  5 4  (a −2) 3 (a 2) 4 (a 4) 5  ⓒ  ⎛ 3xy 2 ⎞ ⎛9xy −3 ⎞ ⎜ ⎟ ⎜ ⎟ ⎝ x 2 y −3 ⎠ ⎝ x 3 y 2 ⎠ 2  −1  .  simplify each expression:  ⓐ (a b ) (4ab ) ⓑ 3 2 6  3 4  (p −3) 4 (p 5) 3 (p 7) 6  ⓒ  ⎛ 4x 3 y 2 ⎞ ⎛8xy −3 ⎞ ⎜ ⎟ ⎜ ⎟ ⎝ x 2 y −1 ⎠ ⎝ x 2 y ⎠ 2  −1  .  use scientific notation working with very large or very small numbers can be awkward. since our number system is base ten we can use powers of ten to rewrite very large or very small numbers to make them easier to work with. consider the numbers 4,000 and 0.004. using place value, we can rewrite the numbers 4,000 and 0.004. we know that 4,000 means  4× 1 . 1,000  4 × 1,000 and 0.004 means  if we write the 1,000 as a power of ten in exponential form, we can rewrite these numbers in this way:  4,000  4 × 1,000  4 × 10 3  0.004  4×  1 1,000  4 × 13 10  4 × 10 −3  when a number is written as a product of two numbers, where the first factor is a number greater than or equal to one but less than ten, and the second factor is a power of 10 written in exponential form, it is said to be in scientific notation. scientific notation a number is expressed in scientific notation when it is of the form a × 10 n where 1 ≤ a < 10 and n is it is customary in scientific notation to use as the in algebra.  an integer.  × multiplication sign, even though we avoid using this sign elsewhere  if we look at what happened to the decimal point, we can see a method to easily convert from decimal notation to  516  chapter 5 polynomials and polynomial functions  scientific notation.  in both cases, the decimal was moved 3 places to get the first factor between 1 and 10. the power of 10 is positive when the number is larger than 1:  4,000 = 4 × 10 3  the power of 10 is negative when the number is between 0 and 1:  0.004 = 4 × 10 −3  how to : : to convert a decimal to scientific notation. step 1.  move the decimal point so that the first factor is greater than or equal to 1 but less than 10.  step 2.  count the number of decimal places, n, that the decimal point was moved.  step 3.  write the number as a product with a power of 10. if the original number is. ◦ greater than 1, the power of 10 will be 10 n. ◦ between 0 and 1, the power of 10 will be  step 4.  check.  example 5.22 write in scientific notation: ⓐ 37,000 ⓑ  0.0052.  solution  ⓐ the original number, 37,000, is greater than 1 so we will have a positive power of 10.  37,000  move the decimal point to get 3.7, a number between 1 and 10. count the number of decimal places the point was moved. write as a product with a power of 10.  check:  3.7 × 10 4 3.7 × 10,000 37,000  ⓑ  this openstax book is available for free at http://cnx.org/content/col12119/1.3  10 −n.  chapter 5 polynomials and polynomial functions  517  the original number, 0.0052, is between 0 and 1 so we will have a negative power of 10.  0.0052  move the decimal point to get 5.2, a number between 1 and 10. count the number of decimal places the point was moved. write as a product with a power of 10.  check:  5.2 × 10 −3 5.2 × 1 3 10 5.2 × 1 1000 5.2 × 0.001 0.0052  try it : : 5.43  write in scientific notation: ⓐ 96,000 ⓑ 0.0078.  try it : : 5.44  write in scientific notation: ⓐ 48,300 ⓑ 0.0129.  how can we convert from scientific notation to decimal form? let’s look at two numbers written in scientific notation and see.  9.12 × 10 4 9.12 × 10,000 91,200  9.12 × 10 −4 9.12 × 0.0001 0.000912  if we look at the location of the decimal point, we can see an easy method to convert a number from scientific notation to decimal form.  in both cases the decimal point moved 4 places. when the exponent was positive, the decimal moved to the right. when the exponent was negative, the decimal point moved to the left.  how to : : convert scientific notation to decimal form. step 1.  determine the exponent, n, on the factor 10.  step 2.  move the decimal n places, adding zeros if needed. ◦ if the exponent is positive, move the decimal point n places to the right. ◦ if the exponent is negative, move the decimal point  step 3.  check.  |n| places to the left.  518  chapter 5 polynomials and polynomial functions  example 5.23 convert to decimal form: ⓐ  6.2 × 10 3  ⓑ −8.9 × 10 −2.  solution  ⓐ determine the exponent, n, on the factor 10. the exponent is 3. since the exponent is positive, move the decimal point 3 places to the right. add zeros as needed for placeholders.  ⓑ  determine the exponent, n, on the factor 10.  the exponent is −2.  since the exponent is negative, move the decimal point 2 places to the left. add zeros as needed for placeholders.  try it : : 5.45  convert to decimal form: ⓐ  1.3 × 10 3  try it : : 5.46  convert to decimal form: ⓐ  −9.5 × 10 4  ⓑ −1.2 × 10 −4. ⓑ 7.5 × 10 −2.  when scientists perform calculations with very large or very small numbers, they use scientific notation. scientific notation provides a way for the calculations to be done without writing a lot of zeros. we will see how the properties of exponents are used to multiply and divide numbers in scientific notation. example 5.24 ⎛  multiply or divide as indicated. write answers in decimal form: ⓐ ⎝−4 ×  10 5⎞⎠⎛⎝2 × 10 −7⎞⎠  solution  ⓐ  ⎛ ⎝−4 ×  use the commutative property to rearrange the factors. multiply. change to decimal form by moving the decimal two places left.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  10 5⎞⎠⎛⎝2 × 10 −7⎞⎠  −4 · 2 · 10 5 · 10 −7 −8 × 10 −2 −0.08  3 ⓑ 9 × 10−2 .  3 × 10  chapter 5 polynomials and polynomial functions  519  ⓑ  9 × 10 3 9 × 10 −2 9 × 10 3 3 10 −2 3 × 10 5  separate the factors, rewriting as the product of two fractions. divide. change to decimal form by moving the decimal fi e places right.  try it : : 5.47  300,000  multiply or divide as indicated. write answers in decimal form: 2 ⓐ ⎛⎝−3 × 10 5⎞⎠⎛⎝2 × 10 −8⎞⎠ ⓑ 8 × 10−2 .  4 × 10  try it : : 5.48  multiply or divide as indicated. write answers in decimal form: 4 ⓐ; ⎛⎝−3 × 10 −2⎞⎠⎛⎝3 × 10 −1⎞⎠ ⓑ 8 × 10−1 .  2 × 10  media : : access these online resources for additional instruction and practice with using multiplication properties of exponents. • properties of exponents (https://openstax.org/l/37propofexpo) • negative exponents (https://openstax.org/l/37negativeexpo) • scientific notation (https://openstax.org/l/37scinotation)  520  chapter 5 polynomials and polynomial functions  5.2 exercises practice makes perfect simplify expressions using the properties for exponents in the following exercises, simplify each expression using the properties for exponents. 81. ⓐ  d3 · d6  83. ⓐ  n 19 · n 12  ⓑ 4 5x · 4 9x ⓒ 2y · 4y 3 ⓓ w · w 2 · w 3 ⓑ 3 x · 3 6 ⓒ 7w 5 · 8w ⓓ a 4 · a 3 · a 9  82. ⓐ  x4 · x2  ⓑ 8 9x · 8 3 ⓒ 3z 25 · 5z 8 ⓓ y · y 3 · y 5  84. ⓐ  q 27 · q 15  ⓓ c 5 · c 11 · c 2  85.  m x · m3  86.  ny · n2  87.  ya · yb  88.  x p · xq  ⓑ 5 x · 5 4x ⓒ 9u 41 · 7u 53  89. ⓐ  x 18 x3  18 12 2 ⓑ 5 3 ⓒ q 36 ⓓ 10 3  90. ⓐ  y 20 y 10  3 10 16 ⓑ 7 2 ⓒ t 40 ⓓ 8 5  91. ⓐ  p 21 p7  16 ⓑ 4 4 ⓒ b9 ⓓ 46  92. ⓐ  u 24 u3  15 ⓑ 9 5 ⓒ x7 ⓓ 103  93. ⓐ  20 0  ⓑ b0  94. ⓐ  13 0  ⓑ k0  95. ⓐ  −27 0  96. ⓐ  −15 0  b −4  5  10  q  4  b  4  ⓑ −⎛⎝27 0⎞⎠  7  t  8  x  9  10  ⓑ −⎛⎝15 0⎞⎠  use the definition of a negative exponent in the following exercises, simplify each expression. 97. ⓐ  a −2  ⓑ 10 −3 ⓒ 1−5 ⓓ 1−2  98. ⓐ  99. ⓐ  r −3  1 ⓓ ⓑ 10 −5 ⓒ −10  100. ⓐ  ⎛ ⎞ 101. ⓐ ⎝5 ⎠ 8  c  q  −2  ⎛ ⎞  103. ⓐ ⎝4 ⎠ 9  −3  1 10 −3  ⓑ 10 −2 ⓒ 1−5 ⓓ 1−2  s −8  1 ⓓ ⓑ 10 −2 ⓒ −9  ⎛ ⎞ 102. ⓐ ⎝ 3 ⎠ 10  −5  ⎛ ⎞ 104. ⓐ ⎝7 ⎠ 2  105. ⓐ  (−5) −2  ⓑ −5 −2 ⓒ ⎛⎝− 15 ⎞⎠  107. ⓐ  3 · 5 −1  ⓑ (3 · 5) −1  −2  ⓓ −⎛⎝15 ⎞⎠  −2  t  −2  −3  106. ⓐ  −5 −3  108. ⓐ  3 · 4 −2  this openstax book is available for free at http://cnx.org/content/col12119/1.3  5  c  −2  ⓑ ⎛⎝− ba ⎞⎠ ⓑ ⎛⎝− uv ⎞⎠  3  ⓑ ⎛⎝− 2z ⎞⎠  ⓑ ⎛⎝− 3x ⎞⎠ ⓑ ⎛⎝− 15 ⎞⎠  1 10 −4  −3  −3  −3  ⓒ −⎛⎝15 ⎞⎠  ⓑ (3 · 4) −2  −3  ⓓ (−5) −3  chapter 5 polynomials and polynomial functions  521  in the following exercises, simplify each expression using the product property. 109. ⓐ  b 4 b −8  111. ⓐ  a 3 · a −3  ⓑ ⎛⎝w 4 x −5⎞⎠⎛⎝w −2 x −4⎞⎠  110. ⓐ  s 3 · s −7  ⓑ ⎛⎝m 3 n −3⎞⎠⎛⎝m −5 n −1⎞⎠  ⓑ ⎛⎝uv −2⎞⎠⎛⎝u −5 v −3⎞⎠  112. ⓐ  y 5 · y −5  ⓑ ⎛⎝pq −4⎞⎠⎛⎝p −6 q −3⎞⎠  ⓒ ⎛⎝−2 j −5 k 8⎞⎠⎛⎝7 j 2 k −3⎞⎠  ⓒ ⎛⎝−6c −3 d 9⎞⎠⎛⎝2c 4 d −5⎞⎠  ⓒ ⎛⎝−5m 4 n 6⎞⎠⎛⎝8m −5 n −3⎞⎠  ⓒ ⎛⎝−4r −2 s −8⎞⎠⎛⎝9r 4 s 3⎞⎠ 113.  p 5 · p −2 · p −4  114.  x 4 · x −2 · x −3  in the following exercises, simplify each expression using the power property. 115. ⓐ  ⓑ (10 3) 6 ⓒ ⎛⎝x 3⎞⎠  (m 4) 2  ⎛ 3⎞ 117. ⓐ ⎝y ⎠  x  ⓑ (5 x) y ⓒ ⎛⎝q 6⎞⎠  −4  116. ⓐ  −8  (b 2) 7  ⓑ (3 8) 2 ⓒ ⎛⎝k 2⎞⎠  y  ⓑ (7 a) b ⓒ ⎛⎝a 9⎞⎠  ⎛  ⎞  118. ⓐ ⎝x 2⎠  −5  −10  in the following exercises, simplify each expression using the product to a power property. −2  ⓓ ⎛⎝−4y −3⎞⎠  119. ⓐ  (−3xy) 2  ⓑ (6a) 0 ⓒ ⎛⎝5x 2⎞⎠  121. ⓐ  (−5ab) 3  ⓑ −4pq 0 ⓒ ⎛⎝−6x 3⎞⎠ ⎛ ⎝  ⎞ ⎠  −2  2  ⓓ ⎛⎝3y −4⎞⎠  2  −3  120. ⓐ  (−4ab) 2  ⓑ (5x) 0 ⓒ ⎛⎝4y 3⎞⎠  122. ⓐ  ⎛ ⎝  −3xyz⎞⎠ 4  ⓑ (−7mn) 0 ⓒ ⎛⎝−3x 3⎞⎠  ⓓ ⎛⎝2y −5⎞⎠  ⓓ ⎛⎝−7y −3⎞⎠  2  −2  2  in the following exercises, simplify each expression using the quotient to a power property.  ⎛ p⎞ 123. ⓐ ⎝ ⎠ 2  125. ⓐ  2⎞ ⎛4p −3 ⎞ −6 ⎛ ⓑ ⎛⎝ xy ⎞⎠ ⓒ ⎜ 2xy z ⎟ ⓓ ⎜ 2 ⎟ 3  5  ⎛a⎞ ⎝3b ⎠  4  ⓑ  ⎛ 5 ⎞ ⎝4m ⎠  −2  ⎝  ⎠  ⓒ  ⎛ 2xy 2 ⎞ ⎜ ⎟ ⎝ z ⎠  ⎝ q  3  ⓓ  2  ⎛ ⎞ 124. ⓐ ⎝ x ⎠ 3  ⎠  ⎛4p −3 ⎞ ⎜ ⎟ ⎝ q2 ⎠  2  4  ⓑ ⎛⎝ab ⎞⎠  2⎞ ⎛4p −3 ⎞ ⎛ ⓒ ⎜ 2xy z ⎟ ⓓ ⎜ 2 ⎟ 3  −5  ⎛10 ⎞ ⎛ ⎞ 126. ⓐ x ⎝2y ⎠ ⓑ ⎝3q ⎠ 3  −4  ⎝ q  ⎝  ⎠  ⓒ  ⎛ 2xy 2 ⎞ ⎜ ⎟ ⎝ z ⎠  3  ⓓ  ⎠  ⎛4p −3 ⎞ ⎜ ⎟ ⎝ q2 ⎠  in the following exercises, simplify each expression by applying several properties. 5  127. ⓐ  ⓒ  2 3  (5t ) (3t)  2  ⓑ  ⎛ 2xy 2 ⎞ ⎛ 12xy 3 ⎞ ⎜ ⎟ ⎜ ⎟ ⎝ x 3 y −2 ⎠ ⎝ x 3 y −1 ⎠ 2  ⎛ 2⎞ ⎛ −4⎞ ⎝t ⎠ ⎝t ⎠  ⎛ 3⎞ ⎝t ⎠  6  2  7  129. ⓐ  2  6 2  (10k ) (5k )  ⓑ  130. ⓐ  4 2  6  2  ⎛ 3⎞ ⎛ −2⎞ ⎝q ⎠ ⎝q ⎠ ⎛ 4⎞ ⎝q ⎠  3  8  −1  4  2  128. ⓐ  4 3  5 4  (m n) (2mn )  ⓑ  ⎛ −2⎞ ⎛ 4⎞ ⎝−2p ⎠ ⎝3p ⎠  ⎛ 3⎞ ⎝−6p ⎠  2  2  2  (3pq ) (6p q)  ⓑ  ⎛ −3⎞ ⎛ 2⎞ ⎝−2k ⎠ ⎝6k ⎠ ⎛ 4⎞ ⎝9k ⎠  2  2  4  2  522  chapter 5 polynomials and polynomial functions  mixed practice in the following exercises, simplify each expression. 131. ⓐ  7n −1  133. ⓐ  ⎛ ⎝  ⓑ (7n) −1 ⓒ (−7n) −1  132. ⓐ  6r −1  ⓑ 3p −2 ⓒ −3p −2  134. ⓐ  ⎛ ⎝  3p⎞⎠ −2  4 ⎛ ⎞2 3  ⎛  ⎞  ⎛  ⎞  135. ⎝x 2⎠  137. ⎝a 2⎠  · ⎝x  · ⎝a  ⎞  3 ⎛ ⎞2 5  ⎛ 7⎞ 138. ⎝b ⎠  5 ⎛ ⎞6 2  ⎛  6 ⎛ ⎞8 3 ⎠  ⓑ 2q −4 ⓒ −2q −4  2q⎞⎠ −4  136. ⎝y 4⎠  ⎠  ⓑ (6r) −1 ⓒ (−6r) −1  · ⎝y  ⎠  · ⎝b  ⎠  139.  (2m 6) 3  140.  (3y 2) 4  141.  (10x 2 y) 3  142.  (2mn 4) 5  143.  (−2a 3 b 2) 4  144.  (−10u 2 v 4) 3  ⎞ ⎛ 145. ⎝2 x 2 y⎠ 3  ⎛  3  ⎞  146. ⎝7 pq 4⎠ 9  2  147.  (8a 3) 2 (2a) 4  148.  (5r 2) 3 (3r) 2  149.  (10p 4) 3 (5p 6) 2  150.  (4x 3) 3 (2x 5) 4  4 2 ⎛ 8 3⎞ 3 ⎞ ⎛ 152. ⎝1 m n 2⎠ ⎝9m n ⎠ 3  4 2 ⎛ 3⎞ ⎛ 5 3⎞ 151. ⎝1 x 2 y ⎠ ⎝4x y ⎠ 2  153.  (3m 2 n) 2 (2mn 5) 4  155. ⓐ  (3x) 2(5x)  157. ⓐ  (2r −2) 3 (4 −1 r) 2  ⎛ j −2 j 5 ⎞ ⎟ 159. ⎜ ⎝ j4 ⎠  ⓑ (2y) 3(6y) ⓑ (3x −3) 3 (3 −1 x 5) 4  (2pq 4) 3 (5p 6 q) 2  156. ⓐ  3  ( 1 y 2) ( 2 y) 2 3  160.  ⎛ 8⎞ ⎝2n ⎠  5 2 ⓑ ( 12 j 2) ( 25 j 3)  ⎛k −2 k 8 ⎞ ⎝ k3 ⎠  2  ⎛ −2⎞ ⎛ 5⎞ ⎝−10n ⎠ ⎝4n ⎠  2  2  158.  3  3  161.  154.  ⎛ −3⎞ ⎛ 4⎞ ⎝−4m ⎠ ⎝5m ⎠  2  2  this openstax book is available for free at http://cnx.org/content/col12119/1.3  ⎛ 6⎞ ⎝−10m ⎠  3  3  chapter 5 polynomials and polynomial functions  523  use scientific notation in the following exercises, write each number in scientific notation. 162. ⓐ 57,000 ⓑ 0.026  163. ⓐ 340,000 ⓑ 0.041  164. ⓐ 8,750,000 ⓑ 0.00000871  165. ⓐ 1,290,000 ⓑ 0.00000103  in the following exercises, convert each number to decimal form. 166. ⓐ  5.2 × 10 2  ⓑ 2.5 × 10 −2  167. ⓐ  −8.3 × 10 2  ⓑ 3.8 × 10 −2  168. ⓐ  7.5 × 10 6  ⓑ −4.13 × 10 −5  169. ⓐ  1.6 × 10 10  ⓑ 8.43 × 10 −6  in the following exercises, multiply or divide as indicated. write your answer in decimal form. ⎛  170. ⓐ ⎝3 ×  10 −5⎞⎠⎛⎝3 × 10 9⎞⎠  ⎛  172. ⓐ ⎝7.1 ×  −3 ⓑ 7 × 10 −7  1 × 10  10 −2⎞⎠⎛⎝2.4 × 10 −4⎞⎠  4 ⓑ 6 × 10−2  3 × 10  ⎛  171. ⓐ ⎝2 × ⎛  10 2⎞⎠⎛⎝1 × 10 −4⎞⎠  173. ⓐ ⎝3.5 ×  −2 ⓑ 5 × 10−10  1 × 10  10 −4⎞⎠⎛⎝1.6 × 10 −2⎞⎠  6 ⓑ 8 × 10−1  4 × 10  writing exercises 174. use the product property for exponents to explain why x · x = x 2.  175. jennifer thinks the quotient  a 24 simplifies to a 4. a6  what is wrong with her reasoning? 176. explain why  −5 3 = (−5) 3 but −5 4 ≠ (−5) 4.  177. when you convert a number from decimal notation to scientific notation, how do you know if the exponent will be positive or negative?  self check  ⓐ after completing the exercises, use this checklist to evaluate your mastery of the objectives of this section.  ⓑ after reviewing this checklist, what will you do to become confident for all goals?  524  5.3  chapter 5 polynomials and polynomial functions  multiply polynomials  learning objectives by the end of this section, you will be able to: multiply monomials multiply a polynomial by a monomial multiply a binomial by a binomial multiply a polynomial by a polynomial multiply special products multiply polynomial functions be prepared! before you get started, take this readiness quiz. 1. distribute:  2(x + 3).  if you missed this problem, review example 1.50. 2. simplify: ⓐ  92  ⓑ (−9) 2 ⓒ −9 2.  if you missed this problem, review example 1.19.  3. evaluate: 2x 2 − 5x + 3 for x = −2. if you missed this problem, review example 1.21.  multiply monomials we are ready to perform operations on polynomials. since monomials are algebraic expressions, we can use the properties of exponents to multiply monomials. example 5.25 ⎛ ⎞⎛ 3⎞ multiply: ⓐ ⎝3x 2⎠⎝−4x ⎠  ⓑ ⎛⎝56 x 3 y⎞⎠⎛⎝12xy 2⎞⎠.  solution  ⓐ  ⎛ 2⎞⎛ 3⎞ ⎝3x ⎠⎝−4x ⎠  use the commutative property to rearrange the terms.  3 · (−4) · x 2 · x 3 −12x 5  multiply.  ⓑ  ⎛5 3 ⎞⎛ 2⎞ ⎝6 x y⎠⎝12xy ⎠  use the commutative property to rearrange the terms. multiply.  5 · 12 · x 3 · x · y · y 2 6 10x 4 y 3  ⓑ ⎛⎝25 a 4 b 3⎞⎠⎛⎝15ab 3⎞⎠.  try it : : 5.49  ⎞ ⎛ 7⎞⎛ multiply: ⓐ ⎝5y ⎠⎝−7y 4⎠  try it : : 5.50  ⎛ ⎞⎛ 5⎞ multiply: ⓐ ⎝−6b 4⎠⎝−9b ⎠  ⓑ ⎛⎝23 r 5 s⎞⎠⎛⎝12r 6 s 7⎞⎠.  multiply a polynomial by a monomial multiplying a polynomial by a monomial is really just applying the distributive property.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  525  example 5.26 multiply: ⓐ  −2y⎛⎝4y 2 + 3y − 5⎞⎠  ⓑ 3x 3 y(x 2 − 8xy + y 2).  solution  ⓐ  distribute. multiply.  ⓑ  3x 3 y(x 2 − 8xy + y 2)  distribute.  3x 3 y · x 2 + ⎛⎝3x 3 y⎞⎠ · (−8xy) + ⎛⎝3x 3 y⎞⎠ · y 2  multiply.  3x 5 y − 24x 4 y 2 + 3x 3 y 3  try it : : 5.51  multiply: ⓐ −3y⎝5y 2 + 8y − 7⎠  ⎛  ⓑ 4x 2 y 2 ⎛⎝3x 2 − 5xy + 3y 2⎞⎠.  try it : : 5.52  multiply: ⓐ 4x 2(2x 2 − 3x + 5)  ⓑ −6a 3 b(3a 2 − 2ab + 6b 2).  ⎞  multiply a binomial by a binomial just like there are different ways to represent multiplication of numbers, there are several methods that can be used to multiply a binomial times a binomial. we will start by using the distributive property. example 5.27 multiply: ⓐ ⎛⎝y + 5⎞⎠⎛⎝y + 8⎞⎠  solution  ⓐ  distribute (y + 8). distribute again. combine like terms.  ⓑ  ⓑ 4y + 3 2y − 5 . ⎛ ⎝  ⎞⎛ ⎠⎝  ⎞ ⎠  526  chapter 5 polynomials and polynomial functions  distribute. distribute again. combine like terms.  try it : : 5.53  multiply: ⓐ (x + 8)(x + 9)  try it : : 5.54  multiply: ⓐ (5x + 9)(4x + 3)  ⓑ (3c + 4)(5c − 2). ⓑ 5y + 2 6y − 3 . ⎛ ⎝  ⎞⎛ ⎠⎝  ⎞ ⎠  if you multiply binomials often enough you may notice a pattern. notice that the first term in the result is the product of the first terms in each binomial. the second and third terms are the product of multiplying the two outer terms and then the two inner terms. and the last term results from multiplying the two last terms, we abbreviate “first, outer, inner, last” as foil. the letters stand for ‘first, outer, inner, last’. we use this as another method of multiplying binomials. the word foil is easy to remember and ensures we find all four products. let’s multiply  (x + 3)(x + 7) using both methods.  we summarize the steps of the foil method below. the foil method only applies to multiplying binomials, not other polynomials!  how to : : use the foil method to multiply two binomials.  when you multiply by the foil method, drawing the lines will help your brain focus on the pattern and make it easier to apply. now we will do an example where we use the foil pattern to multiply two binomials. example 5.28 multiply: ⓐ  ⎛ ⎝  y − 7⎞⎠⎛⎝y + 4⎞⎠  ⓑ (4x + 3)(2x − 5).  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  527  solution  ⓐ  ⓑ  try it : : 5.55  multiply: ⓐ  (x − 7)(x + 5)  ⓑ (3x + 7)(5x − 2).  try it : : 5.56  multiply: ⓐ  (b − 3)(b + 6)  ⓑ 4y + 5 4y − 10 . ⎛ ⎝  ⎞⎛ ⎠⎝  ⎞ ⎠  the final products in the last example were trinomials because we could combine the two middle terms. this is not always the case. example 5.29 ⎛  ⎞  multiply: ⓐ ⎝n 2 + 4⎠(n − 1)  solution  ⓐ  ⓑ 3pq + 5 6pq − 11 . ⎛ ⎝  ⎞⎛ ⎠⎝  ⎞ ⎠  528  chapter 5 polynomials and polynomial functions  step 1. multiply the first terms. step 2. multiply the outer terms. step 3. multiply the inner terms. step 4. multiply the last terms. step 5. combine like terms—there are none.  ⓑ  step 1. multiply the first terms. step 2. multiply the outer terms. step 3. multiply the inner terms. step 4. multiply the last terms. step 5. combine like terms.  ⎛  ⎞  ⎛  ⎞  try it : : 5.57  multiply: ⓐ ⎝x 2 + 6⎠(x − 8)  try it : : 5.58  multiply: ⓐ ⎝y 2 + 7⎠⎛⎝y − 9⎞⎠  ⓑ (2ab + 5)(4ab − 4). ⓑ 2xy + 3 4xy − 5 . ⎛ ⎝  ⎞⎛ ⎠⎝  ⎞ ⎠  the foil method is usually the quickest method for multiplying two binomials, but it only works for binomials. you can use the distributive property to find the product of any two polynomials. another method that works for all polynomials is the vertical method. it is very much like the method you use to multiply whole numbers. look carefully at this example of multiplying two-digit numbers.  now we’ll apply this same method to multiply two binomials.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  529  example 5.30 multiply using the vertical method:  3y − 1⎞⎠⎛⎝2y − 6⎞⎠.  ⎛ ⎝  solution it does not matter which binomial goes on the top.  3y − 1 × 2y −6 ___________ −18y + 6  multiply 3y − 1 by −6. multiply 3y − 1 by 2y. add like terms.  2  6y − 2y ___________  6y 2 − 20y + 6  partial product partial product product  notice the partial products are the same as the terms in the foil method.  try it : : 5.59  multiply using the vertical method:  (5m − 7)(3m − 6).  try it : : 5.60  multiply using the vertical method:  (6b − 5)(7b − 3).  we have now used three methods for multiplying binomials. be sure to practice each method, and try to decide which one you prefer. the methods are listed here all together, to help you remember them. multiplying two binomials to multiply binomials, use the: • distributive property • foil method • vertical method  multiply a polynomial by a polynomial we have multiplied monomials by monomials, monomials by polynomials, and binomials by binomials. now we’re ready to multiply a polynomial by a polynomial. remember, foil will not work in this case, but we can use either the distributive property or the vertical method. example 5.31 multiply  (b + 3)(2b 2 − 5b + 8) using ⓐ the distributive property and ⓑ the vertical method.  solution  ⓐ distribute. multiply. combine like terms.  ⓑ it is easier to put the polynomial with fewer terms on the bottom because we get fewer partial products this way.  530  chapter 5 polynomials and polynomial functions  multiply (2b 2 − 5b + 8) by 3. multiply (2b 2 − 5b + 8) by b . add like terms.  try it : : 5.61  ⎛  ⎞  multiply ⎛⎝y − 3⎞⎠⎝y 2 − 5y + 2⎠ using ⓐ the distributive property and ⓑ the vertical method.  try it : : 5.62 multiply  (x + 4)(2x 2 − 3x + 5) using ⓐ the distributive property and ⓑ the vertical method.  we have now seen two methods you can use to multiply a polynomial by a polynomial. after you practice each method, you’ll probably find you prefer one way over the other. we list both methods are listed here, for easy reference. multiplying a polynomial by a polynomial to multiply a trinomial by a binomial, use the: • distributive property • vertical method  multiply special products mathematicians like to look for patterns that will make their work easier. a good example of this is squaring binomials. while you can always get the product by writing the binomial twice and multiplying them, there is less work to do if you learn to use a pattern. let’s start by looking at three examples and look for a pattern. look at these results. do you see any patterns?  what about the number of terms? in each example we squared a binomial and the result was a trinomial.  (a + b) 2 = ___ + ___ + ___ now look at the first term in each result. where did it come from? the first term is the product of the first terms of each binomial. since the binomials are identical, it is just the square of the first term!  (a + b) 2 = a 2 + ___ + ___ to get the first term of the product, square the first term. where did the last term come from? look at the examples and find the pattern. the last term is the product of the last terms, which is the square of the last term.  (a + b) 2 = ___ + ___ + b 2 to get the last term of the product, square the last term. finally, look at the middle term. notice it came from adding the “outer” and the “inner” terms—which are both the same! so the middle term is double the product of the two terms of the binomial.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  531  (a + b) 2 = ___ + 2ab + ___  (a − b) 2 = ___ − 2ab + ___  to get the middle term of the product, multiply the terms and double their product. putting it all together: binomial squares pattern if a and b are real numbers,  to square a binomial, square the first term, square the last term , double their product. example 5.32 multiply: ⓐ  (x + 5) 2  ⓑ 2x − 3y 2. ⎛ ⎝  ⎞ ⎠  solution  ⓐ  square the first term. square the last term. double their product. simplify.  ⓑ  use the pattern. simplify.  try it : : 5.63  multiply: ⓐ (x + 9) 2  ⓑ (2c − d) 2.  try it : : 5.64  multiply: ⓐ ⎛⎝y + 11⎞⎠ 2  ⓑ 4x − 5y 2. ⎛ ⎝  ⎞ ⎠  we just saw a pattern for squaring binomials that we can use to make multiplying some binomials easier. similarly, there is a pattern for another product of binomials. but before we get to it, we need to introduce some vocabulary.  532  chapter 5 polynomials and polynomial functions  a pair of binomials that each have the same first term and the same last term, but one is a sum and one is a difference is called a conjugate pair and is of the form (a − b), (a + b). conjugate pair a conjugate pair is two binomials of the form  (a − b), (a + b). the pair of binomials each have the same first term and the same last term, but one binomial is a sum and the other is a difference. there is a nice pattern for finding the product of conjugates. you could, of course, simply foil to get the product, but using the pattern makes your work easier. let’s look for the pattern by using foil to multiply some conjugate pairs.  what do you observe about the products? the product of the two binomials is also a binomial! most of the products resulting from foil have been trinomials. each first term is the product of the first terms of the binomials, and since they are identical it is the square of the first term.  (a + b)(a − b) = a 2 − ___ to get the first term, square the first term. the last term came from multiplying the last terms, the square of the last term.  (a + b)(a − b) = a 2 − b 2 to get the last term, square the last term. why is there no middle term? notice the two middle terms you get from foil combine to 0 in every case, the result of one addition and one subtraction. the product of conjugates is always of the form  a 2 − b 2. this is called a difference of squares.  this leads to the pattern: product of conjugates pattern if a and b are real numbers,  the product is called a difference of squares. to multiply conjugates, square the first term, square the last term, write it as a difference of squares. example 5.33 multiply using the product of conjugates pattern: ⓐ  (2x + 5)(2x − 5)  solution  ⓐ  this openstax book is available for free at http://cnx.org/content/col12119/1.3  ⓑ (5m − 9n)(5m + 9n).  chapter 5 polynomials and polynomial functions  533  are the binomials conjugates? it is the product of conjugates. square the first term, 2x. square the last term, 5. simplify. the product is a difference of squares.  ⓑ  this fits the pattern. use the pattern. simplify.  try it : : 5.65  multiply: ⓐ  (6x + 5)(6x − 5)  ⓑ 4p − 7q 4p + 7q .  try it : : 5.66  multiply: ⓐ  (2x + 7)(2x − 7)  ⓑ 3x − y 3x + y .  ⎛ ⎝  ⎞⎛ ⎠⎝  ⎛ ⎝  ⎞⎛ ⎠⎝  ⎞ ⎠  ⎞ ⎠  we just developed special product patterns for binomial squares and for the product of conjugates. the products look similar, so it is important to recognize when it is appropriate to use each of these patterns and to notice how they differ. look at the two patterns together and note their similarities and differences. comparing the special product patterns  binomial squares  product of conjugates  (a + b) 2 = a 2 + 2ab + b 2  (a − b)(a + b) = a 2 − b 2  (a − b) 2 = a 2 − 2ab + b 2 •  squaring a binomial  •  multiplying conjugates  •  product is a trinomial  •  product is a binomial.  • inner and outer terms with foil are the same.  • inner and outer terms with foil are opposites.  • middle term is double the product of the terms  •  there is no middle term.  example 5.34 choose the appropriate pattern and use it to find the product:  ⓐ (2x − 3)(2x + 3) ⓑ (5x − 8) 2 ⓒ (6m + 7) 2 ⓓ (5x − 6)(6x + 5).  534  chapter 5 polynomials and polynomial functions  solution  ⓐ (2x − 3)(2x + 3) these are conjugates. they have the same first numbers, and the same last numbers, and one binomial is a sum and the other is a difference. it fits the product of conjugates pattern.  use the pattern. simplify.  ⓑ (8x − 5) 2 we are asked to square a binomial. it fits the binomial squares pattern.  use the pattern. simplify.  ⓒ (6m + 7) 2 again, we will square a binomial so we use the binomial squares pattern.  use the pattern. simplify.  ⓓ (5x − 6)(6x + 5) this product does not fit the patterns, so we will use foil.  (5x − 6)(6x + 5)  30x 2 + 25x − 36x − 30 30x 2 − 11x − 30  use foil. simplify.  try it : : 5.67  choose the appropriate pattern and use it to find the product:  ⓐ (9b − 2)(2b + 9) ⓑ 9p − 4 2 ⓒ 7y + 1 2 ⓓ (4r − 3)(4r + 3). ⎛ ⎝  try it : : 5.68  ⎞ ⎠  ⎛ ⎝  ⎞ ⎠  choose the appropriate pattern and use it to find the product:  ⓐ (6x + 7) 2 ⓑ (3x − 4)(3x + 4) ⓒ (2x − 5)(5x − 2) ⓓ (6n − 1) 2. multiply polynomial functions just as polynomials can be multiplied, polynomial functions can also be multiplied. multiplication of polynomial functions for functions  f (x) and g(x),  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  535  ⎛ ⎝  f · g⎞⎠(x) = f (x) · g(x)  example 5.35 for functions  f (x) = x + 2 and g(x) = x 2 − 3x − 4, find: ⓐ ⎛⎝ f · g⎞⎠(x)  ⓑ f · g (2). ⎛ ⎝  ⎞ ⎠  solution  ⓐ  ⎛ ⎝  f · g⎞⎠(x) = f (x) · g(x)  f · g⎞⎠(x) = (x + 2)⎛⎝x 2 − 3x − 4⎞⎠  substitute for f (x)and g(x).  ⎛ ⎝  multiply the polynomials.  ⎛ ⎝  f · g⎞⎠(x) = x⎛⎝x 2 − 3x − 4⎞⎠ + 2⎛⎝x 2 − 3x − 4⎞⎠  distribute.  ⎛ ⎝  f · g⎞⎠(x) = x 3 − 3x 2 − 4x + 2x 2 − 6x − 8  combine like terms.  ⎛ ⎝  ⓑ in part ⓐ we found f · g (x) ⎛ ⎝  ⎞ ⎠  f · g⎞⎠(x) = x 3 − x 2 − 10x − 8  and now are asked to find ⎛ ⎝  to fin  ⎛ ⎝  f · g⎞⎠(2), substitute x = 2.  ⎛ ⎝  f · g⎞⎠(2).  f · g⎞⎠(x) = x 3 − x 2 − 10x − 8  f · g⎞⎠(2) = 2 3 − 2 2 − 10 · 2 − 8 ⎛ ⎞ = 8 − 4 − 20 − 8 ⎝ f · g⎠(2) ⎛ ⎞ = −24 ⎝ f · g⎠(2)  ⎛ ⎝  try it : : 5.69  for functions  f (x) = x − 5 and g(x) = x 2 − 2x + 3, find ⓐ ⎛⎝ f · g⎞⎠(x)  ⓑ f · g (2).  try it : : 5.70  for functions  f (x) = x − 7 and g(x) = x 2 + 8x + 4, find ⓐ ⎛⎝ f · g⎞⎠(x)  ⓑ f · g (2).  ⎛ ⎝  ⎛ ⎝  media : : access this online resource for additional instruction and practice with multiplying polynomials. • introduction to special products of binomials (https://openstax.org/l/37introspecprod)  ⎞ ⎠  ⎞ ⎠  536  chapter 5 polynomials and polynomial functions  5.3 exercises practice makes perfect multiply monomials in the following exercises, multiply the monomials. 178.  179.  180.  ⓑ ⎛⎝47 rs 2⎞⎠⎛⎝14rs 3⎞⎠  ⓑ ⎛⎝58 x 3 y⎞⎠⎛⎝24x 5 y⎞⎠  ⓑ ⎛⎝23 x 2 y⎞⎠⎛⎝34 xy 2⎞⎠  ⓐ ⎛⎝6y 7⎞⎠⎛⎝−3y 4⎞⎠  ⓐ ⎛⎝−10x 5⎞⎠⎛⎝−3x 3⎞⎠  ⓐ (−8u 6)(−9u)  181.  ⓐ (−6c 4)(−12c)  ⓑ ⎛⎝35 m 3 n 2⎞⎠⎛⎝59 m 2 n 3⎞⎠ multiply a polynomial by a monomial in the following exercises, multiply. 182.  ⓐ −8x(x 2 + 2x − 15) ⓑ 5pq 3(p 2 − 2pq + 6q 2)  183.  ⓐ −5t(t 2 + 3t − 18); ⓑ 9r 3 s(r 2 − 3rs + 5s 2)  184.  ⓐ −8y(y 2 + 2y − 15) ⓑ −4y 2 z 2(3y 2 + 12yz − z 2)  185.  ⓐ −5m(m 2 + 3m − 18) ⓑ −3x 2 y 2(7x 2 + 10xy − y 2) multiply a binomial by a binomial in the following exercises, multiply the binomials using ⓐ the distributive property; ⓑ the foil method; ⓒ the vertical method. 186.  (w + 5)(w + 7)  189.  (7q + 4)(3q − 8)  187.  (y + 9)(y + 3)  188.  (4p + 11)(5p − 4)  in the following exercises, multiply the binomials. use any method. 190.  (x + 8)(x + 3)  191.  (y − 6)(y − 2)  192.  (2t − 9)(10t + 1)  193.  (6p + 5)(p + 1)  194.  (q − 5)(q + 8)  195.  (m + 11)(m − 4)  196.  (7m + 1)(m − 3)  197.  (3r − 8)(11r + 1)  198.  (x 2 + 3)(x + 2)  199.  (y 2 − 4)(y + 3)  200.  (5ab − 1)(2ab + 3)  201.  (2xy + 3)(3xy + 2)  202.  (x 2 + 8)(x 2 − 5)  203.  (y 2 − 7)(y 2 − 4)  204.  (6pq − 3)(4pq − 5)  205.  (3rs − 7)(3rs − 4)  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  537  multiply a polynomial by a polynomial in the following exercises, multiply using ⓐ the distributive property; ⓑ the vertical method. 206.  (x + 5)(x 2 + 4x + 3)  207.  (u + 4)(u 2 + 3u + 2)  208.  209.  (a + 10)(3a 2 + a − 5)  210.  (y 2 − 3y + 8)(4y 2 + y − 7)  211.  (y + 8)(4y 2 + y − 7)  (2a 2 − 5a + 10)(3a 2 + a − 5)  multiply special products in the following exercises, multiply. use either method. 212.  (w − 7)(w 2 − 9w + 10)  215.  (6r + 1)(r 2 − 7r − 9)  213.  (p − 4)(p 2 − 6p + 9)  214.  (3q + 1)(q 2 − 4q − 5)  in the following exercises, square each binomial using the binomial squares pattern. 216.  (w + 4) 2  217.  219.  ⎛ ⎝  2y − 3z⎞⎠ 2  ⎛ 220. ⎝y +  ⎛  222. ⎝1 x − 5 225.  1 y⎞ 7 ⎠  2  (5u 2 + 9) 2  (q + 12) 2  ⎛  1⎞ 4⎠  223. ⎝1 x − 8 226.  218.  ⎛ 221. ⎝x +  2  1 y⎞ 9 ⎠  3x − y⎞⎠ 2  ⎛ ⎝  2  (4y 3 − 2) 2  2⎞ 3⎠  2  224.  (3x 2 + 2) 2  227.  (8p 3 − 3) 2  in the following exercises, multiply each pair of conjugates using the product of conjugates pattern. 228.  (5k + 6)(5k − 6)  229.  (8 j + 4)(8 j − 4)  230.  (11k + 4)(11k − 4)  231.  (9c + 5)(9c − 5)  232.  (9c − 2d)(9c + 2d)  233.  (7w + 10x)(7w − 10x)  236.  (ab − 4)(ab + 4)  239.  (15m 2 − 8n 4)(15m 2 + 8n 4)  ⎛ 234. ⎝m + 237.  2 n⎞⎛m − 2 n⎞ 3 ⎠ 3 ⎠⎝  (xy − 9)(xy + 9)  ⎛  235. ⎝p + 238.  4 q⎞⎛p − 4 q⎞ 5 ⎠ 5 ⎠⎝  3  2  3  2  (12p − 11q )(12p + 11q )  in the following exercises, find each product. 240.  ⎛ ⎝  243.  p − 3⎞⎠⎛⎝ p + 3⎞⎠  241.  (t − 9) 2  242.  (m + n) 2  (2x + y)(x − 2y)  244.  (2r + 12) 2  245.  (3p + 8)(3p − 8)  246.  (7a + b)(a − 7b)  247.  (k − 6) 2  248.  (a 5 − 7b) 2  249.  (x 2 + 8y)(8x − y 2)  250.  (r 6 + s 6)(r 6 − s 6)  251.  (y 4 + 2z) 2  252.  (x 5 + y 5)(x 5 − y 5)  253.  (m 3 − 8n) 2  254.  (9p + 8q) 2  538  255.  chapter 5 polynomials and polynomial functions  (r 2 − s 3)(r 3 + s 2)  mixed practice 256.  10y − 6⎞⎠ + ⎛⎝4y − 7⎞⎠  ⎛ ⎝  ⎛  ⎞  257.  ⎛  ⎞  ⎛ ⎝  15p − 4⎞⎠ + ⎛⎝3p − 5⎞⎠  ⎛  258. ⎝x 2 − 4x − 34⎠ − ⎝x 2 + 7x − 6⎠  ⎞  ⎛  ⎞  259. ⎝ j 2 − 8 j − 27⎠ − ⎝ j 2 + 2 j − 12⎠  260.  ( 1 f 8)(20 f 3) 5  261.  ( 1 d 5)(36d 2) 4  262.  (4a 3 b)(9a 2 b 6)  263.  (6m 4 n 3)(7mn 5)  264.  −5m(m 2 + 3m − 18)  265.  5q 3(q 2 − 2q + 6)  266.  (s − 7)(s + 9)  267. ⎝y 2 − 2y⎠⎛⎝y + 1⎞⎠  268.  (5x − y)(x − 4)  269.  (6k − 1)⎛⎝k 2 + 2k − 4⎞⎠  270.  ⎛ ⎝  3x − 11y⎞⎠⎛⎝3x − 11y⎞⎠  271.  (11 − b)(11 + b)  272.  (rs − 2 )(rs + 2 ) 7 7  273.  (2x 2 − 3y 4)(2x 2 + 3y 4)  274.  (m − 15) 2  275.  (3d + 1) 2  276.  (4a + 10) 2  ⎛  ⎞  ⎛  277. ⎝3z +  1⎞ 5⎠  2  multiply polynomial functions 278.  for  f (x) = x + 2  functions  g(x) = 3x − 2x + 4, find ⓐ f · g (x) 2  280.  for  ⎛ ⎝  g(x) = 2x + 7, find ⓐ f · g (x) 282.  for  functions  ⎞ ⎠  ⓑ f · g (−1) ⎞ ⎠  and  ⓑ f · g (−3) ⎛ ⎝  ⎛ ⎝  ⎞ ⎠  and  ⓑ f · g (−1) ⎛ ⎝  ⎞ ⎠  for  279.  f (x) = x − 1  functions  g(x) = 4x + 3x − 5, find ⓐ f · g (x) 2  ⎛ ⎝  281. for functions find ⓐ  ⎞ ⎠  f (x) = x 2 − 5x + 2  g(x) = x − 3x − 1, find ⓐ f · g (x) 2  and  ⎛ ⎝  f (x) = 2x − 7  functions ⎛ ⎝  ⎞ ⎠  283.  ⎛ ⎝  ⎞ ⎠  f · g (x)  for  ⎞ ⎠  and  ⓑ f · g (−2) ⎛ ⎝  ⎞ ⎠  f (x) = 7x − 8 and g(x) = 7x + 8,  ⓑ f · g (−2) ⎛ ⎝  ⎞ ⎠  functions  f (x) = x 2 + 4x − 3  g(x) = x + 2x + 4, find ⓐ f · g (x) 2  ⎛ ⎝  ⎞ ⎠  and  ⓑ f · g (1) ⎛ ⎝  ⎞ ⎠  writing exercises 284. which method do you prefer to use when multiplying two binomials: the distributive property or the foil method? why? which method do you prefer to use when multiplying a polynomial by a polynomial: the distributive property or the vertical method? why?  285. multiply the following:  (x + 2)(x − 2) (y + 7)(y − 7) (w + 5)(w − 5) explain the pattern that you see in your answers.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  286. multiply the following:  (p + 3)(p + 3) (q + 6)(q + 6) (r + 1)(r + 1)  539  287. why does  (a + b) 2 result in a trinomial, but  (a − b)(a + b) result in a binomial?  explain the pattern that you see in your answers.  self check  ⓐ after completing the exercises, use this checklist to evaluate your mastery of the objectives of this section.  ⓑ what does this checklist tell you about your mastery of this section? what steps will you take to improve?  540  5.4  chapter 5 polynomials and polynomial functions  dividing polynomials  learning objectives by the end of this section, you will be able to: dividing monomials dividing a polynomial by a monomial dividing polynomials using long division dividing polynomials using synthetic division dividing polynomial functions use the remainder and factor theorems be prepared! before you get started, take this readiness quiz. 1. add:  3 + x. d d  if you missed this problem, review example 1.28. 2. simplify:  30xy 3 . 5xy  if you missed this problem, review example 1.25. 3. combine like terms: 8a 2 + 12a + 1 + 3a 2 − 5a + 4. if you missed this problem, review example 1.7.  dividing monomials we are now familiar with all the properties of exponents and used them to multiply polynomials. next, we’ll use these properties to divide monomials and polynomials. example 5.36 find the quotient:  54a 2 b 3 ÷ ⎛⎝−6ab 5⎞⎠.  solution when we divide monomials with more than one variable, we write one fraction for each variable. 5⎞ 2 3 ⎛  54a b ÷ ⎝−6ab  rewrite as a fraction. use fraction multiplication. simplify and use the quotient property. multiply.  ⎠  54a 2 b 3 −6ab 5 54 · a 2 · b 3 −6 a b 5 −9 · a · 12 b − 9a2 b  try it : : 5.71  find the quotient:  −72a 7 b 3 ÷ ⎛⎝8a 12 b 4⎞⎠.  try it : : 5.72  find the quotient:  −63c 8 d 3 ÷ ⎛⎝7c 12 d 2⎞⎠.  once you become familiar with the process and have practiced it step by step several times, you may be able to simplify a fraction in one step.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  541  example 5.37 find the quotient:  14x 7 y 12 . 21x 11 y 6  solution be very careful to simplify exponents.  14 by dividing out a common factor, and to simplify the variables by subtracting their 21 14x 7 y 12 21x 11 y 6 2y 6 3x 4  simplify and use the quotient property.  try it : : 5.73  try it : : 5.74  find the quotient:  28x 5 y 14 . 49x 9 y 12  find the quotient:  30m 5 n 11 . 48m 10 n 14  divide a polynomial by a monomial now that we know how to divide a monomial by a monomial, the next procedure is to divide a polynomial of two or more terms by a monomial. the method we’ll use to divide a polynomial by a monomial is based on the properties of fraction addition. so we’ll start with an example to review fraction addition. the sum  y 2 y+2 + simplifies to . 5 5 5  now we will do this in reverse to split a single fraction into separate fractions. for example,  y+2 y 2 can be written + . 5 5 5  this is the “reverse” of fraction addition and it states that if a, b, and c are numbers where  b a b c ≠ 0, then a + c = c + c.  we will use this to divide polynomials by monomials. division of a polynomial by a monomial to divide a polynomial by a monomial, divide each term of the polynomial by the monomial. example 5.38 ⎛  find the quotient: ⎝18x  3  y − 36xy 2⎞⎠ ÷ ⎛⎝−3xy⎞⎠.  solution  ⎛ 3 ⎝18x y  18x 3 y − 36xy 2 −3xy  rewrite as a fraction.  18x 3 y 36xy 2 − −3xy −3xy  divide each term by the divisor. be careful with the signs!  −6x 2 + 12y  simplify.  try it : : 5.75  − 36xy 2⎞⎠ ÷ ⎛⎝−3xy⎞⎠  ⎛  ⎞  find the quotient: ⎝32a 2 b − 16ab 2⎠ ÷  (−8ab).  542  chapter 5 polynomials and polynomial functions  try it : : 5.76  ⎛  find the quotient: ⎝−48a  b − 36a 6 b 5⎞⎠ ÷ ⎛⎝−6a 3 b 3⎞⎠.  8 4  divide polynomials using long division divide a polynomial by a binomial, we follow a procedure very similar to long division of numbers. so let’s look carefully the steps we take when we divide a 3-digit number, 875, by a 2-digit number, 25.  we check division by multiplying the quotient by the divisor. if we did the division correctly, the product should equal the dividend.  35 · 25 875 ✓ now we will divide a trinomial by a binomial. as you read through the example, notice how similar the steps are to the numerical example above. example 5.39 ⎛  ⎞  find the quotient: ⎝x 2 + 9x + 20⎠ ÷  (x + 5).  solution  write it as a long division problem. be sure the dividend is in standard form. divide x 2 by x. it may help to ask yourself, “what do i need to multiply x by to get x 2 ?” put the answer, x, in the quotient over the x term. multiply x times x + 5. line up the like terms under the dividend. subtract x 2 + 5x from x 2 + 9x. you may find it easier to change the signs and then add. then bring down the last term, 20. divide 4x by x. it may help to ask yourself, “what do i need to multiply x by to get 4x ?” put the answer, 4 , in the quotient over the constant term. multiply 4 times x + 5.  subtract 4x + 20 from 4x + 20.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  543  check: multiply the quotient by the divisor.  (x + 4)(x + 5)  you should get the dividend.  x 2 + 9x + 20 ✓  ⎛  ⎞  ⎛  ⎞  try it : : 5.77  find the quotient: ⎝y 2 + 10y + 21⎠ ÷  try it : : 5.78  find the quotient: ⎝m 2 + 9m + 20⎠ ÷  y + 3⎞⎠.  ⎛ ⎝  (m + 4).  when we divided 875 by 25, we had no remainder. but sometimes division of numbers does leave a remainder. the same is true when we divide polynomials. in the next example, we’ll have a division that leaves a remainder. we write the remainder as a fraction with the divisor as the denominator. look back at the dividends in previous examples. the terms were written in descending order of degrees, and there were 3 3 no missing degrees. the dividend in this example will be x 4 − x 2 + 5x − 6. it is missing an x term. we will add in 0x as a placeholder. example 5.40 ⎛  ⎞  find the quotient: ⎝x 4 − x 2 + 5x − 6⎠ ÷  (x + 2).  solution notice that there is no  x 3 term in the dividend. we will add 0x 3 as a placeholder.  write it as a long division problem. be sure the dividend is in standard form with placeholders for missing terms. divide x 4 by x. put the answer, x 3, in the quotient over the x 3 term.  multiply x 3 times x + 2. line up the like terms. subtract and then bring down the next term. divide −2x 3 by x.  put the answer, −2x 2, in the quotient over the  x 2 term. multiply −2x 2 times x + 1. line up the like terms subtract and bring down the next term. divide 3x 2 by x. put the answer, 3x, in the quotient over the x term. multiply 3x times x + 1. line up the like terms. subtract and bring down the next term.  544  chapter 5 polynomials and polynomial functions  divide −x by x. put the answer, −1, in the quotient over the constant term. multiply −1 times x + 1. line up the like terms. change the signs, add. write the remainder as a fraction with the divisor as the denominator.  to check, multiply ⎞ ⎛ (x + 2)⎝x 3 − 2x 2 + 3x − 1 − 4 ⎠ . x+2  the result should be x 4 − x 2 + 5x − 6.  ⎛  ⎞  try it : : 5.79  find the quotient: ⎝x 4 − 7x 2 + 7x + 6⎠ ÷  try it : : 5.80  find the quotient: ⎝x 4 − 11x 2 − 7x − 6⎠ ÷  ⎛  in the next example, we will divide by  (x + 3).  ⎞  (x + 3).  2a − 3. as we divide, we will have to consider the constants as well as the variables.  example 5.41 ⎛  find the quotient: ⎝8a  3  + 27⎞⎠ ÷ (2a + 3).  solution this time we will show the division all in one step. we need to add two placeholders in order to divide.  to check, multiply  (2a + 3)⎛⎝4a 2 − 6a + 9⎞⎠.  the result should be  8a 3 + 27. ⎛ 3  − 64⎞⎠ ÷ (x − 4).  try it : : 5.81  find the quotient: ⎝x  try it : : 5.82  find the quotient: ⎝125x  ⎛  3  − 8⎞⎠ ÷ (5x − 2).  divide polynomials using synthetic division as we have mentioned before, mathematicians like to find patterns to make their work easier. since long division can be tedious, let’s look back at the long division we did in example 5.39 and look for some patterns. we will use this as a basis  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  545  for what is called synthetic division. the same problem in the synthetic division format is shown next.  synthetic division basically just removes unnecessary repeated variables and numbers. here all the removed. as well as the −x 2 and −4x as they are opposite the term above. the first row of the synthetic division is the coefficients of the dividend. the  −5 is the opposite of the 5 in the divisor.  the second row of the synthetic division are the numbers shown in red in the division problem. the third row of the synthetic division are the numbers shown in blue in the division problem. notice the quotient and remainder are shown in the third row.  synthetic division only works when the divisor is of the form x − c. the following example will explain the process. example 5.42 use synthetic division to find the quotient and remainder when  2x 3 + 3x 2 + x + 8 is divided by x + 2.  solution write the dividend with decreasing powers of x. write the coefficients of the terms as the first row of the synthetic division. write the divisor as x − c and place c in the synthetic division in the divisor box. bring down the first coefficient to the third row.  multiply that coefficient by the divisor and place the result in the second row under the second coefficient.  add the second column, putting the result in the third row.  multiply that result by the divisor and place the result in the second row under the third coefficient.  add the third column, putting the result in the third row.  multiply that result by the divisor and place the result in the third row under the third coefficient.  x and x 2 are  546  chapter 5 polynomials and polynomial functions  add the final column, putting the result in the third row.  the quotient is 2x 2 − 1x + 3 and the remainder is 2. the division is complete. the numbers in the third row give us the result. the 2 −1 quotient. the quotient is 2x 2 − 1x + 3. the 2 in the box in the third row is the remainder.  3 are the coefficients of the  check:  (quotient)(divisor) + remainder = dividend ⎛ 2 ⎝2x  ? − 1x + 3⎞⎠(x + 2) + 2 = 2x 3 + 3x 2 + x + 8  ? 2x 3 − x 2 + 3x + 4x 2 − 2x + 6 + 2 = 2x 3 + 3x 2 + x + 8  2x 3 + 3x 2 + x + 8 = 2x 3 + 3x 2 + x + 8 ✓  try it : : 5.83 use synthetic division to find the quotient and remainder when  3x 3 + 10x 2 + 6x − 2 is divided by x + 2.  try it : : 5.84 use synthetic division to find the quotient and remainder when  4x 3 + 5x 2 − 5x + 3 is divided by x + 2.  in the next example, we will do all the steps together. example 5.43 use synthetic division to find the quotient and remainder when  x 4 − 16x 2 + 3x + 12 is divided by x + 4.  solution the polynomial  x 4 − 16x 2 + 3x + 12 has its term in order with descending degree but we notice there is no x 3 term.  we will add a 0 as a placeholder for the  x 3 term. in x − c form, the divisor is x − (−4).  we divided a 4th degree polynomial by a 1st degree polynomial so the quotient will be a 3rd degree polynomial. reading from the third row, the quotient has the coefficients  1  −4 0  3, which is x 3 − 4x 2 + 3. the remainder  is 0.  try it : : 5.85 use synthetic division to find the quotient and remainder when  x 4 − 16x 2 + 5x + 20 is divided by x + 4.  try it : : 5.86 use synthetic division to find the quotient and remainder when  x 4 − 9x 2 + 2x + 6 is divided by x + 3.  divide polynomial functions just as polynomials can be divided, polynomial functions can also be divided.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  547  division of polynomial functions for functions  f (x) and g(x), where g(x) ≠ 0,  f (x) ⎛f ⎞ ⎝ g ⎠(x) = g(x)  example 5.44 for functions  ⎛f ⎞ f (x) = x 2 − 5x − 14 and g(x) = x + 2, find: ⓐ ⎝ g ⎠(x)  ⓑ ⎛⎝ gf ⎞⎠(−4).  solution  ⓐ  ⎛f ⎞ x 2 − 5x − 14 ⎝ g ⎠(x) = x+2 ⎛f ⎞ ⎝ g ⎠(x) = x − 7  substitute for f (x) and g(x). divide the polynomials.  ⓑ in part ⓐ we found ⎛⎝ gf ⎞⎠(x)  and now are asked to find  ⎛f ⎞ to fin ⎝ g ⎠(−4), substitute x = −4.  ⎛f ⎞ ⎝ g ⎠(−4).  ⎛f ⎞ ⎝ g ⎠(x) = x − 7 ⎛f ⎞ ⎝ g ⎠(−4) = −4 − 7 ⎛f ⎞ ⎝ g ⎠(−4) = −11  try it : : 5.87  try it : : 5.88  for functions  ⎛f ⎞ f (x) = x 2 − 5x − 24 and g(x) = x + 3, find ⓐ ⎝ g ⎠(x)  ⓑ ⎛⎝ gf ⎞⎠(−3).  for functions  ⎛f ⎞ f (x) = x 2 − 5x − 36 and g(x) = x + 4, find ⓐ ⎝ g ⎠(x)  ⓑ ⎛⎝ gf ⎞⎠(−5).  use the remainder and factor theorem let’s look at the division problems we have just worked that ended up with a remainder. they are summarized in the chart below. if we take the dividend from each division problem and use it to define a function, we get the functions shown in the chart. when the divisor is written as x − c, the value of the function at c, f (c), is the same as the remainder from the division problem.  548  chapter 5 polynomials and polynomial functions  divisor x − c  dividend  remainder  function  f(c)  x 4 − x 2 + 5x − 6  x − (−2)  3x 3 − 2x 2 − 10x + 8  x−2  4  f (x) = 3x 3 − 2x 2 − 10x + 8  4  x 4 − 16x 2 + 3x + 15  x − (−4)  3  f (x) = x 4 − 16x 2 + 3x + 15  3  −4  f (x) = x 4 − x 2 + 5x − 6  −4  table 5.44  to see this more generally, we realize we can check a division problem by multiplying the quotient times the divisor and add the remainder. in function notation we could say, to get the dividend f (x), we multiply the quotient, q(x) times the divisor,  x − c, and add the remainder, r.  if we evaluate this at c, we get:  this leads us to the remainder theorem. remainder theorem if the polynomial function  f (x) is divided by x − c, then the remainder is f (c).  example 5.45 use the remainder theorem to find the remainder when  f (x) = x 3 + 3x + 19 is divided by x + 2.  solution to use the remainder theorem, we must use the divisor in the so, our  c is −2.  to find the remainder, we evaluate  x − c form. we can write the divisor x + 2 as x − (−2).  f (c) which is f (−2).  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  549  to evaluate f (−2), substitute  x = −2. simplify.  the remainder is 5 when f (x) = x 3 + 3x + 19 is divided by  x + 2. check: use synthetic division to check.  the remainder is 5.  try it : : 5.89 use the remainder theorem to find the remainder when  f (x) = x 3 + 4x + 15 is divided by x + 2.  try it : : 5.90 use the remainder theorem to find the remainder when when we divided 4a 2 − 6a + 9 by  8a 3 + 27 by 2a + 3 in example 5.41 the result was 4a 2 − 6a + 9. to check our work, we multiply  2a + 3 to get 8a 3 + 27 .  ⎛ 2 ⎝4a  written this way, we can see that remainder was zero. whenever a divisor, factor of  f (x).  f (x) = x 3 − 7x + 12 is divided by x + 3.  − 6a + 9⎞⎠(2a + 3) = 8a 3 + 27  4a 2 − 6a + 9 and 2a + 3 are factors of 8a 3 + 27. when we did the division, the  x − c, divides a polynomial function, f (x), and resulting in a remainder of zero, we say x − c is a  the reverse is also true. if  x − c is a factor of f (x) then x − c will divide the polynomial function resulting in a  remainder of zero. we will state this in the factor theorem. factor theorem for any polynomial function  f (x),  • if  x − c is a factor of f (x), then f (c) = 0  • if  f (c) = 0, then x − c is a factor of f (x)  example 5.46 use the remainder theorem to determine if  x − 4 is a factor of f (x) = x 3 − 64.  550  chapter 5 polynomials and polynomial functions  solution the factor theorem tells us that  x − 4 is a factor of f (x) = x 3 − 64 if f (4) = 0. f (x) = x 3 − 64  to evaluate f (4) substitute x = 4. simplify. subtract. since  f (4) = 4 3 − 64 f (4) = 64 − 64 f (4) = 0  f (4) = 0, x − 4 is a factor of f (x) = x 3 − 64.  try it : : 5.91  use the factor theorem to determine if  x − 5 is a factor of f (x) = x 3 − 125.  try it : : 5.92  use the factor theorem to determine if  x − 6 is a factor of f (x) = x 3 − 216.  media : : access these online resources for additional instruction and practice with dividing polynomials. • dividing a polynomial by a binomial (https://openstax.org/l/37polybybinom) • synthetic division & remainder theorem (https://openstax.org/l/37syndivision)  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  551  5.4 exercises practice makes perfect divide monomials in the following exercises, divide the monomials. 288.  15r 4 s 9 ÷ ⎛⎝15r 4 s 9⎞⎠  289.  291.  45x 5 y 9 −60x 8 y 6  292.  ⎛ 4 3⎞⎛ 5⎞ ⎝6a b ⎠⎝4ab ⎠ 2 ⎞⎛ 3 ⎞ ⎝12a b⎠⎝a b⎠  295.  294. ⎛  20m 8 n 4 ÷ ⎛⎝30m 5 n 9⎞⎠ ⎛ 3 6⎞ 5 4⎞⎛ ⎝10m n ⎠⎝5m n ⎠  290.  293.  25m 7 n 5  18a 4 b 8 −27a 9 b 5 ⎛ 3 8⎞ 4 7⎞⎛ ⎝−18p q ⎠⎝−6p q ⎠  −36p 12 q 10  ⎛ 2 5⎞⎛ 3 ⎞ ⎝4u v ⎠⎝15u v⎠ ⎛ 3 ⎞⎛ 4 ⎞ ⎝12u v⎠⎝u v⎠  divide a polynomial by a monomial in the following exercises, divide each polynomial by the monomial. ⎛ 3⎞ 296. ⎝9n 4 + 6n ⎠ ÷  ⎛  3n  297. ⎝8x  ⎛ ⎞ 3⎞ ⎛ 299. ⎝48y 4 − 24y ⎠ ÷ ⎝−8y 2⎠  302.  10x 2 + 5x − 4 −5x  3  + 6x 2⎞⎠ ÷ 2x  300.  66x 3 y 2 − 110x 2 y 3 − 44x 4 y 3 11x 2 y 2  303.  ⎛ ⎞ 3⎞ ⎛ 298. ⎝63m 4 − 42m ⎠ ÷ ⎝−7m 2⎠  301.  72r 5 s 2 + 132r 4 s 3 − 96r 3 s 5 12r 2 s 2  20y 2 + 12y − 1 −4y  divide polynomials using long division in the following exercises, divide each polynomial by the binomial. ⎛  ⎞  304. ⎝y 2 + 7y + 12⎠ ÷  ⎛  ⎞  ⎛ ⎝  y + 3⎞⎠  307. ⎝4x 2 − 17x − 15⎠ ÷ ⎛  310. ⎝3b ⎛  313. ⎝m  3  3  (x − 5)  + b 2 + 4⎞⎠ ÷ (b + 1)  + 1000⎞⎠ ÷ (m + 10)  ⎛  ⎞  ⎛  ⎞  305. ⎝a 2 − 2a − 35⎠ ÷  308. ⎝q 2 + 2q + 20⎠ ÷ ⎛  311. ⎝2n  3  ⎛  314. ⎝64x  (a + 5)  306.  ⎛ ⎝  309. ⎝ p 2 + 11p + 16⎠ ÷  q + 6⎞⎠  − 10n + 28⎞⎠ ÷ (n + 3) 3  − 27⎞⎠ ÷ (4x − 3)  ⎛ 2 ⎝6m  − 19m − 20⎞⎠ ÷ (m − 4)  ⎛  ⎛ 3  312. ⎝z ⎛  ⎞  ⎛ ⎝  p + 8⎞⎠  + 1⎞⎠ ÷ (z + 1)  315. ⎝125y  3  − 64⎞⎠ ÷ ⎛⎝5y − 4⎞⎠  divide polynomials using synthetic division in the following exercises, use synthetic division to find the quotient and remainder. 316.  x 3 − 6x 2 + 5x + 14 is divided by x + 1  317.  x 3 − 3x 2 − 4x + 12 is divided by x + 2  318.  2x 3 − 11x 2 + 11x + 12 is divided by x − 3  319.  2x 3 − 11x 2 + 16x − 12 is divided by x − 4  320.  x 4 + 13x 2 + 13x + 3 is divided by x + 3  321.  x 4 + x 2 + 6x − 10 is divided by x + 2  552  chapter 5 polynomials and polynomial functions  322.  2x 4 − 9x 3 + 5x 2 − 3x − 6 is divided by x − 4  323.  3x 4 − 11x 3 + 2x 2 + 10x + 6 is divided by x − 3  divide polynomial functions in the following exercises, divide. 324.  for  functions  g(x) = x − 4, find ⓐ 326. for functions  g(x) = x − 2, find ⓐ 328.  for  f (x) = x 2 − 13x + 36 ⎛f ⎞ ⎛f ⎞ ⎝ g ⎠(x) ⓑ ⎝ g ⎠(−1)  and  f (x) = x 3 + x 2 − 7x + 2 ⎛f ⎞ ⎛f ⎞ ⎝ g ⎠(x) ⓑ ⎝ g ⎠(2)  and  327. for functions  and  329.  functions  f (x) = x 2 − 5x + 2  g(x) = x − 3x − 1, find ⓐ f · g (x) 2  ⎛ ⎝  ⎞ ⎠  for  functions  g(x) = x − 9, find ⓐ  ⓑ f · g (−1) ⎛ ⎝  325.  f (x) = x 2 − 15x + 45 ⎛f ⎞ ⎛f ⎞ ⎝ g ⎠(x) ⓑ ⎝ g ⎠(−5)  f (x) = x 3 + 2x 2 − 19x + 12 and ⎛f ⎞ ⎛f ⎞ g(x) = x − 3, find ⓐ ⎝ g ⎠(x) ⓑ ⎝ g ⎠(0) for  functions  f (x) = x 2 + 4x − 3  g(x) = x + 2x + 4, find ⓐ f · g (x) 2  ⎞ ⎠  and  ⎛ ⎝  ⎞ ⎠  and  ⓑ f · g (1) ⎛ ⎝  ⎞ ⎠  use the remainder and factor theorem in the following exercises, use the remainder theorem to find the remainder. 330.  f (x) = x 3 − 8x + 7 is divided by x + 3  331.  f (x) = x 3 − 4x − 9 is divided by x + 2  332.  f (x) = 2x 3 − 6x − 24 divided by x − 3  333.  f (x) = 7x 2 − 5x − 8 divided by x − 1 x − c is a factor of the polynomial function.  in the following exercises, use the factor theorem to determine if determine whether + 8x 2 + 21x + 18  x+3  determine whether − 7x 2 + 7x − 6  x−2  334. 3  x  336. 3  x  a  factor  of  x  a  factor  of  determine whether + x 2 − 14x + 8  x+4  a  factor  of  determine whether − 7x 2 + 11x + 3  x−3  a  factor  of  335. 3  337. 3  x  writing exercises 338.  james  divides  48y + 6  by  6  this  way:  48y + 6 = 48y. what is wrong with his reasoning? 6 340. explain when you can use synthetic division.  339. divide  10x 2 + x − 12 and explain with words 2x  how you get each term of the quotient.  341. in your own words, write the steps for synthetic division for x 2 + 5x + 6 divided by x − 2.  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  553  self check  ⓐ after completing the exercises, use this checklist to evaluate your mastery of the objectives of this section  ⓑ on a scale of 1-10, how would you rate your mastery of this section in light of your responses on the checklist? how can you improve this?  554  chapter 5 polynomials and polynomial functions  chapter 5 review key terms binomial a binomial is a polynomial with exactly two terms. conjugate pair a conjugate pair is two binomials of the form  (a − b), (a + b). the pair of binomials each have the  same first term and the same last term, but one binomial is a sum and the other is a difference. degree of a constant the degree of any constant is 0. degree of a polynomial the degree of a polynomial is the highest degree of all its terms. degree of a term the degree of a term is the sum of the exponents of its variables. monomial a monomial is an algebraic expression with one term. a monomial in one variable is a term of the form ax m, where a is a constant and m is a whole number. polynomial a monomial or two or more monomials combined by addition or subtraction is a polynomial. polynomial function a polynomial function is a function whose range values are defined by a polynomial. power property according to the power property, a to the m to the n equals a to the m times n. product property according to the product property, a to the m times a to the n equals a to the m plus n. product to a power according to the product to a power property, a times b in parentheses to the m equals a to the m times b to the m. properties of negative exponents according to the properties of negative exponents, a to the negative n equals 1 divided by a to the n and 1 divided by a to the negative n equals a to the n. quotient property according to the quotient property, a to the m divided by a to the n equals a to the m minus n as long as a is not zero. quotient to a negative exponent raising a quotient to a negative exponent occurs when a divided by b in parentheses to the power of negative n equals b divided by a in parentheses to the power of n. quotient to a power property according to the quotient to a power property, a divided by b in parentheses to the power of m is equal to a to the m divided by b to the m as long as b is not zero. standard form of a polynomial a polynomial is in standard form when the terms of a polynomial are written in descending order of degrees. trinomial a trinomial is a polynomial with exactly three terms. zero exponent property according to the zero exponent property, a to the zero is 1 as long as a is not zero.  key concepts 5.1 add and subtract polynomials • monomial ◦ a monomial is an algebraic expression with one term. ◦ a monomial in one variable is a term of the form ax m, where a is a constant and m is a whole number. • polynomials ◦ polynomial—a monomial, or two or more algebraic terms combined by addition or subtraction is a polynomial. ◦ monomial —a polynomial with exactly one term is called a monomial. ◦ binomial — a polynomial with exactly two terms is called a binomial. ◦ trinomial —a polynomial with exactly three terms is called a trinomial. • degree of a polynomial ◦ the degree of a term is the sum of the exponents of its variables. ◦ the degree of a constant is 0. ◦ the degree of a polynomial is the highest degree of all its terms.  5.2 properties of exponents and scientific notation • exponential notation  this openstax book is available for free at http://cnx.org/content/col12119/1.3  chapter 5 polynomials and polynomial functions  this is read a to the in the expression  555  m th power.  m  a , the exponent m tells us how many times we use the base a as a factor.  • product property for exponents if a is a real number and m and n are integers, then  am · an = am + n to multiply with like bases, add the exponents. • quotient property for exponents if a is a real number, a ≠ 0, and m and n are integers, then  a m = a m − n, m > n an  and  am = 1 , n > m an an − m  • zero exponent ◦ if a is a non-zero number, then  a 0 = 1.  ◦ if a is a non-zero number, then a to the power of zero equals 1. ◦ any non-zero number raised to the zero power is 1. • negative exponent ◦ if n is an integer and  a ≠ 0, then a −n = 1n or 1−n = a n. a a  • quotient to a negative exponent property if a, b are real numbers, a ≠ 0, b ≠ 0 and n is an integer, then  ⎛a ⎞ ⎝b ⎠  −n  ⎛ ⎞ = ⎝ba ⎠  n  • power property for exponents if a is a real number and m, n are integers, then  (a m) n = a m · n to raise a power to a power, multiply the exponents. • product to a power property for exponents if a and b are real numbers and m is a whole number, then (ab) m = a m b m to raise a product to a power, raise each factor to that power. • quotient to a power property for exponents if a and are real numbers, b ≠ 0, and m is an integer, then  ⎛a ⎞ ⎝b ⎠  m  m = am b  to raise a fraction to a power, raise the numerator and denominator to that power. • summary of exponent properties if a and b are real numbers, and m and n are integers, then  556  chapter 5 polynomials and polynomial functions  property  description  product property  am · an = am + n  power property  (a m) n = a m · n  product to a power  (ab) n = a m b m  quotient property  a m = a m − n, a ≠ 0 an  zero exponent property  a 0 = 1, a ≠ 0  quotient to a power property:  ⎛a ⎞ ⎝b ⎠  properties of negative exponents  a −n = 1n and 1−n = a n a a  quotient to a negative exponent  ⎛a ⎞ ⎝b ⎠  m  m = am, b ≠ 0 b  −n  • scientific notation a number is expressed in scientific notation when it is of the form a × 10 n where 1 ≤ a < 10 and n is  ⎛ ⎞ = ⎝ba ⎠  n  an integer.  • how to convert a decimal to scientific notation. step 1. move the decimal point so that the first factor is greater than or equal to 1 but less than 10. step 2. count the number of decimal places,  n, that the decimal point was moved.  step 3. write the number as a product with a power of 10. if the original number is. ▪ greater than 1, the power of 10 will be 10 n. ▪ between 0 and 1, the power of 10 will be  10 −n.  step 4. check. • how to convert scientific notation to decimal form. step 1. determine the exponent, step 2. move the decimal  n, on the factor 10.  n places, adding zeros if needed.  ▪ if the exponent is positive, move the decimal point  n places to the right.  ▪ if the exponent is negative, move the decimal point  |n| places to the left.  step 3. check.  5.3 multiply polynomials • how to use the foil method to multiply two",t_c1269295400a,other,0
c_a1888f2fd673,"seeing that the centroid is 2/3 of the way along every median  i want to do a quick refresher on medians of triangles, and also explore an interesting property of them that will be useful, i think, in future problems. so let me just draw an arbitrary triangle over here. now that's good enough. now a median of the triangle-- and we'll see a triangle has three of them-- is just a line that connects a vertex of the triangle with the midpoint of the opposite side. so the opposite side's midpoint looks right about there. this length is equal to that length. and so this is a median. close enough. and of course, we have three vertices, so we'll have three medians. if we start at this vertex, we want to go to the midpoint of the opposite side. it looks right about there. so this blue line right over here is another median. it's not a completely straight line, but i think you get the idea. then we could also do it from this point right over here. draw a line from this vertex to the midpoint of the opposite side. let's see, the midpoint of the opposite side is there. and we draw a line. each of these-- i could draw a straighter line than that. let me draw it. there. well, i think you get the idea. these are all medians of this triangle. and what's neat about medians is that all three medians always intersect in one point. and that by itself is a pretty neat property. and that one point that they intersect in is called the centroid. and if this was actually a physical triangle, let's say you made it out of iron, and if you were to toss it-- well, even before you toss it, the centroid would actually be the center of mass. so let's say this is an iron triangle. let's say that this right here is an iron triangle that has its centroid right over here, then this iron triangle's center of mass would be where the centroid is, assuming it has a uniform density. and if you were to throw that iron triangle, it would rotate around this point. assuming that it had some rotational motion, it would rotate around that centroid, or around the center of mass. but anyway, the point of this video is not to focus on physics and throwing iron triangles. the point here is i want to show you a neat property of medians. and the property is that if you pick any median, the distance from the centroid to the midpoint of the opposite side-- so this distance-- is going to be half of this distance. so if this distance right here is a, then this distance right here is 2a. or another way to think about it is this distance is 2/3 of the length of the entire median, and this distance right here is 1/3 of the length of the entire median. and let's just prove it for ourselves just so you don't have to take things on faith. and to do that, i'll draw an arbitrary triangle. i'll do a two-dimensional triangle, and i'll do it in three dimensions because at least in my mind, it makes the math a little bit easier. in general, whenever you have an n-dimensional figure and you embed it in n plus 1 dimensions, it makes the math a little bit easier. the actual tetrahedron problem that we did, you could actually embed it in four dimensions and it would make the math easier. it's just much harder to visualize, so i didn't do it that way. but let's just have an arbitrary triangle. and let's say it has a vertex and there, a vertex there, and a vertex there. so i'm not making any assumptions about the triangle. i'm not saying it's isosceles, or equilateral or anything. it's just an arbitrary triangle. and so let's say this coordinate right over here is-- i'll call this the x-axis. so, this is the x-axis, the y-axis, and the z-axis. i know some of y'all are used to swapping these two axes, but it doesn't make a difference. so let's call this coordinate right here a, 0, 0. so it's a along the x-axis. let's call this coordinate 0, b, 0. and let's call this coordinate up here, 0, 0, c. and if you connect the points, you're going to have a triangle just like that. now, the centroid of a triangle, especially in three dimensions. the centroid of a triangle is just going to be the average of the coordinates of the vertices. or the coordinate of the centroid here is just going to be the average of the coordinates of the vertices. so this coordinate right over here is going to be-- so for the x-coordinate, we have 0 plus 0 plus a. so we have three coordinates. they add up to a, and we have to divide by 3. so it's a over 3. the y-coordinate is going to b plus 0 plus 0. they add up to b, but we have three of them, so the average is b over 3. and then same thing-- we do it for the z-coordinate. the average is going to be c, is c over 3. and i'm not proving it to you right here. you could verify it for yourself. but it's going to be the average, that if you were to figure out what this line is, this line is, and this line is, this centroid, or this center of mass of this triangle, if it had some mass, is just the average of these coordinates. now, what we want to do is use this information. let's just use this coordinate right here and then compare just using the distance formula. let's compare this distance up here in orange to this distance down here in yellow. and remember, this point right over here-- this is the median of this bottom side right over here. it's just going to be the average of these two points. and so the x-coordinate-- 0 plus a over 2 is going to be a over 2. b plus 0 over 2 is going to be b over 2. and then it has no z-coordinates, so it's just going to be 0. 0 plus 0 over 2 is 0. so we know the coordinates for this point that point and that point. so we can calculate the yellow distance and we can calculate the orange distance. so let's calculate the orange distance. so that is going to be equal to the square root of-- and we just take the difference of each of these points squared. so it's a over 3 minus 0 squared. so that's going to be a squared over 9, plus b over 3 minus 0 squared. so that's b squared over 9. plus c over 3 minus c, which is negative 2/3. and we want to square that. so we're going to have positive 4 over 9c squared. did i do that right? c over 3, so 1/3 minus 1 is negative 2/3. so this is negative 2/3 c. you square it. you're going to get 4/9 c squared. so that's the orange distance. now, let's calculate-- and if we want to do it, we can express this-- let me express it a little bit simpler than this. this is the same thing as the square root of a squared plus b squared plus 4c squared over the square root of 9, which is just equal to 3. now let's do the same thing with the yellow distance. so it's going to be equal to the square root of-- so if we have a over 2 minus a over 3. so 1/2 minus 1/3-- that's the same thing as 3/6 minus 2/6, so it's 1/6 a. 1/6 a squared is a squared over 36. b over 2 minus b over 3 is b over 6. you square it. you get plus b squared over 36. and then finally you have 0 minus c over 3 squared. that's going to be c squared over 9. but just so we get a common denominator, c squared over 9 is the same thing as plus 4c squared over 36. and we can rewrite this as the square root of a squared plus b squared plus 4c squared over 6. so you can see, this distance right here, if you multiply this orange distance by 1/2, you're going to get-- so if you multiply the orange distance by 1/2 or if you divide it by 2, you get the yellow distance. so this is always going to be twice the distance as this because we did this in the most general possible way. we assumed nothing about this triangle. so remember that little property that the centroid, the intersection of the medians-- the intersection happens 2/3 away from the vertex or 1/3 the length of the median away from the midpoint of the opposite side. and we can use that property in-- well, we'lll probably use it in a bunch of problems. but anyway, hopefully you found that interesting.",t_0cf15b627912,other,0
c_f6e713e6e920,"here are a few of the many ways to look at data. which is your favorite?  - [voiceover] what i want to do in this video is think about all of all the different ways that we can represent data. so right over here, we have a list of, and i'm just using this as one form of data, a list of students' scores on, say, the last test, so amy got 90 percent right, bill got 95 percent right, cam got 100 percent right, efra also got 100 percent right, and farah got 80 percent right. this is one way to show data. remember, data is just recorded information, and it could be numeric like this, it could be quantitative, so you're recording actual numbers, or it could even be things you could record data on how do they like the test, and they could have scored it based on, i really liked it, i kind of liked it, i didn't like it, or they might have rated it on a scale of zero to five, which would have been numbers, but it's numbers that are measuring peoples' opinions, as opposed to, here, we have numbers that are measuring their actual scores. so there's all different types of data, and i don't want to get into all of that, but let's just start thinking about different ways to represent this data. so this is one way, you could view this as a table where you have the name, and then you have the score. so you have your name column, and then you have your score column. and i can construct it as a table, so clearly, it looks like a table. like that, that's one way, one very common way of representing data, just like that. that's actually how most traditional databases record data, in tables like this. but you could also do it in other ways. so you could record it as a... often times called a bar graph, or sometimes, a histogram, so you could put score on the vertical axis here, and then you could have your names over here. and let's see the scores, let's see, maybe we'll make this a 50. actually, let me just mark them off. so this is 10, 20, 30, that's too big. 10, 20, 30, 40, 50, 60, 70, 80, 90, so that's... and then 100, so that's 100. one, two, three, four, five, that would be 50 right over there, and then you can go person by person. so amy got a 90 on the exam, so the bar will go up to 90. so that is amy, and then you have bill, got a 95, so it's going to be between 90 and 100, so it's going to be right over there. bill got a 95, and so it'll look like this. bill, so that is bill. and then you have cam, who got 100, on the exam. so, make sure, you see i'm hand drawing it, so it's not as precise as if i were to do it on a computer. so this right over there, that is cam's score. efra got the same score as cam, so her score is going to be, let me do that in efra's color, and that's efra's score right there. she also got 100. so, efra... efra, and then finally, farah got an 80, so 60, 70, 80, so farah got an 80. so this is farah's score right over here. so this is another way of representing the data, and here we see it in visual form, but it has the same information. you can look up someone's name, and then figure out their score. amy scored a 90, bill scored a 95, cam scored 100, efra also scored 100, farah scored an 80. and there's even other ways you can have some of this information. in fact sometimes, you might not even know their names, and so then it would be less information but (mumbles) a list of scores. the professor might say, ""hey, here are the five scores ""that people got on the exam."" and they were listed 90, 95, 100... 100, and 80, now, if it was listed, this was all the data you got, this is less information than the data that's in this bar graph, or this histogram, or the data that's given in this table right over here, because here, not only do we know the scores, but we know who got what score. here, we only know the list of scores, but there's even other ways, and this is not an exhaustive video of all of the different ways you can represent data. you can also represent data by looking at the frequency of scores. so, the frequency of scores right over here, so instead of writing the people, you could write the scores. so let's see, you could say this is 80, 85, 90, 95, and 100, and then you could record the frequency that people got these scores. so how many times do we have a score of an 80? well, farah is the only person with a score of 80, so you put one data point there. no one got an 85, one person got a 90, so you put a data point there. one person got a 95, so you can put that data point right over there. and then two people got 100. so this is one and two. let's see the other 100 is in this color, so i'll just do it in the color. you wouldn't necessarily have to color code it like this. so this is another way to represent, and this axis, you could just view it as the number. so this tells you how many 80s there were, how many 90s there are, how many 95s, and how many 100s. so this right over here, has the same data as this list of numbers. it's just another way of looking at it. and once you have your data arranged in any of these ways, we can start to ask interesting questions. we can ask ourselves things like, well, what is the range of data? what is the range in the data? and the range is just the spread between the lowest point and the highest point. so the range in this data, is going to be the difference between the highest score, and the highest scores are 100, and the lowest score, an 80, so the range is going to be the difference between the max, minus the min. the maximum score minus the minimum score. so it's going to be 100 minus 80 is equal to 20, so that gives you a sense of things, it kind of gives you a sense of spread. you could also ask yourself, well, how many people scored below 100? and these are just interesting questions. below 100, and you can actually answer that question, well, actually, you could have answered either of these questions with any of these different ways of looking at the data. if you say, how many people scored below 100? well, one, two, three? how many people scored below 100? well, 100 is up here, so it's giong to be one, two, three. how many people scored below 100? one, two, three. how many people scored below 100? one, two, three. and so, any way you look at it, you would have gotten three. and you could also ask yourself, what is the most frequent score? so, most frequent. and once again, you could answer that question with any of these ways of representing this data. you could look at our original table and you say, look, there's only one 90, one 95, one 80, there's two 100s. so you'd say look, the most frequent score is 100. you'd see that over here too, you actually have two 100s, there's only one of each of the other scores. here you also see the 200s, and here is probably the clearest if you're looking at frequency. sometimes this might be called a frequency plot. it's often called a frequency plot. and you see here, the most frequent one is the one that has the most dots on it which is 100. so anyway, that's just a very, high level overview of how you can look at data in different ways to represent data, but the one thing i really want you to get from this, is that these are all different ways of representing the same data. and we could probably invent other ways of doing it as well.",t_4db98aa3dbf4,other,0
c_96a3803af264,"in this video, we apply vsepr theory to molecules and ions with six groups or ""clouds"" of electrons around the central atom. to minimize repulsions, six electron clouds will always adopt a octahedral electron geometry. depending on how many of the clouds are lone pairs, the molecular geometry will be octahedral (no lone pairs), square pyramidal (one lone pair), or square planer (two lone pairs).  in this video, we're going to apply vsepr theory to 6 electron clouds. so if our goal is to find the shape of the sulfur hexafluoride molecule, once again we start with our dot structure. so sulfur is in group 6 on the periodic table, so 6 valence electrons. fluorine is in group 7, so 7 valence electrons, but i have 6 of them. so 7 times 6 gives me 42, and 42 plus 6 gives me 48 valence electrons that we need to show in our dot structure. sulfur goes in the center, so we go ahead and put sulfur there. and we surround sulfur with 6 fluorines. so let me go ahead and put in those 6 fluorines surrounding our sulfur. our next step is to see how many valence electrons that we've shown so far. so i go and highlight those-- 2, 4, 6, 8, 10, and 12. so 48 minus 12 gives me 36 valence electrons left over, which we put on our terminal atoms, which are our fluorines. so fluorine is going to follow the octet rule. and since each fluorine is already surrounded by 2 electrons, we're going to give each fluorine 6 more. so by giving each fluorine 6 more, now each fluorine has an octet of electrons around it. so if i'm adding 6 electrons to 6 atoms, 6 times 6 is 36. and so therefore, i have now represented of all my valence electrons. and we're done with our dot structure. we can move on to step two and count the number of electron clouds surrounding our central atom, so regions of electron density. so these bonding electrons here, that's a region of electron density. and i can just keep on going all the way around. so all of these bonding electrons surrounding our sulfur are regions of electron density. therefore, we consider them to be electron clouds. vsepr theory says that these valence electrons are all negatively charged, and therefore, they're all going to repel each other and try to get as far away from each other in space as they possibly can. and so when you have 6 electron clouds, they're going to point towards the corners of a regular octahedron to try to get as far away from each other as they can. so an octahedron with 8 faces on it. so let me see if i can sketch in an octahedron here. so let's see if we can do it. it's a little bit tricky to draw. so if we consider our sulfur to be at the center right here-- let's go ahead and put a point up here and then start connecting some lines. so this is sort of what it looks like. so let's do that and then a point down here as well. and so we connect those lines. and once again, this is just a rough sketch of an octahedron. something like that. so if you think about where your fluorines are-- right there. here's a fluorine right here. there's a fluorine right here. so at these corners, you could think about a fluorine being there like that. so that's our octahedron. so that's step three. the geometry of the electron clouds around the central atom, they occupy an octahedral geometry. step four, ignore any lone pairs in your central atom and predict the geometry of the molecule. well, since we have no lone pairs on our central sulfur, the geometry of the molecule is the same as the geometry of the electron clouds. and so therefore, we can say that sulfur hexafluoride is an octahedral molecule. so let's go ahead and write octahedral here. in terms of bond angles, let's analyze our drawing a little bit more here. so if i look at this top fluorine and i go straight down like an axis to that other fluorine, we would expect one of the ideal bond angles to be 180 degrees for this octahedron here. and the other ideal bond angles would be 90 degrees. so if i think about the angle that the axis i just drew makes with this one right here, so that's 90 degrees as well. and again, anywhere you look, you're also going to get 90 degrees. let me go ahead and change colors here, and we can look at another bond angle in here. so this bond angle, that would also be 90 degrees. so for an octahedral, all 6 positions-- we have 6 fluorines occupying the 6 positions-- are equivalents. they are identical, which means no axial or equatorial groups in an octahedral arrangement. and that makes our life much easier, because in the videos on 5 electron clouds, we had to think about the axial and equatorial groups. let's do one for bromine pentafluoride here, so brf5. so valence electrons, bromine has 7. it's in group 7. fluorine is also in group 7, and i have 5 fluorine. so 7 times 5 gives me 35. 35 plus 7 gives me 42 valence electrons. bromine goes in the center, and bromine is bonded to 5 fluorines. so i can go ahead and put those 5 fluorines around our central atom. we have represented, let's see, 2, 4, 6, 8, and 10 valence electrons so far. 42 minus 10 is, of course, 32 valence electrons. and we're going to start putting those leftover electrons on our terminal atoms, which are our fluorines. so once again, we're going to give each fluorine an octet. so we're going to put 6 more valence electrons around each of our fluorine atoms. and so we're putting 6 more electrons around 5 atoms. so 6 times 5 is 30. so 32 minus 30 gives me 2 valence electrons left over. and whenever you have valence electrons left over after assigning them to your terminal atoms, you put them on your central atom. and so there's going to be a lone pair of electrons on our central bromine like that. so we've drawn our dot structure. let's go back up here and look at our steps again. so after drawing our dot structure, we next count the number of electron clouds that surround our central atom and then predict the geometry of those electron clouds. and so if we look at our central bromine here, let's see how many electron clouds. well, we would have these bonding electrons, a region of electron density, these bonding electrons, these bonding electrons. and we keep on going around here. so those are all electron clouds. so that's 5. and then remember, these non-bonding electrons, this lone pair of electrons, is also a region of electron density. and so we have 6 electron clouds. and so we just saw in the previous example, when you have 6 electron clouds, the electron clouds are going to want to point towards the corners of a regular octahedron. so you're going to get an octahedral geometry for your electron clouds. let's think about this one, though. where will we put those that lone pair of electrons in an octahedron. well, since all 6 positions are identical, it doesn't really matter which one you put that lone pair of electrons in. and so let me see if i can just go ahead and sketch out the shape really fast. so if i were to draw a bromine right here, i'm going to put a fluorine going in this direction, another fluorine going back, this one coming out a little bit, and this one going away. and then i'm going to put a fluorine going this way, and then i'm going to put the lone pair of electrons right down here. again, it didn't really matter which one i chose since they're all identical. i just chose it this way because it's a little bit easier to see the geometry. because when you're looking at the geometry of the molecule, you ignore any lone pairs of electrons on your central atom. and so if we ignore that lone pair of electrons now, and we look at the shape-- so let's see if we can connect these dots here. so we're just going to connect this to look at a shape. so we have a square base here. and if we connect up here to this top fluorine, well, that's kind of a pyramid. so we have a pyramid with a square base. and so we call this square pyramidal. so let's go ahead and write that. this shape is referred to as a square pyramidal shape. and in terms of bond angles, we know our ideal bond angles are going to be 90 degrees. so if we look at that, let's use this green here. so it's just like we talked about before. so that bond angle is 90 degrees. this bond angle in here is 90 degrees. so our ideal bond angles are all 90 degrees for our square pyramidal geometry. let's do one more example of 6 electron clouds. and this is xenon tetrafluoride. so we need to find our valence electrons. so xenon is in group 8, 8 valence electrons. fluorine is in group 7. so 7 valence electrons times 4 gives me 28. 28 plus 8 gives me 36 valence electrons. xenon goes in the center. so we go ahead and put xenon in the center here. and xenon is bonded to 4 fluorines. so we go ahead and put in our 4 fluorines surrounding our xenon. and let's see, we have represented 2, 4, 6, and 8 valence electrons. so 36 minus 8, that would give me 28 valence electrons left over, which we will put on our terminal fluorines here. so each fluorine is going to get an octet. and so we need to put 6 valence electrons on each one of our fluorine atoms. so we are representing 6 more electrons on 4 atoms. so 6 times 4 is 24. so 28 minus 24 gives us 4 valence electrons left over. and we're going to put those on our central atom here, so we're going to put those on the xenon. so we go ahead and add in those 4 electrons in the form of two lone pairs to our central atom. all right. let's go back up and refresh our memory about what we do after we draw our dot structure. so after you draw your dot structure, you count the number of electron clouds. and then you predict the geometry of those electron clouds, and so let's count our electron clouds for this one. so our regions of electron density, so we can see that these bonding electrons are an electron cloud, same with these bonding electrons, and these over here as well. and in this example, we have 2 lone pairs of electrons, and each one of those is a region of electron density. and so we have a total of 6 electron clouds for this example. so once again, 6 electron clouds, they are going to want to get as far away from each other as they can. so they are going to be in an octahedral arrangement, and so let's see if we can sketch out this molecule again. so if the lone pairs of electrons want to get as far away from each other as they possibly can, we're going to put those lone pairs 180 degrees from each other. so here's one lone pair, and then here's our other lone pair. that's as far away from each other as they can get. and then we're going to put our fluorines in here. so here's one fluorine. here would be another fluorine. and then we would have two more back here. so when we look at the shape of xenon tetrafluoride, let's see if we can sketch in what the shape would look like here. so remember, when you're predicting the geometry of the molecule, you ignore the lone pairs of electrons. and so that makes it much easier to see that we have a square that is planar. so we call this square planar. so the geometry is square planar. and in terms of ideal bond angles, that would be 90 degrees. so let me go ahead and show that real fast. so in terms of bond angles, everything here would be 90 degrees for our square planar. and so that's how to approach 6 electron clouds. and our first example had 0 lone pairs of electrons around the central atom. our second example had 1 lone pair. and our third example had 2 lone pairs. and so even though the electron clouds have the same geometry, the actual molecule is said to have a different shape, because you ignore the lone pairs of electrons on your central atom.",t_ebc09946fd5e,other,0
c_d9cc06ae23f8,"lindsay uses fraction models and multiplication to find common denominators for 3/5 and 7/2.  - rewrite each fraction with a denominator of 10. so we have two fractions, three fifths and seven halves and we wanna take their denominators of five and two and change them to be a common denominator of 10. lets start with three fifths and we can look at this visually. here we can use this rectangle to represent a whole, one whole. to show three fifths of that whole, we're gonna need to divide it into fifths or five equal pieces. lets do that. try to make these as equal as possible. we have three pieces, and then finally, there we go. so, these should represent five equal pieces, or fifths. to show three fifths, we need to shade three of those five pieces. so, one, two, three of those five pieces should be shaded in to show three fifths. we've decided we don't want fifths anymore. now, we want tenths. we want a new denominator of 10. to change this fraction over here, to change this to be tenths, we need to split each of these fifths in half. we need to double the amount of pieces. we can do that here. now, instead of fifths, or five equal size pieces, we have tenths. we have one, two, three, four, five, six, seven, eight, nine, ten. we found a way to have tenths without changing the amount that's represented. the same amount is still shaded, but now we have tenths. our denominator doubled. we multiplied it be two, we have twice as many pieces. but look at what happened to our numerator, instead of three pieces, now we have one, two, three, four, five, six pieces. it also doubled. it also was multiplied by two, because if we double all of the pieces, well then the shaded ones will also double. each of those pieces also split in two, so now there's twice as many shaded pieces. so, three fifths can be rewritten as six tenths. three fifths is equal to six tenths, and again, we didn't change the fraction. we didn't change how much was shaded. three fifths and six tenths represented the same amount. we just changed the denominator and wrote it a different way. so, three fifths can be rewritten in tenths as six tenths. now, for seven halves, we again want a denominator of 10. so, we can draw it out, or we could try to use this pattern we just noticed up here to figure out how to make halves turn into tenths. to get from fifths to tenths we had to double, or multiply by two. to get from halves to tenths, we'd have to multiply each of our pieces times five. each of our halves would be split into five pieces. so, we multiply two times five to get tenths. like the pattern showed us up here, if the denominator is multiplied by a number, we multiply the numerator by the same number. those shaded pieces would also be split five times. we multiply our seven times five also. you should match the numerator and denominator are multiplied by the same number. seven times five is 35. so 35 tenths is equal to seven halves. to change these two fractions to have a common denominator of 10, three fifths will become six tenths, and seven halves will become 35 tenths.",t_067ada9a1f34,other,0
c_03c854d0a164,in this video you will learn how to practice against a wall.,t_aab7e54af87b,other,0
c_08063fd31044,"chapter 1 | essential ideas  9  chapter 1  essential ideas  figure 1.1 chemical substances and processes are essential for our existence, providing sustenance, keeping us clean and healthy, fabricating electronic devices, enabling transportation, and much more. (credit “left”: modification of work by “vxla”/flickr; credit “left middle”: modification of work by “the italian voice”/flickr; credit “right middle”: modification of work by jason trim; credit “right”: modification of work by “gosheshe”/flickr)  chapter outline 1.1 chemistry in context 1.2 phases and classification of matter 1.3 physical and chemical properties 1.4 measurements 1.5 measurement uncertainty, accuracy, and precision 1.6 mathematical treatment of measurement results  introduction your alarm goes off and, after hitting “snooze” once or twice, you pry yourself out of bed. you make a cup of coffee to help you get going, and then you shower, get dressed, eat breakfast, and check your phone for messages. on your way to school, you stop to fill your car’s gas tank, almost making you late for the first day of chemistry class. as you find a seat in the classroom, you read the question projected on the screen: “welcome to class! why should we study chemistry?” do you have an answer? you may be studying chemistry because it fulfills an academic requirement, but if you consider your daily activities, you might find chemistry interesting for other reasons. most everything you do and encounter during your day involves chemistry. making coffee, cooking eggs, and toasting bread involve chemistry. the products you use—like soap and shampoo, the fabrics you wear, the electronics that keep you connected to your world, the gasoline that propels your car—all of these and more involve chemical substances and processes. whether you are aware or not, chemistry is part of your everyday world. in this course, you will learn many of the essential principles underlying the chemistry of modern-day life.  10  chapter 1 | essential ideas  1.1 chemistry in context by the end of this module, you will be able to: • outline the historical development of chemistry • provide examples of the importance of chemistry in everyday life • describe the scientific method • differentiate among hypotheses, theories, and laws • provide examples illustrating macroscopic, microscopic, and symbolic domains  throughout human history, people have tried to convert matter into more useful forms. our stone age ancestors chipped pieces of flint into useful tools and carved wood into statues and toys. these endeavors involved changing the shape of a substance without changing the substance itself. but as our knowledge increased, humans began to change the composition of the substances as well—clay was converted into pottery, hides were cured to make garments, copper ores were transformed into copper tools and weapons, and grain was made into bread. humans began to practice chemistry when they learned to control fire and use it to cook, make pottery, and smelt metals. subsequently, they began to separate and use specific components of matter. a variety of drugs such as aloe, myrrh, and opium were isolated from plants. dyes, such as indigo and tyrian purple, were extracted from plant and animal matter. metals were combined to form alloys—for example, copper and tin were mixed together to make bronze—and more elaborate smelting techniques produced iron. alkalis were extracted from ashes, and soaps were prepared by combining these alkalis with fats. alcohol was produced by fermentation and purified by distillation. attempts to understand the behavior of matter extend back for more than 2500 years. as early as the sixth century bc, greek philosophers discussed a system in which water was the basis of all things. you may have heard of the greek postulate that matter consists of four elements: earth, air, fire, and water. subsequently, an amalgamation of chemical technologies and philosophical speculations were spread from egypt, china, and the eastern mediterranean by alchemists, who endeavored to transform “base metals” such as lead into “noble metals” like gold, and to create elixirs to cure disease and extend life (figure 1.2).  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  11  figure 1.2 this portrayal shows an alchemist’s workshop circa 1580. although alchemy made some useful contributions to how to manipulate matter, it was not scientific by modern standards. (credit: chemical heritage foundation)  from alchemy came the historical progressions that led to modern chemistry: the isolation of drugs from natural sources, metallurgy, and the dye industry. today, chemistry continues to deepen our understanding and improve our ability to harness and control the behavior of matter. this effort has been so successful that many people do not realize either the central position of chemistry among the sciences or the importance and universality of chemistry in daily life.  chemistry: the central science chemistry is sometimes referred to as “the central science” due to its interconnectedness with a vast array of other stem disciplines (stem stands for areas of study in the science, technology, engineering, and math fields). chemistry and the language of chemists play vital roles in biology, medicine, materials science, forensics, environmental science, and many other fields (figure 1.3). the basic principles of physics are essential for understanding many aspects of chemistry, and there is extensive overlap between many subdisciplines within the two fields, such as chemical physics and nuclear chemistry. mathematics, computer science, and information theory provide important tools that help us calculate, interpret, describe, and generally make sense of the chemical world. biology and chemistry converge in biochemistry, which is crucial to understanding the many complex factors and processes that keep living organisms (such as us) alive. chemical engineering, materials science, and nanotechnology combine chemical principles and empirical findings to produce useful substances, ranging from gasoline to fabrics to electronics. agriculture, food science, veterinary science, and brewing and wine making help provide sustenance in the form of food and drink to the world’s population. medicine, pharmacology, biotechnology, and botany identify and produce substances that help keep us healthy. environmental science, geology, oceanography, and atmospheric science incorporate many chemical ideas to help us better understand and protect our physical world. chemical ideas are used to help understand the universe in astronomy and cosmology.  12  chapter 1 | essential ideas  figure 1.3 knowledge of chemistry is central to understanding a wide range of scientific disciplines. this diagram shows just some of the interrelationships between chemistry and other fields.  what are some changes in matter that are essential to daily life? digesting and assimilating food, synthesizing polymers that are used to make clothing, containers, cookware, and credit cards, and refining crude oil into gasoline and other products are just a few examples. as you proceed through this course, you will discover many different examples of changes in the composition and structure of matter, how to classify these changes and how they occurred, their causes, the changes in energy that accompany them, and the principles and laws involved. as you learn about these things, you will be learning chemistry, the study of the composition, properties, and interactions of matter. the practice of chemistry is not limited to chemistry books or laboratories: it happens whenever someone is involved in changes in matter or in conditions that may lead to such changes.  the scientific method chemistry is a science based on observation and experimentation. doing chemistry involves attempting to answer questions and explain observations in terms of the laws and theories of chemistry, using procedures that are accepted by the scientific community. there is no single route to answering a question or explaining an observation, but there is an aspect common to every approach: each uses knowledge based on experiments that can be reproduced to verify the results. some routes involve a hypothesis, a tentative explanation of observations that acts as a guide for gathering and checking information. we test a hypothesis by experimentation, calculation, and/or comparison with the experiments of others and then refine it as needed. some hypotheses are attempts to explain the behavior that is summarized in laws. the laws of science summarize a vast number of experimental observations, and describe or predict some facet of the natural world. if such a hypothesis turns out to be capable of explaining a large body of experimental data, it can reach the status of a theory. scientific theories are well-substantiated, comprehensive, testable explanations of particular aspects of nature. theories are accepted because they provide satisfactory explanations, but they can be modified if new data become available. the path of discovery that leads from question and observation to law or hypothesis to theory, combined with experimental verification of the hypothesis and any necessary modification of the theory, is called the scientific method (figure 1.4).  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  13  figure 1.4 the scientific method follows a process similar to the one shown in this diagram. all the key components are shown, in roughly the right order. scientific progress is seldom neat and clean: it requires open inquiry and the reworking of questions and ideas in response to findings.  the domains of chemistry chemists study and describe the behavior of matter and energy in three different domains: macroscopic, microscopic, and symbolic. these domains provide different ways of considering and describing chemical behavior. macro is a greek word that means “large.” the macroscopic domain is familiar to us: it is the realm of everyday things that are large enough to be sensed directly by human sight or touch. in daily life, this includes the food you eat and the breeze you feel on your face. the macroscopic domain includes everyday and laboratory chemistry, where we observe and measure physical and chemical properties, or changes such as density, solubility, and flammability. the microscopic domain of chemistry is almost always visited in the imagination. micro also comes from greek and means “small.” some aspects of the microscopic domains are visible through a microscope, such as a magnified image of graphite or bacteria. viruses, for instance, are too small to be seen with the naked eye, but when we’re suffering from a cold, we’re reminded of how real they are. however, most of the subjects in the microscopic domain of chemistry—such as atoms and molecules—are too small to be seen even with standard microscopes and often must be pictured in the mind. other components of the microscopic domain include ions and electrons, protons and neutrons, and chemical bonds, each of which is far too small to see. this domain includes the individual metal atoms in a wire, the ions that compose a salt crystal, the changes in individual molecules that result in a color change, the conversion of nutrient molecules into tissue and energy, and the evolution of heat as bonds that hold atoms together are created. the symbolic domain contains the specialized language used to represent components of the macroscopic and microscopic domains. chemical symbols (such as those used in the periodic table), chemical formulas, and chemical equations are part of the symbolic domain, as are graphs and drawings. we can also consider calculations as part of the symbolic domain. these symbols play an important role in chemistry because they help interpret the behavior of the macroscopic domain in terms of the components of the microscopic domain. one of the challenges for  14  chapter 1 | essential ideas  students learning chemistry is recognizing that the same symbols can represent different things in the macroscopic and microscopic domains, and one of the features that makes chemistry fascinating is the use of a domain that must be imagined to explain behavior in a domain that can be observed. a helpful way to understand the three domains is via the essential and ubiquitous substance of water. that water is a liquid at moderate temperatures, will freeze to form a solid at lower temperatures, and boil to form a gas at higher temperatures (figure 1.5) are macroscopic observations. but some properties of water fall into the microscopic domain—what we cannot observe with the naked eye. the description of water as comprised of two hydrogen atoms and one oxygen atom, and the explanation of freezing and boiling in terms of attractions between these molecules, is within the microscopic arena. the formula h2o, which can describe water at either the macroscopic or microscopic levels, is an example of the symbolic domain. the abbreviations (g) for gas, (s) for solid, and (l) for liquid are also symbolic.  figure 1.5 (a) moisture in the air, icebergs, and the ocean represent water in the macroscopic domain. (b) at the molecular level (microscopic domain), gas molecules are far apart and disorganized, solid water molecules are close together and organized, and liquid molecules are close together and disorganized. (c) the formula h2o symbolizes water, and (g), (s), and (l) symbolize its phases. note that clouds are actually comprised of either very small liquid water droplets or solid water crystals; gaseous water in our atmosphere is not visible to the naked eye, although it may be sensed as humidity. (credit a: modification of work by “gorkaazk”/wikimedia commons)  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  15  1.2 phases and classification of matter by the end of this section, you will be able to: • describe the basic properties of each physical state of matter: solid, liquid, and gas • define and give examples of atoms and molecules • classify matter as an element, compound, homogeneous mixture, or heterogeneous mixture with regard to its  physical state and composition • distinguish between mass and weight • apply the law of conservation of matter  matter is defined as anything that occupies space and has mass, and it is all around us. solids and liquids are more obviously matter: we can see that they take up space, and their weight tells us that they have mass. gases are also matter; if gases did not take up space, a balloon would stay collapsed rather than inflate when filled with gas. solids, liquids, and gases are the three states of matter commonly found on earth (figure 1.6). a solid is rigid and possesses a definite shape. a liquid flows and takes the shape of a container, except that it forms a flat or slightly curved upper surface when acted upon by gravity. (in zero gravity, liquids assume a spherical shape.) both liquid and solid samples have volumes that are very nearly independent of pressure. a gas takes both the shape and volume of its container.  figure 1.6 the three most common states or phases of matter are solid, liquid, and gas.  a fourth state of matter, plasma, occurs naturally in the interiors of stars. a plasma is a gaseous state of matter that contains appreciable numbers of electrically charged particles (figure 1.7). the presence of these charged particles imparts unique properties to plasmas that justify their classification as a state of matter distinct from gases. in addition to stars, plasmas are found in some other high-temperature environments (both natural and man-made), such as lightning strikes, certain television screens, and specialized analytical instruments used to detect trace amounts of metals.  16  chapter 1 | essential ideas  figure 1.7 a plasma torch can be used to cut metal. (credit: “hypertherm”/wikimedia commons)  link to learning in a tiny cell in a plasma television, the plasma emits ultraviolet light, which in turn causes the display at that location to appear a specific color. the composite of these tiny dots of color makes up the image that you see. watch this video (http://openstaxcollege.org/l/16plasma) to learn more about plasma and the places you encounter it.  some samples of matter appear to have properties of solids, liquids, and/or gases at the same time. this can occur when the sample is composed of many small pieces. for example, we can pour sand as if it were a liquid because it is composed of many small grains of solid sand. matter can also have properties of more than one state when it is a mixture, such as with clouds. clouds appear to behave somewhat like gases, but they are actually mixtures of air (gas) and tiny particles of water (liquid or solid). the mass of an object is a measure of the amount of matter in it. one way to measure an object’s mass is to measure the force it takes to accelerate the object. it takes much more force to accelerate a car than a bicycle because the car has much more mass. a more common way to determine the mass of an object is to use a balance to compare its mass with a standard mass. although weight is related to mass, it is not the same thing. weight refers to the force that gravity exerts on an object. this force is directly proportional to the mass of the object. the weight of an object changes as the force of gravity changes, but its mass does not. an astronaut’s mass does not change just because she goes to the moon. but her weight on the moon is only one-sixth her earth-bound weight because the moon’s gravity is only one-sixth that of the earth’s. she may feel “weightless” during her trip when she experiences negligible external forces (gravitational or any other), although she is, of course, never “massless.” the law of conservation of matter summarizes many scientific observations about matter: it states that there is no detectable change in the total quantity of matter present when matter converts from one type to another (a chemical change) or changes among solid, liquid, or gaseous states (a physical change). brewing beer and the operation of batteries provide examples of the conservation of matter (figure 1.8). during the brewing of beer, the ingredients (water, yeast, grains, malt, hops, and sugar) are converted into beer (water, alcohol, carbonation, and flavoring substances) with no actual loss of substance. this is most clearly seen during the bottling process, when glucose turns  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  17  into ethanol and carbon dioxide, and the total mass of the substances does not change. this can also be seen in a lead-acid car battery: the original substances (lead, lead oxide, and sulfuric acid), which are capable of producing electricity, are changed into other substances (lead sulfate and water) that do not produce electricity, with no change in the actual amount of matter.  figure 1.8 (a) the mass of beer precursor materials is the same as the mass of beer produced: sugar has become alcohol and carbonation. (b) the mass of the lead, lead oxide plates, and sulfuric acid that goes into the production of electricity is exactly equal to the mass of lead sulfate and water that is formed.  although this conservation law holds true for all conversions of matter, convincing examples are few and far between because, outside of the controlled conditions in a laboratory, we seldom collect all of the material that is produced during a particular conversion. for example, when you eat, digest, and assimilate food, all of the matter in the original food is preserved. but because some of the matter is incorporated into your body, and much is excreted as various types of waste, it is challenging to verify by measurement.  atoms and molecules an atom is the smallest particle of an element that has the properties of that element and can enter into a chemical combination. consider the element gold, for example. imagine cutting a gold nugget in half, then cutting one of the halves in half, and repeating this process until a piece of gold remained that was so small that it could not be cut in half (regardless of how tiny your knife may be). this minimally sized piece of gold is an atom (from the greek atomos, meaning “indivisible”) (figure 1.9). this atom would no longer be gold if it were divided any further.  18  chapter 1 | essential ideas  figure 1.9 (a) this photograph shows a gold nugget. (b) a scanning-tunneling microscope (stm) can generate views of the surfaces of solids, such as this image of a gold crystal. each sphere represents one gold atom. (credit a: modification of work by united states geological survey; credit b: modification of work by “erwinrossen”/wikimedia commons)  the first suggestion that matter is composed of atoms is attributed to the greek philosophers leucippus and democritus, who developed their ideas in the 5th century bce. however, it was not until the early nineteenth century that john dalton (1766–1844), a british schoolteacher with a keen interest in science, supported this hypothesis with quantitative measurements. since that time, repeated experiments have confirmed many aspects of this hypothesis, and it has become one of the central theories of chemistry. other aspects of dalton’s atomic theory are still used but with minor revisions (details of dalton’s theory are provided in the chapter on atoms and molecules). an atom is so small that its size is difficult to imagine. one of the smallest things we can see with our unaided eye is a single thread of a spider web: these strands are about 1/10,000 of a centimeter (0.0001 cm) in diameter. although the cross-section of one strand is almost impossible to see without a microscope, it is huge on an atomic scale. a single carbon atom in the web has a diameter of about 0.000000015 centimeter, and it would take about 7000 carbon atoms to span the diameter of the strand. to put this in perspective, if a carbon atom were the size of a dime, the cross-section of one strand would be larger than a football field, which would require about 150 million carbon atom “dimes” to cover it. (figure 1.10) shows increasingly close microscopic and atomic-level views of ordinary cotton.  figure 1.10 these images provide an increasingly closer view: (a) a cotton boll, (b) a single cotton fiber viewed under an optical microscope (magnified 40 times), (c) an image of a cotton fiber obtained with an electron microscope (much higher magnification than with the optical microscope); and (d and e) atomic-level models of the fiber (spheres of different colors represent atoms of different elements). (credit c: modification of work by “featheredtar”/wikimedia commons)  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  19  an atom is so light that its mass is also difficult to imagine. a billion lead atoms (1,000,000,000 atoms) weigh about 3 × 10−13 grams, a mass that is far too light to be weighed on even the world’s most sensitive balances. it would require over 300,000,000,000,000 lead atoms (300 trillion, or 3 × 1014) to be weighed, and they would weigh only 0.0000001 gram. it is rare to find collections of individual atoms. only a few elements, such as the gases helium, neon, and argon, consist of a collection of individual atoms that move about independently of one another. other elements, such as the gases hydrogen, nitrogen, oxygen, and chlorine, are composed of units that consist of pairs of atoms (figure 1.11). one form of the element phosphorus consists of units composed of four phosphorus atoms. the element sulfur exists in various forms, one of which consists of units composed of eight sulfur atoms. these units are called molecules. a molecule consists of two or more atoms joined by strong forces called chemical bonds. the atoms in a molecule move around as a unit, much like the cans of soda in a six-pack or a bunch of keys joined together on a single key ring. a molecule may consist of two or more identical atoms, as in the molecules found in the elements hydrogen, oxygen, and sulfur, or it may consist of two or more different atoms, as in the molecules found in water. each water molecule is a unit that contains two hydrogen atoms and one oxygen atom. each glucose molecule is a unit that contains 6 carbon atoms, 12 hydrogen atoms, and 6 oxygen atoms. like atoms, molecules are incredibly small and light. if an ordinary glass of water were enlarged to the size of the earth, the water molecules inside it would be about the size of golf balls.  figure 1.11 the elements hydrogen, oxygen, phosphorus, and sulfur form molecules consisting of two or more atoms of the same element. the compounds water, carbon dioxide, and glucose consist of combinations of atoms of different elements.  classifying matter we can classify matter into several categories. two broad categories are mixtures and pure substances. a pure substance has a constant composition. all specimens of a pure substance have exactly the same makeup and properties. any sample of sucrose (table sugar) consists of 42.1% carbon, 6.5% hydrogen, and 51.4% oxygen by mass. any sample of sucrose also has the same physical properties, such as melting point, color, and sweetness, regardless of the source from which it is isolated. we can divide pure substances into two classes: elements and compounds. pure substances that cannot be broken down into simpler substances by chemical changes are called elements. iron, silver, gold, aluminum, sulfur, oxygen, and copper are familiar examples of the more than 100 known elements, of which about 90 occur naturally on the earth, and two dozen or so have been created in laboratories. pure substances that can be broken down by chemical changes are called compounds. this breakdown may produce either elements or other compounds, or both. mercury(ii) oxide, an orange, crystalline solid, can be broken down by heat into the elements mercury and oxygen (figure 1.12). when heated in the absence of air, the compound sucrose is broken down into the element carbon and the compound water. (the initial stage of this process, when the sugar is turning brown, is known as caramelization—this is what imparts the characteristic sweet and nutty flavor to caramel  20  chapter 1 | essential ideas  apples, caramelized onions, and caramel). silver(i) chloride is a white solid that can be broken down into its elements, silver and chlorine, by absorption of light. this property is the basis for the use of this compound in photographic films and photochromic eyeglasses (those with lenses that darken when exposed to light).  figure 1.12 (a)the compound mercury(ii) oxide, (b)when heated, (c) decomposes into silvery droplets of liquid mercury and invisible oxygen gas. (credit: modification of work by paul flowers)  link to learning many compounds break down when heated. this site (http://openstaxcollege.org/l/16mercury) shows the breakdown of mercury oxide, hgo. you can also view an example of the photochemical decomposition of silver chloride (http://openstaxcollege.org/l/16silvchloride) (agcl), the basis of early photography.  the properties of combined elements are different from those in the free, or uncombined, state. for example, white crystalline sugar (sucrose) is a compound resulting from the chemical combination of the element carbon, which is a black solid in one of its uncombined forms, and the two elements hydrogen and oxygen, which are colorless gases when uncombined. free sodium, an element that is a soft, shiny, metallic solid, and free chlorine, an element that is a yellow-green gas, combine to form sodium chloride (table salt), a compound that is a white, crystalline solid. a mixture is composed of two or more types of matter that can be present in varying amounts and can be separated by physical changes, such as evaporation (you will learn more about this later). a mixture with a composition that varies from point to point is called a heterogeneous mixture. italian dressing is an example of a heterogeneous mixture (figure 1.13). its composition can vary because we can make it from varying amounts of oil, vinegar, and herbs. it is not the same from point to point throughout the mixture—one drop may be mostly vinegar, whereas a different drop may be mostly oil or herbs because the oil and vinegar separate and the herbs settle. other examples of heterogeneous mixtures are chocolate chip cookies (we can see the separate bits of chocolate, nuts, and cookie dough) and granite (we can see the quartz, mica, feldspar, and more). a homogeneous mixture, also called a solution, exhibits a uniform composition and appears visually the same throughout. an example of a solution is a sports drink, consisting of water, sugar, coloring, flavoring, and electrolytes mixed together uniformly (figure 1.13). each drop of a sports drink tastes the same because each drop contains the same amounts of water, sugar, and other components. note that the composition of a sports drink can vary—it could be made with somewhat more or less sugar, flavoring, or other components, and still be a sports drink. other examples of homogeneous mixtures include air, maple syrup, gasoline, and a solution of salt in water.  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  21  figure 1.13 (a) oil and vinegar salad dressing is a heterogeneous mixture because its composition is not uniform throughout. (b) a commercial sports drink is a homogeneous mixture because its composition is uniform throughout. (credit a “left”: modification of work by john mayer; credit a “right”: modification of work by umberto salvagnin; credit b “left: modification of work by jeff bedford)  although there are just over 100 elements, tens of millions of chemical compounds result from different combinations of these elements. each compound has a specific composition and possesses definite chemical and physical properties by which we can distinguish it from all other compounds. and, of course, there are innumerable ways to combine elements and compounds to form different mixtures. a summary of how to distinguish between the various major classifications of matter is shown in (figure 1.14).  figure 1.14 depending on its properties, a given substance can be classified as a homogeneous mixture, a heterogeneous mixture, a compound, or an element.  eleven elements make up about 99% of the earth’s crust and atmosphere (table 1.1). oxygen constitutes nearly onehalf and silicon about one-quarter of the total quantity of these elements. a majority of elements on earth are found in chemical combinations with other elements; about one-quarter of the elements are also found in the free state. elemental composition of earth element  symbol  percent mass  element  symbol  percent mass  oxygen  o  49.20  chlorine  cl  0.19  silicon  si  25.67  phosphorus  p  0.11  aluminum  al  7.50  manganese  mn  0.09  table 1.1  22  chapter 1 | essential ideas  elemental composition of earth element  symbol  percent mass  element  symbol  percent mass  iron  fe  4.71  carbon  c  0.08  calcium  ca  3.39  sulfur  s  0.06  sodium  na  2.63  barium  ba  0.04  potassium  k  2.40  nitrogen  n  0.03  magnesium  mg  1.93  fluorine  f  0.03  hydrogen  h  0.87  strontium  sr  0.02  titanium  ti  0.58  all others  -  0.47  table 1.1  chemistry in everyday life decomposition of water / production of hydrogen water consists of the elements hydrogen and oxygen combined in a 2 to 1 ratio. water can be broken down into hydrogen and oxygen gases by the addition of energy. one way to do this is with a battery or power supply, as shown in (figure 1.15).  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  figure 1.15 the decomposition of water is shown at the macroscopic, microscopic, and symbolic levels. the battery provides an electric current (microscopic) that decomposes water. at the macroscopic level, the liquid separates into the gases hydrogen (on the left) and oxygen (on the right). symbolically, this change is presented by showing how liquid h2o separates into h2 and o2 gases. the breakdown of water involves a rearrangement of the atoms in water molecules into different molecules, each composed of two hydrogen atoms and two oxygen atoms, respectively. two water molecules form one oxygen molecule and two hydrogen molecules. the representation for what occurs, 2h 2 o(l) ⟶ 2h 2(g) + o 2(g), will be explored in more depth in later chapters. the two gases produced have distinctly different properties. oxygen is not flammable but is required for combustion of a fuel, and hydrogen is highly flammable and a potent energy source. how might this knowledge be applied in our world? one application involves research into more fuel-efficient transportation. fuel-cell vehicles (fcv) run on hydrogen instead of gasoline (figure 1.16). they are more efficient than vehicles with internal combustion engines, are nonpolluting, and reduce greenhouse gas emissions, making us less dependent on fossil fuels. fcvs are not yet economically viable, however, and current hydrogen production depends on natural gas. if we can develop a process to economically decompose water, or produce hydrogen in another environmentally sound way, fcvs may be the way of the future.  23  24  chapter 1 | essential ideas  figure 1.16 a fuel cell generates electrical energy from hydrogen and oxygen via an electrochemical process and produces only water as the waste product.  chemistry in everyday life chemistry of cell phones imagine how different your life would be without cell phones (figure 1.17) and other smart devices. cell phones are made from numerous chemical substances, which are extracted, refined, purified, and assembled using an extensive and in-depth understanding of chemical principles. about 30% of the elements that are found in nature are found within a typical smart phone. the case/body/frame consists of a combination of sturdy, durable polymers comprised primarily of carbon, hydrogen, oxygen, and nitrogen [acrylonitrile butadiene styrene (abs) and polycarbonate thermoplastics], and light, strong, structural metals, such as aluminum, magnesium, and iron. the display screen is made from a specially toughened glass (silica glass strengthened by the addition of aluminum, sodium, and potassium) and coated with a material to make it conductive (such as indium tin oxide). the circuit board uses a semiconductor material (usually silicon); commonly used metals like copper, tin, silver, and gold; and more unfamiliar elements such as yttrium, praseodymium, and gadolinium. the battery relies upon lithium ions and a variety of other materials, including iron, cobalt, copper, polyethylene oxide, and polyacrylonitrile.  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  25  figure 1.17 almost one-third of naturally occurring elements are used to make a cell phone. (credit: modification of work by john taylor)  1.3 physical and chemical properties by the end of this section, you will be able to: • identify properties of and changes in matter as physical or chemical • identify properties of matter as extensive or intensive  the characteristics that enable us to distinguish one substance from another are called properties. a physical property is a characteristic of matter that is not associated with a change in its chemical composition. familiar examples of physical properties include density, color, hardness, melting and boiling points, and electrical conductivity. we can observe some physical properties, such as density and color, without changing the physical state of the matter observed. other physical properties, such as the melting temperature of iron or the freezing temperature of water, can only be observed as matter undergoes a physical change. a physical change is a change in the state or properties of matter without any accompanying change in its chemical composition (the identities of the substances contained in the matter). we observe a physical change when wax melts, when sugar dissolves in coffee, and when steam condenses into liquid water (figure 1.18). other examples of physical changes include magnetizing and demagnetizing metals (as is done with common antitheft security tags) and grinding solids into powders (which can sometimes yield noticeable changes in color). in each of these examples, there is a change in the physical state, form, or properties of the substance, but no change in its chemical composition.  26  chapter 1 | essential ideas  figure 1.18 (a) wax undergoes a physical change when solid wax is heated and forms liquid wax. (b) steam condensing inside a cooking pot is a physical change, as water vapor is changed into liquid water. (credit a: modification of work by “95jb14”/wikimedia commons; credit b: modification of work by “mjneuby”/flickr)  the change of one type of matter into another type (or the inability to change) is a chemical property. examples of chemical properties include flammability, toxicity, acidity, reactivity (many types), and heat of combustion. iron, for example, combines with oxygen in the presence of water to form rust; chromium does not oxidize (figure 1.19). nitroglycerin is very dangerous because it explodes easily; neon poses almost no hazard because it is very unreactive.  figure 1.19 (a) one of the chemical properties of iron is that it rusts; (b) one of the chemical properties of chromium is that it does not. (credit a: modification of work by tony hisgett; credit b: modification of work by “atoma”/wikimedia commons)  to identify a chemical property, we look for a chemical change. a chemical change always produces one or more types of matter that differ from the matter present before the change. the formation of rust is a chemical change because rust is a different kind of matter than the iron, oxygen, and water present before the rust formed. the explosion of nitroglycerin is a chemical change because the gases produced are very different kinds of matter from the original substance. other examples of chemical changes include reactions that are performed in a lab (such as copper reacting with nitric acid), all forms of combustion (burning), and food being cooked, digested, or rotting (figure 1.20).  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  27  figure 1.20 (a) copper and nitric acid undergo a chemical change to form copper nitrate and brown, gaseous nitrogen dioxide. (b) during the combustion of a match, cellulose in the match and oxygen from the air undergo a chemical change to form carbon dioxide and water vapor. (c) cooking red meat causes a number of chemical changes, including the oxidation of iron in myoglobin that results in the familiar red-to-brown color change. (d) a banana turning brown is a chemical change as new, darker (and less tasty) substances form. (credit b: modification of work by jeff turner; credit c: modification of work by gloria cabada-leman; credit d: modification of work by roberto verzo)  properties of matter fall into one of two categories. if the property depends on the amount of matter present, it is an extensive property. the mass and volume of a substance are examples of extensive properties; for instance, a gallon of milk has a larger mass and volume than a cup of milk. the value of an extensive property is directly proportional to the amount of matter in question. if the property of a sample of matter does not depend on the amount of matter present, it is an intensive property. temperature is an example of an intensive property. if the gallon and cup of milk are each at 20 °c (room temperature), when they are combined, the temperature remains at 20 °c. as another example, consider the distinct but related properties of heat and temperature. a drop of hot cooking oil spattered on your arm causes brief, minor discomfort, whereas a pot of hot oil yields severe burns. both the drop and the pot of oil are at the same temperature (an intensive property), but the pot clearly contains much more heat (extensive property).  chemistry in everyday life hazard diamond you may have seen the symbol shown in figure 1.21 on containers of chemicals in a laboratory or workplace. sometimes called a “fire diamond” or “hazard diamond,” this chemical hazard diamond provides valuable information that briefly summarizes the various dangers of which to be aware when working with a particular  28  chapter 1 | essential ideas  substance.  figure 1.21 the national fire protection agency (nfpa) hazard diamond summarizes the major hazards of a chemical substance. the national fire protection agency (nfpa) 704 hazard identification system was developed by nfpa to provide safety information about certain substances. the system details flammability, reactivity, health, and other hazards. within the overall diamond symbol, the top (red) diamond specifies the level of fire hazard (temperature range for flash point). the blue (left) diamond indicates the level of health hazard. the yellow (right) diamond describes reactivity hazards, such as how readily the substance will undergo detonation or a violent chemical change. the white (bottom) diamond points out special hazards, such as if it is an oxidizer (which allows the substance to burn in the absence of air/oxygen), undergoes an unusual or dangerous reaction with water, is corrosive, acidic, alkaline, a biological hazard, radioactive, and so on. each hazard is rated on a scale from 0 to 4, with 0 being no hazard and 4 being extremely hazardous.  while many elements differ dramatically in their chemical and physical properties, some elements have similar properties. we can identify sets of elements that exhibit common behaviors. for example, many elements conduct heat and electricity well, whereas others are poor conductors. these properties can be used to sort the elements into three classes: metals (elements that conduct well), nonmetals (elements that conduct poorly), and metalloids (elements that have properties of both metals and nonmetals). the periodic table is a table of elements that places elements with similar properties close together (figure 1.22). you will learn more about the periodic table as you continue your study of chemistry.  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  29  figure 1.22 the periodic table shows how elements may be grouped according to certain similar properties. note the background color denotes whether an element is a metal, metalloid, or nonmetal, whereas the element symbol color indicates whether it is a solid, liquid, or gas.  1.4 measurements by the end of this section, you will be able to: • explain the process of measurement • identify the three basic parts of a quantity • describe the properties and units of length, mass, volume, density, temperature, and time • perform basic unit calculations and conversions in the metric and other unit systems  measurements provide the macroscopic information that is the basis of most of the hypotheses, theories, and laws that describe the behavior of matter and energy in both the macroscopic and microscopic domains of chemistry. every measurement provides three kinds of information: the size or magnitude of the measurement (a number); a standard of comparison for the measurement (a unit); and an indication of the uncertainty of the measurement. while the number and unit are explicitly represented when a quantity is written, the uncertainty is an aspect of the measurement result that is more implicitly represented and will be discussed later. the number in the measurement can be represented in different ways, including decimal form and scientific notation.  30  chapter 1 | essential ideas  (scientific notation is also known as exponential notation; a review of this topic can be found in appendix b.) for example, the maximum takeoff weight of a boeing 777-200er airliner is 298,000 kilograms, which can also be written as 2.98 × 105 kg. the mass of the average mosquito is about 0.0000025 kilograms, which can be written as 2.5 × 10−6 kg. units, such as liters, pounds, and centimeters, are standards of comparison for measurements. when we buy a 2-liter bottle of a soft drink, we expect that the volume of the drink was measured, so it is two times larger than the volume that everyone agrees to be 1 liter. the meat used to prepare a 0.25-pound hamburger is measured so it weighs onefourth as much as 1 pound. without units, a number can be meaningless, confusing, or possibly life threatening. suppose a doctor prescribes phenobarbital to control a patient’s seizures and states a dosage of “100” without specifying units. not only will this be confusing to the medical professional giving the dose, but the consequences can be dire: 100 mg given three times per day can be effective as an anticonvulsant, but a single dose of 100 g is more than 10 times the lethal amount. we usually report the results of scientific measurements in si units, an updated version of the metric system, using the units listed in table 1.2. other units can be derived from these base units. the standards for these units are fixed by international agreement, and they are called the international system of units or si units (from the french, le système international d’unités). si units have been used by the united states national institute of standards and technology (nist) since 1964. base units of the si system property measured  name of unit  symbol of unit  length  meter  m  mass  kilogram  kg  time  second  s  temperature  kelvin  k  electric current  ampere  a  amount of substance  mole  mol  luminous intensity  candela  cd  table 1.2  sometimes we use units that are fractions or multiples of a base unit. ice cream is sold in quarts (a familiar, non-si base unit), pints (0.5 quart), or gallons (4 quarts). we also use fractions or multiples of units in the si system, but these fractions or multiples are always powers of 10. fractional or multiple si units are named using a prefix and the name of the base unit. for example, a length of 1000 meters is also called a kilometer because the prefix kilo means “one thousand,” which in scientific notation is 103 (1 kilometer = 1000 m = 103 m). the prefixes used and the powers to which 10 are raised are listed in table 1.3. common unit prefixes prefix  symbol  factor  example  femto  f  10−15  1 femtosecond (fs) = 1 × 10−15 s (0.000000000000001 s)  pico  p  10−12  1 picometer (pm) = 1 × 10−12 m (0.000000000001 m)  nano  n  10−9  4 nanograms (ng) = 4 × 10−9 g (0.000000004 g)  table 1.3  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  31  common unit prefixes prefix  symbol  factor  example  micro  µ  10−6  1 microliter (μl) = 1 × 10−6 l (0.000001 l)  milli  m  10−3  2 millimoles (mmol) = 2 × 10−3 mol (0.002 mol)  centi  c  10−2  7 centimeters (cm) = 7 × 10−2 m (0.07 m)  deci  d  10−1  1 deciliter (dl) = 1 × 10−1 l (0.1 l )  kilo  k  103  1 kilometer (km) = 1 × 103 m (1000 m)  mega  m  106  3 megahertz (mhz) = 3 × 106 hz (3,000,000 hz)  giga  g  109  8 gigayears (gyr) = 8 × 109 yr (8,000,000,000 gyr)  tera  t  1012  5 terawatts (tw) = 5 × 1012 w (5,000,000,000,000 w)  table 1.3  link to learning need a refresher or more practice with scientific notation? visit this site (http://openstaxcollege.org/l/16notation) to go over the basics of scientific notation.  si base units the initial units of the metric system, which eventually evolved into the si system, were established in france during the french revolution. the original standards for the meter and the kilogram were adopted there in 1799 and eventually by other countries. this section introduces four of the si base units commonly used in chemistry. other si units will be introduced in subsequent chapters.  length the standard unit of length in both the si and original metric systems is the meter (m). a meter was originally specified as 1/10,000,000 of the distance from the north pole to the equator. it is now defined as the distance light in a vacuum travels in 1/299,792,458 of a second. a meter is about 3 inches longer than a yard (figure 1.23); one meter is about 39.37 inches or 1.094 yards. longer distances are often reported in kilometers (1 km = 1000 m = 103 m), whereas shorter distances can be reported in centimeters (1 cm = 0.01 m = 10−2 m) or millimeters (1 mm = 0.001 m = 10−3 m).  32  chapter 1 | essential ideas  figure 1.23 the relative lengths of 1 m, 1 yd, 1 cm, and 1 in. are shown (not actual size), as well as comparisons of 2.54 cm and 1 in., and of 1 m and 1.094 yd.  mass the standard unit of mass in the si system is the kilogram (kg). a kilogram was originally defined as the mass of a liter of water (a cube of water with an edge length of exactly 0.1 meter). it is now defined by a certain cylinder of platinum-iridium alloy, which is kept in france (figure 1.24). any object with the same mass as this cylinder is said to have a mass of 1 kilogram. one kilogram is about 2.2 pounds. the gram (g) is exactly equal to 1/1000 of the mass of the kilogram (10−3 kg).  figure 1.24 this replica prototype kilogram is housed at the national institute of standards and technology (nist) in maryland. (credit: national institutes of standards and technology)  temperature temperature is an intensive property. the si unit of temperature is the kelvin (k). the iupac convention is to use kelvin (all lowercase) for the word, k (uppercase) for the unit symbol, and neither the word “degree” nor the degree symbol (°). the degree celsius (°c) is also allowed in the si system, with both the word “degree” and the degree symbol used for celsius measurements. celsius degrees are the same magnitude as those of kelvin, but the two scales place their zeros in different places. water freezes at 273.15 k (0 °c) and boils at 373.15 k (100 °c) by definition, and normal human body temperature is approximately 310 k (37 °c). the conversion between these two units and  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  33  the fahrenheit scale will be discussed later in this chapter.  time the si base unit of time is the second (s). small and large time intervals can be expressed with the appropriate prefixes; for example, 3 microseconds = 0.000003 s = 3 × 10−6 and 5 megaseconds = 5,000,000 s = 5 × 106 s. alternatively, hours, days, and years can be used.  derived si units we can derive many units from the seven si base units. for example, we can use the base unit of length to define a unit of volume, and the base units of mass and length to define a unit of density.  volume volume is the measure of the amount of space occupied by an object. the standard si unit of volume is defined by the base unit of length (figure 1.25). the standard volume is a cubic meter (m3), a cube with an edge length of exactly one meter. to dispense a cubic meter of water, we could build a cubic box with edge lengths of exactly one meter. this box would hold a cubic meter of water or any other substance. a more commonly used unit of volume is derived from the decimeter (0.1 m, or 10 cm). a cube with edge lengths of exactly one decimeter contains a volume of one cubic decimeter (dm3). a liter (l) is the more common name for the cubic decimeter. one liter is about 1.06 quarts. a cubic centimeter (cm3) is the volume of a cube with an edge length of exactly one centimeter. the abbreviation cc (for cubic centimeter) is often used by health professionals. a cubic centimeter is also called a milliliter (ml) and is 1/1000 of a liter.  figure 1.25 (a) the relative volumes are shown for cubes of 1 m3, 1 dm3 (1 l), and 1 cm3 (1 ml) (not to scale). (b) the diameter of a dime is compared relative to the edge length of a 1-cm3 (1-ml) cube.  34  chapter 1 | essential ideas  density we use the mass and volume of a substance to determine its density. thus, the units of density are defined by the base units of mass and length. the density of a substance is the ratio of the mass of a sample of the substance to its volume. the si unit for density is the kilogram per cubic meter (kg/m3). for many situations, however, this as an inconvenient unit, and we often use grams per cubic centimeter (g/cm3) for the densities of solids and liquids, and grams per liter (g/l) for gases. although there are exceptions, most liquids and solids have densities that range from about 0.7 g/cm3 (the density of gasoline) to 19 g/cm3 (the density of gold). the density of air is about 1.2 g/l. table 1.4 shows the densities of some common substances. densities of common substances solids  liquids  gases (at 25 °c and 1 atm)  ice (at 0 °c) 0.92 g/cm3  water 1.0 g/cm3  dry air 1.20 g/l  oak (wood) 0.60–0.90 g/cm3  ethanol 0.79 g/cm3  oxygen 1.31 g/l  g/cm3  nitrogen 1.14 g/l  iron 7.9  g/cm3  acetone 0.79  copper 9.0 g/cm3  glycerin 1.26 g/cm3  carbon dioxide 1.80 g/l  lead 11.3 g/cm3  olive oil 0.92 g/cm3  helium 0.16 g/l  silver 10.5 g/cm3  gasoline 0.70–0.77 g/cm3  neon 0.83 g/l  gold 19.3 g/cm3  mercury 13.6 g/cm3  radon 9.1 g/l  table 1.4  while there are many ways to determine the density of an object, perhaps the most straightforward method involves separately finding the mass and volume of the object, and then dividing the mass of the sample by its volume. in the following example, the mass is found directly by weighing, but the volume is found indirectly through length measurements. density = mass volume  example 1.1 calculation of density gold—in bricks, bars, and coins—has been a form of currency for centuries. in order to swindle people into paying for a brick of gold without actually investing in a brick of gold, people have considered filling the centers of hollow gold bricks with lead to fool buyers into thinking that the entire brick is gold. it does not work: lead is a dense substance, but its density is not as great as that of gold, 19.3 g/cm3. what is the density of lead if a cube of lead has an edge length of 2.00 cm and a mass of 90.7 g?  solution the density of a substance can be calculated by dividing its mass by its volume. the volume of a cube is calculated by cubing the edge length. volume of lead cube = 2.00 cm × 2.00 cm × 2.00 cm = 8.00 cm 3 90.7 g 11.3 g density = mass = = = 11.3 g/cm 3 3 3 volume 8.00 cm 1.00 cm  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  35  (we will discuss the reason for rounding to the first decimal place in the next section.)  check your learning (a) to three decimal places, what is the volume of a cube (cm3) with an edge length of 0.843 cm? (b) if the cube in part (a) is copper and has a mass of 5.34 g, what is the density of copper to two decimal places? answer: (a) 0.599 cm3; (b) 8.91 g/cm3  link to learning to learn more about the relationship between mass, volume, and density, use this interactive simulator (http://openstaxcollege.org/l/16phetmasvolden) to explore the density of different materials, like wood, ice, brick, and aluminum.  example 1.2 using displacement of water to determine density this phet simulation (http://openstaxcollege.org/l/16phetmasvolden) illustrates another way to determine density, using displacement of water. determine the density of the red and yellow blocks.  solution when you open the density simulation and select same mass, you can choose from several 5.00-kg colored blocks that you can drop into a tank containing 100.00 l water. the yellow block floats (it is less dense than water), and the water level rises to 105.00 l. while floating, the yellow block displaces 5.00 l water, an amount equal to the weight of the block. the red block sinks (it is more dense than water, which has density = 1.00 kg/l), and the water level rises to 101.25 l. the red block therefore displaces 1.25 l water, an amount equal to the volume of the block. the density of the red block is: density =  mass = 5.00 kg = 4.00 kg/l volume 1.25 l  note that since the yellow block is not completely submerged, you cannot determine its density from this information. but if you hold the yellow block on the bottom of the tank, the water level rises to 110.00 l, which means that it now displaces 10.00 l water, and its density can be found: density =  mass = 5.00 kg = 0.500 kg/l 10.00 l volume  check your learning remove all of the blocks from the water and add the green block to the tank of water, placing it approximately in the middle of the tank. determine the density of the green block. answer: 2.00 kg/l  36  chapter 1 | essential ideas  1.5 measurement uncertainty, accuracy, and precision by the end of this section, you will be able to: • define accuracy and precision • distinguish exact and uncertain numbers • correctly represent uncertainty in quantities using significant figures • apply proper rounding rules to computed quantities  counting is the only type of measurement that is free from uncertainty, provided the number of objects being counted does not change while the counting process is underway. the result of such a counting measurement is an example of an exact number. if we count eggs in a carton, we know exactly how many eggs the carton contains. the numbers of defined quantities are also exact. by definition, 1 foot is exactly 12 inches, 1 inch is exactly 2.54 centimeters, and 1 gram is exactly 0.001 kilogram. quantities derived from measurements other than counting, however, are uncertain to varying extents due to practical limitations of the measurement process used.  significant figures in measurement the numbers of measured quantities, unlike defined or directly counted quantities, are not exact. to measure the volume of liquid in a graduated cylinder, you should make a reading at the bottom of the meniscus, the lowest point on the curved surface of the liquid.  figure 1.26 to measure the volume of liquid in this graduated cylinder, you must mentally subdivide the distance between the 21 and 22 ml marks into tenths of a milliliter, and then make a reading (estimate) at the bottom of the meniscus.  refer to the illustration in figure 1.26. the bottom of the meniscus in this case clearly lies between the 21 and 22 markings, meaning the liquid volume is certainly greater than 21 ml but less than 22 ml. the meniscus appears to be a bit closer to the 22-ml mark than to the 21-ml mark, and so a reasonable estimate of the liquid’s volume would  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  37  be 21.6 ml. in the number 21.6, then, the digits 2 and 1 are certain, but the 6 is an estimate. some people might estimate the meniscus position to be equally distant from each of the markings and estimate the tenth-place digit as 5, while others may think it to be even closer to the 22-ml mark and estimate this digit to be 7. note that it would be pointless to attempt to estimate a digit for the hundredths place, given that the tenths-place digit is uncertain. in general, numerical scales such as the one on this graduated cylinder will permit measurements to one-tenth of the smallest scale division. the scale in this case has 1-ml divisions, and so volumes may be measured to the nearest 0.1 ml. this concept holds true for all measurements, even if you do not actively make an estimate. if you place a quarter on a standard electronic balance, you may obtain a reading of 6.72 g. the digits 6 and 7 are certain, and the 2 indicates that the mass of the quarter is likely between 6.71 and 6.73 grams. the quarter weighs about 6.72 grams, with a nominal uncertainty in the measurement of ± 0.01 gram. if we weigh the quarter on a more sensitive balance, we may find that its mass is 6.723 g. this means its mass lies between 6.722 and 6.724 grams, an uncertainty of 0.001 gram. every measurement has some uncertainty, which depends on the device used (and the user’s ability). all of the digits in a measurement, including the uncertain last digit, are called significant figures or significant digits. note that zero may be a measured value; for example, if you stand on a scale that shows weight to the nearest pound and it shows “120,” then the 1 (hundreds), 2 (tens) and 0 (ones) are all significant (measured) values. whenever you make a measurement properly, all the digits in the result are significant. but what if you were analyzing a reported value and trying to determine what is significant and what is not? well, for starters, all nonzero digits are significant, and it is only zeros that require some thought. we will use the terms “leading,” “trailing,” and “captive” for the zeros and will consider how to deal with them.  starting with the first nonzero digit on the left, count this digit and all remaining digits to the right. this is the number of significant figures in the measurement unless the last digit is a trailing zero lying to the left of the decimal point.  captive zeros result from measurement and are therefore always significant. leading zeros, however, are never significant—they merely tell us where the decimal point is located.  the leading zeros in this example are not significant. we could use exponential notation (as described in appendix b) and express the number as 8.32407 × 10−3; then the number 8.32407 contains all of the significant figures, and 10−3 locates the decimal point. the number of significant figures is uncertain in a number that ends with a zero to the left of the decimal point location. the zeros in the measurement 1,300 grams could be significant or they could simply indicate where the  38  chapter 1 | essential ideas  decimal point is located. the ambiguity can be resolved with the use of exponential notation: 1.3 × 103 (two significant figures), 1.30 × 103 (three significant figures, if the tens place was measured), or 1.300 × 103 (four significant figures, if the ones place was also measured). in cases where only the decimal-formatted number is available, it is prudent to assume that all trailing zeros are not significant.  when determining significant figures, be sure to pay attention to reported values and think about the measurement and significant figures in terms of what is reasonable or likely when evaluating whether the value makes sense. for example, the official january 2014 census reported the resident population of the us as 317,297,725. do you think the us population was correctly determined to the reported nine significant figures, that is, to the exact number of people? people are constantly being born, dying, or moving into or out of the country, and assumptions are made to account for the large number of people who are not actually counted. because of these uncertainties, it might be more reasonable to expect that we know the population to within perhaps a million or so, in which case the population should be reported as 3.17 × 108 people.  significant figures in calculations a second important principle of uncertainty is that results calculated from a measurement are at least as uncertain as the measurement itself. we must take the uncertainty in our measurements into account to avoid misrepresenting the uncertainty in calculated results. one way to do this is to report the result of a calculation with the correct number of significant figures, which is determined by the following three rules for rounding numbers: 1. when we add or subtract numbers, we should round the result to the same number of decimal places as the  number with the least number of decimal places (the least precise value in terms of addition and subtraction). 2. when we multiply or divide numbers, we should round the result to the same number of digits as the number  with the least number of significant figures (the least precise value in terms of multiplication and division). 3. if the digit to be dropped (the one immediately to the right of the digit to be retained) is less than 5, we “round  down” and leave the retained digit unchanged; if it is more than 5, we “round up” and increase the retained digit by 1; if the dropped digit is 5, we round up or down, whichever yields an even value for the retained digit. (the last part of this rule may strike you as a bit odd, but it’s based on reliable statistics and is aimed at avoiding any bias when dropping the digit “5,” since it is equally close to both possible values of the retained digit.) the following examples illustrate the application of this rule in rounding a few different numbers to three significant figures: • 0.028675 rounds “up” to 0.0287 (the dropped digit, 7, is greater than 5) • 18.3384 rounds “down” to 18.3 (the dropped digit, 3, is less than 5) • 6.8752 rounds “up” to 6.88 (the dropped digit is 5, and the retained digit is even) • 92.85 rounds “down” to 92.8 (the dropped digit is 5, and the retained digit is even)  let’s work through these rules with a few examples.  example 1.3 rounding numbers round the following to the indicated number of significant figures:  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  39  (a) 31.57 (to two significant figures) (b) 8.1649 (to three significant figures) (c) 0.051065 (to four significant figures) (d) 0.90275 (to four significant figures)  solution (a) 31.57 rounds “up” to 32 (the dropped digit is 5, and the retained digit is even) (b) 8.1649 rounds “down” to 8.16 (the dropped digit, 4, is less than 5) (c) 0.051065 rounds “down” to 0.05106 (the dropped digit is 5, and the retained digit is even) (d) 0.90275 rounds “up” to 0.9028 (the dropped digit is 5, and the retained digit is even)  check your learning round the following to the indicated number of significant figures: (a) 0.424 (to two significant figures) (b) 0.0038661 (to three significant figures) (c) 421.25 (to four significant figures) (d) 28,683.5 (to five significant figures) answer: (a) 0.42; (b) 0.00387; (c) 421.2; (d) 28,684  example 1.4 addition and subtraction with significant figures rule: when we add or subtract numbers, we should round the result to the same number of decimal places as the number with the least number of decimal places (i.e., the least precise value in terms of addition and subtraction). (a) add 1.0023 g and 4.383 g. (b) subtract 421.23 g from 486 g.  solution (a)  1.0023 g + 4.383 g 5.3853 g  answer is 5.385 g (round to the thousandths place; three decimal places) (b)  486 g −421.23 g 64.77 g  answer is 65 g (round to the ones place; no decimal places)  40  chapter 1 | essential ideas  check your learning (a) add 2.334 ml and 0.31 ml. (b) subtract 55.8752 m from 56.533 m. answer: (a) 2.64 ml; (b) 0.658 m  example 1.5 multiplication and division with significant figures rule: when we multiply or divide numbers, we should round the result to the same number of digits as the number with the least number of significant figures (the least precise value in terms of multiplication and division). (a) multiply 0.6238 cm by 6.6 cm. (b) divide 421.23 g by 486 ml.  solution (a)  0.6238 cm × 6.6 cm = 4.11708 cm 2 ⟶ result is 4.1 cm 2 (round to two significant fig es ) four significant fig es × two significant fig es ⟶ two significant fig es answer  421.23 g = 0.86728... g/ml ⟶ result is 0.867 g/ml ⎛⎝round to three significant fig es ⎞⎠ 486 ml (b) fi e significant fig es ⟶ three significant fig es answer three significant fig es  check your learning (a) multiply 2.334 cm and 0.320 cm. (b) divide 55.8752 m by 56.53 s. answer: (a) 0.747 cm2 (b) 0.9884 m/s  in the midst of all these technicalities, it is important to keep in mind the reason why we use significant figures and rounding rules—to correctly represent the certainty of the values we report and to ensure that a calculated result is not represented as being more certain than the least certain value used in the calculation.  example 1.6 calculation with significant figures one common bathtub is 13.44 dm long, 5.920 dm wide, and 2.54 dm deep. assume that the tub is rectangular and calculate its approximate volume in liters.  solution  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  41  v = l×w×d = 13.44 dm × 5.920 dm × 2.54 dm = 202.09459... dm 3 (value from calculator)  = 202 dm 3 , or 202 l ⎛⎝answer rounded to three significant fig es ⎞⎠  check your learning what is the density of a liquid with a mass of 31.1415 g and a volume of 30.13 cm3? answer: 1.034 g/ml  example 1.7 experimental determination of density using water displacement a piece of rebar is weighed and then submerged in a graduated cylinder partially filled with water, with results as shown.  (a) use these values to determine the density of this piece of rebar. (b) rebar is mostly iron. does your result in (a) support this statement? how?  solution the volume of the piece of rebar is equal to the volume of the water displaced: volume = 22.4 ml − 13.5 ml = 8.9 ml = 8.9 cm 3 (rounded to the nearest 0.1 ml, per the rule for addition and subtraction) the density is the mass-to-volume ratio: density =  mass = 69.658 g = 7.8 g/cm 3 volume 8.9 cm 3  (rounded to two significant figures, per the rule for multiplication and division)  42  chapter 1 | essential ideas  from table 1.4, the density of iron is 7.9 g/cm3, very close to that of rebar, which lends some support to the fact that rebar is mostly iron.  check your learning an irregularly shaped piece of a shiny yellowish material is weighed and then submerged in a graduated cylinder, with results as shown.  (a) use these values to determine the density of this material. (b) do you have any reasonable guesses as to the identity of this material? explain your reasoning. answer: (a) 19 g/cm3; (b) it is likely gold; the right appearance for gold and very close to the density given for gold in table 1.4.  accuracy and precision scientists typically make repeated measurements of a quantity to ensure the quality of their findings and to know both the precision and the accuracy of their results. measurements are said to be precise if they yield very similar results when repeated in the same manner. a measurement is considered accurate if it yields a result that is very close to the true or accepted value. precise values agree with each other; accurate values agree with a true value. these characterizations can be extended to other contexts, such as the results of an archery competition (figure 1.27).  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  43  figure 1.27 (a) these arrows are close to both the bull’s eye and one another, so they are both accurate and precise. (b) these arrows are close to one another but not on target, so they are precise but not accurate. (c) these arrows are neither on target nor close to one another, so they are neither accurate nor precise.  suppose a quality control chemist at a pharmaceutical company is tasked with checking the accuracy and precision of three different machines that are meant to dispense 10 ounces (296 ml) of cough syrup into storage bottles. she proceeds to use each machine to fill five bottles and then carefully determines the actual volume dispensed, obtaining the results tabulated in table 1.5. volume (ml) of cough medicine delivered by 10-oz (296 ml) dispensers dispenser #1  dispenser #2  dispenser #3  283.3  298.3  296.1  284.1  294.2  295.9  283.9  296.0  296.1  284.0  297.8  296.0  284.1  293.9  296.1  table 1.5  considering these results, she will report that dispenser #1 is precise (values all close to one another, within a few tenths of a milliliter) but not accurate (none of the values are close to the target value of 296 ml, each being more than 10 ml too low). results for dispenser #2 represent improved accuracy (each volume is less than 3 ml away from 296 ml) but worse precision (volumes vary by more than 4 ml). finally, she can report that dispenser #3 is working well, dispensing cough syrup both accurately (all volumes within 0.1 ml of the target volume) and precisely (volumes differing from each other by no more than 0.2 ml).  1.6 mathematical treatment of measurement results by the end of this section, you will be able to: • explain the dimensional analysis (factor label) approach to mathematical calculations involving quantities • use dimensional analysis to carry out unit conversions for a given property and computations involving two  or more properties  44  chapter 1 | essential ideas  it is often the case that a quantity of interest may not be easy (or even possible) to measure directly but instead must be calculated from other directly measured properties and appropriate mathematical relationships. for example, consider measuring the average speed of an athlete running sprints. this is typically accomplished by measuring the time required for the athlete to run from the starting line to the finish line, and the distance between these two lines, and then computing speed from the equation that relates these three properties: speed = distance time an olympic-quality sprinter can run 100 m in approximately 10 s, corresponding to an average speed of 100 m = 10 m/s 10 s note that this simple arithmetic involves dividing the numbers of each measured quantity to yield the number of the computed quantity (100/10 = 10) and likewise dividing the units of each measured quantity to yield the unit of the computed quantity (m/s = m/s). now, consider using this same relation to predict the time required for a person running at this speed to travel a distance of 25 m. the same relation between the three properties is used, but in this case, the two quantities provided are a speed (10 m/s) and a distance (25 m). to yield the sought property, time, the equation must be rearranged appropriately: time = distance speed the time can then be computed as: 25 m = 2.5 s 10 m/s again, arithmetic on the numbers (25/10 = 2.5) was accompanied by the same arithmetic on the units (m/m/s = s) to yield the number and unit of the result, 2.5 s. note that, just as for numbers, when a unit is divided by an identical unit (in this case, m/m), the result is “1”—or, as commonly phrased, the units “cancel.” these calculations are examples of a versatile mathematical approach known as dimensional analysis (or the factorlabel method). dimensional analysis is based on this premise: the units of quantities must be subjected to the same mathematical operations as their associated numbers. this method can be applied to computations ranging from simple unit conversions to more complex, multi-step calculations involving several different quantities.  conversion factors and dimensional analysis a ratio of two equivalent quantities expressed with different measurement units can be used as a unit conversion factor. for example, the lengths of 2.54 cm and 1 in. are equivalent (by definition), and so a unit conversion factor may be derived from the ratio, 2.54 cm (2.54 cm = 1 in.) or 2.54 cm in. 1 in. several other commonly used conversion factors are given in table 1.6. common conversion factors length  volume  mass  1 m = 1.0936 yd  1 l = 1.0567 qt  1 kg = 2.2046 lb  1 in. = 2.54 cm (exact)  1 qt = 0.94635 l  1 lb = 453.59 g  1 km = 0.62137 mi  1 ft3 = 28.317 l  1 (avoirdupois) oz = 28.349 g  1 mi = 1609.3 m  1 tbsp = 14.787 ml  1 (troy) oz = 31.103 g  table 1.6  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  45  when we multiply a quantity (such as distance given in inches) by an appropriate unit conversion factor, we convert the quantity to an equivalent value with different units (such as distance in centimeters). for example, a basketball player’s vertical jump of 34 inches can be converted to centimeters by: 34 in. × 2.54 cm = 86 cm 1 in. since this simple arithmetic involves quantities, the premise of dimensional analysis requires that we multiply both numbers and units. the numbers of these two quantities are multiplied to yield the number of the product quantity, 86, whereas the units are multiplied to yield in. × cm . just as for numbers, a ratio of identical units is also numerically in. in. equal to one, = 1, and the unit product thus simplifies to cm. (when identical units divide to yield a factor of 1, in. they are said to “cancel.”) using dimensional analysis, we can determine that a unit conversion factor has been set up correctly by checking to confirm that the original unit will cancel, and the result will contain the sought (converted) unit.  example 1.8 using a unit conversion factor the mass of a competition frisbee is 125 g. convert its mass to ounces using the unit conversion factor derived from the relationship 1 oz = 28.349 g (table 1.6).  solution if we have the conversion factor, we can determine the mass in kilograms using an equation similar the one used for converting length from inches to centimeters. x oz = 125 g × unit conversion factor we write the unit conversion factor in its two forms: 1 oz and 28.349 g 28.349 g 1 oz the correct unit conversion factor is the ratio that cancels the units of grams and leaves ounces. x oz = 125 g ×  1 oz 28.349 g  ⎞ ⎛ = ⎝ 125 ⎠ oz 28.349 = 4.41 oz (three significant fig es)  check your learning convert a volume of 9.345 qt to liters. answer: 8.844 l  beyond simple unit conversions, the factor-label method can be used to solve more complex problems involving computations. regardless of the details, the basic approach is the same—all the factors involved in the calculation must be appropriately oriented to insure that their labels (units) will appropriately cancel and/or combine to yield the desired unit in the result. this is why it is referred to as the factor-label method. as your study of chemistry continues, you will encounter many opportunities to apply this approach.  46  chapter 1 | essential ideas  example 1.9 computing quantities from measurement results and known mathematical relations what is the density of common antifreeze in units of g/ml? a 4.00-qt sample of the antifreeze weighs 9.26 lb.  solution mass , we need to divide the mass in grams by the volume in milliliters. in general: the since density = volume number of units of b = the number of units of a × unit conversion factor. the necessary conversion factors are given in table 1.6: 1 lb = 453.59 g; 1 l = 1.0567 qt; 1 l = 1,000 ml. we can convert mass from pounds to grams in one step: 9.26 lb ×  453.59 g = 4.20 × 10 3 g 1 lb  we need to use two steps to convert volume from quarts to milliliters. step 1.  convert quarts to liters. 4.00 qt ×  step 2.  1l = 3.78 l 1.0567 qt  convert liters to milliliters.  3.78 l × 1000 ml = 3.78 × 10 3 ml 1l  then, density =  4.20 × 10 3 g = 1.11 g/ml 3.78 × 10 3 ml  alternatively, the calculation could be set up in a way that uses three unit conversion factors sequentially as follows: 9.26 lb × 453.59 g × 1.0567 qt × 1 l = 1.11 g/ml 1000 ml 4.00 qt 1l 1 lb  check your learning what is the volume in liters of 1.000 oz, given that 1 l = 1.0567 qt and 1 qt = 32 oz (exactly)? answer: 2.956 × 10 −2 l  example 1.10 computing quantities from measurement results and known mathematical relations while being driven from philadelphia to atlanta, a distance of about 1250 km, a 2014 lamborghini aventador roadster uses 213 l gasoline. (a) what (average) fuel economy, in miles per gallon, did the roadster get during this trip? (b) if gasoline costs $3.80 per gallon, what was the fuel cost for this trip?  solution (a) we first convert distance from kilometers to miles:  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  47  1250 km × 0.62137 mi = 777 mi 1 km and then convert volume from liters to gallons: 213 l ×  1.0567 qt 1 gal × = 56.3 gal 4 qt 1l  then, (average) mileage = 777 mi = 13.8 miles/gallon = 13.8 mpg 56.3 gal alternatively, the calculation could be set up in a way that uses all the conversion factors sequentially, as follows: 4 qt 1l 1250 km × 0.62137 mi × × = 13.8 mpg 1.0567 qt 1 gal 213 l 1 km (b) using the previously calculated volume in gallons, we find: 56.3 gal × $3.80 = $214 1 gal  check your learning a toyota prius hybrid uses 59.7 l gasoline to drive from san francisco to seattle, a distance of 1300 km (two significant digits). (a) what (average) fuel economy, in miles per gallon, did the prius get during this trip? (b) if gasoline costs $3.90 per gallon, what was the fuel cost for this trip? answer: (a) 51 mpg; (b) $62  conversion of temperature units we use the word temperature to refer to the hotness or coldness of a substance. one way we measure a change in temperature is to use the fact that most substances expand when their temperature increases and contract when their temperature decreases. the mercury or alcohol in a common glass thermometer changes its volume as the temperature changes. because the volume of the liquid changes more than the volume of the glass, we can see the liquid expand when it gets warmer and contract when it gets cooler. to mark a scale on a thermometer, we need a set of reference values: two of the most commonly used are the freezing and boiling temperatures of water at a specified atmospheric pressure. on the celsius scale, 0 °c is defined as the freezing temperature of water and 100 °c as the boiling temperature of water. the space between the two temperatures is divided into 100 equal intervals, which we call degrees. on the fahrenheit scale, the freezing point of water is defined as 32 °f and the boiling temperature as 212 °f. the space between these two points on a fahrenheit thermometer is divided into 180 equal parts (degrees). defining the celsius and fahrenheit temperature scales as described in the previous paragraph results in a slightly more complex relationship between temperature values on these two scales than for different units of measure for other properties. most measurement units for a given property are directly proportional to one another (y = mx). using familiar length units as one example: ⎞ ⎛ length in feet = ⎝ 1 ft ⎠ × length in inches 12 in.  where y = length in feet, x = length in inches, and the proportionality constant, m, is the conversion factor. the celsius and fahrenheit temperature scales, however, do not share a common zero point, and so the relationship between these two scales is a linear one rather than a proportional one (y = mx + b). consequently, converting a temperature from one of these scales into the other requires more than simple multiplication by a conversion factor, m, it also must take  48  chapter 1 | essential ideas  into account differences in the scales’ zero points (b). the linear equation relating celsius and fahrenheit temperatures is easily derived from the two temperatures used to define each scale. representing the celsius temperature as x and the fahrenheit temperature as y, the slope, m, is computed to be: m=  δy = 212 °f − 32 °f = 180 °f = 9 °f δx 100 °c − 0 °c 100 °c 5 °c  the y-intercept of the equation, b, is then calculated using either of the equivalent temperature pairs, (100 °c, 212 °f) or (0 °c, 32 °f), as: b = y − mx = 32 °f − 9 °f × 0 °c = 32 °f 5 °c the equation relating the temperature scales is then: ⎛  ⎞  t °f = ⎝ 9 °f × t °c⎠ + 32 °c 5 °c an abbreviated form of this equation that omits the measurement units is: t °f = 9 × t °c + 32 5 rearrangement of this equation yields the form useful for converting from fahrenheit to celsius: t °c = 5 ⎛⎝t °f − 32⎞⎠ 9 as mentioned earlier in this chapter, the si unit of temperature is the kelvin (k). unlike the celsius and fahrenheit scales, the kelvin scale is an absolute temperature scale in which 0 (zero) k corresponds to the lowest temperature that can theoretically be achieved. the early 19th-century discovery of the relationship between a gas's volume and temperature suggested that the volume of a gas would be zero at −273.15 °c. in 1848, british physicist william thompson, who later adopted the title of lord kelvin, proposed an absolute temperature scale based on this concept (further treatment of this topic is provided in this text’s chapter on gases). the freezing temperature of water on this scale is 273.15 k and its boiling temperature 373.15 k. notice the numerical difference in these two reference temperatures is 100, the same as for the celsius scale, and so the linear relation between these two temperature scales will exhibit a slope of 1 k . following the same approach, the °c equations for converting between the kelvin and celsius temperature scales are derived to be: t k = t °c + 273.15 t °c = t k − 273.15 the 273.15 in these equations has been determined experimentally, so it is not exact. figure 1.28 shows the relationship among the three temperature scales. recall that we do not use the degree sign with temperatures on the kelvin scale.  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  49  figure 1.28 the fahrenheit, celsius, and kelvin temperature scales are compared.  although the kelvin (absolute) temperature scale is the official si temperature scale, celsius is commonly used in many scientific contexts and is the scale of choice for nonscience contexts in almost all areas of the world. very few countries (the u.s. and its territories, the bahamas, belize, cayman islands, and palau) still use fahrenheit for weather, medicine, and cooking.  example 1.11 conversion from celsius normal body temperature has been commonly accepted as 37.0 °c (although it varies depending on time of day and method of measurement, as well as among individuals). what is this temperature on the kelvin scale and on the fahrenheit scale?  solution k = °c + 273.15 = 37.0 + 273.2 = 310.2 k ⎛ ⎞ 9 °f = °c + 32.0 = ⎝9 × 37.0⎠ + 32.0 = 66.6 + 32.0 = 98.6 °f 5 5  check your learning convert 80.92 °c to k and °f. answer: 354.07 k, 177.7 °f  50  chapter 1 | essential ideas  example 1.12 conversion from fahrenheit baking a ready-made pizza calls for an oven temperature of 450 °f. if you are in europe, and your oven thermometer uses the celsius scale, what is the setting? what is the kelvin temperature?  solution ⎛ °c = 5 (°f − 32) = 5 (450 − 32) = 5 × 418 = 232 °c ⟶ set oven to 230 °c es ⎞⎠ ⎝two significant fig 9 9 9 ⎛ k = °c + 273.15 = 230 + 273 = 503 k ⟶ 5.0 × 10 2 k es ⎞⎠ ⎝two significant fig  check your learning convert 50 °f to °c and k. answer: 10 °c, 280 k  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  51  key terms accuracy how closely a measurement aligns with a correct value atom smallest particle of an element that can enter into a chemical combination celsius (°c) unit of temperature; water freezes at 0 °c and boils at 100 °c on this scale chemical change change producing a different kind of matter from the original kind of matter chemical property behavior that is related to the change of one kind of matter into another kind of matter chemistry study of the composition, properties, and interactions of matter compound pure substance that can be decomposed into two or more elements cubic centimeter (cm3 or cc) volume of a cube with an edge length of exactly 1 cm cubic meter (m3) si unit of volume density ratio of mass to volume for a substance or object dimensional analysis (also, factor-label method) versatile mathematical approach that can be applied to computations ranging from simple unit conversions to more complex, multi-step calculations involving several different quantities element substance that is composed of a single type of atom; a substance that cannot be decomposed by a chemical change exact number number derived by counting or by definition extensive property property of a substance that depends on the amount of the substance fahrenheit unit of temperature; water freezes at 32 °f and boils at 212 °f on this scale gas state in which matter has neither definite volume nor shape heterogeneous mixture combination of substances with a composition that varies from point to point homogeneous mixture (also, solution) combination of substances with a composition that is uniform throughout hypothesis tentative explanation of observations that acts as a guide for gathering and checking information intensive property property of a substance that is independent of the amount of the substance kelvin (k) si unit of temperature; 273.15 k = 0 ºc kilogram (kg) standard si unit of mass; 1 kg = approximately 2.2 pounds law statement that summarizes a vast number of experimental observations, and describes or predicts some aspect of the natural world law of conservation of matter when matter converts from one type to another or changes form, there is no detectable change in the total amount of matter present length measure of one dimension of an object liquid state of matter that has a definite volume but indefinite shape  52  chapter 1 | essential ideas  liter (l) (also, cubic decimeter) unit of volume; 1 l = 1,000 cm3 macroscopic domain realm of everyday things that are large enough to sense directly by human sight and touch mass fundamental property indicating amount of matter matter anything that occupies space and has mass meter (m) standard metric and si unit of length; 1 m = approximately 1.094 yards microscopic domain realm of things that are much too small to be sensed directly milliliter (ml) 1/1,000 of a liter; equal to 1 cm3 mixture matter that can be separated into its components by physical means molecule bonded collection of two or more atoms of the same or different elements physical change change in the state or properties of matter that does not involve a change in its chemical composition physical property characteristic of matter that is not associated with any change in its chemical composition plasma gaseous state of matter containing a large number of electrically charged atoms and/or molecules precision how closely a measurement matches the same measurement when repeated pure substance homogeneous substance that has a constant composition rounding procedure used to ensure that calculated results properly reflect the uncertainty in the measurements used in the calculation scientific method path of discovery that leads from question and observation to law or hypothesis to theory, combined with experimental verification of the hypothesis and any necessary modification of the theory second (s) si unit of time si units (international system of units) standards fixed by international agreement in the international system of units (le système international d’unités) significant figures (also, significant digits) all of the measured digits in a determination, including the uncertain last digit solid state of matter that is rigid, has a definite shape, and has a fairly constant volume symbolic domain specialized language used to represent components of the macroscopic and microscopic domains, such as chemical symbols, chemical formulas, chemical equations, graphs, drawings, and calculations theory well-substantiated, comprehensive, testable explanation of a particular aspect of nature uncertainty estimate of amount by which measurement differs from true value unit standard of comparison for measurements unit conversion factor ratio of equivalent quantities expressed with different units; used to convert from one unit to a different unit volume amount of space occupied by an object  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  53  weight force that gravity exerts on an object  key equations mass volume  •  density =  •  t °c = 5 × t °f − 32 9  •  t °f = 9 × t °c + 32 5  •  t k = °c + 273.15  •  t °c = k − 273.15  summary 1.1 chemistry in context chemistry deals with the composition, structure, and properties of matter, and the ways by which various forms of matter may be interconverted. thus, it occupies a central place in the study and practice of science and technology. chemists use the scientific method to perform experiments, pose hypotheses, and formulate laws and develop theories, so that they can better understand the behavior of the natural world. to do so, they operate in the macroscopic, microscopic, and symbolic domains. chemists measure, analyze, purify, and synthesize a wide variety of substances that are important to our lives. 1.2 phases and classification of matter matter is anything that occupies space and has mass. the basic building block of matter is the atom, the smallest unit of an element that can enter into combinations with atoms of the same or other elements. in many substances, atoms are combined into molecules. on earth, matter commonly exists in three states: solids, of fixed shape and volume; liquids, of variable shape but fixed volume; and gases, of variable shape and volume. under high-temperature conditions, matter also can exist as a plasma. most matter is a mixture: it is composed of two or more types of matter that can be present in varying amounts and can be separated by physical means. heterogeneous mixtures vary in composition from point to point; homogeneous mixtures have the same composition from point to point. pure substances consist of only one type of matter. a pure substance can be an element, which consists of only one type of atom and cannot be broken down by a chemical change, or a compound, which consists of two or more types of atoms. 1.3 physical and chemical properties all substances have distinct physical and chemical properties, and may undergo physical or chemical changes. physical properties, such as hardness and boiling point, and physical changes, such as melting or freezing, do not involve a change in the composition of matter. chemical properties, such flammability and acidity, and chemical changes, such as rusting, involve production of matter that differs from that present beforehand. measurable properties fall into one of two categories. extensive properties depend on the amount of matter present, for example, the mass of gold. intensive properties do not depend on the amount of matter present, for example, the density of gold. heat is an example of an extensive property, and temperature is an example of an intensive property. 1.4 measurements measurements provide quantitative information that is critical in studying and practicing chemistry. each measurement has an amount, a unit for comparison, and an uncertainty. measurements can be represented in either decimal or scientific notation. scientists primarily use the si (international system) or metric systems. we use base si units such as meters, seconds, and kilograms, as well as derived units, such as liters (for volume) and g/cm3 (for density). in many cases, we find it convenient to use unit prefixes that yield fractional and multiple units, such as microseconds (10−6 seconds) and megahertz (106 hertz), respectively.  54  chapter 1 | essential ideas  1.5 measurement uncertainty, accuracy, and precision quantities can be exact or measured. measured quantities have an associated uncertainty that is represented by the number of significant figures in the measurement. the uncertainty of a calculated value depends on the uncertainties in the values used in the calculation and is reflected in how the value is rounded. measured values can be accurate (close to the true value) and/or precise (showing little variation when measured repeatedly). 1.6 mathematical treatment of measurement results measurements are made using a variety of units. it is often useful or necessary to convert a measured quantity from one unit into another. these conversions are accomplished using unit conversion factors, which are derived by simple applications of a mathematical approach called the factor-label method or dimensional analysis. this strategy is also employed to calculate sought quantities using measured quantities and appropriate mathematical relations.  exercises 1.1 chemistry in context 1. explain how you could experimentally determine whether the outside temperature is higher or lower than 0 °c (32 °f) without using a thermometer. 2. identify each of the following statements as being most similar to a hypothesis, a law, or a theory. explain your reasoning. (a) falling barometric pressure precedes the onset of bad weather. (b) all life on earth has evolved from a common, primitive organism through the process of natural selection. (c) my truck’s gas mileage has dropped significantly, probably because it’s due for a tune-up. 3. identify each of the following statements as being most similar to a hypothesis, a law, or a theory. explain your reasoning. (a) the pressure of a sample of gas is directly proportional to the temperature of the gas. (b) matter consists of tiny particles that can combine in specific ratios to form substances with specific properties. (c) at a higher temperature, solids (such as salt or sugar) will dissolve better in water. 4. identify each of the underlined items as a part of either the macroscopic domain, the microscopic domain, or the symbolic domain of chemistry. for any in the symbolic domain, indicate whether they are symbols for a macroscopic or a microscopic feature. (a) the mass of a lead pipe is 14 lb. (b) the mass of a certain chlorine atom is 35 amu. (c) a bottle with a label that reads al contains aluminum metal. (d) al is the symbol for an aluminum atom. 5. identify each of the underlined items as a part of either the macroscopic domain, the microscopic domain, or the symbolic domain of chemistry. for those in the symbolic domain, indicate whether they are symbols for a macroscopic or a microscopic feature. (a) a certain molecule contains one h atom and one cl atom. (b) copper wire has a density of about 8 g/cm3. (c) the bottle contains 15 grams of ni powder. (d) a sulfur molecule is composed of eight sulfur atoms. 6. according to one theory, the pressure of a gas increases as its volume decreases because the molecules in the gas have to move a shorter distance to hit the walls of the container. does this theory follow a macroscopic or microscopic description of chemical behavior? explain your answer.  this openstax book is available for free at http://cnx.org/content/col11760/1.9  chapter 1 | essential ideas  55  7. the amount of heat required to melt 2 lbs of ice is twice the amount of heat required to melt 1 lb of ice. is this observation a macroscopic or microscopic description of chemical behavior? explain your answer. 1.2 phases and classification of matter 8. why do we use an object's mass, rather than its weight, to indicate the amount of matter it contains? 9. what properties distinguish solids from liquids? liquids from gases? solids from gases? 10. how does a heterogeneous mixture differ from a homogeneous mixture? how are they similar? 11. how does a homogeneous mixture differ from a pure substance? how are they similar? 12. how does an element differ from a compound? how are they similar? 13. how do molecules of elements and molecules of compounds differ? in what ways are they similar? 14. how does an atom differ from a molecule? in what ways are they similar? 15. many of the items you purchase are mixtures of pure compounds. select th",t_d712a0a5e671,other,0
c_27e12d5a171c,"examining the two extremes of elasticity, perfectly elastic and perfectly inelastic demand, can help us beter understand the intuition behind this measure.  to get a better intuition for the price elasticity of demand, i thought i would take a look at some of the more extreme cases and think about what types of elasticities of demand we would see. so this right over here is a vial of insulin. many diabetics, not all diabetics, but many diabetics need to take insulin daily. they need to inject it in order to maintain their blood sugar level. if they don't do it, bad things will happen to their body. and they might even prematurely die if they don't take their insulin on time. so let's think about what the elasticity of demand might look like for something like insulin. so in one column, i'll put price. and in the other column, i will put quantity. so let's say that insulation right now is going for $5 a vial. and we have a group of diabetics who need insulin. and they're all going to buy the insulin they need. and let's say, in this group, that turns out to be 100 vials per week. so this is in vials per week. fair enough, that's exactly what they need to do to maintain their insulin. now, what happens if the price changes? what happens if the price were to go down? let's say the price were to go down to $1. well, what would the quantity be? well, they're not going to buy any more insulin. they're going to buy just what they need in order to maintain their diabetes. and remember, we're holding all else equal. we're not assuming any change in expectations of price. they expect price go up or down or anything like that so in this case, they'll still just by 100 vials. now, what happens if the price went up a ton? and what happens if the price went to-- what happens if we went to $100 a vial. well, it would be hard for them. but they need it to survive. so it's going to squeeze out any other expenses that they need to spend money on. and so they still will buy 100 vials a week. and so you could keep raising price, within reason. and they would still buy the same quantity. obviously, if you raise it to $1 billion, then they would just wouldn't be able to afford it. but within reason, they're going to buy 100 vials per week, no matter what the price is. so this is an example of perfect inelasticity. another way, so if you think of the physical analogy that we talked about with elasticity. it's like a brick. it doesn't matter how much, within reason once again, any amount of force pulling or pushing that a human could put on a brick, it's not going to change. it's not going to deform the brick in any way. and likewise, any change in price within reason, within reason here, isn't going to change the demand in any way. it's perfectly inelastic. and if you want to do the computation, you could look at inelas-- you could figure out the demand elasticity for, let's say, when you're going from a price of $5 to $1. so the price went down by 4. and the quantity changed by 0. so your percent change in quantity, so delta percent-- i'll write it-- percent change in quantity is equal to 0. and then, your percent is going to be over your percent change in price if you use the averaging method. it was-- it would be going down by 4 over an average of 250. it'll be a fairly large number. but at 0 over anything is still going to be 0. so it doesn't matter what that thing is over here. your elasticity of demand in this situation is 0. and if you wanted to see what this demand curve would look like, let's plot it. so this right over here is my price axis. and that is my quantity axis. and so no matter what, let's say this is a quantity of 100 of vials per week. that's true when the price is $5. so that's true in the prices $5. they're going to demand 100 vials a week. that's true when the price is $1. they're going to demand 100 vials a week. and that's true, if the price is $20 or $100 or whatever. they're going to demand 100 vials a week. and so a perfectly inelastic demand curve would look like this. it is a vertical line. it doesn't matter what price you pick. the quantity demanded is always going to be the exact same thing. now, let's go to another extreme. so this is perfectly inelastic. you can imagine. well, what is perfectly elastic. something that changes a lot if you have a small percentage change in price. and to think about that, let's look at these two vending machines. and you see that they both do sell cans of coke. that's a can of coke there. that is can of coke there. and let's say, starting off, the can of coke, let's say that they cost $1 in each vending machine. and we're going to assume that this one, remember all else equal. so we're going to assume that this vending machine right over here doesn't change. does not change. so it's just going to be consistently charging $1 for a can of coke. and they're sitting next to each other. and it looks like they have a little coffee machine in between right over here. so let's think about the demand curve for this, for coca cola in this vending machine right over here. so let's think about the price and the quantity. so i'll do-- let me do price column and quantity demanded. so let's say if the price is $1. so if the price is $1, then just odds are, it's going to get about half of the sales per week. and let's say that ends up being, i don't know, let's say that ends up being 100 cans. this is in cans per week. now what happens? and let me put some decimals here. so this is $1.00. the price is $1.00. it sells 100 cans per week. and probably this one also would also sell about 100 cans per week. now, what happens if we have a very, very small change in price. so if we change, if we go from $1.00, instead of $1.00, we are at $0.99. what's going to happen? so this, remember, this machine right over here is not changing. this is-- we're talking-- our demand curve is for the quantity of cokes sold from this machine. and the price was for this machine. so if this machine is even a penny cheaper. and assuming that people, there aren't lines forming and things like that, people are just always going to go to this machine. if it's easy enough, if there's no difference, they're always going to go to this machine. so this machine will be able to get, will sell all the cokes. so it's going to sell 200 cokes. now, what happens if, instead of lowering the price by a penny, you raise the price by a penny. so instead of $1.00, your at $1.01. well, now everyone's going to go to the other vending machine. they're going to say, oh, we don't-- even a penny, might as well walk to this one. assuming everything else is equal. so then, they're going to sell 0. and so what would the demand curve look like here. let's plot it out. so this is the price. this right over, this axis right over here is quantity. and this is in cans per week. and so this is 0. this is 100. and then, this is 200. and then this is a price of $1. that's $1. so at $1, the quantity demanded is 100 cans. fair enough. now, at $0.99, the quantity demanded is 200 cans. so at $0.99, the quantity demanded is 200. so $0.99 is right below that, it's 200. so it's right over there. it's like right, right, there's a little bit lower. and $1.01 a little bit over here, the quantity demanded is 0. so the demand curve here is looks something like that. so it's going to be almost horizontal. so it's going to be approaching perfect elasticity, very small changes in price end up with these huge changes, huge changes in percent quantity demanded. and i courage to work out the math to see here, that you will get a very large number for elasticity. and so something that is, this is approaching perfect elasticity. a truly perfect elasticity would be something that is a horizontal line. so in this case, so over here, our elasticity of demand-- and i'll talk about the absolute value of it, is 0. and over here, the absolute value of our elasticity of demand is infinity. '50 because, remember, it's percent change in quantity over percent change in price. when you go from either, from one scenario to another over here, you're percent change in price is very small. it's roughly about 1% in this scenario right over here. changing the price up or down about 1%. but then, you see your quantity is changing, depending on which one you're looking. your quantity is changing on the order of 50% to 100%, from that 1% change in price. so you have a huge elasticity of demand here. it would be a real-- it would actually be a number. but as you can imagine, as it becomes more and more sensitive, as quantity demanded becomes more and more sensitive to a percent change in price, this curve is going to flatten out completely. and you will have an infinite, absolute value of your elasticity of demand.",t_06903d9df5c0,other,0
c_d25ddd59c072,"jump to navigation  the unperminent hair dye rule  poor persuasive essay  this middle school essay focuses on a school rule.  title: the unperminent hair dye rule  level: grade 6, grade 7, grade 8  mode: persuasive writing  form: persuasive essay  student model  the unperminent hair dye rule  students, at west middle school, should be able to come to school with their hair dyed unperminent, and do not have to wash it out. yes, it is flaimable but what are the chances your hair is going to start on fire that day?  i say using koolaid for your hair, or spray-in color, can be useful. like, for instance, you could use it for a costume. or you could use a color for a day and se how your classmates like it. sure people say isit is a destraction. though if that is a destraction, then wouldn’t dyeing you hair permanent be just as destracting. or coming back to class with a wet head be destracting.  so what i think, and i am sure you do too, is that students should be able to come to school, with an unperminent color in their hair, and do not have to wash it out.  rubric  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_c219cfab5b80,other,0
c_08192c09eed2,"skills to develop  recognize characteristics of graphs of polynomial functions.  use factoring to ﬁnd zeros of polynomial functions.  identify zeros and their multiplicities.  determine end behavior.  understand the relationship between degree and turning points.  graph polynomial functions.  use the intermediate value theorem.  the revenue in millions of dollars for a fictional cable company from 2006 through 2013 is shown in table \(\pageindex{1}\).  -------------------------------------------------------------------- |     year | 2006 | 2007 | 2008 | 2009 | 2010 | 2011 | 2012 | 2013 |  | revenues | 52.4 | 52.8 | 51.2 | 49.5 | 48.6 | 48.6 | 48.7 | 47.1 |  --------------------------------------------------------------------  the revenue can be modeled by the polynomial function  \[r(t)=−0.037t^4+1.414t^3−19.777t^2+118.696t−205.332\]  where \(r\) represents the revenue in millions of dollars and \(t\) represents the year, with \(t=6\)corresponding to 2006. over which intervals is the revenue for the company increasing? over which intervals is the revenue for the company decreasing? these questions, along with many others, can be answered by examining the graph of the polynomial function. we have already explored the local behavior of quadratics, a special case of polynomials. in this section we will explore the local behavior of polynomials in general.  recognizing characteristics of graphs of polynomial functions  polynomial functions of degree 2 or more have graphs that do not have sharp corners; recall that these types of graphs are called smooth curves. polynomial functions also display graphs that have no breaks. curves with no breaks are called continuous. figure \(\pageindex{1}\) shows a graph that represents a polynomial function and a graph that represents a function that is not a polynomial.  figure \(\pageindex{1}\)  example \(\pageindex{1}\): recognizing polynomial functions  which of the graphs in figure \(\pageindex{2}\) represents a polynomial function?  figure \(\pageindex{2}\)  solution  the graphs of \(f\) and \(h\) are graphs of polynomial functions. they are smooth and continuous.  the graphs of \(g\) and \(k\) are graphs of functions that are not polynomials. the graph of function \(g\) has a sharp corner. the graph of function \(k\) is not continuous.  do all polynomial functions have as their domain all real numbers?  yes. any real number is a valid input for a polynomial function.  using factoring to find zeros of polynomial functions  recall that if \(f\) is a polynomial function, the values of \(x\) for which \(f(x)=0\) are called zeros of \(f\).  if the equation of the polynomial function can be factored, we can set each factor equal to zero and solve for the zeros.  (also, any value \(x=a\) that is a zero of a polynomial function yields a factor of the polynomial, of the form \(x-a)\).(  we can use this method to find x-intercepts because at the x-intercepts we find the input values when the output value is zero. for general polynomials, this can be a challenging prospect. while quadratics can be solved using the relatively simple quadratic formula, the corresponding formulas for cubic and fourth-degree polynomials are not simple enough to remember, and formulas do not exist for general higher-degree polynomials. consequently, we will limit ourselves to three cases in this section:  the polynomial can be factored using known methods: greatest common factor, factor by grouping, and trinomial factoring.     the polynomial is given in factored form.     technology is used to determine the intercepts.  given a polynomial function \(f\), find the x-intercepts by factoring.  set \(f(x)=0\).  if the polynomial function is not given in factored form:  a. factor out any common monomial factors.  b.factor any factorable binomials or trinomials.  set each factor equal to zero and solve to find the x-intercepts.  example \(\pageindex{2}\): finding the x-intercepts of a polynomial function by factoring  find the x-intercepts of \(f(x)=x^6−3x^4+2x^2\).  solution  we can attempt to factor this polynomial to find solutions for \(f(x)=0\).  \[\begin{align} x^6−3x^4+2x^2&=0 & &\text{factor out the greatest common factor.} \\  x^2(x^4−3x^2+2)&=0 & &\text{factor the trinomial, which is in quadratic form.} \\ x^2(x^2−1)(x^2−2)&=0 & &\text{set each factor equal to zero.} \end{align}\]  \[\begin{align} x^2&=0 & & & (x^2−1)&=0 & & & (x^2−2)&=0 \\ x^2&=0 & &\text{ or } &  x^2&=1 & &\text{ or } & x^2&=2  \\ x&=0 &&& x&={\pm}1 &&& x&={\pm}\sqrt{2} \end{align}\]       .  this gives us five x-intercepts: \((0,0)\), \((1,0)\), \((−1,0)\), \((\sqrt{2},0)\),and \((−\sqrt{2},0)\).  see figure \(\pageindex{3}\). we can see that this is an even function.  to confirm algebraically, we have  \[\begin{align} f(-x) =& (-x)^6-3(-x)^4+2(-x)^2\\ =& x^6-3x^4+2x^2\\ =& f(x). \end{align}\]  figure \(\pageindex{3}\).  example \(\pageindex{3}\): finding the x-intercepts of a polynomial function by factoring  find the x-intercepts of \(f(x)=x^3−5x^2−x+5\).  solution  find solutions for \(f(x)=0\) by factoring.  \[\begin{align}  x^3−5x^2−x+5&=0 &\text{factor by grouping.} \\ x^2(x−5)−(x−5)&=0 &\text{factor out the common factor.} \\ (x^2−1)(x−5)&=0 &\text{factor the difference of squares.} \\  (x+1)(x−1)(x−5)&=0 &\text{set each factor equal to zero.}  \end{align}\]  \[\begin{align} x+1&=0 & &\text{or} & x−1&=0 & &\text{or} & x−5&=0 \\ x&=−1 &&& x&=1 &&& x&=5\end{align}\]  there are three x-intercepts: \((−1,0)\), \((1,0)\), and \((5,0)\). see figure \(\pageindex{4}\).  figure \(\pageindex{4}\): graph of \(f(x)\).  example \(\pageindex{4}\): finding the y- and x-intercepts of a polynomial in factored form  find the y- and x-intercepts of \(g(x)=(x−2)^2(2x+3)\).  solution  the y-intercept can be found by evaluating \(g(0)\).  \[\begin{align} g(0)&=(0−2)^2(2(0)+3) \\ &=12 \end{align}\]  so the y-intercept is \((0,12)\).  the x-intercepts can be found by solving \(g(x)=0\).  \[(x−2)^2(2x+3)=0\]  \[\begin{align} (x−2)^2&=0 & & & (2x+3)&=0 \\ x−2&=0 & &\text{or} & x&=−\dfrac{3}{2} \\ x&=2 \end{align}\]  so the x-intercepts are \((2,0)\) and \(\big(−\dfrac{3}{2},0\big)\).  analysis  we can always check that our answers are reasonable by using a graphing utility to graph the polynomial as shown in figure \(\pageindex{5}\).  figure \(\pageindex{5}\): graph of \(g(x)\).  example \(\pageindex{5}\): finding the x-intercepts of a polynomial function using a graph  find the x-intercepts of \(h(x)=x^3+4x^2+x−6\).  solution  this polynomial is not in factored form, has no common factors, and does not appear to be factorable using techniques previously discussed. fortunately, we can use technology to find the intercepts. keep in mind that some values make graphing difficult by hand. in these cases, we can take advantage of graphing utilities.  looking at the graph of this function, as shown in figure \(\pageindex{6}\), it appears that there are x-intercepts at \(x=−3,−2, \text{ and }1\).  figure \(\pageindex{6}\): graph of \(h(x)\).  we can check whether these are correct by substituting these values for \(x\) and verifying that \[h(−3)=h(−2)=h(1)=0.\]  since \(h(x)=x^3+4x^2+x−6\), we have:  \[h(−3)=(−3)^3+4(−3)^2+(−3)−6=−27+36−3−6=0 \\ h(−2)=(−2)^3+4(−2)^2+(−2)−6=−8+16−2−6=0 \\ h(1)=(1)^3+4(1)^2+(1)−6=1+4+1−6=0\]  each x-intercept corresponds to a zero of the polynomial function and each zero yields a factor, so we can now write the polynomial in factored form.  \[\begin{align} h(x)&=x^3+4x^2+x−6  \\ &=(x+3)(x+2)(x−1) \end{align}\]  \(\pageindex{1}\)  use a graphing utility (like desmos) to find the y-and x-intercepts of the function \(f(x)=x^4−19x^2+30x\).  answer  y-intercept \((0,0)\);  x-intercepts \((0,0)\), \((–5,0)\), \((2,0)\), and \((3,0)\)  identifying zeros and their multiplicities  graphs behave differently at various x-intercepts. sometimes, the graph will cross over the horizontal axis at an intercept. other times, the graph will touch the horizontal axis and bounce off. suppose, for example, we graph the function  \[f(x)=(x+3)(x−2)^2(x+1)^3.\]  notice in figure \(\pageindex{7}\) that the behavior of the function at each of the x-intercepts is different.  figure \(\pageindex{7}\): identifying the behavior of the graph at an x-intercept by examining the multiplicity of the zero.  the x-intercept −3 is the solution of equation \((x+3)=0\). the graph passes directly through thex-intercept at \(x=−3\). the factor is linear (has a degree of 1), so the behavior near the intercept is like that of a line—it passes directly through the intercept. we call this a single zero because the zero corresponds to a single factor of the function.  the x-intercept 2 is the repeated solution of equation \((x−2)^2=0\). the graph touches the axis at the intercept and changes direction. the factor is quadratic (degree 2), so the behavior near the intercept is like that of a quadratic—it bounces off of the horizontal axis at the intercept.  \[(x−2)^2=(x−2)(x−2)\]  the factor is repeated, that is, the factor \((x−2)\) appears twice. the number of times a given factor appears in the factored form of the equation of a polynomial is called the multiplicity. the zero associated with this factor, \(x=2\), has multiplicity 2 because the factor \((x−2)\) occurs twice.  the x-intercept −1 is the repeated solution of factor \((x+1)^3=0\).the graph passes through the axis at the intercept, but flattens out a bit first. this factor is cubic (degree 3), so the behavior near the intercept is like that of a cubic—with the same s-shape near the intercept as the toolkit function \(f(x)=x^3\). we call this a triple zero, or a zero with multiplicity 3.  for zeros with even multiplicities, the graphs touch or are tangent to the x-axis. for zeros with odd multiplicities, the graphs cross or intersect the x-axis. see figure \(\pageindex{8}\) for examples of graphs of polynomial functions with multiplicity \(p=1, p=2\), and \(p=3\).  figure \(\pageindex{8}\): three graphs showing three different polynomial functions with multiplicity 1, 2, and 3.  for higher even powers, such as 4, 6, and 8, the graph will still touch and bounce off of the horizontal axis but, for each increasing even power, the graph will appear flatter as it approaches and leaves the x-axis.  for higher odd powers, such as 5, 7, and 9, the graph will still cross through the horizontal axis, but for each increasing odd power, the graph will appear flatter as it approaches and leaves the x-axis.  graphical behavior of polynomials at x-intercepts  if a polynomial contains a factor of the form \((x−h)^p\), the behavior near the x-intercept \(h\) is determined by the power \(p\). we say that \(x=h\) is a zero of multiplicity \(p\).  the graph of a polynomial function will touch the x-axis at zeros with even multiplicities. the graph will cross the x-axis at zeros with odd multiplicities.  the sum of the multiplicities is no greater than the degree of the polynomial function.  given a graph of a polynomial function of degree \(n\), identify the zeros and their multiplicities.  if the graph crosses the x-axis and appears almost linear at the intercept, it is a single zero.  if the graph touches the x-axis and bounces off of the axis, it is a zero with even multiplicity.  if the graph crosses the x-axis at a zero, it is a zero with odd multiplicity.  the sum of the multiplicities is no greater than \(n\).  example \(\pageindex{6}\): identifying zeros and their multiplicities  use the graph of the function of degree 6 in figure \(\pageindex{9}\) to identify the zeros of the function and their possible multiplicities.  figure \(\pageindex{9}\): graph of a polynomial function with degree 6.  solution  the polynomial function is of degree \(6\). the sum of the multiplicities cannot be greater than \(6\).  starting from the left, the first zero occurs at \(x=−3\). the graph touches the x-axis, so the multiplicity of the zero must be even. the zero of \(x=−3\) has multiplicity 2 or 4.  it cannot have multiplicity 6 since there are other zeros.  the next zero occurs at \(x=−1\). the graph looks almost linear at this point. this is probably a single zero of multiplicity 1.  the last zero occurs at \(x=4\).the graph crosses the x-axis, so the multiplicity of the zero must be odd, but is probably not 1 since the graph does not seem to cross in a linear fashion. the multiplicity is probably 3, which means the multiplicity of \(x=-3\) must be 2, and that the sum of the multiplicities is 6.  \(\pageindex{2}\)  use the graph of the function of degree 5 in figure \(\pageindex{10}\) to identify the zeros of the function and their multiplicities.  figure \(\pageindex{10}\): graph of a polynomial function with degree 5.  answer  the graph has a zero of –5 with multiplicity 1, a zero of –1 with multiplicity 2, and a zero of 3 with multiplicity 2.  determining end behavior  as we have already learned, the behavior of a graph of a polynomial function of the form  \[f(x)=a_nx^n+a_{n−1}x^{n−1}+...+a_1x+a_0\]  will either ultimately rise or fall as \(x\) increases without bound and will either rise or fall as \(x\) decreases without bound. this is because for very large inputs, say 100 or 1,000, the leading term dominates the size of the output. the same is true for very small inputs, say –100 or –1,000.  recall that we call this behavior the end behavior of a function. as we pointed out when discussing quadratic equations, when the leading term of a polynomial function, \(a_nx^n\), is an even power function and \(a_n>0\), as \(x\) increases or decreases without bound, \(f(x)\) increases without bound. when the leading term is an odd power function, as \(x\) decreases without bound, \(f(x)\) also decreases without bound; as \(x\) increases without bound, \(f(x)\) also increases without bound. if the leading term is negative, it will change the direction of the end behavior. figure \(\pageindex{11}\) summarizes all four cases.  figure \(\pageindex{11}\).  understanding the relationship between degree and turning points  in addition to the end behavior, recall that we can analyze a polynomial function’s local behavior. it may have a turning point where the graph changes from increasing to decreasing (rising to falling) or decreasing to increasing (falling to rising). look at the graph of the polynomial function \(f(x)=x^4−x^3−4x^2+4x\) in figure \(\pageindex{12}\). the graph has three turning points.  figure \(\pageindex{12}\): graph of \(f(x)=x^4-x^3-4x^2+4x\)  this function \(f\) is a 4th degree polynomial function and has 3 turning points. the maximum number of turning points of a polynomial function is always one less than the degree of the function.  interpreting turning points  a turning point is a point of the graph where the graph changes from increasing to decreasing (rising to falling) or decreasing to increasing (falling to rising). a polynomial of degree \(n\) will have at most \(n−1\) turning points.  example \(\pageindex{7}\): finding the maximum possible number of turning points using the degree of a polynomial function  find the maximum possible number of turning points of each polynomial function.  \(f(x)=−x^3+4x^5−3x^2+1\)  \(f(x)=−(x−1)^2(1+2x^2)\)  solution  a. \(f(x)=−x^3+4x^5−3x^2+1\)  first, rewrite the polynomial function in descending order: \(f(x)=4x^5−x^3−3x^2+1\)  identify the degree of the polynomial function. this polynomial function is of degree 5.  the maximum possible number of turning points is \(\; 5−1=4\).  b. \(f(x)=−(x−1)^2(1+2x^2)\)  first, identify the leading term of the polynomial function if the function were expanded.  then, identify the degree of the polynomial function. this polynomial function is of degree 4.  the maximum possible number of turning points is \(\; 4−1=3\).  graphing polynomial functions  we can use what we have learned about multiplicities, end behavior, and turning points to sketch graphs of polynomial functions. let us put this all together and look at the steps required to graph polynomial functions.  given a polynomial function, sketch the graph.  find the intercepts, if possible.  check for symmetry. if the function is an even function, its graph is symmetrical about the y-axis, that is, \(f(−x)=f(x)\). if a function is an odd function, its graph is symmetrical about the origin, that is, \(f(−x)=−f(x)\).  use the multiplicities of the zeros to determine the behavior of the polynomial at the x-intercepts.  determine the end behavior by examining the leading term.  use the end behavior and the behavior at the intercepts to sketch a graph.  ensure that the number of turning points does not exceed one less than the degree of the polynomial.  optionally, use technology to check the graph.  example \(\pageindex{8}\): sketching the graph of a polynomial function  sketch a graph of \(f(x)=−2(x+3)^2(x−5)\).  solution  this graph has two x-intercepts. at \(x=−3\), the factor is squared, indicating a multiplicity of 2. the graph will bounce at this x-intercept. at \(x=5\),the function has a multiplicity of one, indicating the graph will cross through the axis at this intercept.  the y-intercept is found by evaluating \(f(0)\).  \[\begin{align} f(0)&=−2(0+3)^2(0−5)  \\ &=−2⋅9⋅(−5) \\ &=90 \end{align}\]  the y-intercept is \((0,90)\).  additionally, we can see the leading term, if this polynomial were multiplied out, would be \(−2x3\), so the end behavior is that of a vertically reflected cubic, with the outputs decreasing as the inputs approach infinity, and the outputs increasing as the inputs approach negative infinity. see figure \(\pageindex{13}\).  figure \(\pageindex{13}\): showing the distribution for the leading term.  to sketch this, we consider that:  as \(x{\rightarrow}−{\infty}\) the function \(f(x){\rightarrow}{\infty}\),so we know the graph starts in the second quadrant and is decreasing toward the x-axis.  since \(f(−x)=−2(−x+3)^2(−x–5)\) is not equal to \(f(x)\), the graph does not display symmetry.  at \((−3,0)\), the graph bounces off of thex-axis, so the function must start increasing.  at \((0,90)\), the graph crosses the y-axis at the y-intercept. see figure \(\pageindex{14}\).  figure \(\pageindex{14}\): graph of the end behavior and intercepts, \((-3, 0)\) and \((0, 90)\), for the function \(f(x)=-2(x+3)^2(x-5)\).  somewhere before or after this point, the graph must turn back down or start decreasing toward the horizontal axis because the graph passes through the next intercept at \((5,0)\). see figure \(\pageindex{15}\).  figure \(\pageindex{15}\): graph of the end behavior and intercepts, \((-3, 0)\), \((0, 90)\) and \((5, 0)\), for the function \(f(x)=-2(x+3)^2(x-5)\).  as \(x{\rightarrow}{\infty}\) the function \(f(x){\rightarrow}−{\infty}\),  so we know the graph continues to decrease, and we can stop drawing the graph in the fourth quadrant.  using technology, we can create the graph for the polynomial function, shown in figure \(\pageindex{16}\), and verify that the resulting graph looks like our sketch in figure \(\pageindex{15}\).  figure \(\pageindex{16}\): the complete graph of the polynomial function \(f(x)=−2(x+3)^2(x−5)\).  \(\pageindex{3}\): sketch a graph of \(f(x)=\dfrac{1}{6}(x-1)^3(x+2)(x+3)\).  answer  figure \(\pageindex{17}\): graph of \(f(x)=\frac{1}{6}(x−1)^3(x+2)(x+3)\)  using the intermediate value theorem  in some situations, we may know two points on a graph but not the zeros. if those two points are on opposite sides of the x-axis, we can confirm that there is a zero between them. consider a polynomial function \(f\) whose graph is smooth and continuous. the intermediate value theorem states that for two numbers \(a\) and \(b\) in the domain of \(f\), if \(a&lt;b\) and \(f(a) \neq f(b)\),then the function \(f\) takes on every value between \(f(a)\) and \(f(b)\). we can apply this theorem to a special case that is useful in graphing polynomial functions. if a point on the graph of a continuous function \(f\) at \(x=a\) lies above the x-axis and another point at \(x=b\) lies below the x-axis, there must exist a third point between \(x=a\) and \(x=b\) where the graph crosses the x-axis. call this point \((c,f(c))\).this means that we are assured there is a solution \(c\) where \(f(c)=0\).  in other words, the intermediate value theorem tells us that when a polynomial function changes from a negative value to a positive value, the function must cross the x-axis. figure \(\pageindex{18}\) shows that there is a zero between \(a\) and \(b\).  figure \(\pageindex{18}\): using the intermediate value theorem to show there exists a zero.  intermediate value theorem  let \(f\) be a polynomial function. the intermediate value theorem states that if \(f(a)\) and \(f(b)\) have opposite signs, then there exists at least one value \(c\) between \(a\) and \(b\) for which \(f(c)=0\).  example \(\pageindex{9}\): using the intermediate value theorem  show that the function \(f(x)=x^3−5x^2+3x+6\) has at least two real zeros between \(x=1\) and \(x=4\).  solution  as a start, evaluate \(f(x)\) at the integer values \(x=1,\;2,\;3,\; \text{and }4\).  see table \(\pageindex{2}\).  table \(\pageindex{2}\)  ----------------------------- |    \(x\) | 1 | 2 |  3 | 4 |  | \(f(x)\) | 5 | 0 | -3 | 2 |  -----------------------------  we see that one zero occurs at \(x=2\). also, since \(f(3)\) is negative and \(f(4)\) is positive, by the intermediate value theorem, there must be at least one real zero between 3 and 4.  we have shown that there are at least two real zeros between \(x=1\) and \(x=4\).  analysis  we can also see on the graph of the function in figure \(\pageindex{19}\) that there are two real zeros between \(x=1\) and \(x=4\).  figure \(\pageindex{19}\).  \(\pageindex{4}\): show that the function \(f(x)=7x^5−9x^4−x^2\) has at least one real zero between \(x=1\) and \(x=2\).  answer  because \(f\) is a polynomial function and since \(f(1)\) is negative and \(f(2)\) is positive, there is at least one real zero between \(x=1\) and \(x=2\).  writing formulas for polynomial functions  now that we know how to find zeros of polynomial functions, we can use them to write formulas based on graphs. because a polynomial function written in factored form will have an x-intercept where each factor is equal to zero, we can form a function that will pass through a set of x-intercepts by introducing a corresponding set of factors.  factored form of polynomials  the polynomial of lowest degree \(p\) that has horizontal intercepts at \(x=x_1,x_2,…,x_n\) can be written in the factored form: \(f(x)=a(x−x_1)^{p_1}(x−x_2)^{p_2}⋯(x−x_n)^{p_n}\) where the powers \(p_i\) on each factor can be determined by the behavior of the graph at the corresponding intercept, and the stretch factor \(a\) can be determined given a value of the function other than an x-intercept.  given a graph of a polynomial function, write a possible formula for the function.  identify the x-intercepts of the graph to find the factors of the polynomial.  examine the behavior of the graph at the x-intercepts to determine the multiplicity of each factor.  find the polynomial of least degree containing all the factors found in the previous step.  use any other point on the graph (the y-intercept may be easiest) to determine the stretch factor.  example \(\pageindex{10}\): writing a formula for a polynomial function from the graph  write a formula for the polynomial function shown in figure \(\pageindex{20}\).  figure \(\pageindex{20}\).  solution  this graph has three x-intercepts: \(x=−3,\;2,\text{ and }5\) and three turning points. the y-intercept is located at \((0,-2)\).  at \(x=−3\) and \( x=5\), the graph passes through the axis linearly, suggesting the corresponding factors of the polynomial will be linear. at \(x=2\), the graph bounces at the intercept, suggesting the corresponding factor of the polynomial could be second degree (quadratic). thus, this is the graph of a polynomial of degree at least 5.  together, this gives us the possibility that  \[f(x)=a(x+3)(x−2)^2(x−5)\]  to determine the stretch factor, we utilize another point on the graph. we will use the y-intercept \((0,–2)\), to solve for \(a\).  \[\begin{align} f(0)&=a(0+3)(0−2)^2(0−5) \\ −2&=a(0+3)(0−2)^2(0−5) \\ −2&=−60a \\ a&=\dfrac{1}{30} \end{align}\]  the graphed polynomial appears to represent the function \(f(x)=\dfrac{1}{30}(x+3)(x−2)^2(x−5)\).  \(\pageindex{5}\): given the graph shown in figure \(\pageindex{21}\), write a formula for the function shown.  figure \(\pageindex{21}\).  answer  \(f(x)=−\frac{1}{8}(x−2)^3(x+1)^2(x−4)\)  using local and global extrema  with quadratics, we were able to algebraically find the maximum or minimum value of the function by finding the vertex. for general polynomials, finding these turning points is not possible without more advanced techniques from calculus. even then, finding where extrema occur can still be algebraically challenging. for now, we will estimate the locations of turning points using technology to generate a graph.  each turning point represents a local minimum or maximum. sometimes, a turning point is the highest or lowest point on the entire graph. in these cases, we say that the turning point is a global maximum or a global minimum. these are also referred to as the absolute maximum and absolute minimum values of the function.  local and global extrema  a local maximum or local minimum at \(x=a\) (sometimes called the relative maximum or minimum, respectively) is the output at the highest or lowest point on the graph in an open interval around \(x=a\).if a function has a local maximum at \(a\), then \(f(a){\geq}f(x)\)for all \(x\) in an open interval around \(x=a\). if a function has a local minimum at \(a\), then \(f(a){\leq}f(x)\)for all \(x\) in an open interval around \(x=a\).  a global maximum or global minimum is the output at the highest or lowest point of the function. if a function has a global maximum at \(a\), then \(f(a){\geq}f(x)\) for all \(x\). if a function has a global minimum at \(a\), then \(f(a){\leq}f(x)\) for all \(x\).  we can see the difference between local and global extrema in figure \(\pageindex{22}\).  figure \(\pageindex{22}\): graph of an even-degree polynomial that denotes the local maximum and minimum and the global maximum.  do all polynomial functions have a global minimum or maximum?  no. only polynomial functions of even degree have a global minimum or maximum. for example, \(f(x)=x\) has neither a global maximum nor a global minimum.  example \(\pageindex{11}\): using local extrema to solve applications  an open-top box is to be constructed by cutting out squares from each corner of a 14 cm by 20 cm sheet of plastic then folding up the sides. find the size of squares that should be cut out to maximize the volume enclosed by the box.  solution  we will start this problem by drawing a picture like that in figure \(\pageindex{23}\), labeling the width of the cut-out squares with a variable,w.  figure \(\pageindex{23}\): diagram of a rectangle with four squares at the corners.  notice that after a square is cut out from each end, it leaves a \((14−2w)\) cm by \((20−2w)\) cm rectangle for the base of the box, and the box will be \(w\) cm tall. this gives the volume  \[\begin{align} v(w)&=(20−2w)(14−2w)w \\ &=280w−68w^2+4w^3  \end{align}\]  notice, since the factors are \(w\), \(20–2w\) and \(14–2w\), the three zeros are \(x=10, 7\), and \(0\), respectively. because a height of 0 cm is not reasonable, we consider only the zeros 10 and 7. the shortest side is 14 and we are cutting off two squares, so values \(w\) may take on are greater than zero or less than 7. this means we will restrict the domain of this function to \(0<w<7\).using technology to sketch the graph of \(v(w)\) on this reasonable domain, we get the graph shown in figure \(\pageindex{24}\). we can use this graph to estimate the maximum value for the volume, restricted to values for \(w\) that are reasonable for this problem—values from 0 to 7.  figure \(\pageindex{24}\): graph of \(v(w)=(20-2w)(14-2w)w\)  from this graph, we turn our focus to only the portion on the reasonable domain, \([0, 7]\). we can estimate the maximum value to be around 340 cubic cm, which occurs when the squares are about 2.75 cm on each side. to improve this estimate, we could use advanced features of our technology, if available, or simply change our window to zoom in on our graph to produce figure \(\pageindex{25}\).  figure \(\pageindex{25}\): graph of \(v(w)=(20-2w)(14-2w)w\).  from this zoomed-in view, we can refine our estimate for the maximum volume to about 339 cubic cm, when the squares measure approximately 2.7 cm on each side.  \(\pageindex{6}\): use technology to find the maximum and minimum values on the interval \([−1,4]\) of the function \(f(x)=−0.2(x−2)^3(x+1)^2(x−4)\).  answer  the minimum occurs at approximately the point \((0,−6.5)\),     and the maximum occurs at approximately the point \((3.5,7)\).  key concepts  polynomial functions of degree 2 or more are smooth, continuous functions.  to find the zeros of a polynomial function, if it can be factored, factor the function and set each factor equal to zero.  another way to find the x-intercepts of a polynomial function is to graph the function and identify the points at which the graph crosses the x-axis.  the multiplicity of a zero determines how the graph behaves at the x-intercepts.  the graph of a polynomial will cross the horizontal axis at a zero with odd multiplicity.  the graph of a polynomial will touch the horizontal axis at a zero with even multiplicity.  the end behavior of a polynomial function depends on the leading term.  the graph of a polynomial function changes direction at its turning points.  a polynomial function of degree \(n\) has at most \(n−1\) turning points.  to graph polynomial functions, find the zeros and their multiplicities, determine the end behavior, and ensure that the final graph has at most \(n−1\) turning points.  graphing a polynomial function helps to estimate local and global extremas.  the intermediate value theorem tells us that if \(f(a)\) and \(f(b)\) have opposite signs, then there exists at least one value \(c\) between \(a\) and \(b\) for which \(f(c)=0\).  glossary  global maximum highest turning point on a graph; \(f(a)\) where \(f(a){\geq}f(x)\) for all \(x\).  global minimum lowest turning point on a graph; \(f(a)\) where \(f(a){\leq}f(x)\) for all \(x\).  intermediate value theorem for two numbers \(a\) and \(b\) in the domain of \(f\), if \(a&lt;b\) and \(f(a) \neq f(b)\), then the function \(f\)  takes on every value between \(f(a)\) and \(f(b)\); specifically, when a polynomial function changes from a negative value to a positive value, the function must cross the x-axis  multiplicity the number of times a given factor appears in the factored form of the equation of a polynomial; if a polynomial contains a factor of the form \((x−h)^p\), \(x=h\) is a zero of multiplicity \(p\).  contributors  jay abramson (arizona state university) with contributing authors. textbook content produced by openstax college is licensed under a creative commons attribution license 4.0 (http://creativecommons.org/licenses/by/4.0/) license. download for free at https://openstax.org/details/books/precalculus (https://openstax.org/details/books/precalculus).",t_1b69d1ccbd20,other,0
c_1606e23878e7,in this video you will learn how to score runs in cricket.,t_fe4f2754d822,other,0
c_d8b8e2d5e7be,"the mechanism for the acid-catalyzed hydrolysis of esters (and transesterification).  voiceover: in the video on fischer esterification we saw that if we took a carboxylic and alcohol, in an acid-catalyzed reaction, we produced an ester, and we also produced water. our goal in that video was to make more of our ester, so we shifted the equilibrium to the right, to make more of our product. in this video, we're talking about the reverse reaction; we're going to talk about ester hydrolysis. so if we increase the concentration of water, that would shift the equilibrium back to the left, and we would hydrolyze our ester, and turn it into our alcohol and our carboxylic acid. so, it's important to think about what bond we're going to break; you can see that we're going to break this bond, in here, and this oxygen, and this r prime group turn into our alcohol, and so we'll see that in our mechanism. so let's go ahead, and look at the details of the mechanism, where we're starting with an ester, and we're going to, first, think about what else is present. one solution, h two o, and h plus, would give us h three o plus, and i'm going to go ahead and draw in the hydronium ion, over here, so this is h three o plus. the first step of the mechanism is to protonate the carbon eel oxygen, so this lone pair of electrons picks up a proton from hydronium and let's go ahead and show the protonated carbon eel, so now we have our oxygen, it has been protonated, so it has a plus one formal charge, so let's show those electrons, so these electrons right here, in magenta, pick up this proton to form this bond right here, and this activates our carbon eel, so we've seen this in earlier videos, so when you think about a resonance structure, that actually makes this carbon more positive, it's more electrophilic, and therefore, that carbon is going to react with a nucleophile in our next step, and our nucleophile here is water, so water's gonna function as a nucleophile, the nucleophile attacks our electrophile, and that pushes these electrons off, onto this oxygen, so when we show the bond now, between the oxygen and that carbon, let me go ahead and draw in the rest of this: this would be a plus one formal charge on this oxygen, and let me highlight those electrons here, so these electrons in blue, are going to form the bond between this carbon and this oxygen. we still have an oxygen over here, on the left, and now, that oxygen has two lone pairs of electrons, so let me go ahead and show those electrons here, so let me make them green, so these electrons right here, in green, move off onto here, and are now a lone pair on that oxygen, we still have an oxygen bonded to this carbon, and an r prime group. the next step, we need to deprotonate; we need to get rid of that plus one formal charge, and so, a molecule of water can come along, and this time, function as a base, so water's gonna function as a base, gonna take this proton, leaving these electrons behind, on that oxygen, so let's get some space down here, to show the deprotonation, so we would now have this carbon, with an oh on the left, and after we deprotonate, we're also gonna have an oh on the right, so let me go ahead and draw in that oh, on the right, so, showing those electrons, let's make those red, so these electrons in here, are gonna move off onto this oxygen, and then drawing in everything else, we have our r group on the left, and we have or prime on the right, and i'm gonna go ahead and put in lone pairs of electrons on this oxygen, because in the next step in the mechanism, we're going to protonate that oxygen. so hydronium is present, so h three o plus, so i'm gonna go ahead and draw that in here, so h three o plus, this oxygen is gonna pick up a proton from hydronium, leaving these electrons behind, and so we're gonna protonate that oxygen, and the reason why we protonate that oxygen is it turns it into a better leaving group, so let me go ahead and draw in everything, so we have our oh groups at the top, we have our r group on the left, we have our oxygen, which has been protonated now, so it's gonna have a plus one formal charge, so plus one formal charge on this oxygen, let's show those electrons, so let's make those blue, here, so i'm saying that this lone pair is gonna take this proton, forming this bond, right here, and if you look closely, you now have alcohol hiding as a leaving group, because in the next step of the mechanism, we're going to reform our carbon eel, and alcohol is going to leave, so if these electrons move into here, to reform our carbon eel, that's too many bonds to carbon, and so these electrons are gonna come off, onto the oxygen, and so here's the bond-breaking step, where the alcohol leaves, and so let's go ahead and draw our product, so we're going to form our carbon eel, and this oxygen is going to have a plus one formal charge now, and we have an r group, and, over here, would be an oh, because the alcohol is going to leave, so i'm gonna go ahead, and draw in the alcohol here, so or prime, with now two lone pairs of electrons, so let's follow some electrons, so these electrons in blue, are the same ones as blue up here, and let's make these electrons in here red, so these electrons in red are going to come off, onto this oxygen, so we lose our alcohol at this step, so loss of our alcohol gives us this, over here, so we're almost done with our reaction, so this is really close to a carboxylic acid, all we would have to do is deprotonate, so we could think about another molecule of water coming along, and acting as a base, so water acts as a base, takes this proton, leaves these electrons behind, and that, of course, gives us our carboxylic acid. so, if i just go ahead and draw in our r group, and then we have roh, and let's follow those electrons, so let's make those red as well, so these electrons, right here, come off, and we get our carboxylic acid as our product, so there's your mechanism for acid-catalyzed ester hydrolysis, which produces a carboxylic acid, and it produces an alcohol, and when we look at some reactions in a second here, we're gonna think about this part, right here, where we lose our alcohol as one of our products, to also give us our carboxylic acid. so let's look at a reaction: so, over here on the left, we have methyl salicylate, or oil of wintergreen, and we're looking for an ester, because we have h two o and h plus, giving us hydronium in solution, and so this is the portion of the molecule that's going to react, it's going to hydrolyze that ester, and we know from the mechanism, this is the bond that's going to break in our mechanism, and so, we can go ahead and draw our products, so we're gonna break that bond, and the whole left portion, so let me go ahead and draw that, this whole left portion here is going to form our carboxylic acid, so let's go ahead and draw in our carboxylic acid, as one of our products, so we have our ring we have our carboxylic acid, so this oh on our carboxylic acid, this oh came from h two o in the mechanism, and then we have this other oh, which produces, of course, salicylic acid, and then we're thinking about our alcohol product, let me go ahead and use green for this, so this is going to leave, we can see that, after you protonate, you get loss of that as your alcohol, and so if we just add a proton onto this oxygen here, we can see that we would form methanol, as our other product, so if i go ahead and draw in the methanol here, we have our two products: we have salicylic acid, and we have methanol, so acid-catalyzed ester hydrolysis. this reaction is at equilibrium, technically, and so you could do things like push the equilibrium to the right, and if you remember from the fischer esterification video, this is what we use to make our wintergreen; we used methanol, and we used salicylic acid to produce our wintergreen, and so everything depends on reactions conditions, in terms of shifting the equilibrium. let's look at another practice problem here: so, once again, we have our ester, and we have water, and i drew the water in a little bit of a weird way, and i'll show you why in a second, so acid-catalyzed ester hydrolysis, once again, we think about what bond is gonna break; this bond is gonna break, and the left side is going to turn into our carboxylic acid, so we can go ahead and draw our carboxylic acid, so we would have this portion of the molecule, so our carboxylic acid, like that, and once again, this oh, let me go ahead and highlight it, so this oh right here, in our carboxylic acid came from our water molecule, so we could think about losing a proton off of water, and then we form our carboxylic acid on the right, our other product, let's be consistent and stick with green here, this is the portion that's gonna turn into our alcohol, so we think about adding a proton onto that oxygen, and, once again we have methanol, as our other product, so, acid-catalyzed ester hydrolysis. now the reason i drew the water molecule in a weird way, is because, what would happen if, instead of this hydrogen, what would happen if we had an r group, an alkyl group? well, that would change this hydrogen into an alkyl group, and then we would form an ester as our product, so we'd be starting with one ester, and we'd be turning it into another ester, and that is called, ""transesterification,"" so pretty much the same reaction that we've been talking about, except we wouldn't get a carboxylic acid, as one of our products; we would get another ester. and so, let's go ahead and do this again, starting with the same ester, but this time, we're gonna use butanol, instead of water. so, once again, we can think about losing, we're gonna break that bond, and we're going to lose this proton, and then we could stick those portions of the molecule together. so, if we stick this together with this, we can see the identity of the other ester that will form, so let's go ahead and draw in our product, so we would have an oxygen here, and then we'd have four carbons: one, two, three, four; so these four carbons from butanol, which form our ester. our other product, once again, we see this portion over here, that would give us methanol, so once again, we have methanol as our product, and even though everything is at equilibrium, methanol has a very low boiling point, so we could boil off the methanol, and shift the equilibrium to the right to make more of our product. so we can see, once gain, we're starting with an ester of methanol, and we're converting it into an ester of butanol, simply by changing the reaction conditions, in a transesterification reaction, so this is a pretty useful reaction in industry.",t_6d5bdbdc0e3b,other,0
c_77c19470a044,"chapter 35 of the book on objective-c.chapter 35: fast enumeration section 35.1: fast enumeration of an nsarray with index this example shows how to use fast enumeration in order to traverse through an nsarray. with this way you can also track current object's index while traversing. suppose you have an array, nsarray *weekdays = @[@""monday"", @""tuesday"", @""wednesday"", @""thursday"", @""friday"", @""saturday"", @""sunday""];  now you can traverse through the array like below, [weekdays enumerateobjectsusingblock:^(id obj, nsuinteger idx, bool *stop) { //... do your usual stuff here obj // this is the current object idx // this is the index of the current object stop // set this to true if you want to stop }];  section 35.2: fast enumeration of an nsarray this example shows how to use fast enumeration in order to traverse through an nsarray. when you have an array, such as nsarray *collection = @[@""fast"", @""enumeration"", @""in objc""];  you can use the for ... in syntax to go through each item of the array, automatically starting with the ﬁrst at index 0 and stopping with the last item: for (nsstring *item in collection) { nslog(@""item: %@"", item); }  in this example, the output generated would look like // item: fast // item: enumeration // item: in objc  goalkicker.com – objective-c® notes for professionals  85",t_8623f5b58d4c,other,0
c_d1d336d1d907,topic hierarchy,t_4179253e0ff6,other,0
c_38ffeebb0470,"introduction  the ""size"" of a signal would involve some notion of its strength. we use the mathematical concept of the norm to quantify this concept for both continuous-time and discrete-time signals. as there are several types of norms that can be defined for signals, there are several different conceptions of signal size.  signal energy  infinite length, continuous time signals  the most commonly encountered notion of the energy of a signal defined on \(\mathbb{r}\) is the \(l_2\) norm defined by the square root of the integral of the square of the signal, for which the notation  \[\|f\|_{2}=\left(\int_{-\infty}^{\infty}|f(t)|^{2} d t\right)^{1 / 2} \label{1.4}.\]  however, this idea can be generalized through definition of the \(l_p\) norm, which is given by  \[\|f\|_{p}=\left(\int_{-\infty}^{\infty}|f(t)|^{p} d t\right)^{1 / p} \label{1.5}\]  for all \(1 \leq p<\infty\). because of the behavior of this expression as \(p\) approaches \(\infty\), we furthermore define  \[\|f\|_{\infty}=\sup _{t \in \mathbb{r}}[f(t) |, \label{1.6}\]  which is the least upper bound of \(|f(t)|\). a signal \(f\) is said to belong to the vector space \(l_{p}(\mathbb{r}) \text { if }\|f\|_{p}<\infty\).  example \(\pageindex{1}\)  for example, consider the function defined by  \[f(t)=\left\{\begin{array}{cc} 1 / t &amp; 1 \leq t \\ 0 &amp; \text { otherwise } \end{array}\right. \label{1.7}\]  the \(l_1\) norm is  \[\|f\|_{1}=\int_{-\infty}^{\infty}|f(t)| d t=\int_{-\infty}^{\infty} \frac{1}{t} d t=\infty . \nonumber\]  the \(l_2\) norm is  \[\|f\|_{2}=\left(\int_{-\infty}^{\infty}|f(t)|^{2} d t\right)^{1 / 2}=\left(\int_{-\infty}^{\infty} \frac{1}{t^{2}} d t\right)^{1 / 2}=1.\nonumber\]  the \(l_{\infty}\) norm is  \[\|f\|_{\infty}=\sup _{t \in \mathbb{r}}|f(t)|=\sup _{t \in \mathbb{r}[1, \infty)} \frac{1}{t}=1 . \nonumber\]  finite length, continuous time signals  the most commonly encountered notion of the energy of a signal defined on \(\mathbb{r}[a, b]\) is the \(l_2\) norm defined by the square root of the integral of the square of the signal, for which the notation  \[\|f\|_{2}=\left(\int_{a}^{b}|f(t)|^{2} d t\right)^{1 / 2} \label{1.11}.\]  however, this idea can be generalized through definition of the \(l_p\) norm, which is given by  \[\|f\|_{p}=\left(\int_{a}^{b}|f(t)|^{p} d t\right)^{1 / p} \label{1.12}\]  for all \(1 \leq p<\infty\). because of the behavior of this expression as \(p\) approaches \(\infty\), we furthermore define  \[\|f\|_{\infty}=\sup _{t \in \mathbb{r}[a, b]}|f(t)| \label{1.13} \]  which is the least upper bound of \(|f(t)|\). a signal \(f\) is said to belong to the vector space \(l_{p}(\mathbb{r}[a, b])\) if \(\|f\|_{p}<\infty\). the periodic extension of such a signal would have infinite energy but finite power.  example \(\pageindex{2}\)  for example, consider the function defined on \(\mathbb{r}[-5,3]\) by  \[f(t)=\left\{\begin{array}{ll} t &amp; -5&lt;t&lt;3 \\ 0 &amp; \text { otherwise } \end{array}\right. \label{1.14}.\]  the \(l_1\) norm is  \[\|f\|_{1}=\int_{-5}^{3}|f(t)| d t=\int_{-5}^{3}|t| d t=17. \nonumber\]  the \(l_2\) norm is  \[\|f\|_{2}=\left(\int_{-5}^{3} |f(t)|^{2} d t\right)^{1 / 2}=\left(\int_{-5}^{3}|t|^{2} d t\right)^{1 / 2} \approx 7.12 \nonumber\]  the \(l_{\infty}\) norm is  \[\|f\|_{\infty}=\sup _{t \in \mathbb{r}[-5,3]}|t|=5. \nonumber\]  infinite length, discrete time signals  the most commonly encountered notion of the energy of a signal defined on \(\mathbb{z}\) is the \(l_2\) norm defined by the square root of the sumation of the square of the signal, for which the notation  \[\|x[n]\|_{2}=\left(\sum_{n=-\infty}^{\infty}|x[n]|^{2}\right)^{1 / 2} \label{1.18}.\]  however, this idea can be generalized through definition of the \(l_p\) norm, which is given by  \[\|x[n]\|_{p}=\left(\sum_{n=-\infty}^{\infty}|x[n]|^{p}\right)^{1 / p} \label{1.19}\]  for all \(1 \leq p<\infty\). because of the behavior of this expression as \(p\) approaches \(\infty\), we furthermore define  \[\|x[n]\|_{\infty}=\sup _{n \in \mathbb{z}}|x[n]| \label{1.20},\]  which is the least upper bound of \(|x[n]|\). a signal \(x\) is said to belong to the vector space \(l_{p}(\mathbb{z})\) if \(\|x[n]\|_{p}<\infty\).  example \(\pageindex{3}\)  for example, consider the function defined by  \[x[n]=\left\{\begin{array}{cc} 1 / n &amp; 1 \leq n \\ 0 &amp; \text { otherwise } \end{array}\right. \label{1.21}.\]  the \(l_1\) norm is  \[\|x[n]\|_{1}=\sum n=-\infty^{\infty}|x[n]|=\sum_{n=1}^{\infty} \frac{1}{n}=\infty \label{1.22}.\]  the \(l_2\) norm is  \[\|x[n]\|_{2}=\left(\sum_{n=-\infty}^{\infty}|x[n]|^{2}\right)^{1 / 2}=\left(\sum_{n=1}^{\infty} \frac{1}{n^{2}}\right)^{1 / 2}=\frac{\pi \sqrt{6}}{6} \label{1.23}\]  the \(l_{\infty}\) norm is  \[\|x[n]\|_{\infty}=\sup _{n \in \mathbb{z}}|x[n]|=\sup _{n \in \mathbb{z}[1, \infty)} \frac{1}{n}=1 \label{1.24}.\]  finite length, discrete time signals  the most commonly encountered notion of the energy of a signal defined on \(\mathbb{z}[a, b]\) is the \(l_2\) norm defined by the square root of the sumation of the square of the signal, for which the notation  \[\|x[n]\|_{2}=\left(\sum_{n=a}^{b}|x[n]|^{2}\right)^{1 / 2} \label{1.25}.\]  however, this idea can be generalized through definition of the \(l_p\) norm, which is given by  \[\|x[n]\|_{p}=\left(\sum_{n=a}^{b}|x[n]|^{p}\right)^{1 / p} \label{1.26}\]  for all \(1 \leq p<\infty\). because of the behavior of this expression as \(p\) approaches \(\infty\), we furthermore define  \[\|x[n]\|_{\infty}=\sup _{n \in \mathbb{z}[a, b]}|x[n]| \label{1.27},\]  which is the least upper bound of \(|x[n]|\). in this case, this least upper bound is simply the maximum value of \(|x[n]|\). a signal \(x[n]\) is said to belong to the vector space \(l_{p}(\mathbb{z}[a, b])\) if \(\|x[n]\|_{p}<\infty\). the periodic extension of such a signal would have infinite energy but finite power.  example \(\pageindex{4}\)  for example, consider the function defined on \(\mathbb{z}[-5,3]\) by  \[x[n]=\left\{\begin{array}{cc} n &amp; -5&lt;n&lt;3 \\ 0 &amp; \text { otherwise } \end{array}\right. .\label{1.28}\]  the \(l_1\) norm is  \[\|x[n]\|_{1}=\sum_{n=-5}^{3}|x[n]|=\sum-5^{3}|n|=21 \label{1.29}.\]  the \(l_2\) norm is  \[\|x[n]\|_{2}=\left(\sum_{-5}^{3}|x[n]|^{2}\right)^{1 / 2}=\left(\sum_{-5}^{3}|n|^{2} d t\right)^{1 / 2} \approx 8.31 \label{1.30}\]  the \(l_{\infty}\) norm is  \[\|x[n]\|_{\infty}=\sup _{n \in \mathbb{z}[-5,3]}|x[n]|=5 \label{1.31}.\]  signal norms summary  the notion of signal size or energy is formally addressed through the mathematical concept of norms. there are many types of norms that can be defined for signals, some of the most important of which have been discussed here. for each type norm and each type of signal domain (continuous or discrete, and finite or infinite) there are vector spaces defined for signals of finite norm. finally, while nonzero periodic signals have infinite energy, they have finite power if their single period units have finite energy.",t_1e6c8e0d951c,other,0
c_01be5ca99fc8,"polyketides are secondary metabolites produced from bacteria, fungi, plants, and animals.  learning objectives  describe the characteristics associated with polyketides, including:  type i, ii and iii polyketides  key takeaways  key points  secondary metabolites are organic compounds that are not directly involved in the normal growth, development, or reproduction of an organism.  polyketides are usually biosynthesized through the decarboxylative condensation of malonyl-coa derived extender units in a similar process to fatty acid biosynthesis.  polyketides are structurally a very diverse family of natural products with diverse biological activities and pharmacological properties.  key terms  polyketides: polyketides are secondary metabolites from bacteria, fungi, plants, and animals. polyketides are usually biosynthesized through the decarboxylative condensation of malonyl-coa derived extender units in a similar process to fatty acid synthesis (a claisen condensation).  metabolites: metabolites are the intermediates and products of metabolism. the term metabolite is usually restricted to small molecules. metabolites have various functions, including fuel, structure, signaling, stimulatory and inhibitory effects on enzymes, catalytic activity of their own (usually as a cofactor to an enzyme), defense, and interactions with other organisms (e.g. pigments, odorants, and pheromones).  biosynthesized: biosynthesis (also called biogenesis or “anabolism”) is an enzyme-catalyzed process in cells of living organisms by which substrates are converted to more complex products. the biosynthesis process often consists of several enzymatic steps in which the product of one step is used as substrate in the following step.  polyketides are secondary metabolites produced from bacteria, fungi, plants, and animals.  secondary metabolites are organic compounds that are not directly involved in the normal growth, development, or reproduction of an organism. unlike primary metabolites, the absence of secondary metabolites does not result in immediate death, but rather in long-term impairment of the organism’s survivability, fecundity, or aesthetics, or perhaps in no significant change at all. secondary metabolites are often restricted to a narrow set of species within a phylogenetic group. secondary metabolites often play an important role in plant defense against herbivory and other interspecies defenses. humans use secondary metabolites as medicines, flavorings, and recreational drugs.  tetracycline structural formula  polyketides are usually biosynthesized through the decarboxylative condensation of malonyl-coa derived extender units in a similar process to fatty acid biosynthesis (a claisen condensation). the polyketide chains produced by a minimal polyketide synthase are often further derivitized and modified into bioactive natural products.  polyketides are structurally a very diverse family of natural products with diverse biological activities and pharmacological properties. they are broadly divided into three classes: type i polyketides (often macrolides produced by multimodular megasynthases), type ii polyketides (often aromatic molecules produced by the iterative action of dissociated enzymes ), and type iii polyketides (often small aromatic molecules produced by fungal species). polyketide antibiotics, antifungals, cytostatics, anticholesteremic, antiparasitics, coccidiostats, animal growth promoters, and natural insecticides are in commercial use.  examples of polyketides include: macrolides; pikromycin, the first isolated macrolide; the antibiotics erythromycin a; clarithromycin, and azithromycin; the immunosuppressant tacrolimus; radicicol and pochonin family (hsp90 inhibitor); polyene antibiotics; amphotericin; tetracyclines and the tetracycline family of antibiotics.  polyketides are synthesized by one or more specialized and highly complex polyketide synthase (pks) enzymes.  licenses and attributions  cc licensed content, specific attribution  polysaccharide. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/polysaccharide%23acidic_polysaccharides (http://en.wikipedia.org/wiki/polysaccharide%23acidic_polysaccharides). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  gluconeogenesis. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/gluconeogenesis (http://en.wikipedia.org/wiki/gluconeogenesis). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  glucose-1-phosphate adenylyltransferase. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/glucose-1-phosphate_adenylyltransferase (http://en.wikipedia.org/wiki/glucose-1-phosphate_adenylyltransferase). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  glycogen synthase. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/glycogen_synthase (http://en.wikipedia.org/wiki/glycogen_synthase). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  phosphoenolpyruvic acid. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/phosphoenolpyruvic_acid (http://en.wikipedia.org/wiki/phosphoenolpyruvic_acid). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  uridine diphosphate glucose. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/uridine_diphosphate_glucose (http://en.wikipedia.org/wiki/uridine_diphosphate_glucose). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  gluconeogenesis. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/gluconeogenesis (http://en.wiktionary.org/wiki/gluconeogenesis). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  glucosyltransferases. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/glucosyltransferases (http://en.wikipedia.org/wiki/glucosyltransferases). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/polysaccharides (http://www.boundless.com//microbiology/definition/polysaccharides). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  udp-glucose. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/file:udp-glucose.svg (http://en.wikipedia.org/wiki/file:udp-glucose.svg). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  lipid. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid (http://en.wikipedia.org/wiki/lipid). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  endotoxin. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/endotoxin (http://en.wiktionary.org/wiki/endotoxin). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  lipogenesis. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/lipogenesis (http://en.wiktionary.org/wiki/lipogenesis). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/lipid-a (http://www.boundless.com//microbiology/definition/lipid-a). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  udp-glucose. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/file:udp-glucose.svg (http://en.wikipedia.org/wiki/file:udp-glucose.svg). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  attenuator (genetics). provided by: wikipedia. located at: http://en.wikipedia.org/wiki/attenuator_(genetics) (http://en.wikipedia.org/wiki/attenuator_(genetics)). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/attenuation (http://www.boundless.com//microbiology/definition/attenuation). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  termination. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/termination (http://en.wiktionary.org/wiki/termination). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  transcription. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/transcription (http://en.wiktionary.org/wiki/transcription). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  udp-glucose. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/file:udp-glucose.svg (http://en.wikipedia.org/wiki/file:udp-glucose.svg). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  attenuator (genetics). provided by: wikipedia. located at: http://en.wikipedia.org/wiki/attenuator_(genetics) (http://en.wikipedia.org/wiki/attenuator_(genetics)). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  polyhydroxyalkanoates. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/polyhydroxyalkanoates (http://en.wikipedia.org/wiki/polyhydroxyalkanoates). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  fermentation. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/fermentation (http://en.wiktionary.org/wiki/fermentation). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  biodegradability. provided by: wiktionary. located at: http://en.wiktionary.org/wiki/biodegradability (http://en.wiktionary.org/wiki/biodegradability). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/polyhydroxyalkanoates (http://www.boundless.com//microbiology/definition/polyhydroxyalkanoates). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  udp-glucose. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/file:udp-glucose.svg (http://en.wikipedia.org/wiki/file:udp-glucose.svg). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  attenuator (genetics). provided by: wikipedia. located at: http://en.wikipedia.org/wiki/attenuator_(genetics) (http://en.wikipedia.org/wiki/attenuator_(genetics)). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  polyhydroxyalkanoates. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/polyhydroxyalkanoates (http://en.wikipedia.org/wiki/polyhydroxyalkanoates). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  secondary metabolite. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/secondary_metabolite (http://en.wikipedia.org/wiki/secondary_metabolite). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  polyketide. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/polyketide (http://en.wikipedia.org/wiki/polyketide). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/polyketides (http://www.boundless.com//microbiology/definition/polyketides). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/metabolites (http://www.boundless.com//microbiology/definition/metabolites). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  boundless. provided by: boundless learning. located at: http://www.boundless.com//microbiology/definition/biosynthesized (http://www.boundless.com//microbiology/definition/biosynthesized). license: cc by-sa: attribution-sharealike (https://creativecommons.org/licenses/by-sa/4.0/)  udp-glucose. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/file:udp-glucose.svg (http://en.wikipedia.org/wiki/file:udp-glucose.svg). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  lipid a. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/lipid_a (http://en.wikipedia.org/wiki/lipid_a). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  attenuator (genetics). provided by: wikipedia. located at: http://en.wikipedia.org/wiki/attenuator_(genetics) (http://en.wikipedia.org/wiki/attenuator_(genetics)). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  polyhydroxyalkanoates. provided by: wikipedia. located at: http://en.wikipedia.org/wiki/polyhydroxyalkanoates (http://en.wikipedia.org/wiki/polyhydroxyalkanoates). license: public domain: no known copyright (https://creativecommons.org/about/pdm)  tetracycline_structural_formula_v.1.svg.png. provided by: wikimedia. located at: https://commons.wikimedia.org/wiki/file:tetracycline_structural_formula_v.1.svg (https://commons.wikimedia.org/wiki/file:tetracycline_structural_formula_v.1.svg). license: public domain: no known copyright (https://creativecommons.org/about/pdm)",t_499fc95222d2,other,0
c_c751ab667cf4,"sal gives a proof of the power rule for the specific case where n=½ (i.e. for the derivative of √x).  so i've been requested to do the proof of the derivative of the square root of x, so i thought i would do a quick video on the proof of the derivative of the square root of x. so we know from the definition of a derivative that the derivative of the function square root of x, that is equal to-- let me switch colors, just for a variety-- that's equal to the limit as delta x approaches 0. and you know, some people say h approaches 0, or d approaches 0. i just use delta x. so the change in x over 0. and then we say f of x plus delta x, so in this case this is f of x. so it's the square root of x plus delta x minus f of x, which in this case it's square root of x. all of that over the change in x, over delta x. right now when i look at that, there's not much simplification i can do to make this come out with something meaningful. i'm going to multiply the numerator and the denominator by the conjugate of the numerator is what i mean by that. let me rewrite it. limit is delta x approaching 0-- i'm just rewriting what i have here. so i said the square root of x plus delta x minus square root of x. all of that over delta x. and i'm going to multiply that-- after switching colors-- times square root of x plus delta x plus the square root of x, over the square root of x plus delta x plus the square root of x. this is just 1, so i could of course multiply that times-- if we assume that x and delta x aren't both 0, this is a defined number and this will be 1. and we can do that. this is 1/1, we're just multiplying it times this equation, and we get limit as delta x approaches 0. this is a minus b times a plus b. let me do little aside here. let me say a plus b times a minus b is equal to a squared minus b squared. so this is a plus b times a minus b. so it's going to be equal to a squared. so what's this quantity squared or this quantity squared, either one, these are my a's. well it's just going to be x plus delta x. so we get x plus delta x. and then what's b squared? so minus square root of x is b in this analogy. so square root of x squared is just x. and all of that over delta x times square root of x plus delta x plus the square root of x. let's see what simplification we can do. well we have an x and then a minus x, so those cancel out. x minus x. and then we're left in the numerator and the denominator, all we have is a delta x here and a delta x here, so let's divide the numerator and the denominator by delta x. so this goes to 1, this goes to 1. and so this equals the limit-- i'll write smaller, because i'm running out of space-- limit as delta x approaches 0 of 1 over. and of course we can only do this assuming that delta-- well, we're dividing by delta x to begin with, so we know it's not 0, it's just approaching zero. so we get square root of x plus delta x plus the square root of x. and now we can just directly take the limit as it approaches 0. we can just set delta x as equal to 0. that's what it's approaching. so then that equals one over the square root of x. right, delta x is 0, so we can ignore that. we could take the limit all the way to 0. and then this is of course just a square root of x here plus the square root of x, and that equals 1 over 2 square root of x. and that equals 1/2x to the negative 1/2. so we just proved that x to the 1/2 power, the derivative of it is 1/2x to the negative 1/2, and so it is consistent with the general property that the derivative of-- oh i don't know-- the derivative of x to the n is equal to nx to the n minus 1, even in this case where the n was 1/2. well hopefully that's satisfying. i didn't prove it for all fractions but this is a start. this is a common one you see, square root of x, and it's hopefully not too complicated for proof. i will see you in future videos.",t_3914e25179fa,other,0
c_b1fc16d6604d,"in imperfect competition, firms have some control over the price they charge, so the individual firm's demand curve is not horizontal. learn how that fact also changes the marginal revenue curve in this video.  - [instructor] we've already had several videos where we talk about the types of markets that we might look at in economics. at one end, you might have perfect competition, let's write perfect comp, and this is where you have many firms, what they produce is not differentiated, there is no barriers to entry, and in that situation, we have looked at that the market price, the firms just have to take that market price, and that market price is going to describe what their marginal revenue is going to be. no matter how much each of those individual firms produce, they're just going to get that market price, so that marginal revenue will be that market price, but then we looked at a whole sort of what we could call imperfectly competitive firms, imperfectly, imperfect competition. at the extreme, you have the monopoly, where you only have one firm in the market, huge barriers to entry and so that company or that firm essentially is the market and so their demand curve for their product essentially is the market demand curve. but in between, you have things like monopolistic competition right over there, and in monopolistic competition, you have many firms that are competing but they are all differentiated in some way, and there are some barriers to entry. a good example of monopolistic competition or imperfect competition might be the athletic shoe market. in the athletic shoe market, you have many competitors, you have your nike, adidas, reebok, and i could keep listing names, and they are all differentiated in their own way, they all have their own brands, which they have built up over time, they have associations with certain sports figures, some their shoes might be perceived as better in certain categories, but they are also competing with each other. so the competition is that they are competing with each other but you could consider monopolistic competition because only nike can sell, well, nike shoes, and so you could imagine a demand curve for say only nike shoes, so in imperfect competition, every firm would have their own unique demand curve, and how much they produce actually will affect the price that they get for the product or the service, and what we're going to see in this video is when we are dealing with imperfect competition, the demand curve, the price, isn't exactly what marginal revenue is going to be, and to understand that, let's look at a simple model here. so right over here, i have a very simple model of a demand curve for a firm in an imperfectly competitive market, and you can see here that the more that that firm produces of its goods, the lower price it can get for that good, and we can see very clearly this is a classic downward sloping demand curve, but what's going to be really interesting is to think about, what is going to be the marginal revenue, especially the marginal revenue in a world where if they sell one unit, they get 32.50, but when they sell two units, it's not like they'll get 32.50 for one of those units and then they'll get 25 for the second unit. if you have a market price out there for $25, you're going to get $25 on all two units, so even though someone was willing to pay 32.50 for one, they are still only going to pay $25, so let's think about what that does to the marginal revenue. i encourage you to pause this video and try to fill out this table yourself before i do it with you. all right, now let's do it together, so our total revenue, obviously when we sell nothing, we have, let me do this in another color, we have zero total revenue. now, when we sell one unit at 32.50, well, then our total revenue is going to be 32.50, no surprise there. now it's going to get interesting. when we sell two units, what's going to be our total revenue? well, both of those units are gonna be sold at $25, it's not like, as i just said, it's not like that first person is still willing to pay 32.50, like hey, your market price is $25, that's what everyone is going to pay, so now your total revenue is $50, two times $25. now when you go to three, the market price that you can get is 17.50, let's see, that is going to be, 52.50. 52.50 of total revenue, and then if you, if your market price was $10, you could have a quantity of four. if you wanted to sell four, you could do so at a price of $10, you can do it in either way, but then your total revenue is going to be $40. now, from this, we can think about, well, what's our marginal revenue? well, our marginal revenue for that first unit is the same as what the price of that first unit is, we went from zero to 32.50 with that first unit, so that's 32.50 right over here, but what about as we go from that first unit to that second unit? well, our units go up by one, but our revenue from 32.50 to 50 goes up by 17.50, and so we are already seeing that there is a discrepancy between our marginal revenue and our price, and we can going. when we go from two to three units, our revenue only goes up by 2.50, and so that's going to be our marginal revenue, and then something very interesting happens. as we go from three units to four units, our total revenue actually goes down, it goes down by 12.50, negative 12.50 right over here, and that's because when the price gets that low, you are taking a hit on all of the units that you are selling, so you'll actually get a lower total revenue right over here, and if we plotted, we'll see very clearly that the marginal revenue curve, the parts from the demand curve for that firm that's competing in an imperfectly competitive market, and so we can see here at one unit, our marginal revenue is the same, but at two units, our marginal revenue is 17.50, at three units, our marginal revenue is 2.50, and so we have a marginal revenue curve that looks more like this. so the big takeaway is here that a firm that's operating in an imperfectly market. it isn't just a price taker, it's not that no matter how much it produces it's going to get the same price, it's going to have its own unique demand curve, because there is some differentiation in the market, and so it's going to have a downward sloping demand curve, and because of that downward sloping demand curve, you are also going to have a downward sloping marginal revenue curve and that marginal revenue curve is actually going to be downward sloping at a steeper rate, so when we start doing the firm analysis of marginal cost and where does it intersect the marginal revenue, if you're dealing with a firm that's operating in a perfectly competitive market, that marginal revenue curve when we've seen it before was horizontal, but when we think about that marginal revenue curve for a firm in an imperfectly competitive market, that's going to be downward sloping, it's going to be sloping downward faster than its demand curve.",t_8dea08b2c37a,other,0
c_47745e6678a6,"worked examples practicing the relationship between slope, y-intercept, and linear equation in slope-intercept form.  - [sal] let's do some practice examples from our intro to slope y intercept exercise. what is the slope of y is equal to negative four x minus three? so you might already recognize, this is in slope intercept form. just as a reminder, slope intercept form is y is equal to mx plus b, where the coefficient on this x term right over here, that is our slope, and then this constant right over here, that is going to give you your y intercept. so if they're saying, what is the slope here? well i just need to figure out, what is the coefficient on this x term? and you can see that the coefficient here is a negative four. so that is going to be our m, that is going to be our slope. now just as a reminder, you have to make sure that it's solved in this way, that is is solved for y, y is equal to something times x minus three, so that's our slope. let's do another one of these. so we're asked, what is the y intercept of y is equal to negative three x minus two? so once again we already have it in slope intercept form. it's already been solved for y. it's of the form y is equal to mx plus b, where m, our slope, is given right over here, negative three. but they're not asking for our slope, they're asking for the y intercept. well the y intercept is given by b here, so b is negative two. pay close attention to the sign here. so b is equal to negative two. but when i look at these choices, i don't see a b is equal to negative two, so what are they talking about? well a y intercept is, what is the y value when x is equal to zero? and you could see that here, if x was equal to zero then that term goes away and y is equal to b. so if you want to know the point where the graph described by this equation intercepts the y axis, well it's going to be what is y when x is equal to zero? well when x is equal to zero, y is equal to negative two. and you could see that in our original equation, again. if x were zero, this term would go away, and y would be equal to negative two. so zero, comma, negative two. so it would be that choice right over there. on khan academy obviously you just have to click on that, you don't have to shade it in. let's do one more. complete the equation of the line whose slope is five, and y intercept is zero, comma, four. so once again the general form is y is equal to our slope times x, if i want to put it in slope intercept form, plus our y intercept. well they're telling us, our slope is five. whose slope is five. so we know that m is going to be five. and they tell us that the y intercept is zero, four. so the y intercept, b, that is the value of y when x is equal to zero. so the value of y when x equals zero is this four right over here. so that is going to be four. so i could say y is equal to five times x plus four. and when you're actually entering it on khan academy, you would just type it in, or if you're using the app you would use it with your finger. and i always make the mistake of writing y equals, and i type in y equals five x plus four. notice they already gave you the y equals right over there. that's all you have to do, recognize the slope, the y intercept, and then remember what the slope intercept form actually is.",t_0222f89e4805,other,0
c_2c06a7a671b0,"sal answers a question about scatter plots that show the relationship between study time, shoe size, and test score.  the graphs below show the test grades of the students in dexter's class. the first graph shows the relationship between test grades and the amount of time the students spent studying. so this is study time on this axis and this is the test grade on this axis. and the second graph shows the relationship between test grades and shoes size. so shoe size on this axis and then test grade. choose the best description of the relationship between the graphs. so first, before looking at the explanations, let's look at the actual graphs. so this one on the left right over here, it looks like there is a positive linear relationship right over here. i could almost fit a line that would go just like that. and it makes sense that there would be, that the more time that you spend studying, the better score that you would get. now for a certain amount of time studying, some people might do better than others, but it does seem like there's this relationship. here it doesn't seem like there's really much of a relationship. you see the shoe sizes, for a given shoe size, some people do not so well and some people do very well. someone with a size 10 and 1/2, it looks like, someone it looks like they flunked the exam. someone else, looks like they got a minus or a b plus on the exam. and it really would be hard to somehow fit a line here. no matter how you draw a line, these dots don't seem to form a trend. so let's see which of these choices apply. there's a negative linear relationship between study time and score. no, that's not true. it looks like there's a positive linear relationship. the more you study, the better your score would be. a negative linear relationship would trend downwards like that. there is a non-linear relationship between study time and score and a negative linear relationship between shoe size and score. well that doesn't seem right either. a non-linear relationship, it would not be easy to fit a line to it. and this one seems like a line would be very reasonable. and it doesn't seem like there's any type of relationship between shoe size and score. so i wouldn't pick this one either. there's a positive linear relationship between study time and score. that's right. and no relationship between shoe size and score. well, i'm going to go with that one. both graphs show positive linear trends of approximately equal strength. no, not at all. this one doesn't show a linear relationship of really any strength.",t_4218ac888007,other,0
c_2cf5c8a6ca39,"chapter 37 of the book on css.chapter 37: custom properties (variables) css variables allow authors to create reusable values which can be used throughout a css document. for example, it's common in css to reuse a single color throughout a document. prior to css variables this would mean reusing the same color value many times throughout a document. with css variables the color value can be assigned to a variable and referenced in multiple places. this makes changing values easier and is more semantic than using traditional css values.  section 37.1: variable color :root { --red: #b00; --blue: #4679bd; --grey: #ddd; } .bx1 { color: var(--red); background: var(--grey); border: 1px solid var(--red); }  section 37.2: variable dimensions :root { --w200: 200px; --w10: 10px; } .bx2 { width: var(--w200); height: var(--w200); margin: var(--w10); }  section 37.3: variable cascading css variables cascade in much the same way as other properties, and can be restated safely. you can deﬁne variables multiple times and only the deﬁnition with the highest speciﬁcity will apply to the element selected. assuming this html: <a class=""button"">button green</a> <a class=""button button_red"">button red</a> <a class=""button"">button hovered on</a>  we can write this css: .button { --color: green; padding: .5rem; border: 1px solid var(--color); color: var(--color); }  goalkicker.com – css notes for professionals  180  .button:hover { --color: blue; } .button_red { --color: red; }  and get this result:  section 37.4: valid/invalids naming when naming css variables, it contains only letters and dashes just like other css properties (eg: lineheight, -moz-box-sizing) but it should start with double dashes (--) //these are invalids variable names --123color: blue; --#color: red; --bg_color: yellow --$width: 100px; //valid variable names --color: red; --bg-color: yellow --width: 100px;  css variables are case sensitive. /* the variable names below are all different variables */ --pcolor: ; --pcolor: ; --pcolor: ;  empty vs space /* invalid */ --color:; /* valid */ --color: ; /* space is assigned */  concatenations /* invalid - css doesn't support concatenation*/ .logo{ --logo-url: 'logo'; background: url('assets/img/' var(--logo-url) '.png'); } /* invalid - css bug */ .logo{ --logo-url: 'assets/img/logo.png'; background: url(var(--logo-url)); }  goalkicker.com – css notes for professionals  181  /* valid */ .logo{ --logo-url: url('assets/img/logo.png'); background: var(--logo-url); }  careful when using units /* invalid */ --width: 10; width: var(--width)px; /* valid */ --width: 10px; width: var(--width); /* valid */ --width: 10; width: calc(1px * var(--width)); /* multiply by 1 unit to convert */ width: calc(1em * var(--width));  section 37.5: with media queries you can re-set variables within media queries and have those new values cascade wherever they are used, something that isn't possible with pre-processor variables. here, a media query changes the variables used to set up a very simple grid: html <div></div> <div></div> <div></div> <div></div>  css :root{ --width: 25%; --content: 'this is desktop'; } @media only screen and (max-width: 767px){ :root{ --width:50%; --content: 'this is mobile'; } } @media only screen and (max-width: 480px){ :root{ --width:100%; } } div{ width: calc(var(--width) - 20px); height: 100px; } div:before{ content: var(--content);  goalkicker.com – css notes for professionals  182  } /* other styles */ body { padding: 10px; } div{ display: flex; align-items: center; justify-content: center; font-weight:bold; float:left; margin: 10px; border: 4px solid black; background: red; }  you can try resizing the window in this codepen demo here's an animated screenshot of the resizing in action:  goalkicker.com – css notes for professionals  183",t_38a623c039b8,other,0
c_0ffe9ae5b204,"this finishes the introduction of the jacobian matrix, working out the computations for the example shown in the last video.  - [teacher] so, just as a reminder of where we are, we've got this very non-linear transformation and we showed that if you zoom in on a specific point while that transformation is happening, it looks a lot like something linear and we reason that you can figure out what linear transformation that looks like by taking the partial derivatives of your given function, the one that i defined up here, and then turning that into a matrix. and what i want to do here is basically just finish up what i was talking about by computing all of those partial derivatives. so, first of all, let me just rewrite the function back on the screen so we have it in a convenient place to look at. the first component is x plus sin of y. sin of y and then y plus sin of x was the second component. so, what i want to do here is just compute all of those partial derivatives to show what kind of thing this looks like. so, let's go ahead and get rid of this word and i'll go ahead and kind of redraw the matrix here. so, for that upper left component, we're taking the partial derivative with respect to x of the first component. so, we look up at this first component and the partial derivative with respect to x is just one. since there's one times x plus something that has nothing to do with x and then below that, we take the partial derivative of the second component with respect to x down here. and that guy, the y, well that looks like a constant so nothing happens, and the derivative of sin of x becomes cosine of x. and then up here, we're taking the partial derivative with respect to y of the first component; that upper one here, and for that, partial derivative of x, with respect to y, is zero and partial derivative of sin of y, with respect to y, is cosine of y. and then, finally, the partial derivative of the second component with respect to y looks like one because it's just one times y plus some constant. and this is the general jacobian as a function of x and y, but if we want to understand what happens around this specific point that started off at, well, i think i recorded it here at negative two, one, we plug that in to each one of these values. so, when we plug in negative two, one. so go ahead and just kind of again, rewrite it to remember we're plugging in negative two, one as our specific point, that matrix as a function, kind of a matrix valued function, becomes one, and then next we have cosine, but we're plugging in negative two for x, cosine of negative two, and if you're curious, that is approximately equal to, i calculated this earlier. negative zero point four two, if you just want to think in terms of a number there. then for the upper right, we have cosine again, but now we're plugging in the value for y, which is one and cosine of one is approximately equal to zero point five four; and then bottom right, that's just another constant: one. so, that is the matrix, just as a matrix full of numbers, and just as kind of a gut check we can take a look at the linear transformation this was supposed to look like, and notice how the first basis factor, the thing it got turned into, which is this factor here, does look like it has coordinates one and negative zero point four two, right? it's got this rightward component that's about as long as the vector itself started and then this downward component, which i think that's pretty believable that that's negative zero point four two. and then, likewise, this second column is telling us what happened to that second basis factor, which is the one that looks like this. and again, its y component is about as long as how it started, right, the length of one. and then the rightward component is around half of that, and we actually see that in the diagram, but this is something you compute. again, it's pretty straightforward. you just take all of the possible partial derivatives, and you organize them into a grid like this. so, with that, i'll see you guys next video.",t_25999aacdf15,other,0
c_2b240be56a29,"fractional reserve banking and the multiplier effect. introduction to the money supply.  let's return to our fairly simple banking example, and see if we can use it to actually understand, or at least get a better idea, of what money is and how it's created. so in the original example, i said, i have this idea. i have all of these farmers who, at the end of the season, they sell all of their apples-- let's say that's the main cash crop on our island. and then every year they just have this-- collectively they have-- i'll just make up a number-- 1,000 gold pieces that they get. or at least this year, i'll call it 1,000 gold. they have 1,000 gold coins that they get at the end of the year. normally the farmers just kind of stash it under their mattresses, or dig up a hole and put it there. and i said, boy, what a waste, because there are actually good projects out there that people could-- maybe irrigation ditches, factories, a tool factory, anything else. but there's just no money for those people to build those things. if only somehow i could take this money and use it for those projects, then we would actually create wealth. we'd have innovation. and our entire pie would get bigger. so what i do is, i start up this bank. and i'll do it all over again, just like i did last time. let's say that i personally had 100 gold pieces. i'm going to stick with gold, because i want to show you how the money creation-- there is a small multiplier effect even when you're using gold. some people think it only happens with paper money. this is all a byproduct of the fractional reserve system, which was essentially what i showed you in the last two videos. let's just go through the whole example. so i take 100 gold pieces, and i construct this nice vault looking building. so this is real estate, or building. and it's worth 100 gold. these are my assets. assets on the left-hand side, liabilities on the right-hand side. and then i go tell all of these farmers, one, your money's not safe there. if you actually keep it as a deposit in my nice looking building, i will give you interest on it. so those farmers say, great idea. so they all deposit their 1,000 gold pieces into my bank. so now i have this liability. i have 1,000 gold pieces liability. and why is it a liability? because i owe it to the farmers. at some point in the future, they're going to come back to me and say, hey, you know that gold i gave you, i want it back. so it's a liability to me. but it's also an asset on my side, right? but my whole business model is, i wanted to put this to work. so what i do is, i put some aside. so essentially, i make some reserves. i'll do the reserves in red, because we're going to want to pay attention to them later. let's say i put 10% aside. so i put 100 gold pieces aside. and i do that in case any of those farmers, the next day or the next week, come to me and say, oh, you know what, i actually need my money. my son needs a haircut, or whatever the need might be. but anyway, i put 100 gold pieces aside as reserves. and then the remainder-- this 900 gold pieces-- i lend out. let me do that in a different color. i'll do it in green. 900 gold pieces i lend out. so it's an asset. but the gold is gone. i take that gold-- remember, i had 1,000 gold pieces come in-- i kept 100 of it. and now i'm going to lend it to someone who has a really good project. normally, you would lend it to a bunch of people. but for the sake of simplicity, let's say i lend it to someone who has an irrigation project. he's going to take that 900 gold pieces and pay a bunch of people, who are probably not doing anything anymore because the apple crop has been harvested and sold, and they're going to build an irrigation canal so that more land is usable to make more apples the next year. soon. and i say that's a great investment because they're going to make more apples, or they're going to sell the water to the farmers. and they should be able to pay some interest to me. so i give my 900 gold pieces to them to essentially dig these ditches. well, the 900 gold pieces, that then goes to the workers. the borrower borrowed them, and then paid it to the workers. 900 gold goes to the workers. and so after the project is done, you have a bunch of workers with 900 gold pieces. well, these workers, they're just like the farmers. they say, well, i don't want to put it in my bed. and i want to get interest on it. it's not safe inside my house. so, let's say that my bank is the only game in town. so they go back to my bank. and they say, hey, bank of sal, i want to deposit my money with you. i say, great. so what i do is, i take their 900 gold pieces, and i take it as a deposit. let me try to draw that as a deposit. if this is 1,000, 900 might be about that. so this is the farmers' deposits. that was the initial money. so then i get the 900 gold pieces from the workers. i want to make this as neat as possible. i didn't want to go through the pain of having multiple banks because you could do this with just one bank. maybe in a future video, i'll do it with multiple banks, just to show you that all the deposits don't have to go to one place. but it's the same idea. anyway, these 900 gold pieces are essentially deposited back into my bank for safekeeping. and i say, boy, i don't need to keep all of this 900 gold pieces here. i could lend it out again for some useful project. so once again, i say, well, these are demand deposits, which means that these farmers could demand them at any time. so let me put a little bit aside. i know statistically that no more than maybe 10% of them will come to the given days. so let me set aside 10% of that. so i'll once again have 10% reserves. so i'll set aside 90 gold pieces. and then the other-- let me do that in the lending color-- the other 810 gold pieces i lend out. and let's say i lend it out to some entrepreneur. remember, i'm getting interest on all of this. but we're not concerned with the interest right now, we're concerned with the money supply. so i lend it out to some guy who wants to build a factory, build a factory for cutting tools. that'll help all of us become more productive when we have to harvest our apples, or maybe even digging the ditches. so once again, this 810 gold pieces, they're going to go to the construction workers or the contractors who built the factory. so let's call it factory contractors, the people who build the factory. once again, now they have 810 gold pieces. and they're like, i don't like keeping it in my house. there's that nice fancy vault that sal has, and he gives interest on it. so they take those 810 gold pieces, and they deposit it in my bank. and then, let's just say that i could just continue this process, so forth and so on. and just so you know, it doesn't go infinitely. because every step of the way, we're having a little bit less. i'll do the fancier math on how to figure out how many steps we can do. let's just stop it there, just for the sake of brevity, and just so i you don't run out of space on this. so they take 810 gold pieces, and i for the most part feel that i've lent enough money out there. so i keep all of this 810 gold pieces as reserves. so i don't lend that out, although i could. i could just set aside 10% of it, 81 gold pieces, and then lend the rest of it out. but i don't do that. i just keep all of those 810 gold pieces as reserve. so this is my balance sheet. maybe if these transactions occur all at once, over the course of the year, this is what the bank of sal's balance sheet looks like. these are my assets, and these are my liabilities. and notice, assets are still equal to liabilities plus equity. this was equity. this is liabilities. these are deposits that i owe to people. deposits equal liabilities from a bank's point of view. they're assets for those people. and then these are my assets. some of them are cash money, in magenta. this 810, this 90, this 100, these are gold coins that are sitting in my vault, so that's definitely an asset that i have. and then these are loans that i lent-- at least, this and this-- these are loans that i lent out to somebody. and that's as asset, as long as they pay me back. so now, we have set it all up. my question to you is, how much money is there in the system or in our economy? it all depends how you define money. so let's make a definition. let's say i make a definition called m0. and this is just, how much gold is there? how much gold in the system? well, we can go and count it. remember, notice, all of the gold is being held in my bank. so we just have to go to this one bank and count how much gold it has. it has 100 gold here, 90 gold here, 810 gold here. so 810 plus 90 plus 100 is equal to 1,000 gold. so there's 1,000 gold pieces. and that makes sense, right, because we had 1,000 gold pieces to begin with. and we didn't mine for any new gold, or we didn't use any lodestones to turn lead into gold, or anything like that. we just had the original 1,000 gold pieces. and there's no way to create more. they don't reproduce on their own. so we still have 1,000 gold pieces. and we can view that as our narrowest definition of the money supply. let's say another definition. let's call this m1. and i'm running out of time. and that is, how much money do people think they have, in terms of their checking accounts? well, the farmers think that they have 1,000 gold pieces. the original ditch construction workers think they have 900. and then the factory builders think they have 810. so if you add them, it's 1,000 plus 900 plus 810. let's see, that's 1,900-- that's 2,710 gold pieces. so if you went and surveyed everyone in the city and you said, how much do you keep in your checking accounts? or how much you have on demand deposits in a bank? if you added up all of those numbers, you would have 2,710 gold pieces, if i added my numbers correctly. this is the multiplier effect. this happens whenever you have a fractional reserve system. and this is what people say when they talk about the money supply. it depends how you measured-- and this is what people talk about when they talk about money being created. we had 1,000 gold coins, but because of this multiplier effect, people think that there are 2,710 gold pieces. in the next video, i'll address the issue of whether they are correct to think this. see",t_1829d23f1e76,other,0
c_91a7d510f0d2,"figure 9.1: lean operations word map  wastes  the word “lean” means skinny or having no fat. lean operations have no waste. the types of wastes, also called muda, that lean operations can be referred to as tim woods:  t – transport – moving people, products &amp; information  i – inventory – storing parts, pieces, documentation ahead of requirements  m – motion – bending, turning, reaching, lifting  w – waiting – for parts, information, instructions, equipment  o – over production – making more than is immediately required  o – over processing – tighter tolerances or higher grade materials than are necessary  d – defects – rework, scrap, incorrect documentation  s – skills – under utilizing capabilities, delegating tasks with inadequate training  the framework of lean operations focuses on the concepts of value, value stream, flow, pull, and perfection in order to reduce all of these types of waste.  value  value is defined by the customer. an organization must have a clear definition of value as perceived by the customer. time and money spent on features of a product or a service that the customer does not perceive have value are wasted time and money. knowing what the customer values requires becoming close to the customer and constantly soliciting feedback.  in lean operations, a process flow diagram is called a  value stream map . the diagram is similar, but the reason for creating the diagram is to identify all the activities in a process and place them into one of the following categories.  value added (va) – activities that create value as perceived by the customer  non-value added (nva)– activities which don’t create value as perceived by the customer and so should be eliminated immediately  essential non-value added (enva) – activities that create no value but are company or regulatory policies and so can’t be eliminated just yet  the value stream mapping also identifies the time actually spent in adding value and the time the product spends in storage or transport. time in storage or transport is waste and should be eliminated.  figure 9.2: value stream map  continuous flow  picture-perfect manufacturing (http://www.mmsonline.com/articles/picture-perfect-manufacturing), from mms online, describes how stremel manufacturing, in minneapolis, minnesota, used current state maps and future state maps to make sure that waste-reduction initiatives “improve the overall flow rather than merely optimize individual steps.”  in continuous  flow,  a product never waits but flows continuously through the manufacturing system, thus eliminating time in storage and in transport. batches and queues should be eliminated. if products move through the production systems in batches, then the first item in a batch must wait until the last item in a batch is completed before it moves to the next processing time; batches mean product spends time waiting, and that time is waste. the presence of queues mean that a product was completed at a previous processing step before the next step was ready for more input. since the final step of the production process is shipping the product to customers, product should be produced at the rate that meets the market demand. the principle can be applied in the production of services also.  one barrier to flow and one reason for using batches is the time necessary to switch the production facility from producing one kind of product to producing another, which is referred to as setup .  setup reduction: at the heart of lean manufacturing (http://www.mmsonline.com/articles/setup-reduction-at-the-heart-of-lean-manufacturing) , also from mms online, describes how richards industries, a manufacturer of specialty valves in cincinnati, ohio, reduced its setup times from an average of 50 minutes to 27 minutes. this reduction enabled them to reduce the typical batch size from 200 to about 20 to 30.  flow can be improved by eliminating bottlenecks as shown by the following example from world war ii as described by in methods of operations research [1].  an operations research worker during his first day of assignment to a new field command noticed that there was considerable delay caused by the soldiers having to wait in line to wash and rinse their mess kits after eating. there were four tubs, two for washing and two for rinsing. the operations research worker noticed that on the average it took three times as long for the soldier to wash his kit as it did for him to rinse it. he suggested that, instead of there being two tubs for washing and two for rinsing, there should be three tubs for washing and one for rinsing. this change was made, and the line of waiting soldiers did not merely diminish in size; on most days no waiting line ever formed.  a bottleneck is the narrowest part of a bottle and limits the flow in or out of the bottle. in the original situation with only two tubs for washing, the lines in front of those tubs would have been long, indicating that the wash tubs were the bottleneck, that is, the place in the production process with the least capacity. if washing took three minutes and rinsing took one minute, two wash tubs can serve 40 soldiers per hour while two rinse tubs can serve 120 soldiers per hour. with the new configuration, three wash tubs can serve 60 soldiers per hour, the same service rate as one rinse tub.  bottlenecks can be identified by looking for places where  wip (work in progress) piles up and create queues. the processing rate at a bottleneck can be increased by reducing the time to process one item or by adding more processing capability. as a bottleneck’s rate is improved, wip in front of the bottleneck will disappear, but another bottleneck may now appear.  pull and continuous improvement  in a lean system, no product or service is produced until a customer asks for it, that is, product is pulled not pushed through the system. some product must be maintained in sales places to meet immediate demand, but reduction in lead time through improvements such as daily deliveries reduces the amount of stock kept on hand and allows more variety in stock.  lean systems constantly seek perfection by working to continuously improve. an organization should not compete against its competitors. if benchmarking shows the company is doing better than its competitors, it should not relax. as womack and jones state in their preeminent book on lean operations,  lean thinking [2], state:  to hell with your competitors; compete against perfection by identifying all activities that are muda and eliminating them.  in addition to the tools listed above, industrial engineers use a lot of other tools to continuously try to reduce wastes in a production or service system. you will learn about these tools throughout your industrial engineering curriculum.  exercise  https://uta.pressbooks.pub/industrialengineeringintro/?p=195 (https://uta.pressbooks.pub/industrialengineeringintro/?p=195#pb-interactive-content)  morse, p., & kimball, g. (1951). methods of operations research (1st ed., rev.). cambridge: published jointly by the technology press of massachusetts institute of technology, and wiley, new york. ↵  jones, d. t., & womack, j. p. (2014). lean thinking: banish waste and create wealth in your corporation. place of publication not identified: free press. ↵",t_e63ef6841a5f,other,0
c_5b2c933b307b,"sal proves the identity sin(x+y) = sin(x)*cos(y) + cos(x)*sin(y).  voiceover: what i hope to doin this video is prove the angle addition formula for sine, or in particular prove that the sine of x plus y is equal to the sine of x times the cosine of -- i forgot my x. sine of x times the cosine of y plus cosine of x times the sine of y. the way i'm going to do it is with this diagram right over here. you can view it as, it has this red right triangle. it has this right triangle that has a hypotenuse of one. you could say this triangle adc. it has it stacked on top of, its base is the hypotenuse of triangle acd, which i could, i'm going to outline it in blue since i already labelled the measure of this angle as being y. ac which is the base of triangle adc is the hypotenuse of triangle abc. they're stacked on top of each other like that, just like that. the way i'm going to think about it is first if you just look at this what is sine of x plus y going to be? well x plus y is this entire angle right over here. if you look at this right triangle, right triangle adf, we know that the sine of an angle is the opposite side over the hypotenuse. well the hypotenuse here is one so the sine of this is the opposite over one, or the sine of this angle, the sine of x plus y is equal to the length of this opposite side. so sine of x plus y is going to be equal to the length of segment df. what i'm going to try to do is, okay, length of segment df is essentially what we're looking for but we can decompose the length of segment df into two segments. we can decompose it into length of segment de and the length of segment ef. we can say that df, which is the same thing as sine of x plus y, the length of segment df is the same thing, is equal to the length of segment de plus the length of segment ef. ef is of course the same thing as the length of segment cb. ecbf, this right over here is a rectangle so ef is the same thing as cb. so this thing is going to be equal to de right over here, length of segment de plus the length of segment cb. once again the way i'm going to address this, the sine of x plus y which is the length of df and df can be decomposed as the lengths of de and cb. now with that as a hint i encourage you to figure out what the length of segment de is in terms of x's and y's and sines and cosines, and also figure out what the length of segment cb is in terms of x's and y's and sines and cosines. try to figure out as much as you can about this and these two might fall out of that. i'm assuming you've given a go at it so now that we know that sine of x plus y can be expressed this way, let's see if we can figure these things out. i'm going to try to address it by figuring out as many lengths and angles here as i can. let's go to this top red triangle right over here. its hypotenuse has length one so what's going to be the length of segment dc? that is the opposite side of our angle x so we know sine of x is equal to dc over one, or dc over one is just dc. this length right over here is sine of x. segment ac, same exact logic. cosine of x is the length of ac over one which is just the length of ac. this length right over here, segment ac its length is cosine of x. that's kind of interesting. now let's see what we can figure out about this triangle, triangle acb right over here. how could we figure out cb? well we know that sine of y, let me write this here. sine of y is equal to what? it's equal to the length of segment cb over the hypotenuse. the hypotenuse here is the cosine of x, and i think you might see where all of this is leading. at any point if you get excited pause the video and try to finish the proof on your own. the length of segment cb if we just multiply both sides by cosine of x, the length of segment cb is equal to cosine of x times sine of y. which is neat because we just showed that this thing right over here is equal to this thing right over here. to complete our proof we just need to prove that this thing is equal to this thing right over there. if that's equal to that and that's equal to that well we already know that the sum of these is equal to the length of df which is sine of x plus y. let's see if we can figure out, if we can express de somehow. what angle would be useful? if somehow we could figure out this angle up here or maybe this angle, well let's see. if we could figure out this angle then de we could express in terms of this angle and sine of x. let's see if we can figure out that angle. we know this is angle y over here and we also know that this is a right angle. ec is parallel to ab so you could view ac as a transversal. if this is angle y right over here then we know this is also angle y. these are once again, notice. if ac is a transversal here and ec and ab are parallel then if this is y then that is y. if that's y then this is 90 minus y. if this is 90 degrees and this is 90 minus y then these two angles combined add up to 180 minus y, and if all three of these add up to 180 then this thing up here must be equal to y. validate that. y plus 90 minus y plus 90 is 180 degrees, and that is useful for us because now we can express segment de in terms of y and sine of x. what is de to y? it's the adjacent angle, so we can think of cosine. we know that the cosine of angle y, if we look at triangle dec right over here, we know that the cosine of y is equal to segment de over its hypotenuse, over sine of x. you should be getting excited right about now because we've just shown, if we multiply both sides by sine of x, we've just shown that de is equal to sine of x times cosine of y. we've now shown that this is equal to this. we already showed that cb is equal to that, so the sum of de and cb which is the same thing as the sum of de and ef is the sine of x plus y which is that over there. we are done, we have proven the angle addition formula for sine.",t_fcb5f8006d3b,other,0
c_01992a5bf0a0,watch this video to learn about the importance of cement in masonry.,t_f7afad99031f,other,0
c_846f50891fba,change in period and frequency from the change in angular velocity examples.  ,t_c4f8c17471bc,other,0
c_41b5826ad68e,"mortuary temple and large kneeling statue of hatshepsut, c. 1479-58 b.c.e., new kingdom, egypt. speakers: dr. beth harris and dr. steven zucker  [music playing] &gt;&gt;: we're in the metropolitan museum of art in new york city in the section devoted to the art of ancient egypt. and we're looking at an enormous, granite sculpture. &gt;&gt;: this is a sculpture of the female pharaoh hatshepsut. &gt;&gt;: we think of pharaohs, that is, ancient egyptian kings, as male. and of course the vast majority were. there had been a long tradition in ancient egypt of women assuming enormous authority in the position of regent, that is as a mother or a member of the royal family who would reign until a male ruler reached the age where they could actually assume power. &gt;&gt;: those women were very powerful but hatshepsut is unusual. she assumes the authority of king, of pharaoh. she created a whole mythology around her kingship that described her divine birth, the way that an oracle had predicted that she would become king. she ruled egypt for more than two decades. she commissioned a remarkable number of temples, of sculptures. she was interested in the power of art to convey royal authority. &gt;&gt;: and no building speaks to the authority of the king more than the mortuary temple. &gt;&gt;: the sculpture that we're looking at was actually made for this mortuary temple. there anywhere from six or eight or ten of these kneeling figures. there were also representations of hatshepsut as a sphinx which lined the center of the lower courtyard of her mortuary temple. &gt;&gt;: and that temple is an extraordinary place. it is built directly against this vast cliff face. &gt;&gt;: i can't think of a more dramatic environment for architecture. those cliffs are towering and their organic qualities are in such contrast to the regular order and structure of the built environment. &gt;&gt;: this is hewn right from the living rock. &gt;&gt;: and that sense of permanence, that sense of stability that is expressed by that wall of living rock is a perfect expression of the very sense of stability that we think hatshepsut and her dynasty were trying to reassert after a period of instability. this was the beginning of the new kingdom. &gt;&gt;: in ancient egyptian history, we talk about three major periods... the old kingdom, the middle kingdom, and the new kingdom, and these periods are separated by periods we call intermediate periods. &gt;&gt;: these were periods of relative chaos, often when egypt was divided in its rule or was ruled by external rulers. &gt;&gt;: the representations of kingship in ancient egyptian art are almost two millennia old by the time we get to hatshepsut and so what she can do is adopt those forms to show herself as king. these forms were easily recognizable. that is symmetry, its embeddedness in the stone, we see that there is no space between her arms and her torso or between her legs. there is a real sense of timelessness but there are also more specific symbols. &gt;&gt;: the head cloth that she wears is a symbol of the king that would have originally been a cobra. &gt;&gt;: we have the beard that we associate with kingship. &gt;&gt;: we're talking about a visual language here. and this visual language of kingship was male. in fact, there is no word for queen in the egyptian language. the term is king's wife, or king's mother. &gt;&gt;: her body is represented in a relatively masculine way. her breasts are deemphasized, for example. she has got broad shoulders. &gt;&gt;: the inscriptions that were on many of these sculptures use a feminine form and so the representation itself is masculine but the identifying words, the hieroglyphs identify her as female. about 20 years after hatshepsut died, the pharaoh she had been co-ruler with systematically destroyed all images of hatshepsut. &gt;&gt;: that would not have been an easy matter. you wouldn't have simply toppled the sculpture. it would have shattered into so many pieces. this made of granite, incredibly hard stone. it would have been very difficult to produce and it would have been very difficult to destroy. &gt;&gt;: well, and not only that, but hatshepsut had commissioned hundreds of images of herself. so it would have taken a long time to destroy these sculptures. this was an intentional act, but we're not really sure why this happened. &gt;&gt;: we do know that the fragments were discovered in the early twentieth century thanks to an excavation undertaken by the metropolitan museum of art which is why they are here. and what we're seeing are a series of monumental sculptures that have been put back together but some of this is guesswork. we don't know if one particular fragment goes with one sculpture versus another. &gt;&gt;: so when we look at those sculptures, we see her in a range of positions. in some she is kneeling. in some she is standing. in some she is seated. in some she is represented as a sphinx. a king only would kneel of course to a god. and that really helps us place this sculpture along the processional path. &gt;&gt;: so once a year, there was a ritual involving a sculpture of a god. now we have to remember that for egyptians, the sculpture of the god was the embodiment of the god and temples were houses for a god. so once a year the sculpture of the primary god, amun-re, was taken from the temple in thebes on the eastern side of the nile. &gt;&gt;: and carried across the river on a ceremonial barque, on a shrine that was shaped like a boat. &gt;&gt;: as though he were traveling literally across the nile from the eastern side, the land of the living, toward the land of the dead, and he would be carried up this causeway toward the temple and his primary shrine in the mortuary temple at the very top center. &gt;&gt;: and that sculpture would have been spent one night in that shrine before it would have been returned across the river. &gt;&gt;: and so it makes sense then that you would have this representation of hatshepsut on her knees making an offering, these two bowls or jars that she holds are an offering to the god because the god passed in front of these sculptures who are not just sculptures but embodiments of hatshepsut. &gt;&gt;: it's interesting how the scholarship that surrounds this ruler has changed. early in the twentieth century, for example, the destruction of the images of this ruler were associated with the idea that she was out of place, that she was an usurper, and she was seen very much in a negative light. she is seen much more sympathetically now in the early 21st century. &gt;&gt;: and there were women before hatshepsut who asserted themselves as kings, and there were a few women after her, but hatshepsut had enormous power, enormous influence, the sculptures, the architecture that she commissioned set an important standard and inspiration for all the later work of the new kingdom. imagine walking past these enormous sculptures of hatshepsut. &gt;&gt;: this is all about procession. this is all about pageantry. this is all about expressing the power of the king. &gt;&gt;: kneeling like this is not something you can do for more than a minute or two. it's hard on the toes. it's hard on the knees. so this is a position that someone would only take very temporarily and yet there is something very eternal about the sculpture, something very permanent. this is not a figure who engages us, who is in the world, but who lives in the eternal. this is an image of a king who is also a god. [music]",t_66ea39891a0a,other,0
c_16bcca14e5e9,"contributors and attributions  dr. genick bar-meir (http://www.potto.org/genick.php). permission is granted to copy, distribute and/or modify this document under the terms of the gnu free documentation license, version 1.2 or later or potto license.",t_7397625e6cdc,other,0
c_4d38ce6941d0,"chapter 8 of the book on spring framework.chapter 8: spring jsr 303 bean validation spring has jsr303 bean validation support. we can use this to do input bean validation. separate validation logic from business logic using jsr303.  section 8.1: @valid usage to validate nested pojos suppose we have a pojo class user we need to validate. public class user { @notempty @size(min=5) @email private string email; }  and a controller method to validate the user instance public string registeruser(@valid user user, bindingresult result);  let's extend the user with a nested pojo address we also need to validate. public class address { @notempty @size(min=2, max=3) private string countrycode; }  just add @valid annotation on address ﬁeld to run validation of nested pojos. public class user { @notempty @size(min=5) @email private string email; @valid private address address; }  section 8.2: spring jsr 303 validation - customize error messages suppose we have a simple class with validation annotations public class userdto { @notempty private string name; @min(18) private int age; //getters/setters  goalkicker.com – spring® framework notes for professionals  32  }  a controller to check the userdto validity. @restcontroller public class validationcontroller { @requestmapping(value = ""/validate"", method = requestmethod.post) public responseentity<string> check(@valid @requestbody userdto userdto, bindingresult bindingresult) { return new responseentity<>(""ok"" , httpstatus.ok); } }  and a test. @test public void testvalid() throws exception { testresttemplate template = new testresttemplate(); string url = base + contextpath + ""/validate""; map<string, object> params = new hashmap<>(); params.put(""name"", """"); params.put(""age"", ""10""); multivaluemap<string, string> headers = new linkedmultivaluemap<>(); headers.add(""content-type"", ""application/json""); httpentity<map<string, object>> request = new httpentity<>(params, headers); string res = template.postforobject(url, request, string.class); assertthat(res, equalto(""ok"")); }  both name and age are invalid so in the bindingresult we have two validation errors. each has array of codes. codes for min check 0 1 2 3  = = = =  ""min.userdto.age"" ""min.age"" ""min.int"" ""min""  and for notempty check 0 1 2 3  = = = =  ""notempty.userdto.name"" ""notempty.name"" ""notempty.java.lang.string"" ""notempty""  let's add a custom.properties ﬁle to substitute default messages. @springbootapplication @configuration public class demoapplication { @bean(name = ""messagesource"") public messagesource messagesource() { reloadableresourcebundlemessagesource bean = new reloadableresourcebundlemessagesource(); bean.setbasename(""classpath:custom"");  goalkicker.com – spring® framework notes for professionals  33  bean.setdefaultencoding(""utf-8""); return bean; } @bean(name = ""validator"") public localvalidatorfactorybean validator() { localvalidatorfactorybean bean = new localvalidatorfactorybean(); bean.setvalidationmessagesource(messagesource()); return bean; } public static void main(string[] args) { springapplication.run(demoapplication.class, args); } }  if we add to the custom.properties ﬁle the line notempty=the field must not be empty!  the new value is shown for the error. to resolve message validator looks through the codes starting from the beginning to ﬁnd proper messages. thus when we deﬁne notempty key in the .properties ﬁle for all cases where the @notempty annotation is used our message is applied. if we deﬁne a message min.int=some custom message here.  all annotations where we app min check to integer values use the newly deﬁned message. the same logic could be applied if we need to localize the validation error messages.  section 8.3: jsr303 annotation based validations in springs examples add any jsr 303 implementation to your classpath. popular one used is hibernate validator from hibernate. <dependency> <groupid>org.hibernate</groupid> <artifactid>hibernate-validator</artifactid> <version>4.2.0.final</version> </dependency>  lets say the there is a rest api to create user in the system @requestmapping(value=""/registeruser"", method=requestmethod.post) public string registeruser(user user);  the input json sample would look like as below {""username"" : ""abc@abc.com"", ""password"" : ""password1"", ""password2"":""password1""}  user.java  goalkicker.com – spring® framework notes for professionals  34  public class user { private string username; private string password; private string password2; getxxx and setxxx }  we can deﬁne jsr 303 validations on user class as below. public class user { @notempty @size(min=5) @email private string username; @notempty private string password; @notempty private string password2; }  we may also need to have a business validator like password and password2(conﬁrm password) are same, for this we can add a custom validator as below. write a custom annotation for annotating the data ﬁeld. @target({ elementtype.field }) @retention(retentionpolicy.runtime) @constraint(validatedby = passwordvalidator.class) public @interface goodpassword { string message() default ""passwords won't match.""; class<?>[] groups() default {}; class<? extends payload>[] payload() default {}; }  write a validator class for applying validation logic. public class pastvalidator implements constraintvalidator<goodpassword, user> { @override public void initialize(goodpassword annotation) {} @override public boolean isvalid(user user, constraintvalidatorcontext context) { return user.getpassword().equals(user.getpassword2()); } }  adding this validation to user class @goodpassword public class user { @notempty @size(min=5) @email  goalkicker.com – spring® framework notes for professionals  35  private string username; @notempty private string password; @notempty private string password2; }  @valid triggers validation in spring. bindingresult is an object injected by spring which has list of errors after validation. public string registeruser(@valid user user, bindingresult result);  jsr 303 annotation has message attributes on them which can be used for providing custom messages. @goodpassword public class user { @notempty(message=""username cant be empty"") @size(min=5, message=""username cant be les than 5 chars"") @email(message=""should be in email format"") private string username; @notempty(message=""password cant be empty"") private string password; @notempty(message=""password2 cant be empty"") private string password2; }  goalkicker.com – spring® framework notes for professionals  36",t_6ab671b9b5ef,other,0
c_f015572a0f95,"in this section, we study how the graphs of functions change, or transform, when certain specialized modifications are made to their formulas. the transformations we will study fall into three broad categories: shifts, reflections and scalings, and we will present them in that order. suppose the graph below is the complete graph of a function \(f\).  the fundamental graphing principle for functions says that for a point \((a,b)\) to be on the graph, \(f(a) = b\). in particular, we know \(f(0) = 1\), \(f(2)=3\), \(f(4)=3\) and \(f(5)=5\). suppose we wanted to graph the function defined by the formula \(g(x) = f(x) + 2\). let's take a minute to remind ourselves of what \(g\) is doing. we start with an input \(x\) to the function \(f\) and we obtain the output \(f(x)\). the function \(g\) takes the output \(f(x)\) and adds \(2\) to it. in order to graph \(g\), we need to graph the points \((x,g(x))\). how are we to find the values for \(g(x)\) without a formula for \(f(x)\)? the answer is that we don't need a formula for \(f(x)\), we just need the values of \(f(x)\). the values of \(f(x)\) are the \(y\) values on the graph of \(y=f(x)\). for example, using the points indicated on the graph of \(f\), we can make the following table.  in general, if \((a,b)\) is on the graph of \(y=f(x)\), then \(f(a) = b\), so \(g(a) = f(a) +2 = b+2\). hence, \((a,b+2)\) is on the graph of \(g\). in other words, to obtain the graph of \(g\), we add \(2\) to the \(y\)-coordinate of each point on the graph of \(f\). geometrically, adding \(2\) to the \(y\)-coordinate of a point moves the point \(2\) units above its previous location. adding \(2\) to every \(y\)-coordinate on a graph \(\textit{en masse}\) is usually described as `shifting the graph up \(2\) units'. notice that the graph retains the same basic shape as before, it is just \(2\) units above its original location. in other words, we connect the four points we moved in the same manner in which they were connected before. we have the results side-by-side at the top of the next page.  you'll note that the domain of \(f\) and the domain of \(g\) are the same, namely \([0,5]\), but that the range of \(f\) is \([1,5]\) while the range of \(g\) is \([3,7]\). in general, shifting a function vertically like this will leave the domain unchanged, but could very well affect the range. you can easily imagine what would happen if we wanted to graph the function \(j(x) = f(x) - 2\). instead of adding \(2\) to each of the \(y\)-coordinates on the graph of \(f\), we'd be subtracting \(2\). geometrically, we would be moving the graph down \(2\) units. we leave it to the reader to verify that the domain of \(j\) is the same as \(f\), but the range of \(j\) is \([-1,3]\). what we have discussed is generalized in the following theorem.  theorem 1.2: vertical shifts.  suppose \(f\) is a function and \(k\) is a positive number.  to graph \(y=f(x)+k\), shift the graph of \(y=f(x)\) up \(k\) units by adding \(k\) to the \(y\)-coordinates of the points on the graph of \(f\).  to graph \(y=f(x)-k\), shift the graph of \(y=f(x)\) down \(k\) units by subtracting \(k\) from the \(y\)-coordinates of the points on the graph of \(f\).  the key to understanding theorem 1.2 and, indeed, all of the theorems in this section comes from an understanding of the fundamental graphing principle for functions. if \((a,b)\) is on the graph of \(f\), then \(f(a) = b\). substituting \(x=a\) into the equation \(y=f(x)+k\) gives \(y=f(a)+k = b+k\). hence, \((a,b+k)\) is on the graph of \(y=f(x)+k\), and we have the result. in the language of `inputs' and `outputs', theorem 1.2 can be paraphrased as ``adding to, or subtracting from, the \textit{output} of a function causes the graph to shift up or down, respectively.'' so what happens if we add to or subtract from the \textit{input} of the function?  keeping with the graph of \(y=f(x)\) above, suppose we wanted to graph \(g(x) = f(x+2)\). in other words, we are looking to see what happens when we add \(2\) to the input of the function.\footnote{we have spent a lot of time in this text showing you that \(f(x+2)\) and \(f(x)+2\) are, in general, wildly different algebraic animals. we will see momentarily that their geometry is also dramatically different.} let's try to generate a table of values of \(g\) based on those we know for \(f\). we quickly find that we run into some difficulties.  \[ \begin{array}{|c||c|c|c|c|} x & (x,f(x)) & f(x)& g(x)=f(x+2) & (x, g(x)) \\ 0 & (0,1)& 1 & f(0+2) = f(2) = 3 &(0, 3) \\ 2 & (2,3) & 3 & f(2+2) = f(4) = 3 &(2,3) \\ 4 & (4,3) & 3 & f(4+2) = f(6) = ? & \\ 5 & (5,5) & 5 & f(5+2) = f(7) = ? & \\ \end{array} \]  when we substitute \(x=4\) into the formula \(g(x)=f(x+2)\), we are asked to find \(f(4+2)=f(6)\) which doesn't exist because the domain of \(f\) is only \([0,5]\). the same thing happens when we attempt to find \(g(5)\). what we need here is a new strategy. we know, for instance, \(f(0) = 1\). to determine the corresponding point on the graph of \(g\), we need to figure out what value of \(x\) we must substitute into \(g(x) = f(x+2)\) so that the quantity \(x+2\), works out to be \(0\). solving \(x+2=0\) gives \(x=-2\), and \(g(-2) = f((-2)+2) = f(0) = 1\) so \((-2,1)\) on the graph of \(g\). to use the fact \(f(2) = 3\), we set \(x+2 = 2\) to get \(x=0\). substituting gives \(g(0) = f(0+2) = f(2) = 3\). continuing in this fashion, we get  \[ \begin{array}{|r||c|c|c|} x & x+2 & g(x)=f(x+2) & (x, g(x)) \\ -2 & 0 & g(-2)=f(0) = 1 &(-2, 1) \\ 0 & 2 & g(0)=f(2) = 3 &(0,3) \\ 2 & 4 & g(2)=f(4) = 3 & (2,3)\\ 3 & 5 & g(3)=f(5) = 5 & (3,5) \\ \end{array} \]  in summary, the points \((0,1)\), \((2,3)\), \((4,3)\) and \((5,5)\) on the graph of \(y=f(x)\) give rise to the points \((-2,1)\), \((0,3)\), \((2,3)\) and \((3,5)\) on the graph of \(y=g(x)\), respectively. in general, if \((a,b)\) is on the graph of \(y=f(x)\), then \(f(a) = b\). solving \(x+2 = a\) gives \(x = a-2\) so that \(g(a-2) = f((a-2)+2) = f(a) = b\). as such, \((a-2,b)\) is on the graph of \(y=g(x)\). the point \((a-2,b)\) is exactly \(2\) units to the \emph{left} of the point \((a,b)\) so the graph of \(y=g(x)\) is obtained by shifting the graph \(y=f(x)\) to the left \(2\) units, as pictured below.  note that while the ranges of \(f\) and \(g\) are the same, the domain of \(g\) is \([-2,3]\) whereas the domain of \(f\) is \([0,5]\). in general, when we shift the graph horizontally, the range will remain the same, but the domain could change. if we set out to graph \(j(x) = f(x-2)\), we would find ourselves \(\textit{adding}\) \(2\) to all of the \(x\) values of the points on the graph of \(y=f(x)\) to effect a shift to the \(\textit{right}\) \(2\) units. generalizing these notions produces the following result.  theorem 1.3: horizontal shifts.  suppose \(f\) is a function and \(h\) is a positive number.  to graph \(y=f(x+h)\), shift the graph of \(y=f(x)\) left \(h\) units by subtracting \(h\) from the \(x\)-coordinates of the points on the graph of \(f\).  to graph \(y=f(x-h)\), shift the graph of \(y=f(x)\) right \(h\) units by adding \(h\) to the \(x\)-coordinates of the points on the graph of \(f\).  in other words, theorem 1.3 says that adding to or subtracting from the \textit{input} to a function amounts to shifting the graph left or right, respectively. theorems 1.2 and 1.3 present a theme which will run common throughout the section: changes to the outputs from a function affect the \(y\)-coordinates of the graph, resulting in some kind of vertical change; changes to the inputs to a function affect the \(x\)-coordinates of the graph, resulting in some kind of horizontal change.  example \(\pageindex{1}\):  graph \(f(x) = \sqrt{x}\). plot at least three points.  use your graph in 1 to graph \(g(x) = \sqrt{x}-1\).  use your graph in 1 to graph \(j(x) = \sqrt{x-1}\).  use your graph in 1 to graph \(m(x) = \sqrt{x+3} - 2\).  solution  1.  owing to the square root, the domain of \(f\) is \(x \geq 0\), or \([0,\infty)\). we choose perfect squares to build our table and graph below. from the graph we verify the domain of \(f\) is \([0,\infty)\) and the range of \(f\) is also \([0, \infty)\).  \[\begin{array}{|c||c|c|} x & f(x) & (x,f(x)) \\ 0 & 0& (0,0) \\ 1 & 1 & (1,1) \\ 4 & 2 & (4,2) \\\end{array}\]  2. the domain of \(g\) is the same as the domain of \(f\), since the only condition on both functions is that \(x \geq 0\). if we compare the formula for \(g(x)\) with \(f(x)\), we see that \(g(x) = f(x) - 1\). in other words, we have subtracted \(1\) from the output of the function \(f\). by theorem 1.2, we know that in order to graph \(g\), we shift the graph of \(f\) down one unit by subtracting \(1\) from each of the \(y\)-coordinates of the points on the graph of \(f\). applying this to the three points we have specified on the graph, we move \((0,0)\) to \((0,-1)\), \((1,1)\) to \((1,0)\), and \((4,2)\) to \((4,1)\). the rest of the points follow suit, and we connect them with the same basic shape as before. we confirm the domain of \(g\) is \([0, \infty)\) and find the range of \(g\) to be \([-1, \infty)\).  3. solving \(x-1 \geq 0\) gives \(x \geq 1\), so the domain of \(j\) is \([1,\infty)\). to graph \(j\), we note that \(j(x) = f(x-1)\). in other words, we are subtracting \(1\) from the \(\textit{input}\) of \(f\). according to theorem 1.3, this induces a shift to the right of the graph of \(f\). we add \(1\) to the \(x\)-coordinates of the points on the graph of \(f\) and get the result below. the graph reaffirms that the domain of \(j\) is \([1,\infty)\) and tells us that the range of \(j\) is \([0,\infty)\).  4. to find the domain of \(m\), we solve \(x+3 \geq 0\) and get \([-3, \infty)\). comparing the formulas of \(f(x)\) and \(m(x)\), we have \(m(x) = f(x+3) - 2\). we have \(3\) being added to an input, indicating a horizontal shift, and \(2\) being subtracted from an output, indicating a vertical shift. we leave it to the reader to verify that, in this particular case, the order in which we perform these transformations is immaterial; we will arrive at the same graph regardless as to which transformation we apply first.\footnote{we shall see in the next example that order is generally important when applying more than one transformation to a graph.} we follow the convention `inputs first',\footnote{we could equally have chosen the convention `outputs first'.} and to that end we first tackle the horizontal shift. letting \(m_1(x) = f(x+3)\) denote this intermediate step, theorem 1.3} tells us that the graph of \(y=m_1(x)\) is the graph of \(f\) shifted to the left \(3\) units. hence, we subtract \(3\) from each of the \(x\)-coordinates of the points on the graph of \(f\).  since \(m(x) = f(x+3)-2\) and \(f(x+3) = m_1(x)\), we have \(m(x) = m_1(x) - 2\). we can apply theorem 1.2 and obtain the graph of \(m\) by subtracting \(2\) from the \(y\)-coordinates of each of the points on the graph of \(m_1(x)\). the graph verifies that the domain of \(m\) is \([-3, \infty)\) and we find the range of \(m\) to be \([-2, \infty)\).  keep in mind that we can check our answer to any of these kinds of problems by showing that any of the points we've moved lie on the graph of our final answer. for example, we can check that \((-3,-2)\) is on the graph of \(m\) by computing \(m(-3) = \sqrt{(-3)+3} - 2 = \sqrt{0}-2 = -2\, \checkmark\)  reflections  we now turn our attention to reflections. we know from section 1.1 (https://math.libretexts.org/bookshelves/precalculus/map%3a_precalculus_(stitz-zeager)/1%3a_relations_and_functions/1.1%3a_sets_of_real_numbers_and_the_cartesian_coordinate_plane) that to reflect a point \((x,y)\) across the \(x\)-axis, we replace \(y\) with \(-y\). if \((x,y)\) is on the graph of \(f\), then \(y=f(x)\), so replacing \(y\) with \(-y\) is the same as replacing \(f(x)\) with \(-f(x)\). hence, the graph of \(y=-f(x)\) is the graph of \(f\) reflected across the \(x\)-axis. similarly, the graph of \(y=f(-x)\) is the graph of \(f\) reflected across the \(y\)-axis. returning to the language of inputs and outputs, multiplying the output from a function by \(-1\) reflects its graph across the \(x\)-axis, while multiplying the input to a function by \(-1\) reflects the graph across the \(y\)-axis.\footnote{the expressions \(-f(x)\) and \(f(-x)\) should look familiar - they are the quantities we used in section 1.6 (https://math.libretexts.org/bookshelves/precalculus/map%3a_precalculus_(stitz-zeager)/1%3a_relations_and_functions/1.6%3a_graphs_of_functions) to test if a function was even, odd or neither. the interested reader is invited to explore the role of reflections and symmetry of functions. what happens if you reflect an even function across the \(y\)-axis? what happens if you reflect an odd function across the \(y\)-axis? what about the \(x\)-axis?}  theorem 1.4: reflections.  suppose \(f\) is a function.  to graph \(y=-f(x)\), reflect the graph of \(y=f(x)\) across the \(x\)-axis by multiplying the \(y\)-coordinates of the points on the graph of \(f\) by \(-1\).  to graph \(y=f(-x)\), reflect the graph of \(y=f(x)\) across the \(y\)-axis by multiplying the \(x\)-coordinates of the points on the graph of \(f\) by \(-1\).  applying theorem 1.4 to the graph of \(y=f(x)\) given at the beginning of the section, we can graph \(y=-f(x)\) by reflecting the graph of \(f\) about the \(x\)-axis  by reflecting the graph of \(f\) across the \(y\)-axis, we obtain the graph of \(y=f(-x)\).  with the addition of reflections, it is now more important than ever to consider the order of transformations, as the next example illustrates.  example \(\pageindex{2}\):  let \(f(x) = \sqrt{x}\). use the graph of \(f\) from example 1.7.1 to graph the following functions. also, state their domains and ranges.  \(g(x) = \sqrt{-x}\)  \item \(j(x) = \sqrt{3-x}\)  \item \(m(x) = 3 - \sqrt{x}\)  solution  1. the mere sight of \(\sqrt{-x}\) usually causes alarm, if not panic. when we discussed domains in section 1.4 (https://math.libretexts.org/bookshelves/precalculus/map%3a_precalculus_(stitz-zeager)/1%3a_relations_and_functions/1.4%3a_function_notation), we clearly banished negatives from the radicands of even roots. however, we must remember that \(x\) is a variable, and as such, the quantity \(-x\) isn't always negative. for example, if \(x=-4\), \(-x = 4\), thus \(\sqrt{-x} = \sqrt{-(-4)} = 2\) is perfectly well-defined. to find the domain analytically, we set \(-x \geq 0\) which gives \(x \leq 0\), so that the domain of \(g\) is \((-\infty, 0]\). since \(g(x) = f(-x)\), theorem 1.4 tells us that the graph of \(g\) is the reflection of the graph of \(f\) across the \(y\)-axis. we accomplish this by multiplying each \(x\)-coordinate on the graph of \(f\) by \(-1\), so that the points \((0,0)\), \((1,1)\), and \((4,2)\) move to \((0,0)\), \((-1,1)\), and \((-4,2)\), respectively. graphically, we see that the domain of \(g\) is \((-\infty, 0]\) and the range of \(g\) is the same as the range of \(f\), namely \([0,\infty)\).  2.to determine the domain of \(j(x) = \sqrt{3-x}\), we solve \(3-x \geq 0\) and get \(x \leq 3\), or \((-\infty, 3]\). to determine which transformations we need to apply to the graph of \(f\) to obtain the graph of \(j\), we rewrite \(j(x) = \sqrt{-x+3} = f(-x+3)\). comparing this formula with \(f(x) = \sqrt{x}\), we see that not only are we multiplying the input \(x\) by \(-1\), which results in a reflection across the \(y\)-axis, but also we are adding \(3\), which indicates a horizontal shift to the left. does it matter in which order we do the transformations? if so, which order is the correct order? let's consider the point \((4,2)\) on the graph of \(f\). we refer to the discussion leading up to theorem 1.3. we know \(f(4) = 2\) and wish to find the point on \(y=j(x) = f(-x+3)\) which corresponds to \((4,2)\). we set \(-x+3 = 4\) and solve. our first step is to subtract \(3\) from both sides to get \(-x=1\). subtracting \(3\) from the \(x\)-coordinate \(4\) is shifting the point \((4,2)\) to the left. from \(-x=1\), we then multiply\footnote{or divide - it amounts to the same thing.} both sides by \(-1\) to get \(x=-1\). multiplying the \(x\)-coordinate by \(-1\) corresponds to reflecting the point about the \(y\)-axis. hence, we perform the horizontal shift first, then follow it with the reflection about the \(y\)-axis. starting with \(f(x) = \sqrt{x}\), we let \(j_1(x)\) be the intermediate function which shifts the graph of \(f\) \(3\) units to the left, \(j_1(x) = f(x+3)\).  to obtain the function \(j\), we reflect the graph of \(j_1\) about \(y\)-axis. theorem 1.4 tells us we have \(j(x) = j_1(-x)\). putting it all together, we have \(j(x) = j_1(-x) = f(-x+3) = \sqrt{-x+3}\), which is what we want.\footnote{if we had done the reflection first, then \(j_1(x) = f(-x)\). following this by a shift left would give us \(j(x) = j_1(x+3) = f(-(x+3)) = f(-x-3) = \sqrt{-x-3}\) which isn't what we want. however, if we did the reflection first and followed it by a shift to the right \(3\) units, we would have arrived at the function \(j(x)\). we leave it to the reader to verify the details.} from the graph, we confirm the domain of \(j\) is \((-\infty, 3]\) and we get that the range is \([0, \infty)\).  \item the domain of \(m\) works out to be the domain of \(f\), \([0, \infty)\). rewriting \(m(x) = -\sqrt{x} + 3\), we see \(m(x) = -f(x) + 3\). since we are multiplying the output of \(f\) by \(-1\) and then adding \(3\), we once again have two transformations to deal with: a reflection across the \(x\)-axis and a vertical shift. to determine the correct order in which to apply the transformations, we imagine trying to determine the point on the graph of \(m\) which corresponds to \((4,2)\) on the graph of \(f\). since in the formula for \(m(x)\), the input to \(f\) is just \(x\), we substitute to find \(m(4) = -f(4)+3 = -2+3=1\). hence, \((4,1)\) is the corresponding point on the graph of \(m\). if we closely examine the arithmetic, we see that we first multiply \(f(4)\) by \(-1\), which corresponds to the reflection across the \(x\)-axis, and then we add \(3\), which corresponds to the vertical shift. if we define an intermediate function \(m_1(x) = -f(x)\) to take care of the reflection, we get  to shift the graph of \(m_1\) up \(3\) units, we set \(m(x) = m_1(x)+3\). since \(m_1(x) = -f(x)\), when we put it all together, we get \(m(x) = m_1(x)+3 = -f(x) + 3 = -\sqrt{x}+3\). we see from the graph that the range of \(m\) is \((-\infty, 3]\).  we now turn our attention to our last class of transformations: \(\textbf{scalings}\). a thorough discussion of scalings can get complicated because they are not as straight-forward as the previous transformations. a quick review of what we've covered so far, namely vertical shifts, horizontal shifts and reflections, will show you why those transformations are known as rigid transformations. simply put, they do not change the shape of the graph, only its position and orientation in the plane. if, however, we wanted to make a new graph twice as tall as a given graph, or one-third as wide, we would be changing the shape of the graph. this type of transformation is called \(\textbf{non-rigid}\)for obvious reasons. not only will it be important for us to differentiate between modifying inputs versus outputs, we must also pay close attention to the magnitude of the changes we make. as you will see shortly, the mathematics turns out to be easier than the associated grammar.  suppose we wish to graph the function \(g(x) =2 f(x)\) where \(f(x)\) is the function whose graph is given at the beginning of the section. from its graph, we can build a table of values for \(g\) as before.  \[ \begin{array}{|c||c|c|c|c|} x & (x,f(x)) & f(x) & g(x)=2f(x) & (x, g(x)) \\ 0 & (0,1)& 1 & 2 &(0, 2) \\ 2 & (2,3) & 3 & 6 &(2,6) \\ 4 & (4,3) & 3 & 6 &(4, 6) \\ 5 & (5,5) & 5 & 10 &( 5 ,10) \\ \end{array} \]  in general, if \((a,b)\) is on the graph of \(f\), then \(f(a) = b\) so that \(g(a) = 2 f(a) = 2b\) puts \((a,2b)\) on the graph of \(g\). in other words, to obtain the graph of \(g\), we multiply all of the \(y\)-coordinates of the points on the graph of \(f\) by \(2\). multiplying all of the \(y\)-coordinates of all of the points on the graph of \(f\) by \(2\) causes what is known as a `vertical scaling\footnote{also called a `vertical stretching', `vertical expansion' or `vertical dilation' by a factor of \(2\).} by a factor of \(2\)', and the results are given on the next page.  if we wish to graph \(y = \frac{1}{2} f(x)\), we multiply the all of the \(y\)-coordinates of the points on the graph of \(f\) by \(\frac{1}{2}\). this creates a `vertical scaling\footnote{also called `vertical shrinking', `vertical compression' or `vertical contraction' by a factor of \(2\).} by a factor of \(\frac{1}{2}\)' as seen below.  these results are generalized in the following theorem.  theorem 1.5: vertical scalings.  suppose \(f\) is a function and \(a>0\). to graph \(y=a f(x)\), multiply all of the \(y\)-coordinates of the points on the graph of \(f\) by \(a\). we say the graph of \(f\) has been vertically scaled by a factor of \(a\).  if \(a > 1\), we say the graph of \(f\) has undergone a vertical stretching (expansion, dilation) by a factor of \(a\).  if \(0 < a < 1\), we say the graph of \(f\) has undergone a vertical shrinking (compression, contraction) by a factor of \(\frac{1}{a}\).  a few remarks about theorem 1.5 are in order. first, a note about the verbiage. to the authors, the words `stretching', `expansion', and `dilation' all indicate something getting bigger. hence, `stretched by a factor of \(2\)' makes sense if we are scaling something by multiplying it by \(2\). similarly, we believe words like `shrinking', `compression' and `contraction' all indicate something getting smaller, so if we scale something by a factor of \(\frac{1}{2}\), we would say it `shrinks by a factor of \(2\)' - not `shrinks by a factor of \(\frac{1}{2}\)'. this is why we have written the descriptions `stretching by a factor of \(a\)' and `shrinking by a factor of \(\frac{1}{a}\)' in the statement of the theorem. second, in terms of inputs and outputs, theorem 1.5 says multiplying the \(\textit{outputs}\) from a function by positive number \(a\) causes the graph to be vertically scaled by a factor of \(a\). it is natural to ask what would happen if we multiply the \(\textit{inputs}\) of a function by a positive number. this leads us to our last transformation of the section.  referring to the graph of \(f\) given at the beginning of this section, suppose we want to graph \(g(x) = f(2x)\). in other words, we are looking to see what effect multiplying the inputs to \(f\) by \(2\) has on its graph. if we attempt to build a table directly, we quickly run into the same problem we had in our discussion leading up to theorem 1.3, as seen in the table on the left below. we solve this problem in the same way we solved this problem before. for example, if we want to determine the point on \(g\) which corresponds to the point \((2,3)\) on the graph of \(f\), we set \(2x =2\) so that \(x=1\). substituting \(x=1\) into \(g(x)\), we obtain \(g(1) = f(2 \cdot 1) = f(2) = 3\), so that \((1,3)\) is on the graph of \(g\). continuing in this fashion, we obtain the table on the lower right.  \( \begin{array}{|c||c|c|c|c|} x & (x,f(x)) & f(x)& g(x)=f(2x) & (x, g(x)) \\ 0 & (0,1)& 1 & f(2 \cdot 0) = f(0) = 1 &(0, 1) \\ 2 & (2,3) & 3 & f(2\cdot2) = f(4) = 3 &(2,3) \\ 4 & (4,3) & 3 & f(2 \cdot 4) = f(8) = ? & \\ 5 & (5,5) & 5 & f(2 \cdot 5) = f(10) = ? & \\ \end{array} \)  \( \begin{array}{|r||c|c|c|} x & 2x & g(x)=f(2x) & (x, g(x)) \\ 0 & 0 & g(0)=f(0) = 1 &(0, 0) \\ 1 & 2 & g(1)=f(2) = 3 &(1,3) \\ 2 & 4 & g(2)=f(4) = 3 & (2,3)\\ \frac{5}{2} & 5 & g\left(\frac{5}{2}\right)=f(5) = 5 & \left(\frac{5}{2},5\right) \\ [1pt] \end{array} \)  in general, if \((a,b)\) is on the graph of \(f\), then \(f(a) = b\). hence \(g\left(\frac{a}{2}\right) = f\left(2 \cdot \frac{a}{2}\right) = f(a) = b\) so that \(\left(\frac{a}{2}, b\right)\) is on the graph of \(g\). in other words, to graph \(g\) we divide the \(x\)-coordinates of the points on the graph of \(f\) by \(2\). this results in a horizontal scaling\footnote{also called `horizontal shrinking', `horizontal compression' or `horizontal contraction' by a factor of \(2\).} by a factor of \(\frac{1}{2}\).  if, on the other hand, we wish to graph \(y = f\left( \frac{1}{2} x\right)\), we end up multiplying the \(x\)-coordinates of the points on the graph of \(f\) by \(2\) which results in a horizontal scaling\footnote{also called `horizontal stretching', `horizontal expansion' or `horizontal dilation' by a factor of \(2\).} by a factor of \(2\), as demonstrated below.  we have the following theorem.  theorem 1.6: horizontal scalings.  suppose \(f\) is a function and \(b > 0\). to graph \(y = f(bx)\), divide all of the \(x\)-coordinates of the points on the graph of \(f\) by \(b\). we say the graph of \(f\) has been horizontally scaled by a factor of \( \frac{1}{b}\) . ˆ  if \(0 < b < 1\), we say the graph of \(f\) has undergone a horizontal stretching (expansion, dilation) by a factor of \( \frac{1}{b}\) . ˆ  if \(b > 1\), we say the graph of f has undergone a horizontal shrinking (compression, contraction) by a factor of \(b\).  theorem 1.6 tells us that if we multiply the input to a function by \(b\), the resulting graph is scaled horizontally by a factor of \(\frac{1}{b}\) since the \(x\)-values are divided by \(b\) to produce corresponding points on the graph of \(y = f(bx)\). the next example explores how vertical and horizontal scalings sometimes interact with each other and with the other transformations introduced in this section.  example \(\pageindex{3}\):  let \(f(x)= \sqrt{x}\). use the graph of \(f\) from example 1.7.1 to graph the following functions. also, state their domains and ranges.  1. \(g(x) = 3 \sqrt{x}\)  2. \(j(x) = \sqrt{9x}\)  3. \(m(x) =1 - \sqrt{\frac{x+3}{2}}\)  \( {\bf solution.}\)  1. first we note that the domain of \(g\) is \([0, \infty)\) for the usual reason. next, we have \(g(x) = 3 f(x)\) so by theorem 1.5, we obtain the graph of \(g\) by multiplying all of the \(y\)-coordinates of the points on the graph of \(f\) by \(3\). the result is a vertical scaling of the graph of \(f\) by a factor of \(3\). we find the range of \(g\) is also \([0, \infty)\).  2. to determine the domain of \(j\), we solve \(9x \geq 0\) to find \(x \geq 0\). our domain is once again \([0,\infty)\). we recognize \(j(x) = f(9x)\) and by theorem 1.6, we obtain the graph of \(j\) by dividing the \(x\)-coordinates of the points on the graph of \(f\) by \(9\). from the graph, we see the range of \(j\) is also \([0,\infty)\).  3. solving \(\frac{x+3}{2} \geq 0\) gives \(x \geq -3\), so the domain of \(m\) is \([-3, \infty)\). to take advantage of what we know of transformations, we rewrite \(m(x) = - \sqrt{\frac{1}{2} x + \frac{3}{2}} + 1\), or \(m(x) =- f\left(\frac{1}{2} x + \frac{3}{2}\right) + 1\). focusing on the inputs first, we note that the input to \(f\) in the formula for \(m(x)\) is \(\frac{1}{2} x + \frac{3}{2}\). multiplying the \(x\) by \(\frac{1}{2}\) corresponds to a horizontal stretching by a factor of \(2\), and adding the \(\frac{3}{2}\) corresponds to a shift to the left by \(\frac{3}{2}\). as before, we resolve which to perform first by thinking about how we would find the point on \(m\) corresponding to a point on \(f\), in this case, \((4,2)\). to use \(f(4) = 2\), we solve \(\frac{1}{2} x + \frac{3}{2} = 4\). our first step is to subtract the \(\frac{3}{2}\) (the horizontal shift) to obtain \(\frac{1}{2} x = \frac{5}{2}\). next, we multiply by \(2\) (the horizontal stretching) and obtain \(x = 5\). we define two intermediate functions to handle first the shift, then the stretching. in accordance with theorem 1.3, \(m_1(x) = f\left(x+ \frac{3}{2}\right) = \sqrt{x+\frac{3}{2}}\) will shift the graph of \(f\) to the left \(\frac{3}{2}\) units.  next, \(m_2(x) = m_1\left(\frac{1}{2} x\right) = \sqrt{\frac{1}{2} x + \frac{3}{2}}\) will, according to theorem 1.6, horizontally stretch the graph of \(m_1\) by a factor of \(2\).  we now examine what's happening to the outputs. from \(m(x) = - f\left(\frac{1}{2} x + \frac{3}{2}\right) + 1\), we see that the output from \(f\) is being multiplied by \(-1\) (a reflection about the \(x\)-axis) and then a \(1\) is added (a vertical shift up \(1\)). as before, we can determine the correct order by looking at how the point \((4,2)\) is moved. we already know that to make use of the equation \(f(4)=2\), we need to substitute \(x=5\). we get \(m(5) = - f\left(\frac{1}{2} (5) + \frac{3}{2}\right) + 1= - f(4)+1 = -2+1 = -1\). we see that \(f(4)\) (the output from \(f\)) is first multiplied by \(-1\) then the \(1\) is added meaning we first reflect the graph about the \(x\)-axis then shift up \(1\). theorem 1.4 tells us \(m_3(x) = - m_2(x)\) will handle the reflection.  finally, to handle the vertical shift, theorem 1.2 gives \(m(x) = m_3(x) +1\), and we see that the range of \(m\) is \((-\infty,1]\).  some comments about example 1.7.3 are in order. first, recalling the properties of radicals from intermediate algebra, we know that the functions \(g\) and \(j\) are the same, since \(j\) and \(g\) have the same domains and \(j(x) = \sqrt{9x} = \sqrt{9} \sqrt{x} = 3 \sqrt{x} = g(x)\). (we invite the reader to verify that all of the points we plotted on the graph of \(g\) lie on the graph of \(j\) and vice-versa.) hence, for \(f(x) = \sqrt{x}\), a vertical stretch by a factor of \(3\) and a horizontal shrinking by a factor of \(9\) result in the same transformation. while this kind of phenomenon is not universal, it happens commonly enough with some of the families of functions studied in college algebra that it is worthy of note. secondly, to graph the function \(m\), we applied a series of four transformations. while it would have been easier on the authors to simply inform the reader of which steps to take, we have strived to explain why the order in which the transformations were applied made sense. we generalize the procedure in the theorem below.  theorem 1.7: transformations.  suppose \(f\) is a function. if \(a \neq 0\) and \(b \neq 0\), then to graph  \[g(x) = a f(bx+h)+k\]  subtract \(h\) from each of the \(x\)-coordinates of the points on the graph of \(f\). this results in a horizontal shift to the left if \(h > 0\) or right if \(h< 0\).  divide the \(x\)-coordinates of the points on the graph obtained in step 1 by \(b\). this results in a horizontal scaling, but may also include a reflection about the \(y\)-axis if \(b < 0\).  multiply the \(y\)-coordinates of the points on the graph obtained in step 2 by \(a\). this results in a vertical scaling, but may also include a reflection about the \(x\)-axis if \(a < 0\).  add \(k\) to each of the \(y\)-coordinates of the points on the graph obtained in step 3. this results in a vertical shift up if \(k > 0\) or down if \(k< 0\).  theorem 1.7 can be established by generalizing the techniques developed in this section. suppose \((a,b)\) is on the graph of \(f\). then \(f(a) = b\), and to make good use of this fact, we set \(bx+h = a\) and solve. we first subtract the \(h\) (causing the horizontal shift) and then divide by \(b\). if \(b\) is a positive number, this induces only a horizontal scaling by a factor of \(\frac{1}{b}\). if \(b<0\), then we have a factor of \(-1\) in play, and dividing by it induces a reflection about the \(y\)-axis. so we have \(x = \frac{a-h}{b}\) as the input to \(g\) which corresponds to the input \(x=a\) to \(f\). we now evaluate \(g\left( \frac{a-h}{b}\right) = a f\left(b \cdot \frac{a-h}{b} + h\right) + k = a f(a)+k = a b + k\). we notice that the output from \(f\) is first multiplied by \(a\). as with the constant \(b\), if \(a > 0\), this induces only a vertical scaling. if \(a < 0\), then the \(-1\) induces a reflection across the \(x\)-axis. finally, we add \(k\) to the result, which is our vertical shift. a less precise, but more intuitive way to paraphrase theorem 1.7 is to think of the quantity \(bx+h\) is the `inside' of the function \(f\). what's happening inside \(f\) affects the inputs or \(x\)-coordinates of the points on the graph of \(f\). to find the \(x\)-coordinates of the corresponding points on \(g\), we undo what has been done to \(x\) in the same way we would solve an equation. what's happening to the output can be thought of as things happening `outside' the function, \(f\). things happening outside affect the outputs or \(y\)-coordinates of the points on the graph of \(f\). here, we follow the usual order of operations agreement: we first multiply by \(a\) then add \(k\) to find the corresponding \(y\)-coordinates on the graph of \(g\).  example \(\pageindex{4}\):  below is the complete graph of \(y = f(x)\). use it to graph \(g(x) = \frac{4-3 f(1-2x)}{2}\).  we use theorem 1.7 to track the five `key points' \((-4,-3)\), \((-2,0)\), \((0,3)\), \((2,0)\) and \((4,-3)\) indicated on the graph of \(f\) to their new locations. we first rewrite \(g(x)\) in the form presented in theorem 1.7, \(g(x) = -\frac{3}{2}f(-2x+1) +2\). we set \(-2x+1\) equal to the \(x\)-coordinates of the key points and solve. for example, solving \(-2x+1 = -4\), we first subtract \(1\) to get \(-2x = -5\) then divide by \(-2\) to get \(x = \frac{5}{2}\). subtracting the \(1\) is a horizontal shift to the left \(1\) unit. dividing by \(-2\) can be thought of as a two step process: dividing by \(2\) which compresses the graph horizontally by a factor of \(2\) followed by dividing (multiplying) by \(-1\) which causes a reflection across the \(y\)-axis. we summarize the results in the table on the next page.  \[ \begin{array}{|r||r|r|r|} (a,f(a))& a & -2x+1=a & x \\ (-4,-3) & -4 & -2x+1 = -4 & x = \frac{5}{2} \\ [1pt] (-2,0) & -2 & -2x+1 = -2 & x = \frac{3}{2} \\ [1pt] (0,3) & 0 & -2x+1 = 0 & x = \frac{1}{2} \\ [1pt] (2,0) & 2 & -2x+1 = 2 & x = -\frac{1}{2} \\[1pt] (4,-3) & 4 & -2x+1 = 4 & x = -\frac{3}{2} \\ [1pt] \end{array} \]  next, we take each of the \(x\) values and substitute them into \(g(x) = -\frac{3}{2}f(-2x+1) +2\) to get the corresponding \(y\)-values. substituting \(x=\frac{5}{2}\), and using the fact that \(f(-4)=-3\), we get  \[g\left(\frac{5}{2}\right) = -\frac{3}{2}f\left(-2\left(\frac{5}{2}\right) +1\right) +2 = -\frac{3}{2} f(-4) + 2 = -\frac{3}{2}(-3) + 2 = \frac{9}{2} + 2 = \frac{13}{2}\]  we see that the output from \(f\) is first multiplied by \(-\frac{3}{2}\). thinking of this as a two step process, multiplying by \(\frac{3}{2}\) then by \(-1\), we have a vertical stretching by a factor of \(\frac{3}{2}\) followed by a reflection across the \(x\)-axis. adding \(2\) results in a vertical shift up \(2\) units. continuing in this manner, we get the table below.  \[ \begin{array}{|r||r|r|} x & g(x) & (x, g(x)) \\ \frac{5}{2} & \frac{13}{2} & \left(\frac{5}{2}, \frac{13}{2} \right) \\ [1pt] \frac{3}{2} & 2 & \left(\frac{3}{2}, 2 \right)\\ [1pt] \frac{1}{2} & - \frac{5}{2} & \left(\frac{1}{2}, -\frac{5}{2} \right) \\ [1pt] -\frac{1}{2} & 2 & \left(-\frac{1}{2}, 2 \right) \\ [1pt] -\frac{3}{2} & \frac{13}{2} & \left(-\frac{3}{2}, \frac{13}{2} \right) \\ [1pt] \end{array} \]  to graph \(g\), we plot each of the points in the table above and connect them in the same order and fashion as the points to which they correspond. plotting \(f\) and \(g\) side-by-side gives  the reader is strongly encouraged\footnote{you really should do this once in your life.} to graph the series of functions which shows the gradual transformation of the graph of \(f\) into the graph of \(g\). we have outlined the sequence of transformations in the above exposition; all that remains is to plot the five intermediate stages. \(\box\)  our last example turns the tables and asks for the formula of a function given a desired sequence of transformations. if nothing else, it is a good review of function notation.  example \(\pageindex{5}\):  let \(f(x) = x^2\). find and simplify the formula of the function \(g(x)\) whose graph is the result of \(f\) undergoing the following sequence of transformations. check your answer using a graphing calculator.  vertical shift up \(2\) units  reflection across the \(x\)-axis  horizontal shift right \(1\) unit  horizontal stretching by a factor of \(2\)  \({\bf solution.} \)  we build up to a formula for \(g(x)\) using intermediate functions as we've seen in previous examples. we let \(g_1\) take care of our first step. theorem 1.2 tells us \(g_1(x) = f(x) + 2 = x^2+2\). next, we reflect the graph of \(g_1\) about the \(x\)-axis using theorem 1.4: \(g_2(x) = -g_1(x) = -\left(x^2+2\right) = -x^2-2\). we shift the graph to the right \(1\) unit, according to theorem 1.3, by setting \(g_3(x) = g_2(x-1) = -(x-1)^2-2 = -x^2+2x-3\). finally, we induce a horizontal stretch by a factor of \(2\) using theorem 1.6 to get \(g(x) = g_3\left(\frac{1}{2} x\right) = -\left(\frac{1}{2} x\right)^2+2\left(\frac{1}{2} x\right)-3\) which yields \(g(x) = -\frac{1}{4} x^2 + x -3\). we use the calculator to graph the stages below to confirm our result.  we have kept the viewing window the same in all of the graphs above. this had the undesirable consequence of making the last graph look `incomplete' in that we cannot see the original shape of \(f(x) = x^{2}\). altering the viewing window results in a more complete graph of the transformed function as seen below.  this example brings our first chapter to a close. in the chapters which lie ahead, be on the lookout for the concepts developed here to resurface as we study different families of functions.  contributors  carl stitz (http://www.stitz-zeager.com/), ph.d. (lakeland community college) and jeff zeager, ph.d. (lorain county community college)",t_a154ec974768,other,0
c_9f3a9f0282fe,"there are several different ways to solve problems involving percentages, decimals, and fractions. watch as sal finds the percentage of a whole number.  let's see if we can figure out what 30% of 6 is. so one way of thinking about 30%-- this literally means 30 per 100. so you could view this as 30/100 times 6 is the same thing as 30% of 6. or you could view this as 30 hundredths times 6, so 0.30 times 6. now we could solve both of these, and you'll see that we'll get the same answer. if you do this multiplication right over here, 30/100-- and you could view this times 6/1-- this is equal to 180/100. and let's see. we can simplify. we can divide the numerator and the denominator by 10. and then we can divide the numerator and the denominator by 2. and we will get 9/5, which is the same thing as 1 and 4/5. and then if we wanted to write this as a decimal, 4/5 is 0.8. and if you want to verify that, you could verify that 5 goes into 4-- and there's going to be a decimal. so let's throw some decimals in there. it goes into 4 zero times. so we don't have to worry about that. it goes into 40 eight times. 8 times 5 is 40. subtract. you have no remainder, and you just have 0's left here. so 4/5 is 0.8. you've got the 1 there. this is the same thing as 1.8, which you would have gotten if you divided 5 into 9. you would've gotten 1.8. so 30% of 6 is equal to 1.8. and we can verify it doing this way as well. so if we were to multiply 0.30 times 6-- let's do that. and i could just write that literally as 0.3 times 6. well, 3 times 6 is 18. i have only one digit behind the decimal amongst both of these numbers that i'm multiplying. i only have the 3 to the right of the decimal. so i'm only going to have one number to the right of the decimal here. so i just count one number. it's going to be 1.8. so either way you think about it or calculate it, 30% of 6 is 1.8.",t_de661521412c,other,0
c_0a5ed38e4d0d,"david works through a within-sentence punctuation question from the praxis core writing test.  - [instructor] the darien gap, a thickly forested region of central america, separates panama and colombia, indigenous people have long resisted building a leg of the pan-american highway through the gap. so here we have an error-id question we're gonna try and figure out as quick as we can what is wrong with this sentence. and remember, you don't need to know how to fix the error in an error-id question, all you have to do is flag it and move on. however, khan academy being khan academy, we will endeavor to tell you how to fix the error, because hey, it couldn't hurt, and i'm feeling generous today. so okay, so option a, the darien gap, we have this comma here and that's what's underlined, but we also have another comma here. so this is what we call a comma bounded descriptive aside, you can call an appositive if you want, but what it's doing is it's blocking off this chunk, this description, a thickly forested region of central america, to refer back to the darien gap. so this is being used correctly, so i'm gonna cross it off. this next underline, thickly forested, so this is testing our knowledge of adjectives and adverbs, are they being used correctly? so this is an adverb here, and this, forested, is an adjective. and what's happening is that the word thickly is describing forested, and forested is describing region. this tracks with what we know about how adjectives and adverbs work, gonna cross it off. and now we come to the comma, and this is our error and i'll tell you why. but first i'll say that this is a within-sentence punctuation question. and specifically the kind of error that is being committed here is called a comma splice, which is a kind of error that occurs when you join two independent clauses with just a comma. follow-up question, how do we know these are two independent clauses? well, let's look for subject and verbs. so, okay, so here's our subject, the darien gap, and here's our verb, separates, that's clause the first. indigenous people, so people is the subject, have resisted, and that's our verb, right. so we have these two independent clauses, these two things could be sentences on their own. the darien gap separates panama and colombia. indigenous people have long resisted building a leg of the pan-american highway through the gap. so we have two independent clauses, two sentences that could stand on their own, united incorrectly by a comma. so there's our error. one of the ways you could fix it, though you don't have to for the purposes of this question, is you could change this comma into a semicolon, or you could keep the comma, but add one of the fanboys conjunctions. that's for, and, nor, but, or, yet, so. also known as the coordinating conjunctions of english. so option c is our answer. let's look at d real quick, see what the deal is. a leg of the pan-american highway. this is a conventional expression referring to using the word leg as a metaphor for part of a route, so a leg of the trip. if the entire trip is meant to comprise the entire body, then a leg of the trip is some portion of it. i don't know the origin of that, but i do know it is a conventional expression in english. so, this is not an error, and then we can check off no error because, hello, we found the error and it is c. if you're uncertain about a piece of punctuation inside of a sentence, do the before and after test, especially if you think there might be a comma splice happening, which is, before and after the comma, is there an independent clause? is there an independent clause before and after? if so, and if there's no coordinating conjunction, no fanboys conjunction following the comma, then that comma is being used incorrectly. conversely, if you see a semicolon and it's followed by a fanboys conjunction, that's redundant, and either you need to get rid of the semicolon and turn it into a comma, or you need to get rid of the conjunction. so if you have doubts about a piece within sentence punctuation, look both ways before you cross off that option, as it were.",t_8a342f368a02,other,0
c_98c2b4239359,"organize how changes to a design in the development and realization stages can be registered and processed in bim. these changes may refer to:  change to a property of a symbol (e.g. lengthening of a wall)  change of the type of a symbol (e.g. change of family for a door)  change in a relation between symbols (e.g. relocation of a door in a wall)  change in a time property of a symbol (e.g. as a result of a scheduling change)  organize the process of change management in both stages as a series of tasks that reflect the above types of changes and take into account possible causes of change, such as:  changes in the brief (e.g. new activities added)  changes in the budget (e.g. increase of façade cost necessitating reduction of cost elsewhere)  changes in an aspect of the design (e.g. change in the heating solution or the fire rating of internal doors and ensuing interfacing issues – not just clash detection)  changes in the construction schedules (e.g. due to delays in the delivery of components or to bad weather)  errors in construction (e.g. wrong dimensioning or specifications of an element)  deliverables  process and information diagrams, accompanied by short explanatory comments  basic model in a bim editor demonstrating the way changes can be implemented  short overview of findings (two a4 sheets)  roles  if the exercise is a group assignment, consider roles for the following aspects:  process management  information management  bim modelling  case analyses (for finding realistic examples)",t_d4a31f8e137b,other,0
c_265fd5481a91,"does the figure emerge from the stripes of the flag, or do they imprison him? [see learning resources here.](https://smarthistory.org/seeing- america-2/benny-andrews-flag-day-2/)      benny andrews, _flag day_ , 1966, oil on canvas, 53.3 x 40.6 cm (c)the benny andrews estate (the art institute of chicago), a _seeing america_ video. speakers: robyn farrell, assistant curator of contemporary art, thwe're standing in the galleries of the art institute of chicago looking at a painting by benny andrews called flag day that dates to 1966. we see a figure emerging from the american flag the flag is turned on its side so that the stripes are in a vertical orientation the figure appears to be grasping two of the stripes. it's hard not to read those stripes of the flag as bars, but it also feels like he's enveloped in it and the flag is something reassuring at the same time. another way of reading it, which is not as positive is the way in which the flag is almost actually hiding the figure or the figure is struggling to emerge from from the stripes which of course could be a metaphor for the ways in which the african american community is constantly fighting for their own rights or for visibility and with benny andrews in particular, his interest in african americans being properly promoted with in the art world in america. andrews did grow up in a south that was racially segregated and so this idea of struggling to be seen in america stuggling for ones' rights, these were themes that were incredibly potent in the 1960s. very personal to the artist who was born in 1930 in georgia, to parents who were sharecroppers. he could only go to school when he wasn't needed on the farm right. and sharecropping is very much what it sounds like, you agree to farm a piece of land for a share in the crops, but the landlord supplies you with everything else so this created a cycle of poverty for so many, but at the same time his identity is more complicated than it sounds at first, since his great grandfather was a white plantation owner, his grandfather was white his background is very mixed and so we tend to pigeonhole people but things are a lot more complicated. i think andrews really defied categorization in many ways, he spoke about how he didn't want his art to be only representative pop art, or figural, he wanted to be a painter of his time. and he didn't want to be pigeonholed as an activist artist either although flag day, for example, is not specifically autobiographical, it does represent the larger issues at hand that deal with identity and race he was mobilized to present work that not only was in some ways hopeful of what the american dream can mean but also very critical and i think that's what's so strong about him and his work is that he was able to address both aspects of being an american. and so we could think about the flag as a symbol of freedom and democracy, but we would also need to ask freedom and democracy and equal rights for whom? right.and there's a darker history, and i think that that's something that andrews refused to ignore in his work. we can see the red and white bars of the flag that part and move to make room for him so there's that sense of attempting to make visible, to be included in the history. returning to the idea of the bars, i think that we would be remiss not to mention benny andrews' later involvement with the prison art program a project that was a part of the organization he co-founded in 1969, the black emergency cultural coalition which was an organization of african american artists and creatives and eventually included white artists as well that were promoting the presence of african american artists and curators within the art community. the problem that arose in 1968-1969 when the metropolitan museum of art was planning an exhibition called 'harlem on my mind' that didn't include the work of a single african american artist so it's important to put this painting in the context of the civil rights movement. benny andrews grew up in the jim crow south with laws that institutionalized segregation that institutionalized discrimination and kept people in terrible cycles of poverty and so the civil rights act of 1964 and the voter rights act of 1965 did a lot to dismantle the jim crow laws that were so oppressive to so many african americans. in 1966, there was the hope that african americans might gain a more equal place but at the same time nodding to the fact that the movement hadn't fully affected every area of culture and society. that expression on his face can't be easily interpreted. it's not fear, or anger, or complacency, or protest; it's very hard to locate it. i think he's left it open for interpretation. the flag is such a potent symbol in american art history. the american flag has always been an important symbol and i think most popularized by jasper johns, the post-war artist who inserted the american flag into his work in the mid-to-late 50s which is exactly around the time that benny andrews moved to new york but unlike johns' very flat compositions here andrews really enlivens the flag the stripes have curves, they seem like fabric the white is not evenly distributed, the stars are unfinished and so the imperfections of the flag are highlighted here. so the flag moves here in a way that -right- it doesn't move in jasper john's the flag is a static symbol but here moving with the effect of an african american figure, which does make me think that there is a kind of message of hope in some way that decades of protest and the civil rights movement that america can change for the better and be a place that is more inclusive, and that recognizes the civil rights of every citizen.",t_b969c3e187a6,other,0
c_0e45b1891bed,source_url=http://www.prathamopenschool.org/coursecontent/videos/en_spooky_spoke.mp4,t_77a8d1559561,other,0
c_c966b80d63ad,"assign this prompt to spark students' creativity.jump to navigation  writing: now how do i get out of this one?  writing: now how do i get out of this one?  melica/shutterstock.com  chores are a bore. even though they teach us responsibility, they're no fun. but what if there were a fun way to get out of doing them? in this activity, you will come up with creative excuses for avoiding chores.  your turn write creative excuses.  list ten chores or tasks you hate doing. cleaning my room is an example of a chore you might not like.  select four tasks from your list and write a creative excuse explaining why you can’t or haven’t completed each one. make your excuses as original and wild as possible.  when you’ve finished, exchange your work with a classmate. read and discuss each other’s excuses.  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_cd5d0bb420fa,other,0
c_7c52bc05d1a7,identifying centripetal force vectors for cars and satellites  ,t_31f127926894,other,0
c_1d8f2ee4389c,def terminate():     pygame.quit()     sys.exit()  the terminate() function works the same as in the previous game programs.,t_0a7274289f7b,other,0
c_d5459fa25f63,"the node voltage method solves circuits with the minimum number of kcl equations. steps 1 to 4 out of 5.  - [voiceover] we're going to talk about a really powerful way to analyze circuits called the node voltage method. before we start talking about what this method is, we're going to talk about a new term called a node voltage. so far, we already have the idea of an element has a voltage across it, and we refer to that as an element voltage, or if it's part of a circuit and it's a branch of a circuit, it'd be called a branch voltage. that's a voltage that's associated with a particular element. so now we have the idea of something called a node voltage. this is still a voltage, it's not anything strange, but if we go over to our circuit here, and we label the nodes. let's start labeling the nodes, we'll call this node here where this junction between this resistor and this source, we'll call this node one. this is the junction between these two components here. there's another node that's these two resistors connected to this current source, and that's a single distributed node, so we'll call that node two. and down here, these three components are connected together in a junction, and that's node three. to define a node voltage, the first idea we need is to define a reference node, the idea of a reference node. a good choice for the reference node is usually one that's connected to the terminals of the power sources, or it's the node that's connected to a lot of branches, a lot of elements, and node three here is a good choice for a reference node. the way we mark that is with a symbol that looks like this, a ground symbol, that's called ground in this circuit. there's other kinds of ways to indicate a reference node. that's a common way. you can draw one that looks like the ground, connected to the ground. sometimes you'll see it with just an upside-down t, like that, that's another way to draw a ground. this symbol on a schematic indicates the reference node. we've picked a reference node to be node three, down here. so, a node voltage is measured between a node and the reference node. in our case we have this voltage here, is the node voltage on node one, we'll call it v1. this voltage here is going to be called v2. and in particular, these voltages are measured with respect to node three, so there's the minus and plus and minus and plus. we're going to use these node voltages in the node voltage method. first, what i want to do, i want to label my complements here. we're going to call this vs, and make it 15 volts. this resistor's going to be r1, and we'll give it a value of 4kohms. we'll call this r2, and we'll give it a value of 2kohms. this is the same circuit that we analyzed when we did application of the fundamental laws in another video. oh, and the last guy here, is, current source is, and we'll make that one 3 milliamps. we've analyzed this circuit before. we used kirchoff's laws, kvl and kcl, to figure out what the voltages and currents were in this circuit. we're going to do the same analysis, but this time we're going to use what we call the node voltage method. it's basically the same application of the fundamental laws, we use ohm's law, kirchoff's laws, but it's in a really clever, organized way, that is really efficient. whoever thought this up was pretty bright and i'm really glad that they wrote it down and shared it with us. what i want to do first is just write down what are the steps of this method? it's not a theory, it's a method, so it basically a sequence of steps that you go through to analyze the circuit. i'll write the list right here. first step is pick a reference node. we already did that. the second step is to name the node voltages. we already did that, we named our nodes v1, that node there is v1 and that node there is v2, with respect to the reference node, which is down there at node three. whenever you talk about node voltages, there's always an assumption that one of the nodes is a reference node. the third step is to solve the easy nodes. i'll show you what that means in a second. the fourth step is to write kcl, kirchoff's current law equations. the fifth step is to solve the equations. that's the node voltage method, and we're going to go through the rest of this, we've done the first two steps. what does it mean to solve the easy nodes? the easy nodes are the ones that are connected directly to a source that goes to the reference node. that's an example of an easy node. so v1 is an easy node. so let's solve for v1. by inspection, i can say v1 is 15 volts. that's step three. the other node's not easy, the other node has lots of components and something interesting's going on over here. so this was step three. let's label the steps. here's the step one. here's step two. and here's step three. now we're ready to go to step four, let me move up a little bit. step four is write the kirchoff's current law equations directly from the circuit. we're going to do this in a special way, we're going to perform at this node here, at node two. we're going to write the current law for this. that means we got to identify the currents. there's a current, we'll call that a current, and that's a current. let me give some names to these currents just to be clear. we'll call this one i1 because it goes through r1. we'll call this one here, i2 because it goes through r2. this one is already is. now let's write kirchoff's current law just in terms of i, and we'll say all the currents flowing into the node add up to zero, so these two have arrows going out, so they're going to get negative signs when we write kirchoff's current law. let's do that right here. and we write i1 minus i2 minus is equals to zero. so right now we're working on step four. this is the essence of the node voltage method. this is where we do something new that we haven't done before. we're going to write these currents in terms of the node voltages. so we can write i1, i1 is current flowing this way through this current. i1 equals v1 minus v2 over r1. that's the current flowing in resistor r1, in terms of node voltages. the current flowing down through i2, now we have to subtract i2, so we just apply ohm's law directly, which means that the current in i2 is equal to v2 divided by r2. the last current is is, minus is. we'll write that in terms of is, like that, and that equals zero. this means we have now completed step four. that is kcl written using the terminology of node voltages. we could check off that we've done step four.",t_b7f6b1544f17,other,0
c_d1f98d09bb84,"a parabola is the set of all points equidistant from a point (called the ""focus"") and a line (called the ""directrix""). see this video to learn more about this.  - what i want to do in this video is understand two words that you might hear associated with parabolas. and that is, that is a focus. that is a focus of a parabola, focus. and a directrix. directrix. directrix. directrix, right over there. so what are these things? well, a parabola can be defined as the set of all points, let me draw arbitrary axes right over here. so that's my y axis, this is my x axis. this is my x axis. and so a parabola can be defined as the set of all points that are equidistant to a point and a line. and that point is the focus of that parabola, and that line is the directrix of the parabola. so what am i talking about? so let's give ourselves a point. so let's say this point right over here, and we can even say that that is the point let's say that's the point, let's say the x coordinate is a, and the y coordinate is b right over here. so that is the point (a, b). and then let's give ourselves a line for the directrix. and actually i'm going to do this in a different color instead of just white, cos i did the coordinates in white. so i will do it in this magenta color. so that's (a,b) is the focus. and let's say y=c is the directrix. so this right over here is the line, this right over here is the line y is equal to c. so this on the y axis right over there, that is c, this is the line y=c. so a parabola, what does it mean to be the set of all points that are equidistant between a point and this line? let's think about what those points might be. well, this point right over here would be halfway between, between this point, between the focus and the directrix. and then as we move away from x=a, you're going to get points anywhere along this curve. which is a parabola. and you might be saying, wait, i don't get this, i don't get why points along this curve are going to be equidistant. well, let's just eyeball the distances. so this one, this distance, and obviously i'm drawing it by hand so it's not going to be completely precise, that distance needs to be equal to that distance. well, that seems believable. now this, if we take this point right over here of the parabola, this distance needs to be the same as that distance. well, that seems believable. if you take this point on the parabola, this distance, this distance needs to be the same as this distance. so hopefully you get what i'm talking about when i say that the parabola is a set of all points that are equidistant to this focus and this directrix. so any point along this parabola, this point right over here, this point right over here, the distance to the focus, the distance to the focus, should be the same as the distance, as the distance to the directrix. now, what you might realize is when you're taking the distance between a point and a point, the distance can, it'll be at, i guess you could say it could be at an angle. this one's straight up and down, this one is going from the top left to the bottom right. but when you take the distance from a point to a line, you essentially drop a perpendicular, you essentially go straight down. or if the parabola was down here, you'd go straight up to find that distance. these are all, these are all right angles right over here. so that's all a focus and a directrix is. and every parabola is going to have a focus and a directrix, because every parabola is the set of all points that are equidistant to some focus and some directrix. so that's what they are. in future videos we'll try to think about, how do you relate these points, the focus and directrix, to the actual, to the actual equation, or the actual equation for a parabola.",t_dcea40da564c,other,0
c_ab1508bae3d0,"close your eyes and picture a brick wall. what is the basic building block of that wall? it is a single brick, of course. like a brick wall, your body is composed of basic building blocks, and the building blocks of your body are cells. your body has many kinds of cells, each specialized for a specific purpose. just as a home is made from a variety of building materials, the human body is constructed from many cell types. for example, epithelial cells protect the surface of the body and cover the organs and body cavities within. bone cells help to support and protect the body. cells of the immune system fight invading bacteria. additionally, red blood cells carry oxygen throughout the body. each of these cell types plays a vital role during the growth, development, and day-to-day maintenance of the body. in spite of their enormous variety, however, all cells share certain fundamental characteristics.  a cell is the basic unit of the structure and function of a living thing. a living thing, like you, is called an organism. thus, cells are the basic building blocks of all organisms. in multicellular organisms, several cells of one particular kind interconnect with each other and performed shared functions to form tissues (for example, muscle tissue, connective tissue, and nervous tissue), several tissues combine to form an organ (for example, stomach, heart, or brain), and several organs make up an organ system (such as the digestive system, circulatory system, or nervous system). several systems functioning together form an organism (such as an elephant, for example).  cell theory  the microscopes we use today are far more complex than those used in the 1600s by antony van leeuwenhoek, a dutch shopkeeper who had great skill in crafting lenses. despite the limitations of his now-ancient lenses, van leeuwenhoek observed the movements of protists (a type of single-celled organism) and sperm, which he collectively termed “animalcules.” in a 1665 publication called micrographia, experimental scientist robert hooke coined the term “cell” (from the latin cella, meaning “small room”) for the box-like structures he observed when viewing cork tissue through a lens. in the 1670s, van leeuwenhoek discovered bacteria and protozoa. later advances in lenses and microscope construction enabled other scientists to see different components inside cells.  by the late 1830s, botanist matthias schleiden and zoologist theodor schwann were studying tissues and proposed the unified cell theory, which states that all living things are composed of one or more cells, that the cell is the basic unit of life, and that all new cells arise from existing cells. these principles still stand today.  there are many types of cells, and all are grouped into one of two broad categories: prokaryotic and eukaryotic. animal cells, plant cells, fungal cells, and protist cells are classified as eukaryotic, whereas bacteria and archaea cells are classified as prokaryotic.  components of prokaryotic cells  all cells share four common components: 1) a plasma membrane, an outer covering that separates the cell’s interior from its surrounding environment; 2) cytoplasm, consisting of a jelly-like region within the cell in which other cellular components are found; 3) dna, the genetic material of the cell; and 4) ribosomes, particles that synthesize proteins. however, prokaryotes differ from eukaryotic cells in several ways.  a prokaryotic cell is a simple, single-celled (unicellular) organism that lacks a nucleus, or any other membrane-bound organelle. we will shortly come to see that this is significantly different in eukaryotes. prokaryotic dna is found in the central part of the cell: a darkened region called the nucleoid (figure below).  figure \(\pageindex{1}\): this figure shows the generalized structure of a prokaryotic cell.  unlike archaea and eukaryotes, bacteria have a cell wall made of peptidoglycan, comprised of sugars and amino acids, and many have a polysaccharide capsule. the cell wall acts as an extra layer of protection, helps the cell maintain its shape, and prevents dehydration. the capsule enables the cell to attach to surfaces in its environment. some prokaryotes have flagella, pili, or fimbriae. flagella are used for locomotion. pili are used to exchange genetic material during a type of reproduction called conjugation. fimbriae are protein appendages used by bacteria to attach to other cells.  eukaryotic cells  in nature, the relationship between form and function is apparent at all levels, including the level of the cell, and this will become clear as we explore eukaryotic cells. the principle “form follows function” is found in many contexts. for example, birds and fish have streamlined bodies that allow them to move quickly through the medium in which they live, be it air or water. it means that, in general, one can deduce the function of a structure by looking at its form, because the two are matched. a eukaryotic cell is a cell that has a membrane-bound nucleus and other membrane-bound compartments or sacs, called organelles, which have specialized functions. the word eukaryotic means “true kernel” or “true nucleus,” alluding to the presence of the membrane-bound nucleus in these cells. the word “organelle” means “little organ,” and, as already mentioned, organelles have specialized cellular functions, just as the organs of your body have specialized functions.  cell size  at 0.1–5.0 µm in diameter, prokaryotic cells are significantly smaller than eukaryotic cells, which have diameters ranging from 10–100 µm (figure below). the small size of prokaryotes allows ions and organic molecules that enter them to quickly spread to other parts of the cell. similarly, any wastes produced within a prokaryotic cell can quickly move out. however, larger eukaryotic cells have evolved different structural adaptations to enhance cellular transport. indeed, the large size of these cells would not be possible without these adaptations. in general, cell size is limited because volume increases much more quickly than does cell surface area. as a cell becomes larger, it becomes more and more difficult for the cell to acquire sufficient materials to support the processes inside the cell, because the relative size of the surface area through which materials must be transported declines.  figure \(\pageindex{2}\): this figure shows the relative sizes of different kinds of cells and cellular components. an adult human is shown for comparison.  animal cells versus plant cells  despite their fundamental similarities, there are some striking differences between animal and plant cells. animal cells have centrioles, centrosomes (discussed under the cytoskeleton), and lysosomes, whereas plant cells do not. plant cells have a cell wall, chloroplasts, plasmodesmata, and plastids used for storage, and a large central vacuole, whereas animal cells do not.  the cell wall  in figure below, the diagram of a plant cell, you see a structure external to the plasma membrane called the cell wall. the cell wall is a rigid covering that protects the cell, provides structural support, and gives shape to the cell. fungal and protist cells also have cell walls. while the chief component of prokaryotic cell walls is peptidoglycan, the major organic molecule in the plant cell wall is cellulose, a polysaccharide made up of long, straight chains of glucose units. when nutritional information refers to dietary fiber, it is referring to the cellulose content of food.  figure \(\pageindex{3}\): the figure shows a typical animal cell (top) and a typical plant cell (bottom).  chloroplasts  like mitochondria, chloroplasts also have their own dna and ribosomes. chloroplasts function in photosynthesis and can be found in eukaryotic cells such as plants and algae. in photosynthesis, carbon dioxide, water, and light energy are used to make glucose and oxygen. this is the major difference between plants and animals: plants (autotrophs) are able to make their own food, like glucose, whereas animals (heterotrophs) must rely on other organisms for their organic compounds or food source. like mitochondria, chloroplasts have outer and inner membranes, but within the space enclosed by a chloroplast’s inner membrane is a set of interconnected and stacked, fluid-filled membrane sacs called thylakoids (figure below).  figure \(\pageindex{4}\): this simplified diagram of a chloroplast shows the outer membrane, inner membrane, thylakoids, grana, and stroma.  each stack of thylakoids is called a granum (plural = grana). the fluid enclosed by the inner membrane and surrounding the grana is called the stroma.  contributors and attributions  template:contribccessofenvsc",t_c8e6c65909f8,other,0
c_1a28283d9518,"4.5.1 periodically forced oscillation  let us return to the forced oscillations. consider a mass-spring system as before, where we have a mass \(m\) on a spring with spring constant \(k\), with damping \(c\), and a force \(f(t)\) applied to the mass. suppose the forcing function \(f(t)\) is \(2l\)-periodic for some \(l>0\). we have already seen this problem in chapter 2 with a simple \(f(t)\).  the equation that governs this particular setup is  \[ mx''(t)+cx'(t)+kx(t)=f(t). \]  the general solution consists of the complementary solution \(x_c\), which solves the associated homogeneous equation \( mx''+cx'+kx=0\), and a particular solution of equation 4.5.1 we call \(x_p\). for \(c>0\), the complementary solution \(x_c\) will decay as time goes by. therefore, we are mostly interested in a particular solution \(x_p\) that does not decay and is periodic with the same period as \(f(t)\). we call this particular solution the steady periodic solution and we write it as \(x_{sp}\) as before. what will be new in this section is that we consider an arbitrary forcing function \(f(t)\) instead of a simple cosine.  for simplicity, let us suppose that \(c=0\). the problem with \(c>0\) is very similar. the equation  \[ mx''+kx=0\]  has the general solution  \[ x(t)= a \cos(\omega_0 t)+ b \sin(\omega_0 t),\]  where \( \omega_0= \sqrt{\dfrac{k}{m}}\). any solution to \(mx''(t)+kx(t)=f(t)\) is of the form \(a \cos(\omega_0 t)+ b \sin(\omega_0 t)+x_{sp}\). the steady periodic solution \(x_{sp}\) has the same period as \(f(t)\).  in the spirit of the last section and the idea of undetermined coefficients we first write  \[ f(t)= \dfrac{c_0}{2}+ \sum^{\infty}_{n=1} c_n \cos \left(\dfrac{n \pi}{l}t \right)+ d_n \sin \left(\dfrac{n \pi}{l}t \right).\]  then we write a proposed steady periodic solution \(x\) as  \[ x(t)= \dfrac{a_0}{2}+ \sum^{\infty}_{n=1} a_n \cos \left(\dfrac{n \pi}{l}t \right)+ b_n \sin \left(\dfrac{n \pi}{l}t \right),\]  where \(a_n\) and \(b_n\) are unknowns. we plug \(x\) into the differential equation and solve for \(a_n\) and \(b_n\) in terms of \(c_n\) and \(d_n\). this process is perhaps best understood by example.  example 4.5.1  suppose that \( k=2\), and \( m=1\). the units are again the mks units (meters-kilograms-seconds). there is a jetpack strapped to the mass, which fires with a force of 1 newton for 1 second and then is off for 1 second, and so on. we want to find the steady periodic solution.  solution  the equation is, therefore,  \[x''+2x=f(t),\]  where \(f(t)\) is the step function  \[f(t)= \left\{ \begin{array}{ccc} 0 & {\rm{if}} & -1<t<0, \\ 1 & {\rm{if}} & 0<t<1, \end{array} \right.\]  extended periodically. we write  \[ f(t)= \dfrac{c_0}{2}+ \sum^{\infty}_{n=1} c_n \cos(n \pi t)+ d_n \sin(n \pi t).\]  we compute  \[ c_n= \int^1_{-1} f(t) \cos(n \pi t)dt= \int^1_{0}  \cos(n \pi t)dt= 0 ~~~~~ {\rm{for}}~ n \geq 1, \\  c_0= \int^1_{-1} f(t) dt= \int^1_{0} dt=1, \\ d_n= \int^1_{-1} f(t) \sin(n \pi t)dt \\ = \int^1_{0} \sin(n \pi t)dt \\ \left[ \dfrac{- \cos(n \pi t)}{n \pi}\right]^1_{t=0} \\ = \dfrac{1-(-1)^n}{\pi n}= \left\{ \begin{array}{ccc} \dfrac{2}{\pi n} & {\rm{if~}} n {\rm{~odd}}, \\ 0 & {\rm{if~}} n {\rm{~even}}. \end{array} \right.\]  so  \[ f(t)= \dfrac{1}{2}+ \sum^{\infty}_{ \underset{n ~\rm{odd}}{n=1} }\dfrac{2}{\pi n} \sin(n \pi t).\]  we want to try  \[ x(t)= \dfrac{a_0}{2}+ \sum_{n=1}^{\infty} a_n \cos(n \pi t)+ b_n \sin(n \pi t).\]  once we plug  into the differential equation \( x'' + 2x = f(t)\), it is clear that \(a_n=0\) for \(n \geq 1\) as there are no corresponding terms in the series for \(f(t)\). similarly \(b_n=0\) for \(n\) even. hence we try  \[ x(t)= \dfrac{a_0}{2}+ \sum_{\underset{n ~\rm{odd}}{n=1}}^{\infty} b_n \sin(n \pi t). \]  we plug into the differential equation and obtain  \[ x''+2x = \sum_{\underset{n ~\rm{odd}}{n=1}}^{\infty} \left[ -b_n n^2 \pi^2 \sin(n \pi t) \right] +a_0+2 \sum_{\underset{n ~\rm{odd}}{n=1}}^{\infty} \left[ b_n \sin(n \pi t) \right] \\ = a_0+ \sum_{\underset{n ~\rm{odd}}{n=1}}^{\infty} b_n(2-n^2 \pi^2) \sin(n \pi t) \\ = f(t)= \dfrac{1}{2}+ \sum_{\underset{n ~\rm{odd}}{n=1}}^{\infty} \dfrac{2}{\pi n} \sin(n \pi t).\]  so \(a_0= \dfrac{1}{2}\), \(b_n= 0\) for even \(n\), and for odd \(n\) we get  \[ b_n= \dfrac{2}{\pi n(2-n^2 \pi^2)}.\]  the steady periodic solution has the fourier series  \[  x_{sp}(t)= \dfrac{1}{4}+ \sum_{\underset{n ~\rm{odd}}{n=1}}^{\infty} \dfrac{2}{\pi n(2-n^2 \pi^2)} \sin(n \pi t).\]  we know this is the steady periodic solution as it contains no terms of the complementary solution and it is periodic with the same period as \(f(t)\) itself. see figure 4.12 for the plot of this solution.  figure 4.12: plot of the steady periodic solution \(x_{sp}\) of example 4.5.1.  4.5.2 resonance  just like when the forcing function was a simple cosine, resonance could still happen. let us assume \(c=0\) and we will discuss only pure resonance. again, take the equation  \[ mx''(t)+kx(t)=f(t). \]  when we expand \(f(t)\) and find that some of its terms coincide with the complementary solution to \( mx''+kx=0\), we cannot use those terms in the guess. just like before, they will disappear when we plug into the left hand side and we will get a contradictory equation (such as \(0=1\)). that is, suppose  \[ x_c=a \cos(\omega_0 t)+b \sin(\omega_0 t),\]  where \( \omega_0= \dfrac{n \pi}{l}\) for some positive integer \(n\). in this case we have to modify our guess and try  \[  x(t)= \dfrac{a_0}{2}+t \left( a_n \cos \left( \dfrac{n \pi}{l}t \right)+ b_n \sin \left( \dfrac{n \pi}{l}t \right)  \right) + \sum_{\underset{n \neq n}{n=1}}^{\infty} a_n \cos \left( \dfrac{n \pi}{l}t \right)+ b_n \sin \left( \dfrac{n \pi}{l}t \right). \]  in other words, we multiply the offending term by \(t\). from then on, we proceed as before.  of course, the solution will not be a fourier series (it will not even be periodic) since it contains these terms multiplied by \(t\). further, the terms \( t \left( a_n \cos \left( \dfrac{n \pi}{l}t \right)+ b_n \sin \left( \dfrac{n \pi}{l}t \right)  \right) \) will eventually dominate and lead to wild oscillations. as before, this behavior is called pure resonance or just resonance.  note that there now may be infinitely many resonance frequencies to hit. that is, as we change the frequency of \(f\) (we change \(l\)), different terms from the fourier series of \(f\) may interfere with the complementary solution and will cause resonance. however, we should note that since everything is an approximation and in particular \(c\) is never actually zero but something very close to zero, only the first few resonance frequencies will matter.  example 4.5.2  find the steady periodic solution to the equation  \[  2x''+18 \pi^2 x=f(t),\]  where  \[f(t)= \left\{ \begin{array}{ccc} -1 & {\rm{if}} & -1<t<0, \\ 1 & {\rm{if}} & 0<t<1, \end{array} \right.\]  extended periodically. we note that  \[  f(t)= \sum^{\infty}_{ \underset{n ~\rm{odd}}{n=1} } \dfrac{4}{\pi n} \sin(n \pi t).\]  ﻿  example 4.5.3  compute the fourier series of \(f\) to verify the above equation.  the solution must look like  \[ x(t)= c_1 \cos(3 \pi t)+ c_2 \sin(3 \pi t)+x_p(t)\]  for some particular solution \(x_p\).  we note that if we just tried a fourier series with \(\sin(n \pi t)\) as usual, we would get duplication when \(n=3\). therefore, we pull out that term and multiply by \(t\). we also have to add a cosine term to get everything right. that is, we must try  \[ x_p(t)= a_3 t \cos(3 \pi t) + b_3 t \sin(3 \pi t) + \sum^{\infty}_{ \underset{\underset{n \neq 3}{n ~\rm{odd}}}{n=1} } b_n \sin(n \pi t).\]  let us compute the second derivative.  \[ x_p''(t)= -6a_3 \pi \sin(3 \pi t) -9 \pi^2 a_3 t \cos(3 \pi t) + 6b_3 \pi \cos(3 \pi t) -9 \pi^2 b_3 t \sin(3 \pi t) +\sum^{\infty}_{ \underset{\underset{n \neq 3}{n ~\rm{odd}}}{n=1} } (-n^2 \pi^2 b_n) \sin(n \pi t).\]  we now plug into the left hand side of the differential equation.  \[ 2x''_p + 18 \pi^2 x=-12a_3 \pi \sin(3\pi t)-18 \pi^2 a_3 t \cos(3 \pi t)+12 b_3 \pi \cos(3 \pi t)-18 \pi^2 b_3 t \sin(3 \pi t) +18 \pi^2 a_3 t \cos(3 \pi t)+18 \pi^2 b_3 t \sin(3 \pi t)+  \sum^{\infty}_{ \underset{\underset{n \neq 3}{n ~\rm{odd}}}{n=1} } (-n^2 \pi^2 b_n+18 \pi^2 b_n) \sin(n \pi t).\]  \[ 2x''_p + 18 \pi^2 x=-12a_3 \pi \sin(3\pi t)-18 \pi^2 a_3 t \cos(3 \pi t)+12 b_3 \pi \cos(3 \pi t)-18 \pi^2 b_3 t \sin(3 \pi t)+ \\  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~+18 pi^2 a_3 t \cos(3 \pi t)~~~~~~~~~~~~~~~~~+18 \pi^2 b_3 t \sin(3 \pi t)+ \\  ~~~~~~~~~~~~~~~~~~~~~~~~~~ \sum^{\infty}_{ \underset{\underset{n \neq 3}{n ~\rm{odd}}}{n=1} } (-n^2 \pi^2 b_n+18 \pi^2 b_n) \sin(n \pi t).\]  if we simplify we obtain  \[ 2x_p'' +18 \pi^2 x= -12a_3 \pi \sin(3 \pi t)+ 12b_3 \pi \cos(3 \pi t) +\sum^{\infty}_{ \underset{\underset{n \neq 3}{n ~\rm{odd}}}{n=1} } (-2n^2 \pi^2 b_n+ 18 \pi^2 b_n) \sin(n \pi t.)\]  ---- |  |  ----  this series has to equal to the series for \(f(t)\). we equate the coefficients and solve for \(a_3\) and \(b_n\).  \[ a_3= \frac{4/(3 \pi)}{-12 \pi}= \frac{-1}{9 \pi^2}, \\ b_3 = 0, \\ b_n = \frac{4}{n \pi(18 \pi^2 -2n^2 \pi^2)}=\frac{2}{\pi^3 n(9-n^2 )} ~~~~~~ {\rm{for~}} n {\rm{~odd~and~}} n \neq 3.\]  that is,  \[ x_p(t)= \frac{-1}{9 \pi^2}t \cos(3 \pi t)+ \sum^{\infty}_{ \underset{\underset{n \neq 3}{n ~\rm{odd}}}{n=1} } \frac{2}{\pi^3 n(9-n^2)} \sin(n \pi t.)\]  ---- |  |  ----  when \(c&gt;0\), you will not have to worry about pure resonance. that is, there will never be any conflicts and you do not need to multiply any terms by \(t\). there is a corresponding concept of practical resonance and it is very similar to the ideas we already explored in chapter 2 (http://www.jirka.org/diffyqs/htmlver/diffyqsch2.html#x14-320002). we will not go into details here.  contributors  jiří lebl (http://www.jirka.org/diffyqs/) (oklahoma state university (http://www.math.okstate.edu/)).these pages were supported by nsf grants dms-0900885 and dms-1362337.",t_cec0e6a3f890,other,0
c_3d6e4535641a,"chapter 21 | viruses  849  21 | viruses  figure 21.1 the tobacco mosaic virus (left), seen here by transmission electron microscopy, was the first virus to be discovered. the virus causes disease in tobacco and other plants, such as the orchid (right). (credit a: usda ars; credit b: modification of work by usda forest service, department of plant pathology archive north carolina state university; scale-bar data from matt russell)  chapter outline 21.1: viral evolution, morphology, and classification 21.2: virus infection and hosts 21.3: prevention and treatment of viral infections 21.4: other acellular entities: prions and viroids  introduction have you ever had the measles? like many other diseases, it begins with a fever, runny nose, and sore throat. soon after, a rash begins to cover the body. in about 30% of measles cases other complications develop, such as pneumonia, encephalitis (swelling of the brain), and even death. though the first recorded account of the measles was in the 9th century, it was not until 1912 that healthcare providers in the united states began reporting cases. between 1912 and 1922, there were over 6,000 deaths related to the measles. this trend continued until 1963, when the first measles vaccine became available. the measles was declared eliminated from the united states in 2000 primarily due to the fact that the vast majority of children were receiving two doses of the vaccine. on january 23, 2015, the center for disease control issued a health advisory about an outbreak of measles in several states . the outbreak originated at a popular theme park in california in december 2014 when an infected tourist from another country visited the theme park. many of the people who became infected were not vaccinated or had not received the second dose of the vaccination. you can read more about the health advisory at the cdc website (http://openstaxcollege.org/l/32measles) . no one knows exactly when viruses emerged or from where they came, since viruses do not leave historical footprints such as fossils. modern viruses are thought to be a mosaic of bits and pieces of nucleic acids picked up from various sources along their respective evolutionary paths. viruses are acellular, parasitic entities that are not classified within any kingdom. unlike most living organisms, viruses are not cells and cannot divide. instead, they infect a host cell and use the host’s replication processes to produce identical progeny virus particles. viruses infect organisms as diverse as bacteria, plants, and animals. they exist in a netherworld between a living organism and a nonliving entity. living things grow, metabolize, and reproduce. viruses replicate, but to do so, they are entirely dependent on their host cells. they do not metabolize or grow, but are assembled in their mature form.  850  chapter 21 | viruses  21.1 | viral evolution, morphology, and classification in this section, you will explore the following questions: • how were viruses first discovered and how are they detected? • what three hypotheses describe the evolution of viruses? • what is the basic structure of a virus? • how are viruses classified?  connection for ap® courses the first organisms that originated about 3.5 billion years ago were prokaryotes that possessed the structures and metabolic processes associated with cells (refer to the cell structure chapter). as discussed in the chapter on cell structure, prokaryotic cells are much smaller than eukaryotic cells and inhabit just about every square inch of our planet, from the most inhospitable environments to the surface of the skin. viruses are much smaller than prokaryotes and much simpler in structure. they must reproduce inside a host cell. their origin is still a mystery to us, but we do know that they can make us very sick. viruses have a basic structure: a dna or rna core surrounded by an outer capsid of proteins. some viruses have an outer phospholipid envelope. as we will explore in more detail, many viruses use some sort of glycoprotein to attach to their host cells. viruses infect all known cell types and use the host cell’s replication proteins and metabolic machinery to replicate. classification of viruses is challenging, but one method categorizes them based on how they produce their mrna. retroviruses (also called rna viruses) use the enzyme reverse transcriptase to transcribe dna from rna. (in the genes and proteins chapter we learned that the usual flow of genetic information is from dna to rna to protein.) common viruses include bacteriophage t4, adenovirus, and hiv retrovirus. information presented and the examples highlighted in the section support concepts outlined in big idea 3 of the ap® biology curriculum framework. the ap® learning objectives listed in the curriculum framework provide a transparent foundation for the ap® biology course, an inquiry-based laboratory experience, instructional activities, and ap® exam questions. a learning objective merges required content with one or more of the seven science practices.  big idea 3  living systems store, retrieve, transmit and respond to information essential to life processes.  enduring understanding heritable information provides for continuity of life. 3.a essential knowledge  3.a.1 dna, and in some cases rna, is the primary source of heritable information.  science practice  6.5 the student can evaluate alternative scientific explanations.  learning objective  3.1 the student is able to construct scientific explanations that use the structures and mechanisms of dna and rna to support the claim that dna and, in some cases, that rna are the primary sources of heritable information.  the science practice challenge questions contain additional test questions for this section that will help you prepare for the ap exam. these questions address the following standards: [aplo 2.20][aplo 3.3][aplo 3.29][aplo 3.30][aplo 2.22][aplo 2.26][aplo 1.31][aplo 1.27][aplo 1.30]  discovery and detection viruses were first discovered after the development of a porcelain filter, called the chamberland-pasteur filter, which could remove all bacteria visible in the microscope from any liquid sample. in 1886, adolph meyer demonstrated that a disease of  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  851  tobacco plants, tobacco mosaic disease, could be transferred from a diseased plant to a healthy one via liquid plant extracts. in 1892, dmitri ivanowski showed that this disease could be transmitted in this way even after the chamberland-pasteur filter had removed all viable bacteria from the extract. still, it was many years before it was proven that these “filterable” infectious agents were not simply very small bacteria but were a new type of very small, disease-causing particle. virions, single virus particles, are very small, about 20–250 nanometers in diameter. these individual virus particles are the infectious form of a virus outside the host cell. unlike bacteria (which are about 100-times larger), we cannot see viruses with a light microscope, with the exception of some large virions of the poxvirus family. it was not until the development of the electron microscope in the late 1930s that scientists got their first good view of the structure of the tobacco mosaic virus (tmv) (figure 21.1) and other viruses (figure 21.2). the surface structure of virions can be observed by both scanning and transmission electron microscopy, whereas the internal structures of the virus can only be observed in images from a transmission electron microscope. the use of these technologies has allowed for the discovery of many viruses of all types of living organisms. they were initially grouped by shared morphology. later, groups of viruses were classified by the type of nucleic acid they contained, dna or rna, and whether their nucleic acid was single- or double-stranded. more recently, molecular analysis of viral replicative cycles has further refined their classification.  figure 21.2 in these transmission electron micrographs, (a) a virus is dwarfed by the bacterial cell it infects, while (b) these e. coli cells are dwarfed by cultured colon cells. (credit a: modification of work by u.s. dept. of energy, office of science, lbl, pbd; credit b: modification of work by j.p. nataro and s. sears, unpub. data, cdc; scale-bar data from matt russell)  evolution of viruses although biologists have accumulated a significant amount of knowledge about how present-day viruses evolve, much less is known about how viruses originated in the first place. when exploring the evolutionary history of most organisms, scientists can look at fossil records and similar historic evidence. however, viruses do not fossilize, so researchers must conjecture by investigating how today’s viruses evolve and by using biochemical and genetic information to create speculative virus histories. while most findings agree that viruses don’t have a single common ancestor, scholars have yet to find a single hypothesis about virus origins that is fully accepted in the field. one such hypothesis, called devolution or the regressive hypothesis, proposes to explain the origin of viruses by suggesting that viruses evolved from free-living cells. however, many components of how this process might have occurred are a mystery. a second hypothesis (called escapist or the progressive hypothesis) accounts for viruses having either an rna or a dna genome and suggests that viruses originated from rna and dna molecules that escaped from a host cell. a third hypothesis posits a system of self-replication similar to that of other self-replicating molecules, likely evolving alongside the cells they rely on as hosts; studies of some plant pathogens support this hypothesis. as technology advances, scientists may develop and refine further hypotheses to explain the origin of viruses. the emerging field called virus molecular systematics attempts to do just that through comparisons of sequenced genetic material. these  852  chapter 21 | viruses  researchers hope to one day better understand the origin of viruses, a discovery that could lead to advances in the treatments for the ailments they produce.  viral morphology viruses are acellular, meaning they are biological entities that do not have a cellular structure. they therefore lack most of the components of cells, such as organelles, ribosomes, and the plasma membrane. a virion consists of a nucleic acid core, an outer protein coating or capsid, and sometimes an outer envelope made of protein and phospholipid membranes derived from the host cell. viruses may also contain additional proteins, such as enzymes. the most obvious difference between members of viral families is their morphology, which is quite diverse. an interesting feature of viral complexity is that the complexity of the host does not correlate with the complexity of the virion. some of the most complex virion structures are observed in bacteriophages, viruses that infect the simplest living organisms, bacteria. morphology viruses come in many shapes and sizes, but these are consistent and distinct for each viral family. all virions have a nucleic acid genome covered by a protective layer of proteins, called a capsid. the capsid is made up of protein subunits called capsomeres. some viral capsids are simple polyhedral “spheres,” whereas others are quite complex in structure. in general, the shapes of viruses are classified into four groups: filamentous, isometric (or icosahedral), enveloped, and head and tail. filamentous viruses are long and cylindrical. many plant viruses are filamentous, including tmv. isometric viruses have shapes that are roughly spherical, such as poliovirus or herpesviruses. enveloped viruses have membranes surrounding capsids. animal viruses, such as hiv, are frequently enveloped. head and tail viruses infect bacteria and have a head that is similar to icosahedral viruses and a tail shape like filamentous viruses. many viruses use some sort of glycoprotein to attach to their host cells via molecules on the cell called viral receptors (figure 21.3). for these viruses, attachment is a requirement for later penetration of the cell membrane, so they can complete their replication inside the cell. the receptors that viruses use are molecules that are normally found on cell surfaces and have their own physiological functions. viruses have simply evolved to make use of these molecules for their own replication. for example, hiv uses the cd4 molecule on t lymphocytes as one of its receptors. cd4 is a type of molecule called a cell adhesion molecule, which functions to keep different types of immune cells in close proximity to each other during the generation of a t lymphocyte immune response.  figure 21.3 the kshv virus binds the xct receptor on the surface of human cells. xct receptors protect cells against stress. stressed cells express more xct receptors than non-stressed cells. the kshv virion causes cells to become stressed, thereby increasing expression of the receptor to which it binds. (credit: modification of work by niaid, nih)  among the most complex virions known, the t4 bacteriophage, which infects the escherichia coli bacterium, has a tail structure that the virus uses to attach to host cells and a head structure that houses its dna. adenovirus, a non-enveloped animal virus that causes respiratory illnesses in humans, uses glycoprotein spikes protruding from its capsomeres to attach to host cells. non-enveloped viruses also include those that cause polio (poliovirus), plantar  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  853  warts (papillomavirus), and hepatitis a (hepatitis a virus). enveloped virions like hiv, the causative agent in aids, consist of nucleic acid (rna in the case of hiv) and capsid proteins surrounded by a phospholipid bilayer envelope and its associated proteins. glycoproteins embedded in the viral envelope are used to attach to host cells. other envelope proteins are the matrix proteins that stabilize the envelope and often play a role in the assembly of progeny virions. chicken pox, influenza, and mumps are examples of diseases caused by viruses with envelopes. because of the fragility of the envelope, non-enveloped viruses are more resistant to changes in temperature, ph, and some disinfectants than enveloped viruses. overall, the shape of the virion and the presence or absence of an envelope tell us little about what disease the virus may cause or what species it might infect, but they are still useful means to begin viral classification (figure 21.4).  figure 21.4 viruses can be either complex in shape or relatively simple. this figure shows three relatively complex virions: the bacteriophage t4, with its dna-containing head group and tail fibers that attach to host cells; adenovirus, which uses spikes from its capsid to bind to host cells; and hiv, which uses glycoproteins embedded in its envelope to bind to host cells. notice that hiv has proteins called matrix proteins, internal to the envelope, which help stabilize virion shape. (credit “bacteriophage, adenovirus”: modification of work by ncbi, nih; credit “hiv retrovirus”: modification of work by niaid, nih)  which of the following statements about viral structure is true? a. viruses are very similar in structure. b. the capsomere is made up of small protein subunits called capsids. c. dna is the genetic material in all viruses. d. glycoproteins help the virus attach to the host cell. types of nucleic acid unlike nearly all living organisms that use dna as their genetic material, viruses may use either dna or rna as theirs. the virus core contains the genome or total genetic content of the virus. viral genomes tend to be small, containing only those genes that encode proteins that the virus cannot get from the host cell. this genetic material may be single- or doublestranded. it may also be linear or circular. while most viruses contain a single nucleic acid, others have genomes that have several, which are called segments.  854  chapter 21 | viruses  in dna viruses, the viral dna directs the host cell’s replication proteins to synthesize new copies of the viral genome and to transcribe and translate that genome into viral proteins. dna viruses cause human diseases such as chickenpox and hepatitis b. rna viruses contain only rna as their genetic material. to replicate their genomes in the host cell, the rna viruses encode enzymes that can replicate rna into dna, which cannot be done by the host cell. these rna polymerase enzymes are more likely to make copying errors than dna polymerases, and therefore often make mistakes during transcription. for this reason, mutations in rna viruses occur more frequently than in dna viruses. this causes them to change and adapt more rapidly to their host. human diseases caused by rna viruses include hepatitis c, measles, and rabies.  virus classification to understand the features shared among different groups of viruses, a classification scheme is necessary. as most viruses are not thought to have evolved from a common ancestor, however, the methods that scientists use to classify living things are not very useful. biologists have used several classification systems in the past, based on the morphology and genetics of the different viruses. however, these earlier classification methods grouped viruses differently, based on which features of the virus they were using to classify them. the most commonly used classification method today is called the baltimore classification scheme and is based on how messenger rna (mrna) is generated in each particular type of virus. past systems of classification viruses are classified in several ways: by factors such as their core content (table 21.1 and figure 21.3), the structure of their capsids, and whether they have an outer envelope. the type of genetic material (dna or rna) and its structure (single- or double-stranded, linear or circular, and segmented or non-segmented) are used to classify the virus core structures.  virus classification by genome structure and core core classifications  examples  rna  rabies virus, retroviruses  dna  herpesviruses, smallpox virus  single-stranded  rabies virus, retroviruses  double-stranded  herpesviruses, smallpox virus  linear  rabies virus, retroviruses, herpesviruses, smallpox virus  circular non-segmented: genome consists of a single segment of genetic material segmented: genome is divided into multiple segments table 21.1  this openstax book is available for free at http://cnx.org/content/col12078/1.6  papillomaviruses, many bacteriophages parainfluenza viruses influenza viruses  chapter 21 | viruses  855  figure 21.5 viruses are classified based on their core genetic material and capsid design. (a) rabies virus has a single-stranded rna (ssrna) core and an enveloped helical capsid, whereas (b) variola virus, the causative agent of smallpox, has a double-stranded dna (dsdna) core and a complex capsid. rabies transmission occurs when saliva from an infected mammal enters a wound. the virus travels through neurons in the peripheral nervous system to the central nervous system where it impairs brain function, and then travels to other tissues. the virus can infect any mammal, and most die within weeks of infection. smallpox is a human virus transmitted by inhalation of the variola virus, localized in the skin, mouth, and throat, which causes a characteristic rash. before its eradication in 1979, infection resulted in a 30–35 percent mortality rate. (credit “rabies diagram”: modification of work by cdc; “rabies micrograph”: modification of work by dr. fred murphy, cdc; credit “small pox micrograph”: modification of work by dr. fred murphy, sylvia whitfield, cdc; credit “smallpox photo”: modification of work by cdc; scale-bar data from matt russell)  viruses can also be classified by the design of their capsids (figure 21.4 and figure 21.5). capsids are classified as naked icosahedral, enveloped icosahedral, enveloped helical, naked helical, and complex (figure 21.6 and figure 21.7). the type of genetic material (dna or rna) and its structure (single- or double-stranded, linear or circular, and segmented or nonsegmented) are used to classify the virus core structures (table 21.2).  figure 21.6 adenovirus (left) is depicted with a double-stranded dna genome enclosed in an icosahedral capsid that is 90–100 nm across. the virus, shown clustered in the micrograph (right), is transmitted orally and causes a variety of illnesses in vertebrates, including human eye and respiratory infections. (credit “adenovirus”: modification of work by dr. richard feldmann, national cancer institute; credit “micrograph”: modification of work by dr. g. william gary, jr., cdc; scale-bar data from matt russell)  856  chapter 21 | viruses  virus classification by capsid structure capsid classification  examples  naked icosahedral  hepatitis a virus, polioviruses  enveloped icosahedral  epstein-barr virus, herpes simplex virus, rubella virus, yellow fever virus, hiv-1  enveloped helical  influenza viruses, mumps virus, measles virus, rabies virus  naked helical  tobacco mosaic virus  complex with many proteins; some have combinations of icosahedral and helical capsid structures  herpesviruses, smallpox virus, hepatitis b virus, t4 bacteriophage  table 21.2  figure 21.7 transmission electron micrographs of various viruses show their structures. the capsid of the (a) polio virus is naked icosahedral; (b) the epstein-barr virus capsid is enveloped icosahedral; (c) the mumps virus capsid is an enveloped helix; (d) the tobacco mosaic virus capsid is naked helical; and (e) the herpesvirus capsid is complex. (credit a: modification of work by dr. fred murphy, sylvia whitfield; credit b: modification of work by liza gross; credit c: modification of work by dr. f. a. murphy, cdc; credit d: modification of work by usda ars; credit e: modification of work by linda stannard, department of medical microbiology, university of cape town, south africa, nasa; scale-bar data from matt russell)  baltimore classification the most commonly used system of virus classification was developed by nobel prize-winning biologist david baltimore in the early 1970s. in addition to the differences in morphology and genetics mentioned above, the baltimore classification scheme groups viruses according to how the mrna is produced during the replicative cycle of the virus. group i viruses contain double-stranded dna (dsdna) as their genome. their mrna is produced by transcription in much the same way as with cellular dna. group ii viruses have single-stranded dna (ssdna) as their genome. they convert their single-stranded genomes into a dsdna intermediate before transcription to mrna can occur. group iii viruses use dsrna as their genome. the strands separate, and one of them is used as a template for the generation of mrna using the rna-dependent rna polymerase encoded by the virus. group iv viruses have ssrna as their genome with a positive polarity. positive polarity means that the genomic rna can serve directly as mrna. intermediates of dsrna, called replicative intermediates, are made in the process of copying the genomic rna. multiple, full-length rna strands  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  857  of negative polarity (complementary to the positive-stranded genomic rna) are formed from these intermediates, which may then serve as templates for the production of rna with positive polarity, including both full-length genomic rna and shorter viral mrnas. group v viruses contain ssrna genomes with a negative polarity, meaning that their sequence is complementary to the mrna. as with group iv viruses, dsrna intermediates are used to make copies of the genome and produce mrna. in this case, the negative-stranded genome can be converted directly to mrna. additionally, fulllength positive rna strands are made to serve as templates for the production of the negative-stranded genome. group vi viruses have diploid (two copies) ssrna genomes that must be converted, using the enzyme reverse transcriptase, to dsdna; the dsdna is then transported to the nucleus of the host cell and inserted into the host genome. then, mrna can be produced by transcription of the viral dna that was integrated into the host genome. group vii viruses have partial dsdna genomes and make ssrna intermediates that act as mrna, but are also converted back into dsdna genomes by reverse transcriptase, necessary for genome replication. the characteristics of each group in the baltimore classification are summarized in table 21.3 with examples of each group.  baltimore classification group  characteristics  mode of mrna production  example herpes simplex (herpesvirus)  i  double-stranded dna  mrna is transcribed directly from the dna template  ii  single-stranded dna  canine dna is converted to double-stranded form before rna is parvovirus transcribed (parvovirus)  iii  double-stranded rna  mrna is transcribed from the rna genome  childhood gastroenteritis (rotavirus)  iv  single stranded rna (+)  genome functions as mrna  common cold (pircornavirus)  v  single stranded rna (-)  mrna is transcribed from the rna genome  rabies (rhabdovirus)  vi  single stranded rna viruses with reverse transcriptase  reverse transcriptase makes dna from the rna genome; dna is then incorporated in the host genome; mrna is transcribed from the incorporated dna  human immunodeficiency virus (hiv)  vii  double stranded dna viruses with reverse transcriptase  the viral genome is double-stranded dna, but viral dna hepatitis b virus is replicated through an rna intermediate; the rna may (hepadnavirus) serve directly as mrna or as a template to make mrna  table 21.3  21.2 | virus infection and hosts in this section, you will explore the following questions: • what are the steps in viral replication, and what events occur in each? • what is the difference between the lytic and lysogenic cycles of virus replication? • how are plant and animal viruses transmitted, what are examples of virus-caused diseases in plants and animals, and what are the economic impacts of plant viruses?  858  chapter 21 | viruses  connection for ap® courses viruses differ from other organisms in their method of replication. viruses replicate within a living host cell, producing changes in the cell that often result in the death of the infected cell. thus, viruses are considered intracellular parasites. viral replication involves several steps: attachment, penetration, replication, assembly, and release. viruses are host-specific because they only can attach to and infect cells of certain organisms. cells that a virus may use to replicate are called permissive. the virus attacks the host cell by first attaching to a specific receptor site on the membrane of the host cell. next, the viral nucleic acid, either dna or rna, enters the host cell, either naked, leaving the protein capsid behind, or with the capsid. if the capsid enters the cell, an additional uncoating step is needed. viral nucleic acid then becomes available for replication and transcription. the last stage of viral replication is the release of the new virions produced by the host that are able to infect other cells. depending on the type of virus, the replication cycle facilitates the transfer of genetic information through the lytic and lysogenic cycles. bacteriophages, such as t4 are viruses that infect bacterial cells, can enter both the lytic and lysogenic cycles. animal viruses cause a variety of infections, for example, hepatitis c, herpes, hpv, colds, and flu. occasionally, viruses can “hide” and remain latent (dormant) in cells such as nerve or liver cells for months, or even years; for example, the varicellazoster virus that causes chickenpox in children can reactivate in adults to cause the painful condition known as “shingles.” oncogenic viruses in animals can cause cancer by interfering with the regulation of the host cell cycle. plant viruses can cause considerable economic damage caused by poor crop quality and quantity globally. information presented and the examples highlighted in the section support concepts outlined in big idea 3 of the ap® biology curriculum framework. the ap® learning objectives listed in the curriculum framework provide a transparent foundation for the ap® biology course, an inquiry-based laboratory experience, instructional activities, and ap® exam questions. a learning objective merges required content with one or more of the seven science practices.  big idea 3  living systems store, retrieve, transmit and respond to information essential to life processes.  enduring understanding 3.c  the processing of genetic information is imperfect and is a source of genetic variation.  essential knowledge  3.c.3 viral replication results in genetic variation, and viral infection can introduce genetic variation into the hosts.  science practice  6.2 the student can construct explanations of phenomena based on evidence produced through scientific practices.  learning objective  3.29 the student is able to construct an explanation of how viruses introduce genetic variation in host organisms.  essential knowledge  3.c.3 viral replication results in genetic variation, and viral infection can introduce genetic variation into the hosts.  science practice  1.4 the student can use representations and models to analyze situations or solve problems qualitatively and quantitatively.  learning objective  3.30 the student is able to use representations and appropriate models to describe how viral replication introduces genetic variation in the viral population.  the science practice challenge questions contain additional test questions for this section that will help you prepare for the ap exam. these questions address the following standards: [aplo 3.1][aplo 3.27][aplo 3.29][aplo 1.3][aplo 2.38][aplo 3.40][aplo 3.30]  steps of virus infections a virus must use cell processes to replicate. the viral replication cycle can produce dramatic biochemical and structural changes in the host cell, which may cause cell damage. these changes, called cytopathic (causing cell damage) effects, can change cell functions or even destroy the cell. some infected cells, such as those infected by the common cold virus known as rhinovirus, die through lysis (bursting) or apoptosis (programmed cell death), releasing all progeny virions at once. the symptoms of viral diseases result from the immune response to the virus, which attempts to control and eliminate  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  859  the virus from the body, and from cell damage caused by the virus. many animal viruses leave the infected cells of the immune system by a process known as budding, where virions leave the cell individually. during the budding process, the cell does not undergo lysis and is not immediately killed. however, the damage to the cells that the virus infects may make it impossible for the cells to function normally, even though the cells remain alive for a period of time. most productive viral infections follow similar steps in the virus replication cycle: attachment, penetration, uncoating, replication, assembly, and release (figure 21.8). attachment a virus attaches to a specific receptor site on the host cell membrane through attachment proteins in the capsid or via glycoproteins embedded in the viral envelope. the specificity of this interaction determines the host—and the cells within the host—that can be infected by a particular virus. this can be illustrated by thinking of several keys and several locks, where each key will fit only one specific lock.  this video (http://openstaxcollege.org/l/influenza) explains how influenza attacks the body. the video shows how viruses replicate in our body. using the terminology provided in the video, explain how a virus attaches to a cell in our body? a. when the virus capsule makes contact with the cell, it bursts, and then the virions attach to the cell. b. if a key on the virus fits a lock on the surface of the cell, the virus will attach to the cell. c. the keys automatically attach to all the locks. d. the welcoming committee interlocks with the virus. entry the nucleic acid of bacteriophages enters the host cell naked, leaving the capsid outside the cell. plant and animal viruses can enter through endocytosis, in which the cell membrane surrounds and engulfs the entire virus. some enveloped viruses enter the cell when the viral envelope fuses directly with the cell membrane. once inside the cell, the viral capsid is degraded, and the viral nucleic acid is released, which then becomes available for replication and transcription. replication and assembly the replication mechanism depends on the viral genome. dna viruses usually use host cell proteins and enzymes to make additional dna that is transcribed to messenger rna (mrna), which is then used to direct protein synthesis. rna viruses usually use the rna core as a template for synthesis of viral genomic rna and mrna. the viral mrna directs the host cell to synthesize viral enzymes and capsid proteins, and assemble new virions. of course, there are exceptions to this pattern. if a host cell does not provide the enzymes necessary for viral replication, viral genes supply the information to direct synthesis of the missing proteins. retroviruses have an rna genome that must be reverse transcribed into dna, which then is incorporated into the host cell genome. they are within group vi of the baltimore classification scheme. to convert rna into dna, retroviruses must contain genes that encode the virus-specific enzyme reverse transcriptase that transcribes an rna template to dna. reverse transcription never occurs in uninfected host cells—the needed enzyme reverse transcriptase is only derived from the expression of viral genes within the infected host cells. the fact that some retroviruses produces some of its own enzymes not found in the host has allowed researchers to develop drugs that inhibit these enzymes. these drugs inhibit replication by reducing the activity of the enzyme without affecting the host’s metabolism. this approach has led to the development of a variety of drugs used to treat these viruses and has been effective at reducing the number of infectious virions (copies of viral rna) in the blood to non-detectable levels in people affected with the virus. egress the last stage of viral replication is the release of the new virions produced in the host organism, where they are able to  860  chapter 21 | viruses  infect adjacent cells and repeat the replication cycle. as you’ve learned, some viruses are released when the host cell dies, and other viruses can leave infected cells by budding through the membrane without directly killing the cell.  figure 21.8 in influenza virus infection, glycoproteins attach to a host epithelial cell. as a result, the virus is engulfed. rna and proteins are made and assembled into new virions.  influenza virus is packaged in a viral envelope that fuses with the plasma membrane. this way, the virus can exit the host cell without killing it. what advantage does the virus gain by keeping the host cell alive? a. the virus can live dormant in the host cell. b. the virus capsid is upgraded. c. lysis causes the host cell to die. d. the host cell can continue to make new virus particles.  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  861  visit this website (http://openstaxcollege.org/l/32virusrep) to learn about viral replication. how do viruses get inside a host cell? a. to get inside the host cell, the virus forces the cell to lyse, or break open. b. to get inside a host cell, he virus produces proteins and copies its genome. c. to get inside a host cell, the virus attaches to a specific receptor site on the host cell. d. to get inside a host cell, the virus can fuse the membrane of the cell.  different hosts and their viruses as you’ve learned, viruses are often very specific as to which hosts and which cells within the host they will infect. this feature of a virus makes it specific to one or a few species of life on earth. on the other hand, so many different types of viruses exist on earth that nearly every living organism has its own set of viruses that tries to infect its cells. even the smallest and simplest of cells, prokaryotic bacteria, may be attacked by specific types of viruses.  bacteriophages  figure 21.9 this transmission electron micrograph shows bacteriophages attached to a bacterial cell. (credit: modification of work by dr. graham beards; scale-bar data from matt russell)  bacteriophages are viruses that infect bacteria (figure 21.9). when infection of a cell by a bacteriophage results in the production of new virions, the infection is said to be productive. if the virions are released by bursting the cell, the virus replicates by means of a lytic cycle (figure 21.10). an example of a lytic bacteriophage is t4, which infects escherichia coli found in the human intestinal tract. sometimes, however, a virus can remain within the cell without being released. for example, when a temperate bacteriophage infects a bacterial cell, it replicates by means of a lysogenic cycle (figure 21.10), and the viral genome is incorporated into the genome of the host cell. when the phage dna is incorporated into the host cell genome, it is called a prophage. an example of a lysogenic bacteriophage is the λ (lambda) virus, which also infects  862  chapter 21 | viruses  the e. coli bacterium. viruses that infect plant or animal cells may also undergo infections where they are not producing virions for long periods. an example is the animal herpesviruses, including herpes simplex viruses, the cause of herpes in humans. in a process called latency, these viruses can exist in nervous tissue for long periods of time without producing new virions, only to leave latency periodically and cause lesions in the skin where the virus replicates. even though there are similarities between lysogeny and latency, the term lysogenic cycle is usually reserved to describe bacteriophages. latency will be described in more detail below.  figure 21.10 a temperate bacteriophage has both lytic and lysogenic cycles. in the lytic cycle, the phage replicates and lyses the host cell. in the lysogenic cycle, phage dna is incorporated into the host genome, where it is passed on to subsequent generations. environmental stressors such as starvation or exposure to toxic chemicals may cause the prophage to excise and enter the lytic cycle.  which of the following statements is false? a. in the lytic cycle, new phage are produced and released into the environment. b. an environmental stressor can cause the phage to initiate the lysogenic cycle. c. in the lysogenic cycle, phage dna is incorporated into the host genome. d. bacteriophage is a viruses that infects bacteria.  animal viruses animal viruses, unlike the viruses of plants and bacteria, do not have to penetrate a cell wall to gain access to the host cell. non-enveloped or “naked” animal viruses may enter cells in two different ways. as a protein in the viral capsid binds to its receptor on the host cell, the virus may be taken inside the cell via a vesicle during the normal cell process of receptormediated endocytosis. an alternative method of cell penetration used by non-enveloped viruses is for capsid proteins to undergo shape changes after binding to the receptor, creating channels in the host cell membrane. the viral genome is then “injected” into the host cell through these channels in a manner analogous to that used by many bacteriophages. enveloped  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  863  viruses also have two ways of entering cells after binding to their receptors: receptor-mediated endocytosis, or fusion. many enveloped viruses enter the cell by receptor-mediated endocytosis in a fashion similar to some non-enveloped viruses. on the other hand, fusion only occurs with enveloped virions. these viruses, which include hiv among others, use special fusion proteins in their envelopes to cause the envelope to fuse with the plasma membrane of the cell, thus releasing the genome and capsid of the virus into the cell cytoplasm. after making their proteins and copying their genomes, animal viruses complete the assembly of new virions and exit the cell enveloped animal viruses may bud from the cell membrane as they assemble themselves, taking a piece of the cell’s plasma membrane in the process. on the other hand, non-enveloped viral progeny, such as rhinoviruses, accumulate in infected cells until there is a signal for lysis or apoptosis, and all virions are released together. as you will learn in the next module, animal viruses are associated with a variety of human diseases. some of them follow the classic pattern of acute disease, where symptoms get increasingly worse for a short period followed by the elimination of the virus from the body by the immune system and eventual recovery from the infection. examples of acute viral diseases are the common cold and influenza. other viruses cause long-term chronic infections, such as the virus causing hepatitis c, whereas others, like herpes simplex virus, only cause intermittent symptoms. still other viruses, such as human herpesviruses 6 and 7, which in some cases can cause the minor childhood disease roseola, often successfully cause productive infections without causing any symptoms at all in the host, and thus we say these patients have an asymptomatic infection. in hepatitis c infections, the virus grows and reproduces in liver cells, causing low levels of liver damage. the damage is so low that infected individuals are often unaware that they are infected, and many infections are detected only by routine blood work on patients with risk factors. on the other hand, since many of the symptoms of viral diseases are caused by immune responses, a lack of symptoms is an indication of a weak immune response to the virus. this allows for the virus to escape elimination by the immune system and persist in individuals for years, all the while producing low levels of progeny virions in what is known as a chronic viral disease. as already discussed, herpes simplex virus can remain in a state of latency in nervous tissue for months, even years. as the virus “hides” in the tissue and makes few if any viral proteins, there is nothing for the immune response to act against, and immunity to the virus slowly declines. under certain conditions, including various types of physical and psychological stress, the latent herpes simplex virus may be reactivated and undergo a lytic replication cycle in the skin, causing the lesions associated with the disease. once virions are produced in the skin and viral proteins are synthesized, the immune response is again stimulated and resolves the skin lesions in a few days by destroying viruses in the skin. as a result of this type of replicative cycle, appearances of cold sores outbreaks only occur intermittently, even though the viruses remain in the nervous tissue for life. latent infections are common with other herpesviruses as well, including the varicella-zoster virus that causes chickenpox. after having a chickenpox infection in childhood, the varicella-zoster virus can remain latent for many years and reactivate in adults to cause the painful condition known as “shingles” (figure 21.11ab).  figure 21.11 (a) varicella-zoster, the virus that causes chickenpox, has an enveloped icosahedral capsid visible in this transmission electron micrograph. its double-stranded dna genome becomes incorporated in the host dna and can reactivate after latency in the form of (b) shingles, often exhibiting a rash. (credit a: modification of work by dr. erskine palmer, b. g. martin, cdc; credit b: modification of work by “rosmary”/flickr; scale-bar data from matt russell)  some animal-infecting viruses, including the hepatitis c virus discussed above, are known as oncogenic viruses: they have the ability to cause cancer. these viruses interfere with the normal regulation of the host cell cycle either by either introducing genes that stimulate unregulated cell growth (oncogenes) or by interfering with the expression of genes that  864  chapter 21 | viruses  inhibit cell growth. oncogenic viruses can be either dna or rna viruses. cancers known to be associated with viral infections include cervical cancer caused by human papillomavirus (hpv) (figure 21.12), liver cancer caused by hepatitis b virus, t-cell leukemia, and several types of lymphoma.  figure 21.12 hpv, or human papillomavirus, has a naked icosahedral capsid visible in this transmission electron micrograph and a double-stranded dna genome that is incorporated into the host dna. the virus, is oncogenic and can lead to cervical cancer. (credit: modification of work by nci, nih; scale-bar data from matt russell)  visit the interactive animations (http://openstaxcollege.org/l/animal_viruses) showing the various stages of the replicative cycles of animal viruses and click on the flash animation links. before a virus can replicate in a host cell, the capsid or envelope must be released. this process is sometimes referred to as _____. a. viral attachment or adsorption b. viral entry c. uncoating d. viral replication  plant viruses plant viruses, like other viruses, contain a core of either dna or rna. you have already learned about one of these, the tobacco mosaic virus. as plant cells have a cell wall to protect their cells, these viruses do not use receptor-mediated endocytosis to enter host cells as is seen with animal viruses. for many plant viruses to be transferred from plant to plant, damage to some of the plants’ cells must occur to allow the virus to enter a new host. this damage is often caused by weather, insects, animals, fire, or human activities like farming or landscaping. additionally, plant offspring may inherit  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  865  viral diseases from parent plants. plant viruses can be transmitted by a variety of vectors, through contact with an infected plant’s sap, by living organisms such as insects and nematodes, and through pollen. when plants viruses are transferred between different plants, this is known as horizontal transmission, and when they are inherited from a parent, this is called vertical transmission. symptoms of viral diseases vary according to the virus and its host (table 21.4). one common symptom is hyperplasia, the abnormal proliferation of cells that causes the appearance of plant tumors known as galls. other viruses induce hypoplasia, or decreased cell growth, in the leaves of plants, causing thin, yellow areas to appear. still other viruses affect the plant by directly killing plant cells, a process known as cell necrosis. other symptoms of plant viruses include malformed leaves, black streaks on the stems of the plants, altered growth of stems, leaves, or fruits, and ring spots, which are circular or linear areas of discoloration found in a leaf.  some common symptoms of plant viral diseases symptom  appears as  hyperplasia  galls (tumors)  hypoplasia  thinned, yellow splotches on leaves  cell necrosis  dead, blackened stems, leaves, or fruit  abnormal growth patterns malformed stems, leaves, or fruit discoloration  yellow, red, or black lines, or rings in stems, leaves, or fruit  table 21.4  plant viruses can seriously disrupt crop growth and development, significantly affecting our food supply. they are responsible for poor crop quality and quantity globally, and can bring about huge economic losses annually. others viruses may damage plants used in landscaping. some viruses that infect agricultural food plants include the name of the plant they infect, such as tomato spotted wilt virus, bean common mosaic virus, and cucumber mosaic virus. in plants used for landscaping, two of the most common viruses are peony ring spot and rose mosaic virus. there are far too many plant viruses to discuss each in detail, but symptoms of bean common mosaic virus result in lowered bean production and stunted, unproductive plants. in the ornamental rose, the rose mosaic disease causes wavy yellow lines and colored splotches on the leaves of the plant.  866  chapter 21 | viruses  plant viruses can be spread through sap, insects, organisms living in the soil, seeds, and pollen. they cause damage to fruit, leaves, and stems, which has a large economic impact. for example, estimated yields from barley infected with the barley stripe mosaic virus as pictured below, can be 35–40% less. this virus is transmitted by a parasite that lives in the plant’s roots.  figure 21.13 (credit: h.j. larsen, wikimedia commons)  what symptoms of plant viral diseases do you see in this light micrograph of the cells of a plant root? a. hyperplasia b. abnormal growth patterns c. discoloration d. hypoplasia  activity create a visual representation to describe how viruses differ from bacteria in their modes of reproduction. what characteristics do viruses share with living organisms? how do they differ? what evidence supports the claim that viruses do not fit our usual definition of life?  think about it the influenza virus that causes seasonal “flu” is packaged in a viral envelope that fuses with the plasma membrane. this way, the virus can exit the host cell without killing it. what advantage does the virus gain by keeping the host alive?  21.3 | prevention and treatment of viral infections in this section, you will explore the following questions: • what are examples of major viral illnesses that affect humans? • how do vaccinations differ from antiviral drugs as medical approaches to viruses?  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  867  connection for ap® courses the majority of content described in this section is not within the scope for ap®. we explore some of these concepts when we study the immune system. however, because all of us will fight viral infections and will receive vaccinations against many diseases, including seasonal flu shots, the content in this section is relevant to our lives outside the classroom. while studying, think about why there are many different antibiotics available for treating bacterial infections but relatively few drugs available to treat viral infections. how do viruses differ from bacteria in both structure and activity? viruses cause a variety of diseases in animals, including humans, ranging from the common cold to potentially fatal illnesses like meningitis (figure 21.14). these diseases can be treated by antiviral drugs or by vaccines, but some viruses are capable of both avoiding the immune response and mutating to become resistant to antiviral drugs.  figure 21.14 viruses can cause dozens of ailments in humans, ranging from mild illnesses to serious diseases. (credit: modification of work by mikael häggström)  vaccines for prevention while we do have limited numbers of effective antiviral drugs, such as those used to treat influenza, the primary method of controlling viral disease is by vaccination, which is intended to prevent outbreaks by building immunity to a virus or virus family (figure 21.15). vaccines may be prepared using live viruses, killed viruses, or molecular subunits of the virus. the killed viral vaccines and subunit viruses are both incapable of causing disease. live viral vaccines are designed in the laboratory to cause few symptoms in recipients while giving them protective immunity against future infections. polio was one disease that represented a milestone in the use of vaccines. mass immunization campaigns in the 1950s (killed vaccine) and 1960s (live vaccine) significantly reduced the incidence of the disease, which caused muscle paralysis in children and generated a great amount of fear in the general population when regional epidemics occurred. the success of the polio vaccine paved the way for the routine dispensation of childhood vaccines against measles, mumps, rubella, chickenpox, and other diseases. the danger of using live vaccines, which are usually more effective than killed vaccines, is the low but significant danger that these viruses will revert to their disease-causing form by back mutations. live vaccines are usually made by attenuating (weakening) the “wild-type” (disease-causing) virus by growing it in the laboratory in tissues or at temperatures different from what the virus is accustomed to in the host. adaptations to these new cells or temperatures induce mutations in the genomes of the virus, allowing it to grow better in the laboratory while inhibiting its ability to cause  868  chapter 21 | viruses  disease when reintroduced into conditions found in the host. these attenuated viruses thus still cause infection, but they do not grow very well, allowing the immune response to develop in time to prevent major disease. back mutations occur when the vaccine undergoes mutations in the host such that it readapts to the host and can again cause disease, which can then be spread to other humans in an epidemic. this type of scenario happened as recently as 2007 in nigeria where mutations in a polio vaccine led to an epidemic of polio in that country. some vaccines are in continuous development because certain viruses, such as influenza, have a high mutation rate compared to other viruses and normal host cells. with influenza, mutations in the surface molecules of the virus help the organism evade the protective immunity that may have been obtained in a previous influenza season, making it necessary for individuals to get vaccinated every year. other viruses, such as those that cause the childhood diseases measles, mumps, and rubella, mutate so infrequently that the same vaccine is used year after year.  figure 21.15 vaccinations are designed to boost immunity to a virus to prevent infection. (credit: usace europe district)  watch this nova video (http://openstaxcollege.org/l/1918_flu) to learn how microbiologists are attempting to replicate the deadly 1918 spanish influenza virus so they can understand more about virology. the avian virus and the 1918 spanish influenza virus both infect the _____ system. a. nervous b. respiratory c. cardio vascular d. digestive  vaccines and antiviral drugs for treatment in some cases, vaccines can be used to treat an active viral infection. the concept behind this is that by giving the vaccine, immunity is boosted without adding more disease-causing virus. in the case of rabies, a fatal neurological disease transmitted via the saliva of rabies virus-infected animals, the progression of the disease from the time of the animal bite  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  869  to the time it enters the central nervous system may be 2 weeks or longer. this is enough time to vaccinate an individual who suspects that they have been bitten by a rabid animal, and their boosted immune response is sufficient to prevent the virus from entering nervous tissue. thus, the potentially fatal neurological consequences of the disease are averted, and the individual only has to recover from the infected bite. this approach is also being used for the treatment of ebola, one of the fastest and most deadly viruses on earth. transmitted by bats and great apes, this disease can cause death in 70–90 percent of infected humans within 2 weeks. using newly developed vaccines that boost the immune response in this way, there is hope that affected individuals will be better able to control the virus, potentially saving a greater percentage of infected persons from a rapid and very painful death. another way of treating viral infections is the use of antiviral drugs. these drugs often have limited success in curing viral disease, but in many cases, they have been used to control and reduce symptoms for a wide variety of viral diseases. for most viruses, these drugs can inhibit the virus by blocking the actions of one or more of its proteins. it is important that the targeted proteins be encoded by viral genes and that these molecules are not present in a healthy host cell. in this way, viral growth is inhibited without damaging the host. there are large numbers of antiviral drugs available to treat infections, some specific for a particular virus and others that can affect multiple viruses. antivirals have been developed to treat herpes and influenza. for herpes, drugs such as acyclovir can reduce the number and duration of episodes of active viral disease, during which patients develop viral lesions in their skin cells. as the virus remains latent in nervous tissue of the body for life, this drug is not curative but can make the symptoms of the disease more manageable. for influenza, drugs like oseltamivir (figure 21.16) can reduce the duration of “flu” symptoms by 1 or 2 days, but the drug does not prevent symptoms entirely. oseltamivir works by inhibiting an enzyme (viral neuraminidase) that allows new virions to leave their infected cells. thus, oseltamivir inhibits the spread of virus from infected to uninfected cells. other antiviral drugs, such as ribavirin, have been used to treat a variety of viral infections, although its mechanism of action against certain viruses remains unclear.  figure 21.16 (a) oseltamivir inhibits a viral enzyme called neuraminidase (na) found in the influenza viral envelope. (b) neuraminidase cleaves the connection between viral hemagglutinin (ha), also found in the viral envelope, and glycoproteins on the host cell surface. inhibition of neuraminidase prevents the virus from detaching from the host cell, thereby blocking further infection. (credit a: modification of work by m. eickmann)  by far, the most successful use of antivirals has been in the treatment of the retrovirus hiv, which causes a disease that, if untreated, is usually fatal within 10–12 years after infection. anti-hiv drugs have been able to control viral replication to the point that individuals receiving these drugs survive for a significantly longer time than the untreated. anti-hiv drugs inhibit viral replication at many different phases of the hiv replicative cycle (figure 21.17). drugs have been developed that inhibit the fusion of the hiv viral envelope with the plasma membrane of the host cell (fusion inhibitors), the conversion of its rna genome into double-stranded dna (reverse transcriptase inhibitors), the integration of the viral dna into the host genome (integrase inhibitors), and the processing of viral proteins (protease inhibitors).  870  chapter 21 | viruses  figure 21.17 hiv, an enveloped, icosahedral virus, attaches to the cd4 receptor of an immune cell and fuses with the cell membrane. viral contents are released into the cell, where viral enzymes convert the single-stranded rna genome into dna and incorporate it into the host genome. (credit: niaid, nih)  when any of these drugs are used individually, the high mutation rate of the virus allows it to easily and rapidly develop resistance to the drug, limiting the drug’s effectiveness. the breakthrough in the treatment of hiv was the development of haart, highly active antiretroviral therapy, which involves a mixture of different drugs, sometimes called a drug “cocktail.” by attacking the virus at different stages of its replicative cycle, it is much more difficult for the virus to develop resistance to multiple drugs at the same time. still, even with the use of combination haart therapy, there is concern that, over time, the virus will develop resistance to this therapy. thus, new anti-hiv drugs are constantly being developed with the hope of continuing the battle against this highly fatal virus.  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  871  applied virology the study of viruses has led to the development of a variety of new ways to treat non-viral diseases. viruses have been used in gene therapy. gene therapy is used to treat genetic diseases such as severe combined immunodeficiency (scid), a heritable, recessive disease in which children are born with severely compromised immune systems. one common type of scid is due to the lack of an enzyme, adenosine deaminase (ada), which breaks down purine bases. to treat this disease by gene therapy, bone marrow cells are taken from a scid patient and the ada gene is inserted. this is where viruses come in, and their use relies on their ability to penetrate living cells and bring genes in with them. viruses such as adenovirus, an upper respiratory human virus, are modified by the addition of the ada gene, and the virus then transports this gene into the cell. the modified cells, now capable of making ada, are then given back to the patients in the hope of curing them. gene therapy using viruses as carrier of genes (viral vectors), although still experimental, holds promise for the treatment of many genetic diseases. still, many technological problems need to be solved for this approach to be a viable method for treating genetic disease. another medical use for viruses relies on their specificity and ability to kill the cells they infect. oncolytic viruses are engineered in the laboratory specifically to attack and kill cancer cells. a genetically modified adenovirus known as h101 has been used since 2005 in clinical trials in china to treat head and neck cancers. the results have been promising, with a greater short-term response rate to the combination of chemotherapy and viral therapy than to chemotherapy treatment alone. this ongoing research may herald the beginning of a new age of cancer therapy, where viruses are engineered to find and specifically kill cancer cells, regardless of where in the body they may have spread. a third use of viruses in medicine relies on their specificity and involves using bacteriophages in the treatment of bacterial infections. bacterial diseases have been treated with antibiotics since the 1940s. however, over time, many bacteria have developed resistance to antibiotics. a good example is methicillinresistant staphylococcus aureus (mrsa, pronounced “mersa”), an infection commonly acquired in hospitals. this bacterium is resistant to a variety of antibiotics, making it difficult to treat. the use of bacteriophages specific for such bacteria would bypass their resistance to antibiotics and specifically kill them. although phage therapy is in use in the republic of georgia to treat antibiotic-resistant bacteria, its use to treat human diseases has not been approved in most countries. however, the safety of the treatment was confirmed in the united states when the u.s. food and drug administration approved spraying meats with bacteriophages to destroy the food pathogen listeria. as more and more antibioticresistant strains of bacteria evolve, the use of bacteriophages might be a potential solution to the problem, and the development of phage therapy is of much interest to researchers worldwide. how can viruses be used in gene therapy? a. viruses are used to attack and kill specific cells. b. bacteriophages are used to treat bacterial infections. c. viruses are used to transport a gene into a cell. d. viruses are used to destroy the food pathogen listeria.  21.4 | other acellular entities: prions and viroids in this section, you will explore the following questions: • what are prions and how do they cause disease? • what are viroids and their targets of infection?  872  chapter 21 | viruses  connection for ap® courses the content described in this section is outside the scope for ap®. however, it’s interesting to note that prions and viroids—pathogens that are far simpler in structure than viruses—can produce deadly diseases, including mad cow disease and creutzfeldt–jakob disease. prions are infectious proteins, whereas viroids are single-stranded rna pathogens (agents with the ability to cause disease) that infect plants.  prions prions, so-called because they are proteinaceous, are infectious particles—smaller than viruses—that contain no nucleic acids (neither dna nor rna). historically, the idea of an infectious agent that did not use nucleic acids was considered impossible, but pioneering work by nobel prize-winning biologist stanley prusiner has convinced the majority of biologists that such agents do indeed exist. fatal neurodegenerative diseases, such as kuru in humans and bovine spongiform encephalopathy (bse) in cattle (commonly known as “mad cow disease”) were shown to be transmitted by prions. the disease was spread by the consumption of meat, nervous tissue, or internal organs between members of the same species. kuru, native to humans in papua new guinea, was spread from human to human via ritualistic cannibalism. bse, originally detected in the united kingdom, was spread between cattle by the practice of including cattle nervous tissue in feed for other cattle. individuals with kuru and bse show symptoms of loss of motor control and unusual behaviors, such as uncontrolled bursts of laughter with kuru, followed by death. kuru was controlled by inducing the population to abandon its ritualistic cannibalism. on the other hand, bse was initially thought to only affect cattle. cattle dying of the disease were shown to have developed lesions or “holes” in the brain, causing the brain tissue to resemble a sponge. later on in the outbreak, however, it was shown that a similar encephalopathy in humans known as variant creutzfeldt-jakob disease (cjd) could be acquired from eating beef from animals with bse, sparking bans by various countries on the importation of british beef and causing considerable economic damage to the british beef industry (figure 21.18). bse still exists in various areas, and although a rare disease, individuals that acquire cjd are difficult to treat. the disease can be spread from human to human by blood, so many countries have banned blood donation from regions associated with bse. the cause of spongiform encephalopathies, such as kuru and bse, is an infectious structural variant of a normal cellular protein called prp (prion protein). it is this variant that constitutes the prion particle. prp exists in two forms, prpc, the normal form of the protein, and prpsc, the infectious form. once introduced into the body, the prpsc contained within the prion binds to prpc and converts it to prpsc. this leads to an exponential increase of the prpsc protein, which aggregates. prpsc is folded abnormally, and the resulting conformation (shape) is directly responsible for the lesions seen in the brains of infected cattle. thus, although not without some detractors among scientists, the prion seems likely to be an entirely new form of infectious agent, the first one found whose transmission is not reliant upon genes made of dna or rna.  figure 21.18 (a) endogenous normal prion protein (prpc) is converted into the disease-causing form (prpsc) when it encounters this variant form of the protein. prpsc may arise spontaneously in brain tissue, especially if a mutant form of the protein is present, or it may occur via the spread of misfolded prions consumed in food into brain tissue. (b) this prion-infected brain tissue, visualized using light microscopy, shows the vacuoles that give it a spongy texture, typical of transmissible spongiform encephalopathies. (credit b: modification of work by dr. al jenny, usda aphis; scale-bar data from matt russell)  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  873  viroids viroids are plant pathogens: small, single-stranded, circular rna particles that are much simpler than a virus. they do not have a capsid or outer envelope, but like viruses can reproduce only within a host cell. viroids do not, however, manufacture any proteins, and they only produce a single, specific rna molecule. human diseases caused by viroids have yet to be identified. viroids are known to infect plants (figure 21.19) and are responsible for crop failures and the loss of millions of dollars in agricultural revenue each year. some of the plants they infect include potatoes, cucumbers, tomatoes, chrysanthemums, avocados, and coconut palms.  figure 21.19 these potatoes have been infected by the potato spindle tuber viroid (pstv), which is typically spread when infected knives are used to cut healthy potatoes, which are then planted. (credit: pamela roberts, university of florida institute of food and agricultural sciences, usda ars)  874  chapter 21 | viruses  virologist virology is the study of viruses, and a virologist is an individual trained in this discipline. training in virology can lead to many different career paths. virologists are actively involved in academic research and teaching in colleges and medical schools. some virologists treat patients or are involved in the generation and production of vaccines. they might participate in epidemiologic studies (figure 21.20) or become science writers, to name just a few possible careers.  figure 21.20 this virologist is engaged in fieldwork, sampling eggs from this nest for avian influenza. (credit: don becker, usgs eros, u.s. fish and wildlife service)  if you think you may be interested in a career in virology, find a mentor in the field. many large medical centers have departments of virology, and smaller hospitals usually have virology labs within their microbiology departments. volunteer in a virology lab for a semester or work in one over the summer. discussing the profession and getting a first-hand look at the work will help you decide whether a career in virology is right for you. the american society of virology’s website (http://openstaxcollege.org/l/asv) is a good resource for information regarding training and careers in virology.  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  875  key terms acellular lacking cells acute disease disease where the symptoms rise and fall within a short period of time asymptomatic disease disease where there are no symptoms and the individual is unaware of being infected unless lab tests are performed attenuation weakening of a virus during vaccine development azt anti-hiv drug that inhibits the viral enzyme reverse transcriptase back mutation when a live virus vaccine reverts back to it disease-causing phenotype bacteriophage virus that infects bacteria budding method of exit from the cell used in certain animal viruses, where virions leave the cell individually by capturing a piece of the host plasma membrane capsid protein coating of the viral core capsomere protein subunit that makes up the capsid cell necrosis cell death chronic infection describes when the virus persists in the body for a long period of time cytopathic causing cell damage envelope lipid bilayer that envelopes some viruses fusion method of entry by some enveloped viruses, where the viral envelope fuses with the plasma membrane of the host cell gall appearance of a plant tumor gene therapy treatment of genetic disease by adding genes, using viruses to carry the new genes inside the cell group i virus virus with a dsdna genome group ii virus virus with a ssdna genome group iii virus virus with a dsrna genome group iv virus virus with a ssrna genome with positive polarity group v virus virus with a ssrna genome with negative polarity group vi virus virus with a ssrna genomes converted into dsdna by reverse transcriptase group vii virus virus with a single-stranded mrna converted into dsdna for genome replication horizontal transmission transmission of a disease from parent to offspring hyperplasia abnormally high cell growth and division hypoplasia abnormally low cell growth and division intermittent symptom symptom that occurs periodically latency virus that remains in the body for a long period of time but only causes intermittent symptoms lysis bursting of a cell  876  chapter 21 | viruses  lysogenic cycle type of virus replication in which the viral genome is incorporated into the genome of the host cell lytic cycle type of virus replication in which virions are released through lysis, or bursting, of the cell matrix protein envelope protein that stabilizes the envelope and often plays a role in the assembly of progeny virions negative polarity ssrna viruses with genomes complementary to their mrna oncogenic virus virus that has the ability to cause cancer oncolytic virus virus engineered to specifically infect and kill cancer cells pathogen agent with the ability to cause disease permissive cell type that is able to support productive replication of a virus phage therapy treatment of bacterial diseases using bacteriophages specific to a particular bacterium positive polarity ssrna virus with a genome that contains the same base sequences and codons found in their mrna prion infectious particle that consists of proteins that replicate without dna or rna productive viral infection that leads to the production of new virions prophage phage dna that is incorporated into the host cell genome prpc normal prion protein prpsc infectious form of a prion protein replicative intermediate dsrna intermediate made in the process of copying genomic rna retrovirus virus with an rna genome that must be reverse transcribed into dna before being incorporated into the host cell genome reverse transcriptase enzyme found in baltimore groups vi and vii that converts single-stranded rna into doublestranded dna vaccine weakened solution of virus components, viruses, or other agents that produce an immune response vertical transmission transmission of disease from parent to offspring viral receptor glycoprotein used to attach a virus to host cells via molecules on the cell virion individual virus particle outside a host cell viroid plant pathogen that produces only a single, specific rna virus core contains the virus genome  chapter summary 21.1 viral evolution, morphology, and classification viruses are tiny, acellular entities that can usually only be seen with an electron microscope. their genomes contain either dna or rna—never both—and they replicate using the replication proteins of a host cell. viruses are diverse, infecting archaea, bacteria, fungi, plants, and animals. viruses consist of a nucleic acid core surrounded by a protein capsid with or without an outer lipid envelope. the capsid shape, presence of an envelope, and core composition dictate some elements of the classification of viruses. the most commonly used classification method, the baltimore classification, categorizes viruses based on how they produce their mrna.  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  877  21.2 virus infection and hosts viral replication within a living cell always produces changes in the cell, sometimes resulting in cell death and sometimes slowly killing the infected cells. there are six basic stages in the virus replication cycle: attachment, penetration, uncoating, replication, assembly, and release. a viral infection may be productive, resulting in new virions, or nonproductive, which means that the virus remains inside the cell without producing new virions. bacteriophages are viruses that infect bacteria. they have two different modes of replication: the lytic cycle, where the virus replicates and bursts out of the bacteria, and the lysogenic cycle, which involves the incorporation of the viral genome into the bacterial host genome. animal viruses cause a variety of infections, with some causing chronic symptoms (hepatitis c), some intermittent symptoms (latent viruses such a herpes simplex virus 1), and others that cause very few symptoms, if any (human herpesviruses 6 and 7). oncogenic viruses in animals have the ability to cause cancer by interfering with the regulation of the host cell cycle. viruses of plants are responsible for significant economic damage in both agriculture and plants used for ornamentation.  21.3 prevention and treatment of viral infections viruses cause a variety of diseases in humans. many of these diseases can be prevented by the use of viral vaccines, which stimulate protective immunity against the virus without causing major disease. viral vaccines may also be used in active viral infections, boosting the ability of the immune system to control or destroy the virus. a series of antiviral drugs that target enzymes and other protein products of viral genes have been developed and used with mixed success. combinations of anti-hiv drugs have been used to effectively control the virus, extending the lifespans of infected individuals. viruses have many uses in medicines, such as in the treatment of genetic disorders, cancer, and bacterial infections.  21.4 other acellular entities: prions and viroids prions are infectious agents that consist of protein, but no dna or rna, and seem to produce their deadly effects by duplicating their shapes and accumulating in tissues. they are thought to contribute to several progressive brain disorders, including mad cow disease and creutzfeldt-jakob disease. viroids are single-stranded rna pathogens that infect plants. their presence can have a severe impact on the agriculture industry.  review questions 1. viruses were first discovered after the development of the porcelain filter, called the chamberland-pasteur filter. how did the porcelain filter enable scientists to discover viruses? a. the porcelain filter removed diseases from a liquid sample. b. the porcelain filter removed virions from a liquid sample. c. the porcelain filter removed bacteria from a liquid sample. d. the porcelain filter removed a disease from tobacco plants. 2. in the late 1930s, scientists got their first good view of viruses. how did this happen?  a. the development of the light microscope helped scientists discover many viruses of all types of living organisms. b. the development of the viral receptor helped scientists discover many viruses of all types of living organisms. c. the development of the porcelain filter helped scientists discover many viruses of all types of living organisms. d. the development of the electron microscope helped scientists discover many viruses of all types of living organisms. 3. determining the origins of viruses is challenging. the _____ hypothesis proposes to explain the origin of viruses by suggesting that viruses evolved from free-living cells. a. escapist or the progressive b. system of self-replication c. devolution or the regressive d. virus molecular systematics 4. which statement best describes what biologists know about the evolution of viruses?  878  chapter 21 | viruses  a. scientists can look at fossil records and similar historic evidence. b. much about virus origins and evolution remains unknown. c. biologists have accumulated a significant amount of knowledge about how viruses originated. d. biologists know exactly when viruses emerged and from where they came. 5. a(n) _____ is an individual virus particle outside a host cell that consists of a nucleic acid core, an outer protein coating, and sometimes an outer envelope. a. capsid b. virion c. capsomere d. viral receptor 6. for many viruses to penetrate the cell membrane and complete their replication inside the cell, the virus must attach to their host cells. describe how a virus attaches to a host cell. a. a virus uses its cellular structure to attach to a host cell. b. a virus uses a plasma membrane to connect to a host cell. c. a virus uses matrix proteins to attach to a host cell. d. viruses use viral receptors to attach to a host cell. 7. _____ means that the genomic rna can function as mrna. a. double-stranded  a. scanning electron microscope b. transmission electron microscope c. porcelain filter d. light microscope 10. which of the following statements about the viral replication cycle is accurate? a. the viral replication cycle does not affect the structure of the host cell. b. the viral replication cycle cannot affect genetic material of the host cell. c. the viral replication cycle has seven basic steps. d. the viral replication cycle can change cell functions or even destroy the host cell. 11. what happens in the replication cycle? a. during the budding process, virions leave the host cell individually b. during the budding process, the host cell bursts. c. during the budding process, the virus connects with a permissive host cell. d. during the budding process, the host cell dies immediately. 12. in the _____ cycle, the virus replicates and bursts out of the host cell. a. lytic b. lysogenic c. cytopathic d. latency 13. how is the lytic cycle different from the lysogenic cycle?  b. negative polarity  a. the phage infects a cell in the lytic cycle.  c. positive polarity  b. the lytic cycle contains the formation of a prophage.  d. replica intermediates 8. viruses are often classified based on the type of genetic material and its structure. in the baltimore classification scheme, the _____ virus has a single-stranded rna (–) genome. a. human immunodeficiency virus (hiv) b. rabies (rhabdovirus) c. canine parvovirus (parvovirus) d. common cold (pircornavirus) 9. to get a visual look at the internal structure of virions, scientists must use a(n) ____.  this openstax book is available for free at http://cnx.org/content/col12078/1.6  c. in the lytic cycle, new phages are produced; immediately in the lysogenic cycle phage dna is merged into the host genome. d. the phages move on to infect other cells in the lysogenic phase. 14. which of the following statements is false?  chapter 21 | viruses  879  a. enveloped viruses and naked viruses both may enter cells using the fusion method.  a. the measles virus causes nasal and lung infections.  b. many enveloped viruses enter the cell by receptor-mediated endocytosis.  b. the measles virus causes pancreas and liver infections.  c. naked viruses enter the cell by receptormediated endocytosis.  c. the measles virus causes mouth and gum infections.  d. undergoing shape changes and creating channels in the host cell membrane is an alternative method of cell penetration used by naked viruses.  d. the measles virus causes brain and skin infections.  15. an apple tree has yellow splotches on the leaves. this is a symptom of _____. a. cell necrosis b. discoloration  20. which of the following statements best describes vaccines? a. vaccines kill viruses. b. vaccines stimulate an immune response against future infections.  c. hyperplasia  c. vaccines inhibit the virus by blocking the action of key viral proteins.  d. hypoplasia  d. vaccines control and reduce symptoms.  16. what happens during the release step in the viral replication cycle?  21. which kind of therapy attacks a stage of the virus replicative cycle? a. phage therapy  a. during the release step, genetic information is transferred through the lytic and lysogenic cycles.  b. anti-retroviral  b. during the release step, dna is transcribed to messenger rna.  d. cancer therapy  c. during the release step, the nucleic acid is released from the viral capsid or envelope. d. during the release step, the new virions are able to infect adjacent cells and repeat the replication cycle. 17. why does the hiv virus use reverse transcriptase in the replication process? a. the hiv virus uses reverse transcriptase to replicate cells and build proteins. b. the hiv virus uses reverse transcriptase to erase mutated virions. c. the hiv virus uses reverse transcriptase because it is a retrovirus. d. the hiv virus uses reverse transcriptase because it has a dna genome. 18. what are the symptoms of the herpes simplex virus? a. the herpes simplex virus causes eye infections. b. the herpes simplex virus causes pneumonia. c. the herpes simplex virus causes pancreatitis. d. the herpes simplex virus can cause septicemia. 19. which of the following statements accurately describes the measles virus?  c. gene therapy 22. which virus causes parotitis? a. measles virus b. norovirus c. hiv d. mumps virus 23. which of the following statements about prions is true? a. prions are larger than viruses. b. prions contain dna and rna. c. the prpcis the normal form of the protein. d. the prpscis folded abnormally. 24. kuru is a prion disease that affects both humans and animals. how is kuru spread? a. kuru disease is spread between cattle. b. kuru is passed from person to person. c. kuru is passed from cows with bse to humans. d. kuru is a viroid that infects plants. 25. which of the following statements about viroids is true? a. viroids are single-stranded rna particles. b. viroids reproduce only outside of the cell. c. viroids produce proteins. d. viroids affect both plants and animals.  880  chapter 21 | viruses  26. on which industry can viroids have a severe impact? a. dairy b. poultry c. avocado d. livestock 27. which of the following statements best explains how infected prions cause disease?  a. infected prions cause disease by transmitting nucleic acids to normal prion proteins. b. infected prions cause disease by converting dna to rna in normal prion proteins. c. infected prions cause disease by converting the shapes of normal proteins. d. infected prions cause disease by replicating the normal form of the protein.  critical thinking questions 28. how did the development of a porcelain filter, called the chamberland-pasteur filter, help scientists discover viruses?  azt work? a. azt blocks the enzyme called hiv protease, which the virus uses to reproduce itself.  a. after filtering a liquid plant extract, the scientists could see the virions using the light microscope.  b. azt blocks the hiv integrase enzyme, which the virus uses to insert its viral dna into the dna of the host cell.  b. after filtering a liquid plant extract, the disease was still transferred to a healthy plant.  c. azt prevents reverse transcriptase and hiv protease enzyme from functioning inside the body.  c. after filtering a liquid plant extract, the virus cells multiplied. d. after filtering a liquid plant extract, scientists were able to trace historical footprints. 29. scientists have a few hypotheses about virus origins. why might they develop and refine further hypotheses to explain the origin of viruses? a. advances in technology provide historic evidence. b. biochemical and genetic information provide historic evidence. c. advances in technology provide new information for scientists. d. advances in technology have proven that viruses have a single common ancestor. 30. why don’t dogs catch the measles? a. measles is a dna virus, and dna viruses cause human diseases. b. dogs do not have glycoproteins. c. the virus can’t attach to dog cells. d. dogs do not get rna viruses. 31. the baltimore classification system groups viruses according to how the mrna is produced. when classified this way, the viruses in each group _____. a. behave in a similar manner b. look very similar c. connect with living things d. are based on the type of disease they cause 32. researchers have been able to develop a variety of anti-hiv drugs, such as the drug azt. how does the drug  this openstax book is available for free at http://cnx.org/content/col12078/1.6  d. azt prevents reverse transcriptase from making dna from the viral rna genome. 33. compare the lytic and lysogenic cycles and explain which cycle has the potential to produce the most virions. a. the lytic cycle can theoretically produce more virions as the viral genome is incorporated into the host cell’s genome replicating along with the host cell. b. the lysogenic cycle can theoretically produce more virions as the reproductive cycle of viruses undergoing lysogeny is much faster than the reproductive cycle of viruses following lytic cycle. c. the lysogenic cycle can theoretically produce more virions as the viral genome is incorporated into the host cell’s genome replicating along with the host cell. d. the lytic cycle can theoretically produce more virions as the prophage following lysogenic cycle ultimately gets excised from the host cell’s genome and enter the lytic cycle. 34. would a person who has never been in contact with the varicella-zoster virus be at risk of developing chickenpox or shingles if they come in close contact with a person with shingles? explain your reasoning.  chapter 21 | viruses  a. the person is at risk of developing chickenpox. chickenpox is the first infection with the virus before it enters latency in the host. b. the person is at risk of developing shingles. shingles is the first infection with the virus before it enters latency in the host. c. the person is at risk of developing chickenpox. chickenpox is the first infection with the virus that is already latent in the body. d. the person is at risk of developing shingles. the virus enters the person and gets activated when a person with shingles comes in close contact. 35. which step in the replication cycle of viruses do you think is most critical for the virus to infect cells? explain why. a. the attachment step is the most critical, as infection cannot begin if virus does not attach to the host cell. b. the replication step is the most critical as this step directs protein synthesis. c. the assembly step is the most critical because new virions are assembled to infect cells. d. the entry step is the most critical as nucleic acid of virus needs to enter the host cell naked, leaving the capsid outside. 36. for most people, the measles virus does not cause a serious illness. symptoms include fever and a rash, but the symptoms are usually gone in about a week. however, for some, the measles virus can be much more serious. how can the measles virus cause a potentially fatal illness? a. measles can cause meningococcal disease, which causes severe headaches, seizures and in severe cases can be life-threatening. b. measles can cause variant creutzfeldt–jakob disease, which causes severe headaches, seizures and in severe cases can be life-threatening. c. measles can cause encephalitis/meningitis, which causes severe headaches, seizures and in severe cases can be life-threatening. d. measles can cause legionnaires’ disease, which causes severe headaches, seizures and in severe cases can be life-threatening. 37. why is immunization after being bitten by a rabid animal so effective and why aren’t people vaccinated for rabies like dogs and cats are?  881  a. it takes a month for the virus to travel from the site of the bite to the central nervous system. people are not vaccinated beforehand as routine vaccination of domestic animals makes it unlikely that humans will contract rabies from an animal bite. b. it takes a week for the virus to travel from the site of the bite to the peripheral nervous system. people are not vaccinated beforehand as routine vaccination of domestic animals makes it unlikely that humans will contract rabies from an animal bite. c. it takes a week for the virus to travel from the site of the bite to the central nervous system. people are not vaccinated beforehand as routine vaccination of domestic animals makes it unlikely that humans will contract rabies from an animal bite, and also. d. it takes a week for the virus to travel from the site of the bite to the central nervous system. people are not vaccinated beforehand, as routine vaccination of domestic animals makes it fully sure that humans will contract rabies from an animal bite, and also. 38. why don’t dogs and cats catch human colds from humans? a. as cats and dogs have different proteins than humans, the virus that causes colds in humans cannot find receptors in dogs and cats. b. as cats and dogs have different receptors than humans, the virus that causes colds in humans cannot find receptors in dogs and cats. c. as cats and dogs’ immune system attacks the virus unlike humans, so the virus that causes colds in humans cannot find receptors in dogs and cats. d. as natural killer cells of cats and dogs attack the virus, the virus that causes colds in humans cannot find receptors in dogs and cats. 39. prions are responsible for variant cjd (creutzfeldt jakob disease). how has this disease been documented to spread from human to human?  882  chapter 21 | viruses  a. surgery with instruments previously used in a patient with vcjd that were not adequately sterilized and contaminated pineal growth hormones taken from human pineal glands from infected cadavers. b. through human consumption of infected meat and contaminated pituitary growth hormones taken from human pituitary glands from infected cadavers. c. surgery with instruments previously used in a patient with vcjd that were not adequately sterilized and contaminated pituitary growth hormones taken from human pituitary glands from unwell individuals. d. surgery with instruments previously used in a patient with vcjd that were not adequately sterilized and contaminated pituitary growth hormones taken from human pituitary glands from infected cadavers. 40. what characteristics do viroids and viruses have in  common? a. they both replicate within a host cell and contain nucleic acids. b. they both replicate within a host cell and do not contain nucleic acids. c. they both replicate within a host cell and contain proteins. d. they both replicate within a host cell and contain only rna. 41. why is the transmission of a prion not reliant upon genes made of dna or rna? a. dna or rna, though present, is not transmitted when a prion causes infection. b. the prion does not contain dna or rna. c. only parts of dna or rna are transmitted in a prion. d. more of protein and less of dna or rna is transmitted.  test prep for ap® courses 42. the table below shows the baltimore classification used to classify viruses based on their genetic material. what is the difference between how group i and group iii viruses reproduce?  a. in group i, rna is transcribed from an rna genome while in group iii, rna is transcribed from a dna genome. b. in group i, rna is transcribed from a dna genome while in group iii, rna is transcribed from an rna genome. c. in group i, dna is transcribed from a dna genome while in group iii, rna is transcribed from an rna genome. d. in group i, dna is transcribed from an rna genome while in group iii, rna is transcribed from a dna genome. 43. the table below shows the baltimore classification used to classify viruses based on their genetic material. what is a similar or different between the genome of group i and group vi, as well as how the two virus types reproduce?  this openstax book is available for free at http://cnx.org/content/col12078/1.6  chapter 21 | viruses  883  change within the host cell and why?  a. group i and vi viruses use rna as their genome. group i viruses reproduce by transcribing rna from their dna genome, while group vi viruses first synthesize their rna genome using reverse transcriptase before they can reproduce. b. group i and vi viruses use dna as their genome. group i viruses reproduce by transcribing rna from their dna genome while group vi viruses first synthesize their dna genome using reverse transcriptase before they can reproduce. c. group i and vi viruses use dna as their genome. group i viruses reproduce by transcribing rna from their dna genome, while group vi viruses first synthesize rna genome using reverse transcriptase before they can reproduce. d. group i viruses use dna as their genome while group vi use rna. group i viruses reproduce by transcribing rna from their dna genome while group vi viruses synthesize dna from rna using reverse transcriptase before they can reproduce. 44. the diagram below shows the stages during which a virus infects a host cell. during which of the numbered steps does the amount of viral genetic material begin to  a. 1; virus enters the cell b. 2; virus rna enters the nucleus c. 3; new viruses assemble within the cell d. 4; viruses leave the cell 45. the diagram below shows the stages during which a virus infects a host cell. how could the influenza virus change the function of a host cell? which has the potential to produce the most copies of the virus?  884  chapter 21 | viruses  a. because it replicates its dna within the cell and reproduces, which could interfere with cell processes.  a. lysogenic, because the viral dna can be excised from the host cell’s dna when under stress.  b. because it replicates rna within the cell and reproduces which could interfere with cell processes.  b. lytic, because the viral dna can be excised from the host cell’s dna when under stress.  c. because it attacks the immune system of the host cell, which would in turn interfere with cell processes. d. because it replicates its protein within the cell and reproduces, which could interfere with cell processes. 46. the diagrams below model the lytic and lysogenic reproductive cycles of viruses. which cycle would maintain the dna of the virus over several generations, and why?  this openstax book is available for free at http://cnx.org/content/col12078/1.6  c. lytic, because the viral dna can be passed on when the host cell replicates. d. lysogenic, because the viral dna can be passed on when the host cell replicates. 47. the diagrams below model the lytic and lysogenic reproductive cycles of viruses. based on the diagram, identify whether the following statement is true or false, and explain why or why not: “the lysogenic cycle allows viruses to preserve their genome during unfavorable conditions.”  chapter 21 | viruses  885  a. true. because when the host cell experiences unfavorable conditions, it stops dividing and stays in the same state. b. true. because the host cell in both the replication stage and during unfavorable conditions stays in the lysogenic cycle as it is more preferable over the lytic cycle. c. false. because when the host cell experiences unfavorable conditions, the prophage exits the genome and enters the lytic cycle. d. false. because when the host cell experiences unfavorable conditions, the virus enters latency period.  science practice challenge questions 48. influenza a virus is the most pathogenic of the human influenza viruses. its envelope encloses a protein complex (vrnp) and eight, single-stranded, negative rna (the complement of a positive rna strand that can be transcribed by a ribosome) segments (vrna). each segment encodes one or two proteins that support viral replication. on the outer surface of the envelope are proteins that recognize and bind to host receptors. a. annotate the representation below to briefly describe each process associated with a numbered label.  figure 21.21  b. describe influenza a viral replication as a process regulated by either positive or negative feedback and  886  justify your selection. the human-acquired immunodeficiency syndrome (aids) and many cancers are cause by double-stranded rna retroviruses. c. contrast the processes of viral replication of hiv and influenza a virus. d. explain the difference in the effects of infection by hiv and influenza a virus on host genetic variability. e. measured mutation rates for influenza a virus and hiv are nearly identical (sanjuan et al., jour. virology, 2010). explain this observation even though host error-checking operates in one of these replication modes. 49. three-dimensional (3d) structures, or foldin",t_42dacaed953f,other,0
c_5be5c03b250b,(1) adjustable dc power supply  model:________________ srn:__________________  (1) digital multimeter  model:________________ srn:__________________  (1) 10 k\(\omega\) potentiometer  (1) 100 k\(\omega\) potentiometer  (1) 1 k\(\omega\)  __________________  (1) 4.7 k\(\omega\)  __________________  (1) 47 k\(\omega\)  __________________,t_86afbe97aaa7,other,0
c_053233908d12,"upper bound on forward settlement price  let's see if there's a way to make a risk free profit. and let me just tell you right from the get go, there's usually not many ways to make a risk free profit in the world. so this is very theoretical. if the spot price for gold was $1,000-- so the spot price literally just means the market price. if you were to buy or sell gold today and actually exchange hands, then you would pay or sell the gold for $1,000 per ounce. and let's also say that the one year forward settlement price is $1,200 per ounce. so if you want to buy gold one year from now, you could agree right now to buy it for $1,200. or if you want to sell gold one year from now, you could agree right now to sell it for $1,200 by entering into a forward, or futures, contract. and just the other details, the interest rate to borrow money is 10%, and the carrying cost of gold is $50 per ounce per year. and the carrying cost means, if i had an ounce of gold, and i wanted to hold it responsibly-- i wanted to store it, maybe someplace in a safe at a bank, and i wanted to insure it in case it got stolen, or in case someone lost it-- that would cost me $50 per ounce per year. so that's what we mean by carrying cost. let's say you could also invest money risk free in this type of a market-- i've just made up these numbers-- for 5% a year. so, how could you make the money? we're assuming you start with nothing. so you could literally just borrow $1,000, and then you use that to buy an ounce of gold in the spot market, and you also agree to sell it in the future. so you enter into that forward contract. let me write this way-- enter into forward as the seller. so, on the spot market you are the buyer, and on the forward market, one year from now, you agree to be the seller. so, let's just think about how this is going to play out. so over the course of the year, you will have some costs. you will have to pay the interest on this $1,000. that's 10%. so you're going to pay $100 in interest. and you're going to pay the carrying cost, $50 per ounce. so $50 carrying cost. and so, when we end up a year from now, you will sell the gold $1,200. and you know you can do that, because you entered into the forward agreement. and then you can pay back the $1,000 loan plus $100 interest. and let's say you have to pay the carrying cost at the end of the year to the bank. so plus the $50 carrying cost. so how much did we profit? well, we get $1,200, and we have to pay back $1,150. so $1,200 minus $1,000 minus $100 minus $50, we make a profit of $50. so the big takeaway here is that these type of things normally don't exist. if they did, people would do it all day and all night. and this price would go up, because everyone would want to buy on spot, and this price would go down because everyone would want to sell in the futures market. everyone would want to do this right here. so the appropriate price is, this price, based on these numbers right here should not be any higher than $1,150. so, the correct market price here, if we didn't want to risk free profit or essentially what the arbitragers would make happen by taking advantage of this, it would eventually go to $1,150. so it's essentially the spot price plus the cost to borrow money at that spot price plus the carrying cost. so that's essentially what would be the rational price for the futures contract, or the forward settlement price.",t_cb5999e7e1eb,other,0
c_a6e6d2f1fa77,"in this video we show you how to create bit-zee's fenders out of hair dryer motor mounts and we also take you through how to mount the hair dryer motors in bit-zee's frame.  in this video, we're going to take our motor that's going to be our wheel from our hair dryer, and we're going to find a way to connect it to our tap light housing. so we're marking the screw boss locations on our tap light. and that's where the screws from the tap light connected to the bottom of the tap light housing. and we're going to measure between those. and so we've got about nine centimeters between those, so four and a half centimeters will be right in the center. and we're going to mark that because we don't have a direct line connecting it. we're going to double check those measurements with our ruler on both sides. and it's important that the mark is right in the center so that our wheels line up when we put them in. so we're going to do the same on the other side. again, it's about nine centimeters across, so four and a half between. and then we're going to just drop that mark down the side. and we're going to use the inside of our tape roll to create the arc that we need for our wheel well. and we're going to measure off of the boss, the screw boss, to the bottom. and that'll be 1.5 centimeters. and we're going to measure off of that. and then we'll transfer that 1.5 centimeters to the outside, and that'll be the top of the arc that we're going to create with our tape roll. so we're going to just line it up with the mark there. and then we'll take our sharpie, and we'll draw our arc. so once we have our arc drawn, we can begin removing the material that we need to remove so that the motors fit inside of the tap light housing. and now we're going to put on safety gloves. and we're going to use a break off blade knife. the break off blade is probably not the best knife to use for this. i'd probably use an x-acto knife or another kind of carving knife, but it's the one i happen to have. you can see the blade just snap there, so make sure if you do use this kind of knife that you wear safety glasses. but right now, we're just whittling away at the material. and it's very soft, very easy to cut with a knife. you can just trim it down. you want to just take the material away just a little bit at a time. and then, obviously, you want to try and make sure they stay inside that black line. you don't want to cut too far away. otherwise your wheel well will not line up with the wheel just perfectly. of course if you do go a little over, it's fine. it won't hurt anything, but it definitely won't look quite as good. so we're just trimming up the inside edge of that wheel well now and cleaning it up with the knife. and we'll do this on both sides, so it's the exact same process on the other side. so we're lining it up to see if it fits with the motor and it looks like it's pretty well. so we're just lining our motor up with housing, making sure that the opening is the right size. you see the vanes here on the motor, that connects the inner motor surround to the outer motor surround, the surround that basically protects you from the fan blades? we're going to have to remove some of those in order to get the fan to contact the floor. now the fan is acting like our wheel, and in order for it to move the craft forward, we have to remove the bottom part of that outer housing around the fan, the clear plastic housing. so we're going to remove two of the vanes on the bottom and three on the top. and the two that we're going to keep we just marked with our sharpie. so the two that we're removing on the bottom, we're using our nipper pliers. so we're snipping those off. and then we're going to take our hacksaw blade, and we're going to clamp the motor in place as best we can. and we're going to take our hacksaw blade and trim off-- just basically cut straight through the outer housing, the outer clear plastic piece that goes around the blades. we want to make sure that we line the two propeller blades up in such a way that when we cut through the outer housing, we don't cut into the propeller blades. because we want to use those as our wheel. now this is time lapsed, so it's going faster than normal. but i've already cut through the other side. this side's almost cut through. i'm going to use the nipper pliers to trim off the rest. then we're going to make sure that we've got enough blade exposed, and it does look like it. we're going to clean up the edges with a break off blade knife. and that's just to clean off the burrs and the rough edges of our motor. make sure everything is clean and exposed and ready to go. and we're just trimming off the excess there. so now you can see the motor spins freely and can connect with the floor. and on top of the motor, there's a-- we're just checking to make sure it still works and spins freely. so on top of the motor, you can see there's a sharpie marker mark. and that was drawn from just taking the bezel and putting it over the motor. and so we want to see if we can cut that mark out. and so we're going to take our hacksaw blade, and we're going to cut the plastic housing at an angle so we can try and get as close to that line as possible. so it's at about a 20 degree angle. and we're just cutting straight down to try and cut along that line that we drew with our sharpie. and the point of this is basically just to get that plastic surround to sort of wrap around the tap light housing. and we're cutting through it. it takes a good bit of work to get it lined up, but since we're doing it by hand we can hold it like that. now we're taking our nipper pliers, and we're snapping those connections. and we're just going to cut right through the rest of the housing. now we're pretty close to where we need to be. so in order to get it to fit just right, we're going to need to trim it. and we're going to use our nipper pliers to finish the trimming and make sure that we can get the kind of fit that we want. it takes a fair bit of patience, but i think it's better to take a little bit off at a time than to try and do it all at once and not get a nice, clean fit. so we're just snapping through the different parts there. and you can see that the motor fits nicely against the white plastic housing. so we've got protection on our motor, around our blades, and it fits nicely against the outside. we're taking just a little bit more material off now to make sure that the motor fits pretty well. and again, this material cuts very easily with our nipper pliers. so you could potentially cut the whole thing with the nipper pliers and not use the hacksaw if you wanted to, but i felt like it was a little easier to use the hack saw. so we're just checking our motor out, and making sure it fits, and double checking the connection between the motor and the housing. giving it a close inspection. you can see that there's a pretty good fit there. we're trying to find out if there's any places where there may be an interference, or the parts don't come together the way we want them to. and we're also looking at how we could fasten the motor to the housing and making sure everything clears. so there are a couple of little nibs, plastic nibs, left from when we cut off the vanes using our nipper pliers. so we're just filing those down so that the motor will sit flush with the lexan. and the motor needs to sit flush, because we're going to zip tie the motor in place. we're going to hold it in place. and if the motor has those bumps on it, it won't have quite as good a fit. so right now, we're just making marks. we made four little marks there. and those marks go on either side of the motor. and we're going to use those to run our zip tie through. so we'll run our zip tie through from one side to the other. and we're just going to use a quarter inch drill bit. all right, so now we're just removing the screws from our polystyrene housing and getting them out of the way. and we're going to drill our holes that we marked for the motor. and that will allow us to run our zip tie through. and we're just going to clean the edges of the holes up with our break off blade knife there, making sure that they line up with our motor. and they do. and those holes are roughly a quarter of an inch in diameter. doesn't really matter exactly the size, but as long as they're just a little bigger than your zip tie, you're fine. so we're going to thread the zip tie through. we want to make sure that the bump on the end of the zip tie is on top of the lexan so that the zip tie holds tightly against the motor. and because the motor has got two levels of plastic, we're putting a little shim in there, just a little piece of extra plastic. and that'll help hold the motor flat. and now we're going to pull the zip tie down. we'll pull it down all the way and snap it in place. you can see now the motor's pretty securely in place. we're going to go ahead and grab another zip tie and do the other side. so we'll grab-- oh we're just pushing the shim the rest of the way in. i forgot to mention that. we want to make sure the shim is tightly secured in there. and the shim is just made out of another-- it's same type of lexan, same thickness. we just cut a little piece of it that's about half an inch square and stuck it underneath that part of the motor. all right, so one more zip tie on this motor. and the other motor's done exactly the same way, but we're going to run the zip tie through and connect it. again, the raised portion of the zip tie needs to be above the lexan. we'll feed the bottom of the zip tie through and pull it tight against the motor. this'll give us the ability to adjust the motor if we need to. make sure that it's lined up along the imaginary axis between two, where the two motors will be. and as we're tightening that down, we may want to grab a screwdriver to finish tightening it the rest of the way. and we'll leave the zip ties long so we can make some changes later, if we need to undo the zip ties. so basically, that's how to mount the motors for your bit-zee bot. the other one's done exactly the same way. thanks.",t_921f2dc4ef82,other,0
c_47751542d30c,"to understand the concept of bubble sort using a game.sorting lesson plan:​ ​ class 08 / alg / 01 o​verall goal of the lesson​: children will learn the concept of linear search. prior knowledge required: module 1: module time: ​35 x 2 minutes goal: ​to understand the concept of bubble sort using a game. description: ​children will learn understand the concept of sorting. material required: physical: 1. one copy of the worksheet per child. 2. writing material to solve the worksheet: pencil and eraser. electronic: ppt presentation procedure summary: 1. run through the presentation 2. do all the activities that are in the presentation 3. distribute the worksheets 4. let children try to solve them in class and help them with the answers procedure details: slide 2 learning objectives: explain to the students in brief about ascending and descending order and tell them that they will learn how a computer sorts numbers slide 3: this slide is to explain the importance of sorting. show them two pictures one which is an untidy room and the other which is a neat and tidy room. ask them which room they will prefer to study and why typical answers expected are the first room is untidy where as the second one is tidy. the books are arranged neatly. there is no clutter in the second room etc. explain the importance of keeping their rooms clean and sorted so that they don’t need to search for anything they need. now tell that a computer also uses sorting so that it will be easy for it to search for a given number when asked. slide 4: touch upon the two types of sorting ascending and descending order. slide 5: explain the game we are going to play. here we are sorting numbers using a robot which cannot see so well. it can pick one number in its left hand, the other one in its right hand, take it close to its eyes to read the numbers. if the number on the left hand is greater than the number on the right hand then it will swap the numbers and place them back. the robot will do this exercise until no more numbers require to be swapped. slide 6 to 26 gives a pictorial representation of bubble sort algorithm. this can be explained to students taking a robot which cannot see so well. in order to read the numbers it has to hold the numbers close to its eyes to see. number on the right hand is greater than the left hand, then the robot swaps the numbers and places them down. slide 27: summary slide: ask the students if the robot could arrange all the numbers just by going through the list once?  1  the answer is no because every time it went through the list it was able to find the right place for the largest number in the list. it had to go through the list again and again until no more swap is required. explain the concept of worst case execution time for a bubble sort algorithm. it takes o(n​2​) for a n numbers. this concept is just for teachers. you can simplify that if we have 5 numbers to sort then we can take a maximum of 5 x 5 = 25 iterations to complete the sorting process  2",t_e78e25bd21a5,other,0
c_93184a5739a3,"finding the length of an arc using the degree of the angle subtended by the arc and the perimeter of the circle.  i have a circle here whose circumference is 18 pi. so if we were to measure all the way around the circle, we would get 18 pi. and we also have a central angle here. so this is the center of the circle. and this central angle that i'm about to draw has a measure of 10 degrees. so this angle right over here is 10 degrees. and what i'm curious about is the length of the arc that subtends that central angle. so what is the length of what i just did in magenta? and one way to think about it, or actually maybe the way to think about it, is that the ratio of this arc length to the entire circumference-- let me write this down-- should be the same as the ratio of the central angle to the total number of angles if you were to go all the way around the circle-- so to 360 degrees. so let's just think about that. we know the circumference is 18 pi. we're looking for the arc length. i'm just going to call that a. a for arc length. that's what we're going to try to solve for. we know that the central angle is 10 degrees. so you have 10 degrees over 360 degrees. so we could simplify this by multiplying both sides by 18 pi. and we get that our arc length is equal to-- well, 10/360 is the same thing as 1/36. so it's equal to 1/36 times 18 pi, so it's 18 pi over 36, which is the same thing as pi/2. so this arc right over here is going to be pi/2, whatever units we're talking about, long. now let's think about another scenario. let's imagine the same circle. so it's the same circle here. our circumference is still 18 pi. there are people having a conference behind me or something. that's why you might hear those mumbling voices. but this circumference is also 18 pi. but now i'm going to make the central angle an obtuse angle. so let's say we were to start right over here. this is one side of the angle. i'm going to go and make a 350 degree angle. so i'm going to go all the way around like that. so this right over here is a 350 degree angle. and now i'm curious about this arc that subtends this really huge angle. so now i want to figure out this arc length-- so all of this. i want to figure out this arc length, the arc that subtends this really obtuse angle right over here. well, same exact logic-- the ratio between our arc length, a, and the circumference of the entire circle, 18 pi, should be the same as the ratio between our central angle that the arc subtends, so 350, over the total number of degrees in a circle, over 360. so multiply both sides by 18 pi. we get a is equal to-- this is 35 times 18 over 36 pi. 350 divided by 360 is 35/36. so this is 35 times 18 times pi over 36. well both 36 and 18 are divisible by 18, so let's divide them both by 18. and so we are left with 35/2 pi. let me just write it that way-- 35 pi over 2. or, if you wanted to write it as a decimal, this would be 17.5 pi. now does this makes sense? this right over here, this other arc length, when our central angle was 10 degrees, this had an arc length of 0.5 pi. so when you add these two together, this arc length and this arc length, 0.5 plus 17.5, you get to 18 pi, which was the circumference, which makes complete sense because if you add these angles, 10 degrees and 350 degrees, you get 360 degrees in a circle.",t_ea0d5b486bdd,other,0
c_5e5fbf33e31d,"sal determines if y is a function of x from looking at a table.  in the following table, is y a function of x? in order for y to be a function of x, for any x that we input into our little function box-- so let's say this is y as a function of x. it needs to spit out only one value of y. if it spit out multiple values of y, then it might be a relationship, but it's not going to be a function. so this is a function. this is a function. if we had a situation where if we input x into a box, it could be multiple possible y's, then this is not a function. so let's think about this table right over here. when x is equal to 1, we get y is equal to 1. but when x is equal to 1 again, all of a sudden, y is equal to 2. so here we have a situation where we input 1 into our little relationship box, and when we input 1 into our relationship box, we could get a 1, or we could get a 2 for y. so this is definitely not a function. for any input into a function, it has to map to exactly one output. here it's mapping to two outputs. so this is not a function.",t_86392a2140b0,other,0
c_83a24dca0e7c,"visit us (http://www.khanacademy.org/science/healthcare-and-medicine) for health and medicine content or (http://www.khanacademy.org/test-prep/mcat) for mcat related content. these videos do not provide medical advice and are for informational purposes only. the videos are not intended to be a substitute for professional medical advice, diagnosis or treatment. always seek the advice of a qualified- so let's say this person has extremely low cd4 cell counts, right, let's say it's because of an immune deficiency like aids. and you know, let's say they have a really high viral load, as well, right? and we've decided, right, or their doctor, and jointly us and them have decided that it's time to start haart therapy, right, antiretroviral therapy. so we do. we prescribe the drug and they take the drug and everything is cool, everything is good at this point, right? viral load is going down, all these viruses are being stopped from replicating, that's great. but what else happens when viral load goes down? well, i mean this is a good thing, but immune cells are gonna start coming back, right, that's good. cd4 cells are gonna come back, and cd8 cells, and macrophages, and neutrophils&lrm;, and all sorts of white blood cells are going to start being, sort of, recreated in the bone marrow, and they're gonna start being able to survive in the body without being destroyed by the effects of hiv, right? so i want you to think about something here. well, we're essentially flooding the body now with white blood cells, right? the plan is to get our level of white cells to pre-infection levels, really healthy levels of white cells. but just what was going on when they weren't around, when their levels were really low? well remember someone with an immunodeficiency they can pick up opportunistic infections. and these opportunistic infections can sort of lay low, right, and they might not cause any outward symptoms. so the person might have bacteria floating around, or viruses, or fungi, but they might not have any outward symptoms. they might not know that they have occult, opportunistic infections, that's what we call infections, or really anything that's not really readily detectable, we call it occult. the problem is, now that the immune system is getting stronger, right, it's reconstituting, so to speak, now we have the tools, right, the fire power to recognize these occult infections, and we might start to fight against them. and when we start this war, right, this battle against these, they might, again, they might be bacteria, or viruses, or fungal infections, our immune cells are gonna release these little chemicals called cytokines and little molecules that create a really inflammatory environment. which is normal, i mean, that's part of our immune response, and that's kind of one of the mechanisms that we have to call in reinforcements, right, sending out all these inflammatory signals. but sometimes they go overboard, they take it a little too far and they overdo the inflammatory signals. so there are cytokines everywhere, and this might cause the person to have a really high fever. and there's little compounds, that the white little blood cells release, that are designed to damage the bad guys, but they can actually end up damaging tissue, as well. so there's potentially some tissue damage happening. and remember, i said reinforcements are coming in, right, so more white cells are coming in and this cascade is sort of cascading away, right? well, this whole thing, right, everything i've described here, there's a name for it, and it's called immune reconstitution inflammatory syndrome, or iris. so it's basically a tremendous amount of inflammation, right, systemic inflammation all over the body due to the immune system reacting against bugs that it just discovered upon it's sort of return from low function. so i mentioned that the person is gonna have a fever, right, a high fever, but they're also gonna feel really, really sick when this is happening. you know, it's kind of paradoxical, but they might actually start to get symptoms of the opportunistic infections that they have. they might actually start to get worstening of those symptoms, which is kind of interesting. they're just gonna feel really unwell. so everything i've just described there, that's the classic, sort of, manifestation of iris when the immune system comes back and then it realizes, it recognizes that there's all these little bugs running wild everywhere and then it starts up this crazy inflammatory syndrome, that's the usual way that iris manifests. but there's also another fairly common scenario that iris can sort of manifest as, and this one's a little bit more bizarre. so sometimes some of the t cells that get reconstituted, they get replenished, remade, and are now patrolling around the body. well, they might run into some dead bugs, or little bits of dead bugs, right? maybe bacteria, or viruses, or fungi that maybe haven't been cleared out of the body yet. oten a few weeks previously, the person was infected with an opportunistic infection and they took medication and the bugs all died off because of the medication the person took. but you know, the dead bugs might just not be cleared out yet, it takes a little bit of time, even though they're dead. but these reconstituted t cells, they might mistakenly think that they've encountered a real threat. so again, they kick off the big inflammatory cascade that we call iris. so those are really the two most common manifestations of iris. now a few things i just want to touch on before we wrap up here, so, does this happen in everyone? and the answer is no. it seems to only happen in about 20% of people who have just started haart treatment. and that's kind of interesting in itself, right, i mean, the same sort of thing is happening in everyone on haart, right? high viral load, and low t cells, and lots of bugs hanging around and doing whatever they want, and then immune reconstitution. so why only 20%? why not everyone? well, the answer isn't completely known right now, but it's thought that a couple things can increase the odds of iris after starting antiretroviral treatment. so having a really low amount of immune cells before starting haart, and, having any active opportunistic infections, or high burden of bugs in your system when you do start haart. and again, these qualities have just been associated with the development of iris and you know we're free to hypothesize why, but we can't exactly put our finger on why this is the way it is, as of yet. but in practice, we just try to minimize the risk of things like iris happening by treating any opportunistic infections a few weeks before we start anyone on haart. so the last thing i wanted to say is, you know, what's the prognosis, is the person gonna get better, are they gonna be okay? and also, how do we treat it? how do we treat iris? well, usually the person spontaneously gets better as the immune system gets stronger and stronger. so people usually get better without any extra treatment. but sometimes, just as a little boost, the person might be given antibiotics, or antivirals, against any known bug that they might have. and that's just to help the immune system fight off the infection a bit more easily. and sometimes if the inflammation is really bad, then the person might be given steroids to tone down the inflammation, that's one of the things that steroids do. so that'll sort of tone things down until the infection's been taken care of. but again, in that 20% of people who get iris after starting haart, usually they spontaneously get better without any extra treatment.",t_ba74a1bf2d5a,other,0
c_79aaf4a583a4,"david explains ""work"" as the way forces transfer energy to and from objects  one way to find the amount of work done is by using the formula fd cosine theta. but this number for the amount of work done represents the amount of energy transferred to an object. for instance, if you solve for the work done and you get positive 200 joules, it means that the force gave something 200 joules of energy. so if you have a way of determining the amount of energy that something gains or loses, then you have an alternate way of finding the work done, since the work done on an object is the amount of energy it gains or loses. for instance, imagine a 50-kilogram skateboarder that starts at rest. if a force starts the skateboarder moving at 10 meters per second, that force did work on the skateboarder since it gave the skateboarder energy. the amount of kinetic energy gained by the skateboarder is 2,500 joules. that means that the work done by the force on the skateboarder was positive 2,500 joules. it's positive because the force on the skateboarder gave the skateboarder 2,500 joules. if a force gives energy to an object, then the force is doing positive work on that object. and if a force takes away energy from an object, the force is doing negative work on that object. now imagine that the skateboarder, who's moving with 10 meters per second, gets stopped because he crashes into a stack of bricks. the stack of bricks does negative work on the skateboarder because it takes away energy from the skateboarder. to find the work done by the stack of bricks, we just need to figure out how much energy it took away from the skateboarder. since the skateboarder started with 2,500 joules of kinetic energy and ends with zero joules of kinetic energy, it means that the work done by the bricks on the skateboarder was negative 2,500 joules. it's negative because the bricks took away energy from the skateboarder. let's say we instead lift the bricks, which are 500 kilograms, upwards a distance of four meters. to find the work that we've done on the bricks, we could use fd cosine theta. but we don't have to. we could just figure out the amount of energy that we've given to the bricks. the bricks gain energy here. and they're gaining gravitational potential energy, which is given by the formula mgh. if we solve, we get that the bricks gained 19,600 joules of gravitational potential energy. that means that the work we did on the bricks was positive 19,600 joules. it's positive because our force gave the bricks energy. this idea doesn't just work with gravitational potential energy and kinetic energy. it works for every kind of energy. you can always find the work done by a force on an object if you could determine the energy that that force gives or takes away from that object. [music playing]",t_615bb8505813,other,0
c_4d7a81a2665a,"a polyhedron is a three-dimensional shape that has flat surfaces and straight edges.  learn whether or not a certain net could be folded up into a certain rectangular prism.  teddy knows that a figure has a surface area of 40 square centimeters. the net below has 5 centimeter and 2 centimeter edges. could the net below represent the figure? so let's just make sure we understand what this here represents. so it tells us that it has 5 centimeter edges. so this is one of the 5 centimeter edges right over here. and we know that it has several other 5 centimeter edges because any edge that has this double hash mark right over here is also going to be 5 centimeters. so this edge is also 5 centimeters, this is also 5 centimeters, this is also 5 centimeters, and then these two over here are also 5 centimeters. so that's 5 centimeters, and that's 5 centimeters. and then we have several 2 centimeter edges. so this one has 2 centimeters. and any other edge that has the same number of hash marks, in this case one, is also going to be 2 centimeters. so all of these other edges, pretty much all the rest of the edges, are going to be 2 centimeters. now, they don't ask us to do this in the problem, but it's always fun to start with a net like this and try to visualize the polyhedron that it actually represents. it looks pretty clear this is going to be a rectangular prism. but let's actually draw it. so if we were to-- we're going to fold this in. we're going to fold this that way. you could view this as our base right over here. we're going to fold this in. we're going to fold that up. and then this is going to be our top. this is the top right over here. this polyhedron is going to look something like this. so you're going to have your base that has a length of 5 centimeters. so this is our base. let me do that in a new color. so this is our base right over here. i'll do it in the same color. so that's our base, this dimension right over here. i could put the double hash marks if i want. 5 centimeters, and that's of course the same as that dimension up there. now, when we fold up this side-- we'll do this in orange, actually-- when we fold up that side, that could be this side right over here, along this 2 centimeter edge. so that's that side right over here. when you fold this side in right over here, that could be that. that's that side right over there. and then when of course we fold this side in-- that's the same color. let me do a different color. when we fold this side in, that's the side that's kind of facing us a little bit. so that's that right over there. that's that right over there. color that in a little bit better. and then we can fold this side in, and that would be that side. and then, of course, we have the top that's connected right over here. so the top would go-- this would be the top, and then the top would, of course, go on top of our rectangular prism. so that's the figure that we're talking about. it's 5 centimeters in this dimension. it is 2 centimeters tall, and it is 2 centimeters wide. but let's go back to the original question. is this thing's surface area 40 square centimeters? well, the good thing about this net here is it's laid out all of the surfaces for us, so we just have to figure out the surface area of each of these sections and then add them together, the surface area of each of these surfaces. so what is the surface area of this one here? well, it's going to be 5 centimeters times 2 centimeters. so it's going to be 10 square centimeters. same thing for this one. it's going to be 5 by 2, 5 by 2. this one is 5 by 2. so these are each 10 square centimeters, and so is this one. this is 5 long, 5 centimeters long, 2 centimeters wide. so once again, that's 10 square centimeters. now, these two sections right over here, they're 2 centimeters by 2 centimeters. so they're each going to be 4 square centimeters. so what's the total surface area? well, 10 plus 10 plus 10 plus 10 is 40, plus 4 plus 4 gets us to 48 square centimeters, or centimeters squared. so could the net below represent the figure that has a surface area of 40 square centimeters? no. this represents a figure that has a surface area of 48 square centimeters.",t_dc5df8d7cbc8,other,0
c_e2feb7b02e86,"chapter 30 | government budgets and fiscal policy  30 | government budgets and fiscal policy  figure 30.1 shut downs and parks yellowstone national park is one of the many national parks forced to close down during the government shut down in october 2013. (credit: modification of work by “daveynin”/flickr creative commons)  no yellowstone park? so you had trekked all the way to see yellowstone national park in the beautiful month of october 2013, only to find it… closed. closed! why? for two weeks in october 2013, the u.s. federal government shut down. many federal services, like the national parks, closed and 800,000 federal employees were furloughed. tourists were shocked and so was the rest of the world: congress and the president could not agree on a budget. inside the capitol, republicans and democrats argued about spending priorities and whether to increase the national debt limit. each year's budget, which is over $3 trillion of spending, must be approved by congress and signed by the president. two thirds of the budget is entitlements and other mandatory spending which occur without congressional or presidential action once the programs are set up. tied to the budget debate was the issue of increasing the debt ceiling—how high the national debt of the u.s. government can be. the house of representatives refused to sign on to the bills to fund the government unless they included provisions to stop or change the affordable health care act (more colloquially known as obamacare). as the days ticked by, the united states came very close to defaulting on its debt. why does the federal budget create such intense debates? what would happen if the united states actually defaulted on its debt? in this chapter, we will examine the federal budget, taxation, and fiscal policy. we will also look at the annual federal budget deficits and the national debt.  689  690  chapter 30 | government budgets and fiscal policy  introduction to government budgets and fiscal policy in this chapter, you will learn about: • government spending • taxation • federal deficits and the national debt • using fiscal policy to fight recessions, unemployment, and inflation • automatic stabilizers • practical problems with discretionary fiscal policy • the question of a balanced budget all levels of government—federal, state, and local—have budgets that show how much revenue the government expects to receive in taxes and other income and how the government plans to spend it. budgets, however, can shift dramatically within a few years, as policy decisions and unexpected events shake up earlier tax and spending plans. in this chapter, we revisit fiscal policy, which was first covered in welcome to economics! fiscal policy is one of two policy tools for fine tuning the economy (the other is monetary policy). while monetary policy is made by policymakers at the federal reserve, fiscal policy is made by congress and the president. the discussion of fiscal policy focuses on how federal government taxing and spending affects aggregate demand. all government spending and taxes affect the economy, but fiscal policy focuses strictly on the policies of the federal government. we begin with an overview of u.s. government spending and taxes. we then discuss fiscal policy from a short-run perspective; that is, how government uses tax and spending policies to address recession, unemployment, and inflation; how periods of recession and growth affect government budgets; and the merits of balanced budget proposals.  30.1 | government spending by the end of this section, you will be able to: • identify u.s. budget deficit and surplus trends over the past five decades • explain the differences between the u.s. federal budget, and state and local budgets government spending covers a range of services provided by the federal, state, and local governments. when the federal government spends more money than it receives in taxes in a given year, it runs a budget deficit. conversely, when the government receives more money in taxes than it spends in a year, it runs a budget surplus. if government spending and taxes are equal, it is said to have a balanced budget. for example, in 2009, the u.s. government experienced its largest budget deficit ever, as the federal government spent $1.4 trillion more than it collected in taxes. this deficit was about 10% of the size of the u.s. gdp in 2009, making it by far the largest budget deficit relative to gdp since the mammoth borrowing used to finance world war ii. this section presents an overview of government spending in the united states.  total u.s. government spending federal spending in nominal dollars (that is, dollars not adjusted for inflation) has grown by a multiple of more than 38 over the last four decades, from $93.4 billion in 1960 to $3.9 trillion in 2014. comparing spending over time in nominal dollars is misleading because it does not take into account inflation or growth in population and the real economy. a more useful method of comparison is to examine government spending as a percent of gdp over time. the top line in figure 30.2 shows the level of federal spending since 1960, expressed as a share of gdp. despite a widespread sense among many americans that the federal government has been growing steadily larger, the graph shows that federal spending has hovered in a range from 18% to 22% of gdp most of the time since 1960. the other lines in figure 30.2 show the major federal spending categories: national defense, social security, health  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  691  programs, and interest payments. from the graph, we see that national defense spending as a share of gdp has generally declined since the 1960s, although there were some upward bumps in the 1980s buildup under president ronald reagan and in the aftermath of the terrorist attacks on september 11, 2001. in contrast, social security and healthcare have grown steadily as a percent of gdp. healthcare expenditures include both payments for senior citizens (medicare), and payments for low-income americans (medicaid). medicaid is also partially funded by state governments. interest payments are the final main category of government spending shown in the figure.  figure 30.2 federal spending, 1960–2014 since 1960, total federal spending has ranged from about 18% to 22% of gdp, although it climbed above that level in 2009, but quickly dropped back down to that level by 2013. the share spent on national defense has generally declined, while the share spent on social security and on healthcare expenses (mainly medicare and medicaid) has increased. (source: economic report of the president, tables b-2 and b-22, http://www.gpo.gov/fdsys/pkg/erp-2014/content-detail.html)  each year, the government borrows funds from u.s. citizens and foreigners to cover its budget deficits. it does this by selling securities (treasury bonds, notes, and bills)—in essence borrowing from the public and promising to repay with interest in the future. from 1961 to 1997, the u.s. government has run budget deficits, and thus borrowed funds, in almost every year. it had budget surpluses from 1998 to 2001, and then returned to deficits. the interest payments on past federal government borrowing were typically 1–2% of gdp in the 1960s and 1970s but then climbed above 3% of gdp in the 1980s and stayed there until the late 1990s. the government was able to repay some of its past borrowing by running surpluses from 1998 to 2001 and, with help from low interest rates, the interest payments on past federal government borrowing had fallen back to 1.4% of gdp by 2012. we investigate the patterns of government borrowing and debt in more detail later in this chapter, but first we need to clarify the difference between the deficit and the debt. the deficit is not the debt. the difference between the deficit and the debt lies in the time frame. the government deficit (or surplus) refers to what happens with the federal government budget each year. the government debt is accumulated over time; it is the sum of all past deficits and surpluses. if you borrow $10,000 per year for each of the four years of college, you might say that your annual deficit was $10,000, but your accumulated debt over the four years is $40,000. these four categories—national defense, social security, healthcare, and interest payments—account for roughly 73% of all federal spending, as figure 30.3 shows. the remaining 27% wedge of the pie chart covers all other categories of federal government spending: international affairs; science and technology; natural resources and the environment; transportation; housing; education; income support for the poor; community and regional development; law enforcement and the judicial system; and the administrative costs of running the government.  692  chapter 30 | government budgets and fiscal policy  figure 30.3 slices of federal spending, 2014 about 73% of government spending goes to four major areas: national defense, social security, healthcare, and interest payments on past borrowing. this leaves about 29% of federal spending for all other functions of the u.s. government. (source: https://www.whitehouse.gov/omb/budget/ historicals/)  state and local government spending although federal government spending often gets most of the media attention, state and local government spending is also substantial—at about $3.1 trillion in 2014. figure 30.4 shows that state and local government spending has increased during the last four decades from around 8% to around 14% today. the single biggest item is education, which accounts for about one-third of the total. the rest covers programs like highways, libraries, hospitals and healthcare, parks, and police and fire protection. unlike the federal government, all states (except vermont) have balanced budget laws, which means any gaps between revenues and spending must be closed by higher taxes, lower spending, drawing down their previous savings, or some combination of all of these.  figure 30.4 state and local spending, 1960–2013 spending by state and local government increased from about 10% of gdp in the early 1960s to 14–16% by the mid-1970s. it has remained at roughly that level since. the single biggest spending item is education, including both k–12 spending and support for public colleges and universities, which has been about 4–5% of gdp in recent decades. source: (source: bureau of economic analysis.)  u.s. presidential candidates often run for office pledging to improve the public schools or to get tough on crime. however, in the u.s. system of government, these tasks are primarily the responsibilities of state and local governments. indeed, in fiscal year 2014 state and local governments spent about $840 billion per year on education (including k–12 and college and university education), compared to only $100 billion by the federal government, according to usgovernmentspending.com. in other words, about 90 cents of every dollar spent on education happens  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  693  at the state and local level. a politician who really wants hands-on responsibility for reforming education or reducing crime might do better to run for mayor of a large city or for state governor rather than for president of the united states.  30.2 | taxation by the end of this section, you will be able to: • differentiate among a regressive tax, a proportional tax, and a progressive tax • identify the major sources of revenue for the u.s. federal budget there are two main categories of taxes: those collected by the federal government and those collected by state and local governments. what percentage is collected and what that revenue is used for varies greatly. the following sections will briefly explain the taxation system in the united states.  federal taxes just as many americans erroneously think that federal spending has grown considerably, many also believe that taxes have increased substantially. the top line of figure 30.5 shows total federal taxes as a share of gdp since 1960. although the line rises and falls, it typically remains within the range of 17% to 20% of gdp, except for 2009, when taxes fell substantially below this level, due to recession.  figure 30.5 federal taxes, 1960–2014 federal tax revenues have been about 17–20% of gdp during most periods in recent decades. the primary sources of federal taxes are individual income taxes and the payroll taxes that finance social security and medicare. corporate income taxes and social insurance taxes provide smaller shares of revenue. (source: economic report of the president, 2015. table b-21, https://www.whitehouse.gov/administration/eop/cea/ economic-report-of-the-president/2015)  figure 30.5 also shows the patterns of taxation for the main categories of taxes levied by the federal government: individual income taxes, corporate income taxes, and social insurance and retirement receipts. when most people think of taxes levied by the federal government, the first tax that comes to mind is the individual income tax that is due every year on april 15 (or the first business day after). the personal income tax is the largest single source of federal government revenue, but it still represents less than half of federal tax revenue. the second largest source of federal revenue is the payroll tax (captured in social insurance and retirement receipts), which provides funds for social security and medicare. payroll taxes have increased steadily over time. together, the personal income tax and the payroll tax accounted for about 80% of federal tax revenues in 2014. although personal income tax revenues account for more total revenue than the payroll tax, nearly three-quarters of households pay more in payroll taxes than in income taxes.  694  chapter 30 | government budgets and fiscal policy  the income tax is a progressive tax, which means that the tax rates increase as a household’s income increases. taxes also vary with marital status, family size, and other factors. the marginal tax rates (the tax that must be paid on all yearly income) for a single taxpayer range from 10% to 35%, depending on income, as the following clear it up feature explains.  how does the marginal rate work? suppose that a single taxpayer’s income is $35,000 per year. also suppose that income from $0 to $9,075 is taxed at 10%, income from $9,075 to $36,900 is taxed at 15%, and, finally, income from $36,900 and beyond is taxed at 25%. since this person earns $35,000, their marginal tax rate is 15%.  the key fact here is that the federal income tax is designed so that tax rates increase as income increases, up to a certain level. the payroll taxes that support social security and medicare are designed in a different way. first, the payroll taxes for social security are imposed at a rate of 12.4% up to a certain wage limit, set at $118,500 in 2015. medicare, on the other hand, pays for elderly healthcare, and is fixed at 2.9%, with no upper ceiling. in both cases, the employer and the employee split the payroll taxes. an employee only sees 6.2% deducted from his paycheck for social security, and 1.45% from medicare. however, as economists are quick to point out, the employer’s half of the taxes are probably passed along to the employees in the form of lower wages, so in reality, the worker pays all of the payroll taxes. the medicare payroll tax is also called a proportional tax; that is, a flat percentage of all wages earned. the social security payroll tax is proportional up to the wage limit, but above that level it becomes a regressive tax, meaning that people with higher incomes pay a smaller share of their income in tax. the third-largest source of federal tax revenue, as shown in figure 30.5 is the corporate income tax. the common name for corporate income is “profits.” over time, corporate income tax receipts have declined as a share of gdp, from about 4% in the 1960s to an average of 1% to 2% of gdp in the first decade of the 2000s. the federal government has a few other, smaller sources of revenue. it imposes an excise tax—that is, a tax on a particular good—on gasoline, tobacco, and alcohol. as a share of gdp, the amount collected by these taxes has stayed nearly constant over time, from about 2% of gdp in the 1960s to roughly 3% by 2014, according to the nonpartisan congressional budget office. the government also imposes an estate and gift tax on people who pass large amounts of assets to the next generation—either after death or during life in the form of gifts. these estate and gift taxes collected about 0.2% of gdp in the first decade of the 2000s. by a quirk of legislation, the estate and gift tax was repealed in 2010, but reinstated in 2011. other federal taxes, which are also relatively small in magnitude, include tariffs collected on imported goods and charges for inspections of goods entering the country.  state and local taxes at the state and local level, taxes have been rising as a share of gdp over the last few decades to match the gradual rise in spending, as figure 30.6 illustrates. the main revenue sources for state and local governments are sales taxes, property taxes, and revenue passed along from the federal government, but many state and local governments also levy personal and corporate income taxes, as well as impose a wide variety of fees and charges. the specific sources of tax revenue vary widely across state and local governments. some states rely more on property taxes, some on sales taxes, some on income taxes, and some more on revenues from the federal government.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  695  figure 30.6 state and local tax revenue as a share of gdp, 1960–2014 state and local tax revenues have increased to match the rise in state and local spending. (source: economic report of the president, 2015. table b-21, https://www.whitehouse.gov/administration/eop/cea/economic-report-of-the-president/2015)  30.3 | federal deficits and the national debt by the end of this section, you will be able to: • explain the u.s. federal budget in terms of annual debt and accumulated debt • understand how economic growth or decline can influence a budget surplus or budget deficit having discussed the revenue (taxes) and expense (spending) side of the budget, we now turn to the annual budget deficit or surplus, which is the difference between the tax revenue collected and spending over a fiscal year, which starts october 1 and ends september 30 of the next year. figure 30.7 shows the pattern of annual federal budget deficits and surpluses, back to 1930, as a share of gdp. when the line is above the horizontal axis, the budget is in surplus; when the line is below the horizontal axis, a budget deficit occurred. clearly, the biggest deficits as a share of gdp during this time were incurred to finance world war ii. deficits were also large during the 1930s, the 1980s, the early 1990s, and most recently during the recession of 2008–2009.  figure 30.7 pattern of federal budget deficits and surpluses, 1929–2014 the federal government has run budget deficits for decades. the budget was briefly in surplus in the late 1990s, before heading into deficit again in the first decade of the 2000s—and especially deep deficits in the recession of 2008–2009. (source: federal reserve bank of st. louis (fred). http://research.stlouisfed.org/fred2/series/fyfsgda188s)  696  chapter 30 | government budgets and fiscal policy  debt/gdp ratio another useful way to view the budget deficit is through the prism of accumulated debt rather than annual deficits. the national debt refers to the total amount that the government has borrowed over time; in contrast, the budget deficit refers to how much has been borrowed in one particular year. figure 30.8 shows the ratio of debt/gdp since 1940. until the 1970s, the debt/gdp ratio revealed a fairly clear pattern of federal borrowing. the government ran up large deficits and raised the debt/gdp ratio in world war ii, but from the 1950s to the 1970s the government ran either surpluses or relatively small deficits, and so the debt/gdp ratio drifted down. large deficits in the 1980s and early 1990s caused the ratio to rise sharply. when budget surpluses arrived from 1998 to 2001, the debt/gdp ratio declined substantially. the budget deficits starting in 2002 then tugged the debt/gdp ratio higher—with a big jump when the recession took hold in 2008–2009.  figure 30.8 federal debt as a percentage of gdp, 1942–2014 federal debt is the sum of annual budget deficits and surpluses. annual deficits do not always mean that the debt/gdp ratio is rising. during the 1960s and 1970s, the government often ran small deficits, but since the debt was growing more slowly than the economy, the debt/gdp ratio was declining over this time. in the 2008–2009 recession, the debt/gdp ratio rose sharply. (source: economic report of the president, table b-20, http://www.gpo.gov/fdsys/pkg/erp-2015/content-detail.html)  the next clear it up feature discusses how the government handles the national debt.  what is the national debt? one year’s federal budget deficit causes the federal government to sell treasury bonds to make up the difference between spending programs and tax revenues. the dollar value of all the outstanding treasury bonds on which the federal government owes money is equal to the national debt.  the path from deficits to surpluses to deficits why did the budget deficits suddenly turn to surpluses from 1998 to 2001? and why did the surpluses return to deficits in 2002? why did the deficit become so large after 2007? figure 30.9 suggests some answers. the graph combines the earlier information on total federal spending and taxes in a single graph, but focuses on the federal budget since 1990.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  697  figure 30.9 total government spending and taxes as a share of gdp, 1990–2014 when government spending exceeds taxes, the gap is the budget deficit. when taxes exceed spending, the gap is a budget surplus. the recessionary period starting in late 2007 saw higher spending and lower taxes, combining to create a large deficit in 2009. (source: economic report of the president, tables b-21 and b-1,""http://www.gpo.gov/fdsys/pkg/erp-2015/ content-detail.html)  government spending as a share of gdp declined steadily through the 1990s. the biggest single reason was that defense spending declined from 5.2% of gdp in 1990 to 3.0% in 2000, but interest payments by the federal government also fell by about 1.0% of gdp. however, federal tax collections increased substantially in the later 1990s, jumping from 18.1% of gdp in 1994 to 20.8% in 2000. powerful economic growth in the late 1990s fueled the boom in taxes. personal income taxes rise as income goes up; payroll taxes rise as jobs and payrolls go up; corporate income taxes rise as profits go up. at the same time, government spending on transfer payments such as unemployment benefits, foods stamps, and welfare declined with more people working. this sharp increase in tax revenues and decrease in expenditures on transfer payments was largely unexpected even by experienced budget analysts, and so budget surpluses came as a surprise. but in the early 2000s, many of these factors started running in reverse. tax revenues sagged, due largely to the recession that started in march 2001, which reduced revenues. a series of tax cuts was enacted by congress and signed into law by president george w. bush, starting in 2001. in addition, government spending swelled due to increases in defense, healthcare, education, social security, and support programs for those who were hurt by the recession and the slow growth that followed. deficits returned. when the severe recession hit in late 2007, spending climbed and tax collections fell to historically unusual levels, resulting in enormous deficits. longer-term forecasts of the u.s. budget, a decade or more into the future, predict enormous deficits. the higher deficits run during the recession of 2008–2009 have repercussions, and the demographics will be challenging. the primary reason is the “baby boom”—the exceptionally high birthrates that began in 1946, right after world war ii, and lasted for about two decades. starting in 2010, the front edge of the baby boom generation began to reach age 65, and in the next two decades, the proportion of americans over the age of 65 will increase substantially. the current level of the payroll taxes that support social security and medicare will fall well short of the projected expenses of these programs, as the following clear it up feature shows; thus, the forecast is for large budget deficits. a decision to collect more revenue to support these programs or to decrease benefit levels would alter this long-term forecast.  698  chapter 30 | government budgets and fiscal policy  what is the long-term budget outlook for social security and medicare? in 1946, just one american in 13 was over age 65. by 2000, it was one in eight. by 2030, one american in five will be over age 65. two enormous u.s. federal programs focus on the elderly—social security and medicare. the growing numbers of elderly americans will increase spending on these programs, as well as on medicaid. the current payroll tax levied on workers, which supports all of social security and the hospitalization insurance part of medicare, will not be enough to cover the expected costs. so, what are the options? long-term projections from the congressional budget office in 2009 are that medicare and social security spending combined will rise from 8.3% of gdp in 2009 to about 13% by 2035 and about 20% in 2080. if this rise in spending occurs, without any corresponding rise in tax collections, then some mix of changes must occur: (1) taxes will need to be increased dramatically; (2) other spending will need to be cut dramatically; (3) the retirement age and/or age receiving medicare benefits will need to increase, or (4) the federal government will need to run extremely large budget deficits. some proposals suggest removing the cap on wages subject to the payroll tax, so that those with very high incomes would have to pay the tax on the entire amount of their wages. other proposals suggest moving social security and medicare from systems in which workers pay for retirees toward programs that set up accounts where workers save funds over their lifetimes and then draw out after retirement to pay for healthcare. the united states is not alone in this problem. indeed, providing the promised level of retirement and health benefits to a growing proportion of elderly with a falling proportion of workers is an even more severe problem in many european nations and in japan. how to pay promised levels of benefits to the elderly will be a difficult public policy decision.  in the next module we shift to the use of fiscal policy to counteract business cycle fluctuations. in addition, we will explore proposals requiring a balanced budget—that is, for government spending and taxes to be equal each year. the impacts of government borrowing will also cover how fiscal policy and government borrowing will affect national saving—and thus affect economic growth and trade imbalances.  30.4 | using fiscal policy to fight recession, unemployment, and inflation by the end of this section, you will be able to: • explain how expansionary fiscal policy can shift aggregate demand and influence the economy • explain how contractionary fiscal policy can shift aggregate demand and influence the economy we need to emphasize that fiscal policy is the use of government spending and tax policy to alter the economy. fiscal policy does not include all spending (such as the increase in spending that accompanies a war). graphically, we see that fiscal policy, whether through change in spending or taxes, shifts the aggregate demand outward in the case of expansionary fiscal policy and inward in the case of contractionary fiscal policy. figure 30.10 illustrates the process by using an aggregate demand/aggregate supply diagram in a growing economy. the original equilibrium occurs at e0, the intersection of aggregate demand curve ad0 and aggregate supply curve sras0, at an output level of 200 and a price level of 90. one year later, aggregate supply has shifted to the right to sras1 in the process of long-term economic growth, and aggregate demand has also shifted to the right to ad1, keeping the economy operating at the new level of potential gdp. the new equilibrium (e1) is an output level of 206 and a price level of 92. one more year later, aggregate  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  699  supply has again shifted to the right, now to sras2, and aggregate demand shifts right as well to ad2. now the equilibrium is e2, with an output level of 212 and a price level of 94. in short, the figure shows an economy that is growing steadily year to year, producing at its potential gdp each year, with only small inflationary increases in the price level.  figure 30.10 a healthy, growing economy in this well-functioning economy, each year aggregate supply and aggregate demand shift to the right so that the economy proceeds from equilibrium e0 to e1 to e2. each year, the economy produces at potential gdp with only a small inflationary increase in the price level. but if aggregate demand does not smoothly shift to the right and match increases in aggregate supply, growth with deflation can develop.  aggregate demand and aggregate supply do not always move neatly together. aggregate demand may fail to increase along with aggregate supply, or aggregate demand may even shift left, for a number of possible reasons: households become hesitant about consuming; firms decide against investing as much; or perhaps the demand from other countries for exports diminishes. for example, investment by private firms in physical capital in the u.s. economy boomed during the late 1990s, rising from 14.1% of gdp in 1993 to 17.2% in 2000, before falling back to 15.2% by 2002. conversely, if shifts in aggregate demand run ahead of increases in aggregate supply, inflationary increases in the price level will result. business cycles of recession and recovery are the consequence of shifts in aggregate supply and aggregate demand. monetary policy and bank regulation shows us that a central bank can use its powers over the banking system to engage in countercyclical—or “against the business cycle”—actions. if recession threatens, the central bank uses an expansionary monetary policy to increase the supply of money, increase the quantity of loans, reduce interest rates, and shift aggregate demand to the right. if inflation threatens, the central bank uses contractionary monetary policy to reduce the supply of money, reduce the quantity of loans, raise interest rates, and shift aggregate demand to the left. fiscal policy is another macroeconomic policy tool for adjusting aggregate demand by using either government spending or taxation policy.  expansionary fiscal policy expansionary fiscal policy increases the level of aggregate demand, through either increases in government spending or reductions in taxes. expansionary policy can do this by (1) increasing consumption by raising disposable income through cuts in personal income taxes or payroll taxes; (2) increasing investments by raising after-tax profits through cuts in business taxes; and (3) increasing government purchases through increased spending by the federal government on final goods and services and raising federal grants to state and local governments to increase their expenditures on final goods and services. contractionary fiscal policy does the reverse: it decreases the level of aggregate demand by decreasing consumption, decreasing investments, and decreasing government spending, either through cuts in government spending or increases in taxes. the aggregate demand/aggregate supply model is useful in judging whether expansionary or contractionary fiscal policy is appropriate. consider first the situation in figure 30.11, which is similar to the u.s. economy during the recession in 2008–2009. the intersection of aggregate demand (ad0) and aggregate supply (sras0) is occurring below the level of potential gdp as indicated by the lras curve. at the equilibrium (e0), a recession occurs and unemployment rises. in this  700  chapter 30 | government budgets and fiscal policy  case, expansionary fiscal policy using tax cuts or increases in government spending can shift aggregate demand to ad1, closer to the full-employment level of output. in addition, the price level would rise back to the level p1 associated with potential gdp.  figure 30.11 expansionary fiscal policy the original equilibrium (e0) represents a recession, occurring at a quantity of output (y0) below potential gdp. however, a shift of aggregate demand from ad0 to ad1, enacted through an expansionary fiscal policy, can move the economy to a new equilibrium output of e1 at the level of potential gdp which is shown by the lras curve. since the economy was originally producing below potential gdp, any inflationary increase in the price level from p0 to p1 that results should be relatively small.  should the government use tax cuts or spending increases, or a mix of the two, to carry out expansionary fiscal policy? after the great recession of 2008–2009 (which started, actually, in very late 2007), u.s. government spending rose from 19.6% of gdp in 2007 to 24.6% in 2009, while tax revenues declined from 18.5% of gdp in 2007 to 14.8% in 2009. the choice between whether to use tax or spending tools often has a political tinge. as a general statement, conservatives and republicans prefer to see expansionary fiscal policy carried out by tax cuts, while liberals and democrats prefer that expansionary fiscal policy be implemented through spending increases. the obama administration and congress passed an $830 billion expansionary policy in early 2009 involving both tax cuts and increases in government spending, according to the congressional budget office. however, state and local governments, whose budgets were also hard hit by the recession, began cutting their spending—a policy that offset federal expansionary policy. the conflict over which policy tool to use can be frustrating to those who want to categorize economics as “liberal” or “conservative,” or who want to use economic models to argue against their political opponents. but the ad–as model can be used both by advocates of smaller government, who seek to reduce taxes and government spending, and by advocates of bigger government, who seek to raise taxes and government spending. economic studies of specific taxing and spending programs can help to inform decisions about whether taxes or spending should be changed, and in what ways. ultimately, decisions about whether to use tax or spending mechanisms to implement macroeconomic policy is, in part, a political decision rather than a purely economic one.  contractionary fiscal policy fiscal policy can also contribute to pushing aggregate demand beyond potential gdp in a way that leads to inflation. as shown in figure 30.12, a very large budget deficit pushes up aggregate demand, so that the intersection of aggregate demand (ad0) and aggregate supply (sras0) occurs at equilibrium e0, which is an output level above potential gdp. this is sometimes known as an “overheating economy” where demand is so high that there is upward pressure on wages and prices, causing inflation. in this situation, contractionary fiscal policy involving federal spending cuts or tax increases can help to reduce the upward pressure on the price level by shifting aggregate demand to the left, to ad1, and causing the new equilibrium e1 to be at potential gdp, where aggregate demand intersects the lras curve.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  701  figure 30.12 a contractionary fiscal policy the economy starts at the equilibrium quantity of output y0, which is above potential gdp. the extremely high level of aggregate demand will generate inflationary increases in the price level. a contractionary fiscal policy can shift aggregate demand down from ad0 to ad1, leading to a new equilibrium output e1, which occurs at potential gdp, where ad1 intersects the lras curve.  again, the ad–as model does not dictate how this contractionary fiscal policy is to be carried out. some may prefer spending cuts; others may prefer tax increases; still others may say that it depends on the specific situation. the model only argues that, in this situation, aggregate demand needs to be reduced.  30.5 | automatic stabilizers by the end of this section, you will be able to: • describe how discretionary fiscal policy can be used by the federal government to stabilize the economy. • identify examples of automatic stabilizers. • understand how a standardized employment budget can be used to identify automatic stabilizers. the millions of unemployed in 2008–2009 could collect unemployment insurance benefits to replace some of their salaries. federal fiscal policies include discretionary fiscal policy, when the government passes a new law that explicitly changes tax or spending levels. the stimulus package of 2009 is an example. changes in tax and spending levels can also occur automatically, due to automatic stabilizers, such as unemployment insurance and food stamps, which are programs that are already laws that stimulate aggregate demand in a recession and hold down aggregate demand in a potentially inflationary boom.  counterbalancing recession and boom consider first the situation where aggregate demand has risen sharply, causing the equilibrium to occur at a level of output above potential gdp. this situation will increase inflationary pressure in the economy. the policy prescription in this setting would be a dose of contractionary fiscal policy, implemented through some combination of higher taxes and lower spending. to some extent, both changes happen automatically. on the tax side, a rise in aggregate demand means that workers and firms throughout the economy earn more. because taxes are based on personal income and corporate profits, a rise in aggregate demand automatically increases tax payments. on the spending side, stronger aggregate demand typically means lower unemployment and fewer layoffs, and so there is less need for government spending on unemployment benefits, welfare, medicaid, and other programs in the social safety net. the process works in reverse, too. if aggregate demand were to fall sharply so that a recession occurs, then the prescription would be for expansionary fiscal policy—some mix of tax cuts and spending increases. the lower level of aggregate demand and higher unemployment will tend to pull down personal incomes and corporate profits, an  702  chapter 30 | government budgets and fiscal policy  effect that will reduce the amount of taxes owed automatically. higher unemployment and a weaker economy should lead to increased government spending on unemployment benefits, welfare, and other similar domestic programs. in 2009, the stimulus package included an extension in the time allowed to collect unemployment insurance. in addition, the automatic stabilizers react to a weakening of aggregate demand with expansionary fiscal policy and react to a strengthening of aggregate demand with contractionary fiscal policy, just as the ad/as analysis suggests. the very large budget deficit of 2009 was produced by a combination of automatic stabilizers and discretionary fiscal policy. the great recession, starting in late 2007, meant less tax-generating economic activity, which triggered the automatic stabilizers that reduce taxes. most economists, even those who are concerned about a possible pattern of persistently large budget deficits, are much less concerned or even quite supportive of larger budget deficits in the short run of a few years during and immediately after a severe recession. a glance back at economic history provides a second illustration of the power of automatic stabilizers. remember that the length of economic upswings between recessions has become longer in the u.s. economy in recent decades (as discussed in unemployment). the three longest economic booms of the twentieth century happened in the 1960s, the 1980s, and the 1991–2001 time period. one reason why the economy has tipped into recession less frequently in recent decades is that the size of government spending and taxes has increased in the second half of the twentieth century. thus, the automatic stabilizing effects from spending and taxes are now larger than they were in the first half of the twentieth century. around 1900, for example, federal spending was only about 2% of gdp. in 1929, just before the great depression hit, government spending was still just 4% of gdp. in those earlier times, the smaller size of government made automatic stabilizers far less powerful than in the last few decades, when government spending often hovers at 20% of gdp or more.  the standardized employment deficit or surplus each year, the nonpartisan congressional budget office (cbo) calculates the standardized employment budget—that is, what the budget deficit or surplus would be if the economy were producing at potential gdp, where people who look for work were finding jobs in a reasonable period of time and businesses were making normal profits, with the result that both workers and businesses would be earning more and paying more taxes. in effect, the standardized employment deficit eliminates the impact of the automatic stabilizers. figure 30.13 compares the actual budget deficits of recent decades with the cbo’s standardized deficit.  visit this website (http://openstaxcollege.org/l/cbo) to learn more from the congressional budget office.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  703  figure 30.13 comparison of actual budget deficits with the standardized employment deficit when the economy is in recession, the standardized employment budget deficit is less than the actual budget deficit because the economy is below potential gdp, and the automatic stabilizers are reducing taxes and increasing spending. when the economy is performing extremely well, the standardized employment deficit (or surplus) is higher than the actual budget deficit (or surplus) because the economy is producing about potential gdp, so the automatic stabilizers are increasing taxes and reducing the need for government spending. (sources: actual and cyclically adjusted budget surpluses/deficits, http://www.cbo.gov/publication/43977; and economic report of the president, table b-1, http://www.gpo.gov/fdsys/pkg/erp-2013/content-detail.html)  notice that in recession years, like the early 1990s, 2001, or 2009, the standardized employment deficit is smaller than the actual deficit. during recessions, the automatic stabilizers tend to increase the budget deficit, so if the economy was instead at full employment, the deficit would be reduced. however, in the late 1990s the standardized employment budget surplus was lower than the actual budget surplus. the gap between the standardized budget deficit or surplus and the actual budget deficit or surplus shows the impact of the automatic stabilizers. more generally, the standardized budget figures allow you to see what the budget deficit would look like with the economy held constant—at its potential gdp level of output. automatic stabilizers occur quickly. lower wages means that a lower amount of taxes is withheld from paychecks right away. higher unemployment or poverty means that government spending in those areas rises as quickly as people apply for benefits. however, while the automatic stabilizers offset part of the shifts in aggregate demand, they do not offset all or even most of it. historically, automatic stabilizers on the tax and spending side offset about 10% of any initial movement in the level of output. this offset may not seem enormous, but it is still useful. automatic stabilizers, like shock absorbers in a car, can be useful if they reduce the impact of the worst bumps, even if they do not eliminate the bumps altogether.  30.6 | practical problems with discretionary fiscal policy by the end of this section, you will be able to: • understand how fiscal policy and monetary policy are interconnected • explain the three lag times that often occur when solving economic problems. • identify the legal and political challenges of responding to an economic problem. in the early 1960s, many leading economists believed that the problem of the business cycle, and the swings between cyclical unemployment and inflation, were a thing of the past. on the cover of its december 31, 1965, issue, time magazine, then the premier news magazine in the united states, ran a picture of john maynard keynes, and the story inside identified keynesian theories as “the prime influence on the world’s economies.” the article reported that policymakers have “used keynesian principles not only to avoid the violent [business] cycles of prewar days but to produce phenomenal economic growth and to achieve remarkably stable prices.” this happy consensus, however, did not last. the u.s. economy suffered one recession from december 1969 to november 1970, a deeper recession from november 1973 to march 1975, and then double-dip recessions from  704  chapter 30 | government budgets and fiscal policy  january to june 1980 and from july 1981 to november 1982. at various times, inflation and unemployment both soared. clearly, the problems of macroeconomic policy had not been completely solved. as economists began to consider what had gone wrong, they identified a number of issues that make discretionary fiscal policy more difficult than it had seemed in the rosy optimism of the mid-1960s.  fiscal policy and interest rates because fiscal policy affects the quantity that the government borrows in financial capital markets, it not only affects aggregate demand—it can also affect interest rates. in figure 30.14, the original equilibrium (e0) in the financial capital market occurs at a quantity of $800 billion and an interest rate of 6%. however, an increase in government budget deficits shifts the demand for financial capital from d0 to d1. the new equilibrium (e1) occurs at a quantity of $900 billion and an interest rate of 7%. a consensus estimate based on a number of studies is that an increase in budget deficits (or a fall in budget surplus) by 1% of gdp will cause an increase of 0.5–1.0% in the long-term interest rate.  figure 30.14 fiscal policy and interest rates when a government borrows money in the financial capital market, it causes a shift in the demand for financial capital from d0 to d1. as the equilibrium moves from e0 to e1, the equilibrium interest rate rises from 6% to 7% in this example. in this way, an expansionary fiscal policy intended to shift aggregate demand to the right can also lead to a higher interest rate, which has the effect of shifting aggregate demand back to the left.  a problem arises here. an expansionary fiscal policy, with tax cuts or spending increases, is intended to increase aggregate demand. if an expansionary fiscal policy also causes higher interest rates, then firms and households are discouraged from borrowing and spending (as occurs with tight monetary policy), thus reducing aggregate demand. even if the direct effect of expansionary fiscal policy on increasing demand is not totally offset by lower aggregate demand from higher interest rates, fiscal policy can end up being less powerful than was originally expected. this is referred to as crowding out, where government borrowing and spending results in higher interest rates, which reduces business investment and household consumption. the broader lesson is that fiscal and monetary policy must be coordinated. if expansionary fiscal policy is to work well, then the central bank can also reduce or keep short-term interest rates low. conversely, monetary policy can also help to ensure that contractionary fiscal policy does not lead to a recession.  long and variable time lags monetary policy can be changed several times each year, but fiscal policy is much slower to be enacted. imagine that the economy starts to slow down. it often takes some months before the economic statistics signal clearly that a downturn has started, and a few months more to confirm that it is truly a recession and not just a one- or two-month blip. the time it takes to determine that a recession has occurred is often called the recognition lag. after this lag, policymakers become aware of the problem and propose fiscal policy bills. the bills go into various congressional committees for hearings, negotiations, votes, and then, if passed, eventually for the president’s signature. many fiscal  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  705  policy bills about spending or taxes propose changes that would start in the next budget year or would be phased in gradually over time. the time to get a bill passed is often referred to as the legislative lag. finally, once the bill is passed it takes some time for the funds to be dispersed to the appropriate agencies to implement the programs. the time to get the projects started is often called the implementation lag. moreover, the exact level of fiscal policy to be implemented is never completely clear. should the budget deficit be increased by 0.5% of gdp? by 1% of gdp? by 2% of gdp? in an ad/as diagram, it is straightforward to sketch an aggregate demand curve shifting to the potential gdp level of output. in the real world, the actual level of potential output is known only roughly, not precisely, and exactly how a spending cut or tax increase will affect aggregate demand is always somewhat controversial. also unknown is the state of the economy at any point in time. during the early days of the obama administration, for example, no one knew how deep in the hole the economy really was. during the financial crisis of 2008-09, the rapid collapse of the banking system and automotive sector made it difficult to assess how quickly the economy was collapsing. thus, it can take many months or even more than a year to begin an expansionary fiscal policy after a recession has started—and even then, uncertainty will remain over exactly how much to expand or contract taxes and spending. when politicians attempt to use countercyclical fiscal policy to fight recession or inflation, they run the risk of responding to the macroeconomic situation of two or three years ago, in a way that may be exactly wrong for the economy at that time. george p. schultz, a professor of economics, former secretary of the treasury, and director of the office of management and budget, once wrote: “while the economist is accustomed to the concept of lags, the politician likes instant results. the tension comes because, as i have seen on many occasions, the economist’s lag is the politician’s nightmare.”  temporary and permanent fiscal policy a temporary tax cut or spending increase will explicitly last only for a year or two, and then revert back to its original level. a permanent tax cut or spending increase is expected to stay in place for the foreseeable future. the effect of temporary and permanent fiscal policies on aggregate demand can be very different. consider how you would react if the government announced a tax cut that would last one year and then be repealed, in comparison with how you would react if the government announced a permanent tax cut. most people and firms will react more strongly to a permanent policy change than a temporary one. this fact creates an unavoidable difficulty for countercyclical fiscal policy. the appropriate policy may be to have an expansionary fiscal policy with large budget deficits during a recession, and then a contractionary fiscal policy with budget surpluses when the economy is growing well. but if both policies are explicitly temporary ones, they will have a less powerful effect than a permanent policy.  structural economic change takes time when an economy recovers from a recession, it does not usually revert back to its exact earlier shape. instead, the internal structure of the economy evolves and changes and this process can take time. for example, much of the economic growth of the mid-2000s was in the sectors of construction (especially of housing) and finance. however, when housing prices started falling in 2007 and the resulting financial crunch led into recession (as discussed in monetary policy and bank regulation), both sectors contracted. the manufacturing sector of the u.s. economy has been losing jobs in recent years as well, under pressure from technological change and foreign competition. many of the people thrown out of work from these sectors in the great recession of 2008–2009 will never return to the same jobs in the same sectors of the economy; instead, the economy will need to grow in new and different directions, as the following clear it up feature shows. fiscal policy can increase overall demand, but the process of structural economic change—the expansion of a new set of industries and the movement of workers to those industries—inevitably takes time.  why do jobs vanish? people can lose jobs for a variety of reasons: because of a recession, but also because of longer-run changes in the economy, such as new technology. productivity improvements in auto manufacturing, for example, can  706  chapter 30 | government budgets and fiscal policy  reduce the number of workers needed, and eliminate these jobs in the long run. the internet has created jobs but also caused the loss of jobs as well, from travel agents to book store clerks. many of these jobs may never come back. short-run fiscal policy to reduce unemployment can create jobs, but it cannot replace jobs that will never return.  the limitations of fiscal policy fiscal policy can help an economy that is producing below its potential gdp to expand aggregate demand so that it produces closer to potential gdp, thus lowering unemployment. but fiscal policy cannot help an economy produce at an output level above potential gdp without causing inflation at this point, unemployment becomes so low that workers become scarce and wages rise rapidly.  visit this website (http://openstaxcollege.org/l/fiscalpolicy) to read about how the recovery is being affected by fiscal policies.  political realties and discretionary fiscal policy a final problem for discretionary fiscal policy arises out of the difficulties of explaining to politicians how countercyclical fiscal policy that runs against the tide of the business cycle should work. politicians often have a gut-level belief that when the economy and tax revenues slow down, it is time to hunker down, pinch pennies, and trim expenses. countercyclical policy, however, says that when the economy has slowed down, it is time for the government to go on a spree, raising spending, and cutting taxes. this offsets the drop in the economy in the other sectors. conversely, when economic times are good and tax revenues are rolling in, politicians often feel that it is time for tax cuts and new spending. but countercyclical policy says that this economic boom should be an appropriate time for keeping taxes high and restraining spending. politicians tend to prefer expansionary fiscal policy over contractionary policy. there is rarely a shortage of proposals for tax cuts and spending increases, especially during recessions. however, politicians are less willing to hear the message that in good economic times, they should propose tax increases and spending limits. in the economic upswing of the late 1990s and early 2000s, for example, the u.s. gdp grew rapidly. estimates from respected government economic forecasters like the nonpartisan congressional budget office and the office of management and budget stated that the gdp was above potential gdp, and that unemployment rates were unsustainably low. however, no mainstream politician took the lead in saying that the booming economic times might be an appropriate time for spending cuts or tax increases.  discretionary fiscal policy: summing up expansionary fiscal policy can help to end recessions and contractionary fiscal policy can help to reduce inflation. given the uncertainties over interest rate effects, time lags, temporary and permanent policies, and unpredictable political behavior, many economists and knowledgeable policymakers had concluded by the mid-1990s that discretionary fiscal policy was a blunt instrument, more like a club than a scalpel. it might still make sense to use it in extreme economic situations, like an especially deep or long recession. for less extreme situations, it was often preferable to let fiscal policy work through the automatic stabilizers and focus on monetary policy to steer short-term countercyclical efforts.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  707  30.7 | the question of a balanced budget by the end of this section, you will be able to: • understand the arguments for and against requiring the u.s. federal budget to be balanced • consider the long-run and short-run effects of a federal budget deficit for many decades, going back to the 1930s, proposals have been put forward to require that the u.s. government balance its budget every year. in 1995, a proposed constitutional amendment that would require a balanced budget passed the u.s. house of representatives by a wide margin, and failed in the u.s. senate by only a single vote. (for the balanced budget to have become an amendment to the constitution would have required a two-thirds vote by congress and passage by three-quarters of the state legislatures.) most economists view the proposals for a perpetually balanced budget with bemusement. after all, in the short term, economists would expect the budget deficits and surpluses to fluctuate up and down with the economy and the automatic stabilizers. economic recessions should automatically lead to larger budget deficits or smaller budget surpluses, while economic booms lead to smaller deficits or larger surpluses. a requirement that the budget be balanced each and every year would prevent these automatic stabilizers from working and would worsen the severity of economic fluctuations. some supporters of the balanced budget amendment like to argue that, since households must balance their own budgets, the government should too. but this analogy between household and government behavior is severely flawed. most households do not balance their budgets every year. some years households borrow to buy houses or cars or to pay for medical expenses or college tuition. other years they repay loans and save funds in retirement accounts. after retirement, they withdraw and spend those savings. also, the government is not a household for many reasons, one of which is that the government has macroeconomic responsibilities. the argument of keynesian macroeconomic policy is that the government needs to lean against the wind, spending when times are hard and saving when times are good, for the sake of the overall economy. there is also no particular reason to expect a government budget to be balanced in the medium term of a few years. for example, a government may decide that by running large budget deficits, it can make crucial long-term investments in human capital and physical infrastructure that will build the long-term productivity of a country. these decisions may work out well or poorly, but they are not always irrational. such policies of ongoing government budget deficits may persist for decades. as the u.s. experience from the end of world war ii up to about 1980 shows, it is perfectly possible to run budget deficits almost every year for decades, but as long as the percentage increases in debt are smaller than the percentage growth of gdp, the debt/gdp ratio will decline at the same time. nothing in this argument should be taken as a claim that budget deficits are always a wise policy. in the short run, a government that runs a very large budget deficit can shift aggregate demand to the right and trigger severe inflation. additionally, governments may borrow for foolish or impractical reasons. the macroeconomic impacts of government borrowing will discuss how large budget deficits, by reducing national saving, can in certain cases reduce economic growth and even contribute to international financial crises. a requirement that the budget be balanced in each calendar year, however, is a misguided overreaction to the fear that in some cases, budget deficits can become too large.  no yellowstone park? the federal budget shutdown of 2013 illustrated the many sides to fiscal policy and the federal budget. in 2013, republicans and democrats could not agree on which spending policies to fund and how large the government debt should be. due to the severity of the recession in 2008–2009, the fiscal stimulus, and previous policies, the federal budget deficit and debt was historically high. one way to try to cut federal spending and borrowing was to refuse to raise the legal federal debt limit, or tie on conditions to appropriation bills to stop the affordable health care act. this disagreement led to a two-week shutdown of the federal  708  chapter 30 | government budgets and fiscal policy  government and got close to the deadline where the federal government would default on its treasury bonds. finally, however, a compromise emerged and default was avoided. this shows clearly how closely fiscal policies are tied to politics.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  709  key terms automatic stabilizers tax and spending rules that have the effect of slowing down the rate of decrease in aggregate demand when the economy slows down and restraining aggregate demand when the economy speeds up, without any additional change in legislation balanced budget when government spending and taxes are equal budget deficit when the federal government spends more money than it receives in taxes in a given year budget surplus when the government receives more money in taxes than it spends in a year contractionary fiscal policy fiscal policy that decreases the level of aggregate demand, either through cuts in government spending or increases in taxes corporate income tax a tax imposed on corporate profits crowding out federal spending and borrowing causes interest rates to rise and business investment to fall discretionary fiscal policy the government passes a new law that explicitly changes overall tax or spending levels with the intent of influencing the level or overall economic activity estate and gift tax a tax on people who pass assets to the next generation—either after death or during life in the form of gifts excise tax a tax on a specific good—on gasoline, tobacco, and alcohol expansionary fiscal policy fiscal policy that increases the level of aggregate demand, either through increases in government spending or cuts in taxes implementation lag the time it takes for the funds relating to fiscal policy to be dispersed to the appropriate agencies to implement the programs individual income tax a tax based on the income, of all forms, received by individuals legislative lag the time it takes to get a fiscal policy bill passed marginal tax rates or the tax that must be paid on all yearly income national debt the total accumulated amount the government has borrowed, over time, and not yet paid back payroll tax a tax based on the pay received from employers; the taxes provide funds for social security and medicare progressive tax a tax that collects a greater share of income from those with high incomes than from those with lower incomes proportional tax a tax that is a flat percentage of income earned, regardless of level of income recognition lag the time it takes to determine that a recession has occurred regressive tax a tax in which people with higher incomes pay a smaller share of their income in tax standardized employment budget the budget deficit or surplus in any given year adjusted for what it would have been if the economy were producing at potential gdp  710  chapter 30 | government budgets and fiscal policy  key concepts and summary 30.1 government spending fiscal policy is the set of policies that relate to federal government spending, taxation, and borrowing. in recent decades, the level of federal government spending and taxes, expressed as a share of gdp, has not changed much, typically fluctuating between about 18% to 22% of gdp. however, the level of state spending and taxes, as a share of gdp, has risen from about 12–13% to about 20% of gdp over the last four decades. the four main areas of federal spending are national defense, social security, healthcare, and interest payments, which together account for about 70% of all federal spending. when a government spends more than it collects in taxes, it is said to have a budget deficit. when a government collects more in taxes than it spends, it is said to have a budget surplus. if government spending and taxes are equal, it is said to have a balanced budget. the sum of all past deficits and surpluses make up the government debt. 30.2 taxation the two main federal taxes are individual income taxes and payroll taxes that provide funds for social security and medicare; these taxes together account for more than 80% of federal revenues. other federal taxes include the corporate income tax, excise taxes on alcohol, gasoline and tobacco, and the estate and gift tax. a progressive tax is one, like the federal income tax, where those with higher incomes pay a higher share of taxes out of their income than those with lower incomes. a proportional tax is one, like the payroll tax for medicare, where everyone pays the same share of taxes regardless of income level. a regressive tax is one, like the payroll tax (above a certain threshold) that supports social security, where those with high income pay a lower share of income in taxes than those with lower incomes. 30.3 federal deficits and the national debt for most of the twentieth century, the u.s. government took on debt during wartime and then paid down that debt slowly in peacetime. however, it took on quite substantial debts in peacetime in the 1980s and early 1990s, before a brief period of budget surpluses from 1998 to 2001, followed by a return to annual budget deficits since 2002, with very large deficits in the recession of 2008 and 2009. a budget deficit or budget surplus is measured annually. total government debt or national debt is the sum of budget deficits and budget surpluses over time. 30.4 using fiscal policy to fight recession, unemployment, and inflation expansionary fiscal policy increases the level of aggregate demand, either through increases in government spending or through reductions in taxes. expansionary fiscal policy is most appropriate when an economy is in recession and producing below its potential gdp. contractionary fiscal policy decreases the level of aggregate demand, either through cuts in government spending or increases in taxes. contractionary fiscal policy is most appropriate when an economy is producing above its potential gdp. 30.5 automatic stabilizers fiscal policy is conducted both through discretionary fiscal policy, which occurs when the government enacts taxation or spending changes in response to economic events, or through automatic stabilizers, which are taxing and spending mechanisms that, by their design, shift in response to economic events without any further legislation. the standardized employment budget is the calculation of what the budget deficit or budget surplus would have been in a given year if the economy had been producing at its potential gdp in that year. many economists and politicians criticize the use of fiscal policy for a variety of reasons, including concerns over time lags, the impact on interest rates, and the inherently political nature of fiscal policy. we cover the critique of fiscal policy in the next module. 30.6 practical problems with discretionary fiscal policy because fiscal policy affects the quantity of money that the government borrows in financial capital markets, it not only affects aggregate demand—it can also affect interest rates. if an expansionary fiscal policy also causes higher interest rates, then firms and households are discouraged from borrowing and spending, reducing aggregate demand in a situation called crowding out. given the uncertainties over interest rate effects, time lags (implementation lag, legislative lag, and recognition lag), temporary and permanent policies, and unpredictable political behavior, many economists and knowledgeable policymakers have concluded that discretionary fiscal policy is a blunt instrument and better used only in extreme situations.  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  711  30.7 the question of a balanced budget balanced budget amendments are a popular political idea, but the economic merits behind such proposals are questionable. most economists accept that fiscal policy needs to be flexible enough to accommodate unforeseen expenditures, such as wars or recessions. while persistent, large budget deficits can indeed be a problem, a balanced budget amendment prevents even small, temporary deficits that might, in some cases, be necessary.  self-check questions 1. when governments run budget deficits, how do they make up the differences between tax revenue and spending? 2. when governments run budget surpluses, what is done with the extra funds? 3. is it possible for a nation to run budget deficits and still have its debt/gdp ratio fall? explain your answer. is it possible for a nation to run budget surpluses and still have its debt/gdp ratio rise? explain your answer. 4. suppose that gifts were taxed at a rate of 10% for amounts up to $100,000 and 20% for anything over that amount. would this tax be regressive or progressive? 5. if an individual owns a corporation for which he is the only employee, which different types of federal tax will he have to pay? 6. what taxes would an individual pay if he were self-employed and the business is not incorporated? 7. the social security tax is 6.2% on employees’ income earned below $113,000. is this tax progressive, regressive or proportional? 8. debt has a certain self-reinforcing quality to it. there is one category of government spending that automatically increases along with the federal debt. what is it? 9. true or false: a. federal spending has grown substantially in recent decades. b. by world standards, the u.s. government controls a relatively large share of the u.s. economy. c. a majority of the federal government’s revenue is collected through personal income taxes. d. education spending is slightly larger at the federal level than at the state and local level. e. state and local government spending has not risen much in recent decades. f. defense spending is higher now than ever. g. the share of the economy going to federal taxes has increased substantially over time. h. foreign aid is a large portion, although less than half, of federal spending. i. federal deficits have been very large for the last two decades. j. the accumulated federal debt as a share of gdp is near an all-time high. 10. what is the main reason for employing contractionary fiscal policy in a time of strong economic growth? 11. what is the main reason for employing expansionary fiscal policy during a recession? 12. in a recession, does the actual budget surplus or deficit fall above or below the standardized employment budget? 13. what is the main advantage of automatic stabilizers over discretionary fiscal policy? 14. explain how automatic stabilizers work, both on the taxation side and on the spending side, first in a situation where the economy is producing less than potential gdp and then in a situation where the economy is producing more than potential gdp. 15. what would happen if expansionary fiscal policy was implemented in a recession but, due to lag, did not actually take effect until after the economy was back to potential gdp?  712  chapter 30 | government budgets and fiscal policy  16. what would happen if contractionary fiscal policy were implemented during an economic boom but, due to lag, it did not take effect until the economy slipped into recession? 17. do you think the typical time lag for fiscal policy is likely to be longer or shorter than the time lag for monetary policy? explain your answer? 18. how would a balanced budget amendment affect a decision by congress to grant a tax cut during a recession? 19. how would a balanced budget amendment change the effect of automatic stabilizer programs?  review questions 20. give some examples of changes in federal spending and taxes by the government that would be fiscal policy and some that would not. 21. have the spending and taxes of the u.s. federal government generally had an upward or a downward trend in the last few decades? 22. what are the main categories of u.s. federal government spending? 23. what is the difference between a budget deficit, a balanced budget, and a budget surplus? 24. have spending and taxes by state and local governments in the united states had a generally upward or downward trend in the last few decades? 25. what are the main categories of u.s. federal government taxes? 26. what is the difference between a progressive tax, a proportional tax, and a regressive tax?  28. what is the difference between a budget deficit and the national debt? 29. what is the difference between expansionary fiscal policy and contractionary fiscal policy? 30. under what general macroeconomic circumstances might a government use expansionary fiscal policy? when might it use contractionary fiscal policy? 31. what is the difference between discretionary fiscal policy and automatic stabilizers? 32. why do “automatically?”  automatic  stabilizers  function  33. what is the standardized employment budget? 34. what are some practical discretionary fiscal policy?  weaknesses  of  35. what are some of the arguments for and against a requirement that the federal government budget be balanced every year?  27. what has been the general pattern of u.s. budget deficits in recent decades?  critical thinking questions 36. why is government spending typically measured as a percentage of gdp rather than in nominal dollars?  everyone pays the same rate regardless of income, why might this be so?  37. why are expenditures such as crime prevention and education typically done at the state and local level rather than at the federal level?  40. what is the benefit of having state and local taxes on income instead of collecting all such taxes at the federal level?  38. why is spending by the u.s. government on scientific research at nasa fiscal policy while spending by the university of illinois is not fiscal policy? why is a cut in the payroll tax fiscal policy whereas a cut in a state income tax is not fiscal policy?  41. in a booming economy, is the federal government more likely to run surpluses or deficits? what are the various factors at play?  39. excise taxes on tobacco and alcohol and state sales taxes are often criticized for being regressive. although  42. economist arthur laffer famously pointed out that, in some cases, income tax revenue can actually go up when tax rates go down. why might this be the case?  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy  43. is it possible for a nation to run budget deficits and still have its debt/gdp ratio fall? explain your answer. is it possible for a nation to run budget surpluses and still have its debt/gdp ratio rise? explain your answer. 44. how will cuts in state budget spending affect federal expansionary policy? 45. is expansionary fiscal policy more attractive to politicians who believe in larger government or to politicians who believe in smaller government? explain your answer. 46. is medicaid (federal government aid to low-income families and individuals) an automatic stabilizer?  713  48. if the government gives a $300 tax cut to everyone in the country, explain the mechanism by which this will cause interest rates to rise. 49. do you agree or disagree with this statement: “it is in the best interest of our economy for congress and the president to run a balanced budget each year.” explain your answer. 50. during the great recession of 2008–2009, what actions would have been required of congress and the president had a balanced budget amendment to the constitution been ratified? what impact would that have had on the unemployment rate?  47. what is a potential problem with a temporary tax increase designed to increase aggregate demand if people know that it is temporary?  problems 51. a government starts off with a total debt of $3.5 billion. in year one, the government runs a deficit of $400 million. in year two, the government runs a deficit of $1 billion. in year three, the government runs a surplus of $200 million. what is the total debt of the government at the end of year three? 52. if a government runs a budget deficit of $10 billion dollars each year for ten years, then a surplus of $1 billion for five years, and then a balanced budget for another ten years, what is the government debt?  53. specify whether expansionary or contractionary fiscal policy would seem to be most appropriate in response to each of the situations below and sketch a diagram using aggregate demand and aggregate supply curves to illustrate your answer: a. a recession. b. a stock market collapse that hurts consumer and business confidence. c. extremely rapid growth of exports. d. rising inflation. e. a rise in the natural rate of unemployment. f. a rise in oil prices.  714  this openstax book is available for free at http://cnx.org/content/col11613/1.11  chapter 30 | government budgets and fiscal policy",t_43ae0763a37b,other,0
c_32337c93b97d,"watch water boil at room temperature..field-slideshow-caption {   margin-top:10px;   margin-left:5px;  }   .item-list {   margin-top:25px;  }   .item-list ul li{   margin:0 10px 10px 0;   opacity: 0.6;      filter: alpha(opacity=60); /* for ie8 and earlier */  }   .item-list ul .activeslide{   opacity: 1;      filter: alpha(opacity=100); /* for ie8 and earlier */  }  boyle-ing water  watch water boil at room temperature.  the temperature at which water boils depends on pressure. you can demonstrate this by dramatically lowering the pressure on a water-filled plastic syringe at room temperature.  subjects:                  keywords:  chemistry  states of matter  gas  pressure  boyle's law  liquid  phase change  matter  boiling  video  video demonstration  tools and materials  clear plastic syringe (10 ml works well)  water  optional: carbonated water  assembly  fill a syringe a quarter full of water. try to keep out as much air as possible.  to do and notice  hold the syringe in one hand and cover the tip with your finger. with your other hand, pull on the plunger.  notice that, as you pull on the plunger, it pulls back on you. notice also that an empty space—a bubble of air—appears inside the syringe.  allow the plunger to slide slowly back into the syringe. look again to see if there’s still an air bubble in the syringe.  keep your finger on the tip and pull out the plunger again. release the plunger suddenly. notice that it snaps back quickly.  pull on the plunger a third time. notice that, this time, bubbles form inside the water, and the water appears to be boiling.  what's going on?  not only does the water in your syringe                 appear                to be boiling, it                 is                boiling.  living as we do at typical atmospheric pressures, we tend to think that water has to be hot to boil. but the transition from liquid to gas can occur not just as the result of increased temperature, but also as the result of decreased pressure.  pulling on the plunger reduces the pressure on the gases inside the syringe by increasing the volume—a relationship given by                 boyle’s law                : for a gas in an enclosed space at a constant temperature, volume and pressure vary inversely. in other words, doubling the volume halves the pressure.  tap water has air dissolved in it. when you reduce the pressure in the syringe by pulling out the plunger, the dissolved air comes out of solution and forms an air pocket at the tip of the syringe. when you slowly allow the plunger to slide back in, the air that has come out of solution stays out of solution. that’s why there may seem to be more air in the syringe than when you started.  but something else happens when you pull back on the syringe: under reduced pressure, water changes from liquid to gas. bubbles of water vapor form inside the liquid, and the water in the syringe boils at room temperature.  in a clean liquid, it’s not easy for small bubbles to form, or                 nucleate                . however, when you pull out the plunger and allow it to snap back in, you create many tiny “seed” bubbles throughout the water. the next time you pull back the plunger, boiling happens more easily, thanks to the nucleation sites provided by these seed bubbles.  one way to understand the importance of seed bubbles is to remember the last time you tried to blow up a balloon. at first, a balloon can be difficult to get started. but once started, it’s easier to inflate. the same rule applies to bubbles of water vapor forming in water. if you reduce the pressure and temperature even further, either by using a vacuum pump or by traveling to the surface of mars, it’s possible to have water both boil and freeze at the same time. at this combination of low temperature and pressure—0.01 °c and 0.006 atmospheres, also known as the                 triple point                of water—all three phases of water can exist at the same time.  going further  try this experiment with carbonated water.  carbonated water has carbon dioxide dissolved in it. when it’s in an unopened bottle, this carbon dioxide is under pressure and remains in solution. when you open the bottle and lower the pressure, the carbon dioxide comes out of solution, forming the bubbles you see when you pour it into a glass. sometimes you can see the bubbles rise in long, vertical lines, originating from a scratch or pit in the wall or bottom of the glass.  with carbonated water in the syringe, the carbon dioxide comes out of solution rapidly when you pull back on the plunger, and even more bubbles form in the water. by tapping the sides of the syringe, you can force all the bubbles together into one larger bubble.",t_8eff21845058,other,0
c_b6f4dc09f507,"you don't need to know how to speak latin and greek in order to understand english, but some words in english come from those languages. it's helpful to know how some greek and latin words change from singular to plural.  - [voiceover] hello grammarians! today we're talking about another kind of irregular plural noun, and that is the foreign plural. those are words that are borrowed into english from some other language. words like fungus, or cactus, or thesis, or criteria. and these words come from latin and greek, respectively, but don't get the idea that you need to learn to be able to speak latin or greek in order to speak english. no, not at all. but while some words that got borrowed into english have lost their language-specific plurals, some have not. some have maintained those plurals. and it kind of depends on which situation you're using them in. so, for example, in an informal context, it would be perfectly acceptable for you or me to say funguses, like that. but if i was talking to a biologist, she would probably say fungi if she were talking about them in a scientific context. just like it's okay in informal speech to talk about cactuses. you're driving along a road in arizona, you see a lot of cactuses. but, again, if you studied cactuses for a living, you would probably call them cacti. it's more precise, it's more formal. if you like, it's more polite. now, my feeling is, that as fungus and cactus get more and more entrenched into english eventually these formal endings are going to fall away and we're just gonna have this regular plural. but for now there are still some pluralizing rules for other languages that it helps to know. so let's go through those. so i made this little chart to go over the six most common latin and greek irregular plurals that you're going to encounter in english. so the first one is final -a to final -ae. so you take a word like larva in the singular, which is like a little baby bug, like an ant larva, or a caterpillar larva, and the traditional irregular plural, the latin plural of that, is larvae, -ae. but the regular plural that will probably get more popular over time is larvas. but this is the first one, -a to -ae. larva to larvae. just like antenna becomes antennae. secondly the ending change from final -us to final -i, which we find in a word like fungus, is the singular, and then the irregular plural of that is fungi. and, as i said before, there are some people who use funguses, but again, that regular plural is more informal. this next one is also latin and it's the change from final -um to final -a. so we take a word like datum, which is a single unit of data, so the plural of data, so we change singular datum to plural data and there is no accepted, you wouldn't say the datas, that is not an accepted regular plural. i think what's going to happen instead is that datum is gonna fall away. but, again, it hasn't really happened yet. not in a formal context, anyway. this next one is also latin, and it's final -ex or final -ix to final -ices. so if you take a word like index, or matrix, the plural of that is not indexes, but indices. indexes is, again, the informal regular plural, but indices is the more formal irregular plural. likewise, matrices. this one is greek and it's the change from final -is to final -es, as in the word thesis in the singular becoming theses in the irregular plural. the regular plural of this i do not care for because it is thesises, and i think that sounds silly. but thinking something is silly is no reason to stand athwart the tide of linguistic change, grumble grumble. this last one is also greek, and it's the change from singular -on to plural -a. so we this word like criterion, or phenomenon, and in the plural it is criteria or phenomena. (singing) do do do do do. and as with datum, there isn't really a regular plural form for criteria. nobody says criterions, because the word criteria is so much better known. anyway, so these are six little ending rules, but, like i said, you don't need to learn latin or greek in order to make sense of english. but having these six rules in your tool belt, if you use them judiciously, will probably come in handy. but, for real, if you see a word and you don't know it's derivation, just trust your instincts and give it a regular plural. just tack on an -s. you know, the world's not gonna end, not harm will come to you. and if you're curious, you can look it up later. you can learn anything. david out.",t_32df13199d3b,other,0
c_d8903824d7f8,"introduction  understanding of the stresses induced in beams by bending loads took many years to develop. galileo worked on this problem, but the theory as we use it today is usually credited principally to the great mathematician leonard euler (1707–1783). as will be developed below, beams develop normal stresses in the lengthwise direction that vary from a maximum in tension at one surface, to zero at the beam’s midplane, to a maximum in compression at the opposite surface. shear stresses are also induced, although these are often negligible in comparision with the normal stresses when the length-to-height ratio of the beam is large. the procedures for calculating these stresses for various loading conditions and beam cross-section shapes are perhaps the most important methods to be found in introductory mechanics of materials, and will be developed in the sections to follow. this theory requires that the user be able to construct shear and bending moment diagrams for the beam, as developed for instance in module 12.  normal stresses  a beam subjected to a positive bending moment will tend to develop a concave-upward curvature. intuitively, this means the material near the top of the beam is placed in compression along the \(x\) direction, with the lower region in tension. at the transition between the compressive and tensile regions, the stress becomes zero; this is the neutral axis of the beam. if the material tends to fail in tension, like chalk or glass, it will do so by crack initiation and growth from the lower tensile surface. if the material is strong in tension but weak in compression, it will fail at the top compressive surface; this might be observed in a piece of wood by a compressive buckling of the outer fibers.  we seek an expression relating the magnitudes of these axial normal stresses to the shear and bending moment within the beam, analogously to the shear stresses induced in a circular shaft by torsion. in fact, the development of the needed relations follows exactly the same direct approach as that used for torsion:  1. geometrical statement: we begin by stating that originally transverse planes within the beam remain planar under bending, but rotate through an angle \(\theta\) about points on the neutral axis as shown in fig. 1. for small rotations, this angle is given approximately by the \(x\)-derivative of the beam's vertical deflection function \(v(x)\) (the exact expression for curvature is  \[\dfrac{d \theta}{ds} = \dfrac{d^2 v/dx^2}{[1 + (dv/dx)^2]^{3/2}}.\]  this gives \(\theta \approx dv/dx\) when the squared derivative in the denominator is small compared to 1.):  \[u = -y v_{,x}\]  where the comma indicates differentiation with respect to the indicated variable (\(v_{,x} \equiv dv/dx\)). here \(y\) is measured positive upward from the neutral axis, whose location within the beam has not yet been determined.  figure 1: geometry of beam bending.  2. kinematic equation: the \(x\)-direction normal strain \(\epsilon_x\) is then the gradient of the displacement:  \[\epsilon_x = \dfrac{du}{dx} = -yv_{,xx}\]  note that the strains are zero at the neutral axis where \(y = 0\), negative (compressive) above the axis, and positive (tensile) below. they increase in magnitude linearly with \(y\), much as the shear strains increased linearly with \(r\) in a torsionally loaded circular shaft. the quantity \(v_{,xx} \equiv d^2v/dx^2\) is the spatial rate of change of the slope of the beam deflection curve, the ""slope of the slope."" this is called the curvature of the beam.  3. constitutive equation: the stresses are obtained directly from hooke’s law as  \[\sigma_x = e\epsilon_x = -y ev_{,xx}\]  this restricts the applicability of this derivation to linear elastic materials. hence the axial normal stress, like the strain, increases linearly from zero at the neutral axis to a maximum at the outer surfaces of the beam.  4. equilibrium relations: since there are no axial (\(x\)-direction) loads applied externally to the beam, the total axial force generated by the normal \(\sigma_x\) stresses (shown in fig. 2) must be zero. this can be expressed as  \(\sum f_x = 0 = \int_a \sigma_x da = \int_a -y ev_{,xx} da\)  which requires that  \(\int_a y da = 0\)  the distance \(\bar{y}\) from the neutral axis to the centroid of the cross-sectional area is  \(\bar{y} = \dfrac{\int_a y da}{\int_a da}\)  hence \(\bar{y} = 0\), i.e. the neutral axis is coincident with the centroid of the beam cross-sectional area. this result is obvious on reflection, since the stresses increase at the same linear rate, above the axis in compression and below the axis in tension. only if the axis is exactly at the centroidal position will these stresses balance to give zero net horizontal force and keep the beam in horizontal equilibrium.  figure 2: moment and force equilibrium in the beam.  the normal stresses in compression and tension are balanced to give a zero net horizontal force, but they also produce a net clockwise moment. this moment must equal the value of \(m(x)\) at that value of \(x\), as seen by taking a moment balance around point \(o\):  \(\sum m_o = 0 = m + \int_a \sigma_x \cdot y da\)  \[m = \int_a (y ev_{,xx}) \cdot y da = ev_{,xx} \int_a y^2 da\]  figure 3: moment of inertia for a rectangular section.  the quantity \(\int y^2 da\) is the rectangular moment of inertia with respect to the centroidal axis, denoted \(i\). for a rectangular cross section of height \(h\) and width \(b\) as shown in fig. 3 this is:  \[i = \int_{-h/2}^{h/2} y^2 b dy = \dfrac{bh^3}{12}\]  solving eqn. 4.2.4 for \(v_{,xx}\), the beam curvature is  \[v_{,xx} = \dfrac{m}{ei}\]  5. an explicit formula for the stress can be obtained by using this in eqn. 4.2.3:  \[\sigma_x = -y e \dfrac{m}{ei} = \dfrac{-my}{i}\]  the final expression for stress, eqn. 4.2.7, is similar to \(\tau_{\theta_z} = tr/j\) for twisted circular shafts: the stress varies linearly from zero at the neutral axis to a maximum at the outer surface, it varies inversely with the moment of inertia of the cross section, and it is independent of the material’s properties. just as a designer will favor annular drive shafts to maximize the polar moment of inertia \(j\), beams are often made with wide flanges at the upper and lower surfaces to increase \(i\).  example \(\pageindex{1}\): cantilevered t-beam  consider a cantilevered t-beam with dimensions as shown in fig. 4, carrying a uniform loading of \(w n/m\). the maximum bending moment occurs at the wall, and is easily found to be \(m_{\max} = (wl)(l/2)\). the stress is then given by eqn. 4.2.7, which requires that we know the location of the neutral axis (since \(y\) and \(i\) are measured from there).  figure 4: a cantilevered t-beam.  the distance \(y\) from the bottom of the beam to the centroidal neutral axis can be found using the ""composite area theorem"" (see exercise \(\pageindex{1}\)). this theorem states that the distance from an arbitrary axis to the centroid of an area made up of several subareas is the sum of the subareas times the distance to their individual centroids, divided by the sum of the subareas( i.e. the total area):  \(\bar{y} = \dfrac{\sum_i a_i \bar{y}_i}{\sum_i a_i}\)  for our example, this is  \(\bar{y} = \dfrac{(d/2)(cd) + (d + b/2)(ab)}{cd + ab}\)  the moments of inertia of the individual parts of the compound area with respect to their own centroids are just \(ab^3/12\) and \(cd^3/12\). these moments can be referenced to the horizontal axis through the centroid of the compound area using the ""parallel axis theorem"" (see exercise \(\pageindex{3}\)). this theorem states that the moment of inertia \(i_{z'}\) of an area \(a\), relative to any arbitrary axis \(z'\) parallel to an axis through the centroid but a distance \(d\) from it, is the moment of inertia relative to the centroidal axis \(i_z\) plus the product of the area \(a\) and the square of the distance \(d\):  \(i_{z'} = i_z + a d^2\)  for our example, this is  the moment of inertia of the entire compound area, relative to its centroid, is then the sum of these two contributions:  \(i = i^{(1)} + i^{(2)}\)  the maximum stress is then given by eqn. 4.2.7 using this value of \(i\) and \(y = \bar{y}/2\) (the distance from the neutral axis to the outer fibers), along with the maximum bending moment \(m_{\max}\). the result of these substitutions is  \(\sigma_x = \dfrac{(3d^2c + 6abd + 3ab^2)wl^2}{2c^2d^4 + 8abcd^3 + 12ab^2cd^2 + 8ab^3cd + 2a^2b^4}\)  in practice, each step would likely be reduced to a numerical value rather than working toward an algebraic solution.  in pure bending (only bending moments applied, no transverse or longitudinal forces), the only stress is \(\sigma_x\) as given by eqn. 4.2.7. all other stresses are zero (\(\sigma_y = \sigma_z = \tau_{xy} = \tau_{xz} = \tau_{yz} = 0\)). however, strains other than \(\epsilon_x\) are present, due to the poisson effect. this does not generate shear strain \((\gamma_{xy} = \gamma_{xz} = \gamma_{yz} = 0)\), but the normal strains are  the strains can also be written in terms of curvatures. from eqn. 4.2.2, the curvature along the beam is  \(v_{,xx} = -\dfrac{\epsilon_x}{y}\)  this is accompanied by a curvature transverse to the beam axis given by  \(v_{,zz} = -\dfrac{\epsilon_z}{y} = \dfrac{\nu\epsilon_x}{y} = -\nu v_{,xx}\)  this transverse curvature, shown in fig. 5, is known as anticlastic curvature; it can be seen by bending a ""pink pearl"" type eraser in the fingers.  figure 5: anticlastic curvature.  as with tension and torsion structures, bending problems can often be done more easily with energy methods. knowing the stress from eqn. 4.2.7, the strain energy due to bending stress \(u_b\) can be found by integrating the strain energy per unit volume \(u^* = \sigma^2/2e\) over the specimen volume:  \(u_b = \int_v u^* dv = \int_l \int_a \dfrac{\sigma_x^2}{2e} da dl\)  \(= \int_l \int_a \dfrac{1}{2e} (\dfrac{-my}{i})^2 da dl = \int_l \dfrac{m^2}{2ei^2} \int_a y^2 dadl\)  since \(\int_a y^2 da = i\), this becomes  \[u_b = \int_l \dfrac{m^2 dl}{2ei}\]  if the bending moment is constant along the beam (definitely not the usual case), this becomes  \(u = \dfrac{m^2 l}{2ei}\)  this is another analog to the expression for uniaxial tension, \(u = p^2l/2ae\).  buckling  long slender columns placed in compression are prone to fail by buckling, in which the column develops a kink somewhere along its length and quickly collapses unless the load is relaxed. this is actually a bending phenomenon, driven by the bending moment that develops if and when when the beam undergoes a transverse deflection. consider a beam loaded in axial compression and pinned at both ends as shown in fig. 6. now let the beam be made to deflect transversely by an amount v, perhaps by an adventitious sideward load or even an irregularity in the beam’s cross section. positions along the beam will experience a moment given by  \[m(x) = pv(x)\]  the beam's own stiffness will act to restore the deflection and recover a straight shape, but the effect of the bending moment is to deflect the beam more. it’s a battle over which influence wins out. if the tendency of the bending moment to increase the deflection dominates over the ability of the beam’s elastic stiffness to resist bending, the beam will become unstable, continuing to bend at an accelerating rate until it fails.  figure 6: imminent buckling in a beam.  the bending moment is related to the beam curvature by eqn. 4.2.6, so combining this with eqn. 4.2.9 gives  \[v_{,xx} = \dfrac{p}{ei} v\]  of course, this governing equation is satisfied identically if \(v = 0\), i.e. the beam is straight. we wish to look beyond this trivial solution, and ask if the beam could adopt a bent shape that would also satisfy the governing equation; this would imply that the stiffness is insufficient to restore the unbent shape, so that the beam is beginning to buckle. equation 4.2.10 will be satisfied by functions that are proportional to their own second derivatives. trigonometric functions have this property, so candidate solutions will be of the form  \(v = c_1 \sin \sqrt{\dfrac{p}{ei}} x + c_2 \cos \sqrt{\dfrac{p}{ei}} x\)  it is obvious that \(c_2\) must be zero, since the deflection must go to zero at \(x = 0\) and \(l\). further, the sine term must go to zero at these two positions as well, which requires that the length \(l\) be exactly equal to a multiple of the half wavelength of the sine function:  \(\sqrt{\dfrac{p}{ei} l} = n\pi, n = 1, 2, 3, \cdots\)  the lowest value of \(p\) leading to the deformed shape corresponds to \(n = 1\); the critical buckling load \(p_{cr}\) is then:  \[p_{cr} = \dfrac{\pi^2 ei}{l^2}\]  note the dependency on \(l^2\), so the buckling load drops with the square of the length.  this strong dependency on length shows why crossbracing is so important in preventing buckling. if a brace is added at the beam’s midpoint as shown in fig. 7 to eliminate deflection there, the buckling shape is forced to adopt a wavelength of \(l\) rather than 2\(l\). this is equivalent to making the beam half as long, which increases the critical buckling load by a factor of four.  figure 7: effect of lateral support and end conditions on beam buckling.  similar reasoning can be used to assess the result of having different support conditions. if for instance the beam is cantilevered at one end but unsupported at the other, its buckling shape will be a quarter sine wave. this is equivalent to making the beam twice as long as the case with both ends pinned, so the buckling load will go down by a factor of four. cantilevering both ends forces a full-wave shape, with the same buckling load as the pinned beam with a midpoint support.  shear stresses  transverse loads bend beams by inducing axial tensile and compressive normal strains in the beam's \(x\)-direction, as discussed above. in addition, they cause shear effects that tend to slide vertical planes tangentially to one another as depicted in fig. 8, much like sliding playing cards past one another. the stresses \(\tau_{xy}\) associated with this shearing effect add up to the vertical shear force we have been calling \(v\), and we now seek to understand how these stresses are distributed over the beam's cross section. the shear stress on vertical planes must be accompanied by an equal stress on horizontal planes since \(\tau_{xy} = \tau_{yx}\), and these horizontal shearing stresses must become zero at the upper and lower surfaces of the beam unless a traction is applied there to balance them. hence they must reach a maximum somewhere within the beam.  the variation of this horizontal shear stress with vertical position y can be determined by examining a free body of width \(dx\) cut from the beam a distance y above neutral axis as shown in fig. 9. the moment on the left vertical face is \(m(x)\), and on the right face it has increased to \(m + dm\). since the horizontal normal stresses are directly proportional to the moment (\(\sigma x = my/i\)), any increment in moment dm over the distance \(dx\) produces an imbalance in the horizontal force arising from the normal stresses. this imbalance must be compensated by a shear stress \(\tau_{xy}\) on the horizontal plane at \(y\). the horizontal force balance is written as  \(\tau_{xy} b dx = \int_{a'} \dfrac{dm \xi}{i} da'\)  figure 8: shearing displacements in beam bending.  figure 9: shear and bending moment in a differential length of beam.  where \(b\) is the width of the beam at \(y, \xi\) is a dummy height variable ranging from \(y\) to the outer surface of the beam, and \(a'\) is the cross-sectional area between the plane at \(y\) and the outer surface. using \(dm = v\ dx\) from eqn. 4.2.8 of module 12, this becomes  \[\tau_{xy} = \dfrac{v}{ib} \int_a' \xi da' = \dfrac{vq}{ib}\]  where here \(q(y) = \int_{a'} \xi da' = \bar{\xi} a'\) is the first moment of the area above \(y\) about the neutral axis.  figure 10: section of a rectangular beam.  the parameter \(q(y)\) is notorious for confusing persons new to beam theory. to determine it for a given height \(y\) relative to the neutral axis, begin by sketching the beam cross section, and draw a horizontal line line at the position \(y\) at which \(q\) is sought (fig. 10 shows a rectangular beam of of constant width \(b\) and height \(h\) for illustration). note the area \(a'\) between this line and the outer surface (indicated by cross-hatching in fig. 10). now compute the distance \(\bar{\xi}\) from the neutral axis to the centroid of \(a'\). the parameter \(q(y)\) is the product of \(a'\) and \(\xi\); this is the first moment of the area \(a'\) with respect to the centroidal axis. for the rectangular beam, it is  note that \(q(y)\), and therefore \(\tau_{xy}(y)\) as well, is parabolic, being maximum at the neutral axis (\(y\) = 0) and zero at the outer surface (\(y = h/2\)). using \(i = bh^3/12\) for the rectangular beam, the maximum shear stress as given by eqn. 4.2.12 is  \(\tau_{xy, \max} = \tau_{xy}|_{y = 0} = \dfrac{3v}{2bh}\)  (keep in mind than the above two expressions for \(q\) and \(\tau_{xy,\max}\) are for rectangular cross section only; sections of other shapes will have different results.) these shear stresses are most important in beams that are short relative to their height, since the bending moment usually increases with length and the shear force does not (see exercise \(\pageindex{11}\)). one standard test for interlaminar shear strength(""apparent horizontal shear strength of reinforced plastics by short beam method,"" astm d2344, american society for testing and materials.) is to place a short beam in bending and observe the load at which cracks develop along the midplane.  example \(\pageindex{2}\)  since the normal stress is maximum where the horizontal shear stress is zero (at the outer fibers), and the shear stress is maximum where the normal stress is zero (at the neutral axis), it is often possible to consider them one at a time. however, the juncture of the web and the flange in i and t beams is often a location of special interest, since here both stresses can take on substantial values.  consider the t beam seen previously in example \(\pageindex{1}\), and examine the location at point \(a\) shown in fig. 11, in the web immediately below the flange. here the width \(b\) in eqn. 4.2.12 is the dimension labeled \(c\); since the beam is thin here the shear stress \(\tau_{xy}\) will tend to be large, but it will drop dramatically in the flange as the width jumps to the larger value a. the normal stress at point \(a\) is computed from \(\sigma_x = my/i\), using \(y = d − y\). this value will be almost as large as the outer-fiber stress if the flange thickness b is small compared with the web height \(d\). the mohr’s circle for the stress state at point \(a\) would then have appreciable contributions from both \(\sigma_x\) and \(\tau_{xy}\), and can result in a principal stress larger than at either the outer fibers or the neutral axis.  this problem provides a good review of the governing relations for normal and shear stresses in beams, and is also a natural application for symbolic-manipulation computer methods. using maple software, we might begin by computing the location of the centroidal axis:  figure 11: section of t beam.  here the "">"" symbol is the maple prompt, and the "";"" is needed by maple to end the command. the maximum shear force and bending moment (present at the wall) are defined in terms of the distributed load and the beam length as  > ybar := ((d/2)*c*d) + ( (d+(b/2) )*a*b )/( c*d + a*b );  for plotting purposes, it will be convenient to have a height variable y measured from the bottom of the section. the relations for normal stress, shear stress, and the first principal stress are functions of y; these are defined using the maple “procedure” command:  > v := w*l; > m := -(w*l)*(l/2);  for plotting purposes, it will be convenient to have a height variable y measured from the bottom of the section. the relations for normal stress, shear stress, and the first principal stress are functions of y; these are defined using the maple “procedure” command:  > sigx := proc (y) -m*(y-ybar)/iz end; > tauxy := proc (y) v*q(y)/(iz*b(y) ) end; > sigp1 := proc (y) (sigx(y)/2) + sqrt( (sigx(y)/2)^2 + (tauxy(y))^2 ) end;  the moment of inertia iz is computed as  > i1 := (a*b^3)/12 + a*b* (d+(b/2)-ybar)^2;  > i2 := (c*d^3)/12 + c*d* ((d/2)-ybar)^2; > iz := i1+i2;  the beam width b is defined to take the appropriate value depending on whether the variable y is in the web or the flange:  > b:= proc (y) if y<d then b:=c else b:=a fi end;  the command ""fi"" (""if"" spelled backwards) is used to end an if-then loop. the function q(y) is defined for the web and the flange separately:  > q:= proc (y) if y<d then >      int( (yy-ybar)*c,yy=y..d) + int( (yy-ybar)*a,yy=d..(d+b) ) >    else >      int( (yy-ybar)*a,yy=y.. (d+b) )  >    fi end;  here ""int"" is the maple command for integration, and yy is used as the dummy height variable. the numerical values of the various parameters are defined as  > a:=3: b:=1/4: c:=1/4: d:=3-b: l:=8: w:=100:  figure 12: stresses at the web-flange junction in a short cantilevered t beam subjected to uniform loading.  finally, the stresses can be graphed using the maple plot command  > plot({sigx,tauxy,sigp1},y=0..3,sigx=-500..2500);  the resulting plot is shown in fig. 12.  example \(\pageindex{3}\)  in the previous example, we were interested in the variation of stress as a function of height in a beam of irregular cross section. another common design or analysis problem is that of the variation of stress not only as a function of height but also of distance along the span dimension of the beam. the shear and bending moments \(v(x)\) and \(m(x)\) vary along this dimension, and so naturally do the stresses \(\sigma_x (x,y)\) and \(\tau_{xy} (x,y)\) that depend on them according to eqn. 4.2.7 and 4.2.12.  figure 13: (a) beam in four-point bending. (b) free-body diagram.  consider a short beam of rectangular cross section subjected to four-point loading as seen in fig. 13. the loading, shear, and bending moment functions are:  the shear and normal stresses can be determined as functions of \(x\) and \(y\) directly from these functions, as well as such parameters as the principal stress. since \(\sigma_y\) is zero everywhere, the principal stress is  \(\sigma_{p1} = \dfrac{\sigma_x}{2} + \sqrt{(\dfrac{\sigma_x}{2})^2 + \tau_{xy}^2}\)  one way to visualize the x-y variation of \(\sigma_{p1}\) is by means of a 3d surface plot, which can be prepared easily by maple. for the numerical values \(p = 100, a = h = 10, b = 3\), we could use the expressions (maple responses removed for brevity):  > # use heaviside for singularity functions > readlib(heaviside); > sfn := proc(x,a,n) (x-a)^n * heaviside(x-a) end; > # define shear and bending moment functions > v:=(x)-> -p*sfn(x,0,0)+p*sfn(x,a,0)+p*sfn(x,2*a,0)-p*sfn(x,3*a,0);  > m:=(x)-> p*sfn(x,0,1)-p*sfn(x,a,1)-p*sfn(x,2*a,1)+p*sfn(x,3*a,1);  > # define shear stress function > tau:=v(x)*q/(iz*b); > q:=(b/2)*( (h^2/4) -y^2); > iz:=b*h^3/12; > # define normal stress function > sig:=m(x)*y/iz; > # define principal stress > sigp:= (sig/2) + sqrt( (sig/2)^2 + tau^2 ); > # define numerical parameters > p:=100;a:=10;h:=10;b:=3; > # make plot > plot3d(sigp,x=0..3*a,y=-h/2 .. h/2);  the resulting plot is shown in fig. 14. the dominance of the parabolic shear stress is evident near the beam ends, since here the shear force is at its maximum value but the bending moment is small (plot the shear and bending moment diagrams to confirm this). in the central part of the beam, where \(a < x < 2a\), the shear force vanishes and the principal stress is governed only by the normal stress \(\sigma_x\), which varies linearly from the beam’s neutral axis. the first principal stress is zero in the compressive lower part of this section, since here the normal stress \(\sigma_x\) is negative and the right edge of the mohr’s circle must pass through the zero value of the other normal stress \(\sigma_y\). working through the plot of fig. 14 is a good review of the beam stress formulas.  figure 14: variation of principal stress \(\sigma_{p1}\) in four-point bending.  exercise \(\pageindex{1}\)  derive the composite area theorem for determining the centroid of a compound area.  \(\bar{y} = \dfrac{\sum_i a_i \bar{y}_i}{\sum_i a_i}\)  exercise \(\pageindex{2}\)  (a)-(d) locate the centroids of the areas shown.  exercise \(\pageindex{3}\)  derive the ""parallel-axis theorem"" for moments of inertia of a plane area:  \(i_x = i_{xg} + a \bar{y}^2\)  \(i_y = i_{yg} + a \bar{x}^2\)  exercise \(\pageindex{4}\)  (a)-(d) determine the moment of inertia relative to the horizontal centroidal axis of the areas shown.  exercise \(\pageindex{5}\)  show that the moment of inertia transforms with respect to axis rotations exactly as does the stress:  where \(i_x\) and \(i_y\) are the moments of inertia relative to the \(x\) and \(y\) axes respectively and \(i_{xy}\) is the product of inertia defined as  \(i_{xy} = \int_a xy da\)  exercise \(\pageindex{6}\)  (a)–(h) determine the maxiumum normal stress σx in the beams shown here, using the values (as needed) \(l = 25\ in\), \(a = 5 \ in\), \(w = 10\ lb/in\), \(p = 150\ lb\). assume a rectangular cross-section of width \(b = 1\) in and height \(h = 2\ in\).  exercise \(\pageindex{7}\)  justify the statement in astm test d790, ""standard test methods for flexural properties of unreinforced and reinforced plastics and electrical insulating materials,"" which reads:  when a beam of homogeneous, elastic material is tested in flexure as a simple beam supported at two points and loaded at the midpoint, the maximum stress in the outer fibers occurs at midspan. this stress may be calculated for any point on the load-deflection curve by the following equation:  \(s = 3pl/2bd^2\)  where \(s\) = stress in the outer fibers at midspan, mpa; \(p\) = load at a given point on the load-deflection curve; \(l\) = support span, mm; \(b\) = width of beam tested, mm; and d = depth of beam tested, mm.  exercise \(\pageindex{8}\)  justify the statement in astm test d790, ""standard test methods for flexural properties of unreinforced and reinforced plastics and electrical insulating materials,"" which reads:  the tangent modulus of elasticity, often called the ""modulus of elasticity,"" is the ratio, within the elastic limit of stress to corresponding strain and shall be expressed in megapascals. it is calculated by drawing a tangent to the steepest initial straight-line portion of the load-deflection curve and using [the expression:]  \(e_b = l^3 m/4bd^3\)  where \(e_b\) = modulus of elasticity in bending, mpa; \(l\) = support span, mm; \(d\) = depth of beam tested, mm; and \(m\) = slope of the tangent to the initial straight-line portion of the load-deflection curve, \(n/mm\) of deflection.  exercise \(\pageindex{9}\)  a rectangular beam is to be milled from circular stock as shown. what should be the ratio of height to width \((b/h)\) to as to minimize the stresses when the beam is put into bending?  exercise \(\pageindex{10}\)  (a)-(h) determine the maxiumum shear τxy in the beams of exercise \(\pageindex{6}\), , using the values (as needed) \(l = 25\ in, a = 5\ in, w = 10\ lb/in, p = 150\ lb\). assume a rectangular cross-section of width \(b = 1\) in and height \(h = 2\ in\).  exercise \(\pageindex{11}\)  show that the ratio of maximum shearing stress to maximum normal stress in a beam subjected to 3-point bending is  \(\dfrac{\tau}{\sigma} = \dfrac{h}{2l}\)  hence the importance of shear stress increases as the beam becomes shorter in comparison with its height.  exercise \(\pageindex{12}\)  read the astm test d4475, ""standard test method for apparent horizontal shear strength of pultruded reinforced plastic rods by the short-beam method,"" and justify the expression given there for the apparent shear strength:  \(s = 0.849 p/d^2\)  where \(s\) = apparent shear strength, \(n/m^2\), (or psi); \(p\) = breaking load, \(n\), (or lbf); and \(d\) = diameter of specimen, m (or in.).  exercise \(\pageindex{13}\)  for the t beam shown here, with dimensions \(l = 3, a = 0.05, b = 0.005, c = 0.005, d = 0.7\) (all in \(m\)) and a loading distribution of \(w = 5000 n/m\), determine the principal and maximum shearing stress at point \(a\).  exercise \(\pageindex{14}\)  determine the maximum normal stress in a cantilevered beam of circular cross section whose radius varies linearly from \(4r_0\) to \(r_0\) in a distance \(l\), loaded with a force \(p\) at the free end.  exercise \(\pageindex{15}\)  a carbon steel column has a length \(l = 1\ m\) and a circular cross section of diameter \(d = 20\ mm\). determine the critical buckling load \(p_c\) for the case of (a) both ends pinned, (b) one end cantilevered, (c) both ends pinned but supported laterally at the midpoint.  exercise \(\pageindex{16}\)  a carbon steel column has a length \(l = 1\ m\) and a circular cross section. determine the diameter \(d\) at which the column has an equal probablity of buckling or yielding in compression.",t_fc5c2b91b262,other,0
c_435b019a49c8,"visually proving the pythagorean theorem  in case you haven't noticed, i've gotten somewhat obsessed with doing as many proofs of the pythagorean theorem as i can do. so let's do one more. and like how all of these proofs start, let's construct ourselves a right triangle. so i'm going to construct it so that its hypotenuse sits on the bottom. so that's the hypotenuse of my right triangle. try to draw it as big as possible, so that we have space to work with. so that's going to be my hypotenuse. and then let's say that this is the longer side that's not the hypotenuse. we can have two sides that are equal. but i'll just draw it so that it looks a little bit longer. let's call that side length a. and then let's draw this side right over here. it has to be a right triangle. so maybe it goes right over there. that's side of length b. let me extend the length a a little bit. so it definitely looks like a right triangle. and this is our 90-degree angle. so the first thing that i'm going to do is take this triangle and then rotate it counterclockwise by 90 degrees. so if i rotate it counterclockwise by 90 degrees, i'm literally just going to rotate it like that and draw another completely congruent version of this one. so i'm going to rotate it by 90 degrees. and if i did that, the hypotenuse would then sit straight up. so i'm going to do my best attempt to draw it almost to scale as much as i can eyeball it. this side of length a will now look something like this. it'll actually be parallel to this over here. so let me see how well i can draw it. so this is the side of length a. and if we cared, this would be 90 degrees. the rotation between the corresponding sides are just going to be 90 degrees in every case. that's going to be 90 degrees. that's going to be 90 degrees. now, let me draw side b. so it's going to look something like that or the side that's length b. and this and the right angle is now here. so all i did is i rotated this by 90 degrees counterclockwise. now, what i want to do is construct a parallelogram. i'm going to construct a parallelogram by essentially-- and let me label. so this is height c right over here. let me do that white color. this is height c. now, what i want to do is go from this point and go up c as well. now, so this is height c as well. and what is this length? what is the length over here from this point to this point going to be? well, a little clue is this is a parallelogram. this line right over here is going to be parallel to this line. it's maintained the same distance. and since it's traveling the same distance in the x direction or in the horizontal direction and the vertical direction, this is going to be the same length. so this is going to be of length a. now, the next question i have for you is, what is the area of this parallelogram that i have just constructed? well, to think about that, let's redraw this part of the diagram so that the parallelogram is sitting on the ground. so this is length a. this is length c. this is length c. and if you look at this part right over here, it gives you a clue. i'll use this green color. the height of the parallelogram is given right over here. this side is perpendicular to the base. so the height of the parallelogram is a as well. so what's the area? well, the area of a parallelogram is just the base times the height. so the area of this parallelogram right over here is going to be a squared. now, let's do the same thing. but let's rotate our original right triangle. let's rotate it the other way. so let's rotate it 90 degrees clockwise. and this time, instead of pivoting on this point, we're going to pivot on that point right over there. so what are we going to get? so the side of length c if we rotate it like that, it's going to end up right over here. i'll try to draw it as close to scale as possible. so that side has length c. now, the side of length of b is going to pop out and look something like this. it's going to be parallel to that. this is going to be a right angle. so let me draw it like that. that looks pretty good. and then the side of length a is going to be out here. so that's a. and then this right over here is b. and i wanted to do that b in blue. so let me do the b in blue. and then this right angle once we've rotated is just sitting right over here. now, let's do the same exercise. let's construct a parallelogram right over here. so this is height c. this is height c as well. so by the same logic we used over here, if this length is b, this length is b as well. these are parallel lines. we're going the same distance in the horizontal direction. we're rising the same in the vertical direction. we know that because they're parallel. so this is length b down here. this is length b up there. now, what is the area of this parallelogram right over there? what is the area of that parallelogram going to be? well, once again to help us visualize it, we can draw it sitting flat. so this is that side. then you have another side right over here. they both have length b. and you have the sides of length c. so that's c. that's c. what is its height? well, you see it right over here. its height is length b as well. it gives us right there. we know that this is 90 degrees. we did a 90-degree rotation. so this is how we constructed the thing. so given that, the area of a parallelogram is just the base times the height. the area of this parallelogram is b squared. so now, things are starting to get interesting. and what i'm going to do is i'm going to copy and paste this part right over here, because this is, in my mind, the most interesting part of our diagram. let me see how well i can select it. so let me select this part right over here. so let me copy. and then i'm going to scroll down. and then let me paste it. so this diagram that we've constructed right over here, it's pretty clear what the area of it is, the combined diagram. and let me delete a few parts of it. i want to do that in black so that it cleans it up. so let me clean this thing up, so we really get the part that we want to focus on. so cleaning that up and cleaning this up, cleaning this up right over there. and actually, let me delete this right down here as well, although we know that this length was c. and actually, i'll draw it right over here. this was from our original construction. we know that this length is c. we know this height is c. we know this down here is c. but my question for you is, what is the area of this combined shape? well, it's just a squared plus b squared. let me write that down. the area is just a squared plus b squared, the area of those two parallelograms. now, how can we maybe rearrange pieces of this shape so that we can express it in terms of c? well, it might have jumped out at you when i drew this line right over here. i want to do that in white. we know that this part right over here is of length c. this comes from our original construction. whoops. i lost my diagram. this is of length c. that's of length c. and then this right over here is of length c. and so what we could do is take this top right triangle, which is completely congruent to our original right triangle, and shift it down. so remember, the entire area, including this top right triangle, is a squared plus b squared. but we're excluding this part down here, which was our original triangle. but what happens if we take that? so let me actually cut. and then let me paste it. and all i'm doing is i'm moving that triangle down here. so now, it looks like this. so i've just rearranged the area that was a squared b squared. so this entire area of this entire square is still a squared plus b squared. a squared is this entire area right over here. it was before a parallelogram. i just shifted that top part of the parallelogram down. b squared is this entire area right over here. well, what's this going to be in terms of c? well, we know that this entire thing is a c by c square. so the area in terms of c is just c squared. so a squared plus b squared is equal to c squared. and we have, once again, proven the pythagorean theorem.",t_dd8f398324b2,other,0
c_46d2b13d4744,"sal uses an election example to compare population proportions.  let's say there's an election coming up and i want to figure out if there's a meaningful difference between the proportion of men and the proportion of women that are going to vote for a candidate. so let's look at the population distributions here. so we have the men, some proportion are going to vote for the candidate. we'll call that p1. so this is the proportion that will vote for the candidate. and the rest of the men will not vote for the candidate. so 1 minus p1 will not vote for the candidate. and then for the women, you're going to see something similar. so this is the women right over here. and some proportion will vote for the candidate. we don't know if it's the same as p1, we don't know if it's same as the men, so we'll call it p2. and then the rest of the women will not vote for the candidate. 1 minus p2. so the not voting are zeroes, the ones that are voting are ones. and these are both bernoulli distributions and we know, just because this'll be useful later on, that the means of this distribution are the same as the proportion that will vote for it. so the mean of the men, or the proportion of the men that will vote, so we'll call that mean one, is equal to p1. i should do everything in yellow. so the mean of this distribution is p1. the variance of this distribution, we'll call that variance one, is just these two proportions multiplied by each other. so it's p1 times 1 minus p1. and we saw this many many videos ago when we learned about bernoulli distributions. and we're going to see the exact same thing with the women. the mean of this bernoulli distribution is going to be p2. and then the variance of this bernoulli distribution is going to be these two proportions multiplied. so p2 times 1 minus p2. now, what i want to do, and i think i said this at the beginning of the video, is i want to figure out if there's a meaningful difference between the way that the men will vote and the women will vote. i want to figure out, let me write this, is this meaningful? so is there a meaningful difference here? and what we're going to do in this video is try to come up with a 95% confidence interval for this parameter. this difference of parameters is still a parameter. we don't know what the true difference of these two population parameters are. or these two population proportions. but we're going to try to come up with a 95% confidence interval for that difference. and the way we do that, we go out and we find 1,000 men likely to vote. and 1,000 women likely to vote. so let's write this down. so we get 1,000 men. when we survey the 1,000 men, let's say 642 say that they will vote for the candidate. so they are ones. and then the remainder, 358, i'll just say the remainder. so the rest are zeros. that we do the same thing with women. we survey 1,000 women who are likely to vote. but we survey them randomly. and let's say 591 say that they will vote for the candidate. and the rest say that they will not vote for the candidate. so just here based on our sample proportions, or our sample means, it looks like there is a difference. but we still have to come up with our confidence interval. and let's just make sure we understand what we just did. so we could figure out a sample proportion over here for the men. which is really just the sample mean of this sample right over here. we have 642 ones, the rest are zero. so we have 642 in the numerator. we have 1,000 samples. 642 divided by 1,000 is 0.642. so you could view this is a sample mean or as a sample proportion. if you do the same thing for the women, the sample proportion is going to be 0.591. or you could even just view this as the sample mean of the sample of 1,000 women. where the ones voting for it are one, the rest are zero. and just to visualize it properly, let me draw the sampling distribution for the sample proportions. we have a large sample size. and especially because the proportions that we're dealing with aren't close to one or zero, and we have a large sample size, the sampling distribution will be approximately normal. let me write this. so it's going to have some mean over here. so the mean of the sampling distribution of the sample proportion. and we've seen in multiple times. it's going to be the same thing as the mean of the population. and the mean of the population is actually the true population proportion. so this is going to be equal to p1. this is something that we don't to know about. and then the variance of this, and we've seen this several times already, the variance of this distribution, i have to put a one here, we're dealing with the men. the variance of this distribution by the central limit theorem is going to be the variance of this distribution up here, which is p1 times 1 minus p1 over our sample size, over 1,000. and we can do the exact same thing for the women. so this is the sampling distribution. this is for p2 bar, or this sample mean over here. let me put a one over here. remember, this is all for the men. and then this over here is all for the women. can't forget those twos over there. and so this distribution is going to have some mean. let me draw it right over here. so mu sub p2 with a bar over it. so the mean of the sampling distribution for this sample proportion, for the women, which is going to be the same thing as the mean of the population, which we already saw is going to be equal to p2. and then the variance for this distribution, for this sampling and distribution over here, is going to be this variance over here divided by our sample size. so p2 times 1 minus p2. all of that over n. now, our whole goal is to get a 95% confidence interval for that. and so what we're going to do is we're going to think about the sampling distribution, not for this, and not the sampling distribution for this. but we're going to think about the sampling distribution for the difference of this sample proportion and this sample proportion. we've seen it already. we're talking about proportions, but it's really the same exact ideas that we did when we just compared sample means generally. so let's look at that. let's look at this distribution. and just to be clear, when we got this sample mean here, this sample proportion, we just sampled it. you could view it as taking a sample from this distribution over here. when we got this sample proportion, it was like taking a sample from this over here. we took 1,000 samples from this, when we took their mean. where it's equivalent to taking a sample from the sampling distribution. now, this distribution over here is going to be the distribution of all of the differences of the sampling proportions, or of the sample proportions. so it will look like this. it will have some mean value. i should do this in a different color. i'll do it in green. yellow and blue make green. so i'll call this the sampling distribution of this statistic, of p1 minus p2. and so it has some mean over here. the sample of p1 minus the sample mean, or the sample proportion, of p2. and we know, from things that we've done in the last several videos, that this is going to be the exact same thing as this mean minus this mean. which is the exact same thing as p1 minus p2. so this is going to be equal to p1 minus p2. and the variance of this distribution, p1 minus p2, just like this, is going to be the sum of the variances of these two distributions. so it's going to be this thing over here, i'll just copy and paste it, plus this variance over here. there's no radical sign, because we're not taking the standard deviation. we're focused on the variance right now. so plus this thing right over here. so let me copy and let me paste it. so that's going to be the variance. and if you want the standard deviation, you can literally just get rid of this. you're taking the square root of both sides. so you take the square root of the variance, you get the standard deviation, that's why i got rid of that to the second power. and you want to take a square root of the right-hand side just like that. now, all i did right now was just to kind of conceptually set things up in our brain. what we now need to do is actually tackle the confidence interval. we actually need to come up with a 95% confidence interval for p1 minus p2. or a 95% confidence interval for this mean right over here. and because i'm trying to make my best effort not to make videos too long, i'll do part two in the next video, where we actually solve the confidence interval.",t_dfd7f3b13a38,other,0
c_86a7cb86dfab,"introducing the notation of infinite limits.  - [instructor] in a previous video, we explored the graphs of y equals one over x squared and one over x. in a previous video we've looked at these graphs. this is y is equal to one over x squared. this is y is equal to one over x. and we explored what's the limit as x approaches zero in either of those scenarios. and in this left scenario we saw as x becomes less and less negative, as it approaches zero from the left hand side, the value of one over x squared is unbounded in the positive direction. and the same thing happens as we approach x from the right, as we become less and less positive but we are still positive, the value of one over x squared becomes unbounded in the positive direction. so in that video, we just said, ""hey, ""one could say that this limit is unbounded."" but what we're going to do in this video is introduce new notation. instead of just saying it's unbounded, we could say, ""hey, from both the left and the right it looks like we're going to positive infinity"". so we can introduce this notation of saying, ""hey, this is going to infinity"", which you will sometimes see used. some people would call this unbounded, some people say it does not exist because it's not approaching some finite value, while some people will use this notation of the limit going to infinity. but what about this scenario? can we use our new notation here? well, when we approach zero from the left, it looks like we're unbounded in the negative direction, and when we approach zero from the right, we are unbounded in the positive direction. so, here you still could not say that the limit is approaching infinity because from the right it's approaching infinity, but from the left it's approaching negative infinity. so you would still say that this does not exist. you could do one sided limits here, which if you're not familiar with, i encourage you to review it on khan academy. if you said the limit of one over x as x approaches zero from the left hand side, from values less than zero, well then you would look at this right over here and say, ""well, look, it looks like we're going unbounded in the negative direction"". so you would say this is equal to negative infinity. and of course if you said the limit as x approaches zero from the right of one over x, well here you're unbounded in the positive direction so that's going to be equal to positive infinity. let's do an example problem from khan academy based on this idea and this notation. so here it says, consider graphs a, b, and c. the dashed lines represent asymptotes. which of the graphs agree with this statement, that the limit as x approaches 1 of h of x is equal to infinity? pause this video and see if you can figure it out. alright, let's go through each of these. so we want to think about what happens at x equals one. so that's right over here on graph a. so as we approach x equals one, so let me write this, so the limit, let me do this for the different graphs. so, for graph a, the limit as x approaches one from the left, that looks like it's unbounded in the positive direction. that equals infinity and the limit as x approaches one from the right, well that looks like it's going to negative infinity. that equals negative infinity. and since these are going in two different directions, you wouldn't be able to say that the limit as x approaches one from both directions is equal to infinity. so i would rule this one out. now let's look at choice b. what's the limit as x approaches one from the left? and of course these are of h of x. gotta write that down. so, of h of x right over here. well, as we approach from the left, looks like we're going to positive infinity. and it looks like the limit of h of x as we approach one from the right is also going to positive infinity. and so, since we're approaching you could say the same direction of infinity, you could say this for b. so b meets the constraints, but let's just check c to make sure. well, you can see very clearly x equals one, that as we approach it from the left, we go to negative infinity, and as we approach from the right, we got to positive infinity. so this, once again, would not be approaching the same infinity. so you would rule this one out, as well.",t_11cc3fb820f4,other,0
c_2c20deb3bcb2,"chapter 25 of the book on mysql.chapter 25: table creation section 25.1: table creation with primary key create table person ( personid int unsigned not null, lastname varchar(66) not null, firstname varchar(66), address varchar(255), city varchar(66), primary key (personid) );  a primary key is a not null single or a multi-column identiﬁer which uniquely identiﬁes a row of a table. an index is created, and if not explicitly declared as not null, mysql will declare them so silently and implicitly. a table can have only one primary key, and each table is recommended to have one. innodb will automatically create one in its absence, (as seen in mysql documentation) though this is less desirable. often, an auto_increment int also known as ""surrogate key"", is used for thin index optimization and relations with other tables. this value will (normally) increase by 1 whenever a new record is added, starting from a default value of 1. however, despite its name, it is not its purpose to guarantee that values are incremental, merely that they are sequential and unique. an auto-increment int value will not reset to its default start value if all rows in the table are deleted, unless the table is truncated using truncate table statement. deﬁning one column as primary key (inline deﬁnition) if the primary key consists of a single column, the primary key clause can be placed inline with the column deﬁnition: create table person ( personid int unsigned not null primary key, lastname varchar(66) not null, firstname varchar(66), address varchar(255), city varchar(66) );  this form of the command is shorter and easier to read. deﬁning a multiple-column primary key it is also possible to deﬁne a primary key comprising more than one column. this might be done e.g. on the child table of a foreign-key relationship. a multi-column primary key is deﬁned by listing the participating columns in a separate primary key clause. inline syntax is not permitted here, as only one column may be declared primary key inline. for example: create table invoice_line_items ( linenum smallint unsigned not null, invoicenum int unsigned not null, -- other columns go here  goalkicker.com – mysql® notes for professionals  78  primary key (invoicenum, linenum), foreign key (invoicenum) references -- references to an attribute of a table );  note that the columns of the primary key should be speciﬁed in logical sort order, which may be diﬀerent from the order in which the columns were deﬁned, as in the example above. larger indexes require more disk space, memory, and i/o. therefore keys should be as small as possible (especially regarding composed keys). in innodb, every 'secondary index' includes a copy of the columns of the primary key.  section 25.2: basic table creation the create table statement is used to create a table in a mysql database. create table person `personid` `lastname` `firstname` `address` `city` ) engine=innodb;  ( integer not null primary key, varchar(80), varchar(80), text, varchar(100)  every ﬁeld deﬁnition must have: 1. field name: a valid ﬁeld name. make sure to encolse the names in `-chars. this ensures that you can use eg space-chars in the ﬁeldname. 2. data type [length]: if the ﬁeld is char or varchar, it is mandatory to specify a ﬁeld length. 3. attributes null | not null: if not null is speciﬁed, then any attempt to store a null value in that ﬁeld will fail. 4. see more on data types and their attributes here. engine=... is an optional parameter used to specify the table's storage engine. if no storage engine is speciﬁed, the  table will be created using the server's default table storage engine (usually innodb or myisam). setting defaults additionally, where it makes sense you can set a default value for each ﬁeld by using default: create table address ( `addressid` integer not null primary key, `street` varchar(80), `city` varchar(80), `country` varchar(80) default ""united states"", `active` boolean default 1, ) engine=innodb;  if during inserts no street is speciﬁed, that ﬁeld will be null when retrieved. when no country is speciﬁed upon insert, it will default to ""united states"". you can set default values for all column types, except for blob, text, geometry, and json ﬁelds.  section 25.3: table creation with foreign key create table account ( accountid int unsigned not null, accountno int unsigned not null,  goalkicker.com – mysql® notes for professionals  79  personid int unsigned, primary key (accountid), foreign key (personid) references person (personid) ) engine=innodb;  foreign key: a foreign key (fk) is either a single column, or multi-column composite of columns, in a referencing table. this fk is conﬁrmed to exist in the referenced table. it is highly recommended that the referenced table key conﬁrming the fk be a primary key, but that is not enforced. it is used as a fast-lookup into the referenced where it does not need to be unique, and in fact can be a left-most index there. foreign key relationships involve a parent table that holds the central data values, and a child table with identical values pointing back to its parent. the foreign key clause is speciﬁed in the child table. the parent and child tables must use the same storage engine. they must not be temporary tables. corresponding columns in the foreign key and the referenced key must have similar data types. the size and sign of integer types must be the same. the length of string types need not be the same. for nonbinary (character) string columns, the character set and collation must be the same. note: foreign-key constraints are supported under the innodb storage engine (not myisam or memory). db setups using other engines will accept this create table statement but will not respect foreign-key constraints. (although newer mysql versions default to innodb, but it is good practice to be explicit.)  section 25.4: show table structure if you want to see the schema information of your table, you can use one of the following: show create table child; -- option 1 create table `child` ( `id` int(11) not null auto_increment, `fullname` varchar(100) not null, `myparent` int(11) not null, primary key (`id`), key `mommy_daddy` (`myparent`), constraint `mommy_daddy` foreign key (`myparent`) references `parent` (`id`) on delete cascade on update cascade ) engine=innodb default charset=utf8;  if used from the mysql commandline tool, this is less verbose: show create table child \g  a less descriptive way of showing the table structure: mysql> create table tab1(id int, name varchar(30)); query ok, 0 rows affected (0.03 sec) mysql> describe tab1; -- option 2 +-------+-------------+------+-----+---------+-------+ | field | type | null | key | default | extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | yes | | null | | | name | varchar(30) | yes | | null | | +-------+-------------+------+-----+---------+-------+  goalkicker.com – mysql® notes for professionals  80  both describe and desc gives the same result. to see describe performed on all tables in a database at once, see this example.  section 25.5: cloning an existing table a table can be replicated as follows: create table clonedpersons like persons;  the new table will have exactly the same structure as the original table, including indexes and column attributes. as well as manually creating a table, it is also possible to create table by selecting data from another table: create table clonedpersons select * from persons;  you can use any of the normal features of a select statement to modify the data as you go: create table modifiedpersons select personid, firstname + lastname as fullname from persons where lastname is not null;  primary keys and indexes will not be preserved when creating tables from select. you must redeclare them: create table modifiedpersons (primary key (personid)) select personid, firstname + lastname as fullname from persons where lastname is not null;  section 25.6: table create with timestamp column to show last update the timestamp column will show when the row was last updated. create table `testlastupdate` ( `id` int null, `name` varchar(50) null, `address` varchar(50) null, `lastupdate` timestamp null default current_timestamp on update current_timestamp ) comment='last update' ;  section 25.7: create table from select you can create one table from another by adding a select statement at the end of the create table statement: create table stack ( id_user int, username varchar(30), password varchar(30) );  create a table in the same database:  goalkicker.com – mysql® notes for professionals  81  -- create a table from another table in the same database with all attributes create table stack2 as select * from stack; -- create a table from another table in the same database with some attributes create table stack3 as select username, password from stack;  create tables from diﬀerent databases: -- create a table from another table from another database with all attributes create table stack2 as select * from second_db.stack; -- create a table from another table from another database with some attributes create table stack3 as select username, password from second_db.stack;  n.b to create a table same of another table that exist in another database, you need to speciﬁes the name of the database like this: from name_database.name_table  goalkicker.com – mysql® notes for professionals  82",t_4ba4e5cf6f39,other,0
c_05e9e227f16b,"making at least 3 out of 5 free throws.  welcome back. i actually recorded this video earlier today, but then i realized my microphone wasn't plugged in. and i won't name names in terms of who unplugged it. but anyway, back to probability. my wife is giggling mischievously. anyway, so let's do a slightly harder problem than we did before. we were dealing with fair coins, let's deal with a slightly unfair coin. let's say i have a coin and it's-- actually instead of unfair coin let's do basketball. let's say i'm shooting free throws and i have a free throw percentage of 80%. so when i shot a free throw, 8 out of 10 times, or 80% of the time i will make it. but that also says that 20% of time i will miss it. so given that, if i were to take-- i don't know-- 5 free throws, what is the probability that i make at least 3 of the 5 free throws? well, let's think of it this way, what is the probability of any particular combination of making 3 out of the 5? so what do i mean by that? let me pick a particular combination. let's say it's a basket, basket, basket, and then i miss, miss. so that would be i made 3 out of the 5. it could be-- i don't know-- basket, miss, basket, miss, basket. and there's a bunch of them and we'll actually try to figure out how many of them there are. but what is the probability of this particular combination? well, i have an 80% chance of making this first basket. times 80%. that's a times right there. times 80%. and then what's my probability of missing? well, that's 20%, right? times 0.2. times 0.2. so this sequels 0.8 to the third power times 0.2 squared. what's the probability of getting this exact combination? well, it's 0.8 times-- then i miss. there's a 20% chance of that. so times 0.2 times 0.8 times 0.2 times 0.8. we could rearrange this because when you multiply numbers it doesn't matter what order you multiply them in. so this is the same thing as 0.8 times 0.8 times 0.8 times 0.2 times 0.2. so this is also the same thing as 0.8 to the third times 0.2 squared. the probability of getting any particular combination of 3 baskets and 2 misses is going to be 0.8 to third times 0.2 squared. now what's the total probability of getting 3 out of 5? well, it's going to be the sum of all of these combinations. you know, i could list them all, but we hopefully now are proficient enough in combinatorics and combinations to figure out how many different ways, if we have 5 baskets and we're picking-- or we have 5 shots and we're picking 3 of them to be the ones that are basket shots. so what do i mean? so let's say my 5 shots-- you know, i've shot 1, 2, 3, 4, 5. out of these five, i'm going to choose 3. so once again, i'm putting my hat on as the god of probability and i will choose 3 of these shots to be the ones that happen to be the ones that get made. so essentially, out of 5 i am choosing 3. 5 choose 3. and what does that equal to? that's 5 factorial over 3 factorial times 5 minus 3 factorial, so that's 2 factorial. and that equals 5 times 4 times 3 times 2 times 1 over 3 times 2 times 1 times 2 times 1. we can ignore all the 1's. let's see. we get 3 times 2 times 1. 3 times 2 times 1. we can cancel that. this 1 we can ignore, and then this 2 and then this turns into 2. so there are 10 possible combinations. these are two of them. you know, basket, basket, basket, miss, miss. basket, miss, basket, miss, basket. and you know, it's a good exercise for you to list the other 8 of them. but using just the binomial coefficient, and hopefully you have an intuition of why that works and i'd be happy to make more videos if you feel that that you need more explanation. but i made a couple. there are 10 combinations. so essentially, the probability of getting exactly 3 out of 5 baskets, if i am an 80% free throw shot, is going to be-- switch colors. the probability of 3 out of 5 baskets is going to be equal to the probability of each of the combinations, which is 0.8 to the third times 0.2 squared. i make 3, miss 2. and then, times the total number of combinations. each of these has a probability of this much. and then there's 10 different arrangements that i could make. there's 10 different ways of getting 3 baskets and 2 misses. so times 10, and what does that equal to? let me get my high-end calculator here. so let's see what that is. that is 0.8 times 0.8 times 0.8 times 0.2 times 0.2 times 10. equals 20.48. so it's essentially, a 20.48% chance that i get exactly 3 out of 5 of the baskets. now let's make it slightly more interesting. let's say i don't want it as a probability of 3 out of the 5. and this is actually something that probably, people are more likely to ask. what is the probability of getting at least 3 baskets? well, if you think about it, this is the probability. this is equal to the probability of getting 3 out of 5 baskets, plus the probability of getting exactly 4 out of 5 baskets, plus the probability of getting exactly 5 out of 5 baskets. we already figured this one out. that's 20.48%. so what's the probability of getting 4 out of 5 baskets? well, once again, if we want exactly 4 out of 5 baskets, so an example could be-- i don't know-- miss, basket, basket, basket, basket. what's the probability of any one of the combinations where i make 4 baskets? well, it's going to be 0.8 to the fourth times-- and then i have a 20% chance that one miss. you know, it could have been basket, miss, basket, basket, basket. that's also exactly 4, but when you multiply them, the probability of getting any one of these particular combinations is exactly this-- 0.8 to the fourth times 0.2. if i have 5 baskets, how many ways can i pick 4 of them to be the ones that i make if i'm once again the god of probability? so this is going to be 0.8 to the fourth times 0.2 times 0.2 times-- out of 5 baskets, i'm choosing 4 that i'm going to make. so this is the number of combinations where i get 4 out of the 5. so what is 5 choose 4? that's 5 factorial over 4 factorial times 1 factorial. well, that equals just 5. you can work that out. so let's just figure this out. this is going to be 0.8 times 0.8 times 0.8-- that's 3-- times 0.8. that equals-- did i do that right? let's see. 0.1. wait. 0.8 times 0.8-- yeah, that's right. times 0.2 times 5. so 40.96%. so this is 40.96%. so roughly, 41% chance that i get exactly 4 out of 5 baskets. which is interesting because that's kind of my free throw percentage. so it's almost a little less-- you know, 2/3 shot of kind of hitting my free throw percentage on the mark on that time. and what's the probability of getting 5 out of 5 well, there's only one way of getting 5 out of 5. you have to get all 5 of them. so this is 0.8 to the fifth power. let me get the calculator back. so it's 0.8 times 0.-- oh, wait-- times 0.8 times 0.8 times 0.8 times 0.8 equals 0.3276. so 32.77% shot. and then we can add them all up because we want the probability of at least 3. so it's going to be that, the probability of getting 5 out of 5, plus the probability of getting 4 out of 5, which is 0.4096. plus, the probability of getting 3 out of 5. so that's 0.2048 equals 0.94208. so 94.21-- roughly, rounding-- % chance, which makes sense. if i have an 80% free throw percentage on any one shot, i have a very high probability of getting at least 3 out of 5 when i go to the free throw line. anyway, i'm all out of time. i'll see you in the next video.",t_c6dca5d0a746,other,0
c_e83cdee5062d,"an interesting case of taxes and tax incidence is when one of the curves is perfectly elastic. explore what happens when demand is perfectly elastic in this video.  let's think about how a tax on a product might affect it, if the demand for it is very, very, very elastic. so what i've done here -- we're going to think about flags -- the market for a certain typeof flag that's made in china. and to think about this flag -- think about it this way. if the price -- the price right now -- the equilibrium price between where the supply and the demand intersect -- the supply curve and the demand curve intersect -- is right about seventy dollars per flag. so this is a pretty nice flag. it's right at seventy dollars per flag. and the quantity demanded, in thousands per year, it looks like it's about twenty five thousand flags are demanded per year. now if at the price were to go slightly above that equilibrium price,what's going to happen? well, if the price goes slightly above that equilibrium price, people are going to say, ""well, i can go by the american flags made in taiwan, or even the ones made in america, or made in mexico, or made some place else. [because...] ""people won't be able to tell the difference from a distance."" so i'm going to buy one of the substitutes -- [because] especially the ones from taiwan or mexico or wherever else. are identical to the ones made in china. so if the price for slightly -- even slightly higher, the quantity demanded would be much, much, much lower. and if the price were even a little bit lower, then people say, ""i'm not going to buy the mexican flag-- or the taiwanese [or] american flags. i'm going to buy the ones that were made in china."" and then the quantity demanded would be much larger. and so what you have here is a very large, a high elasticity of demand. so this right over here, this is almost perfectly elastic. if it was perfectly elastic, it would be completely horizontal. so this is almost almost almost perfectly -- perfectly elastic -- elastic demand. a very small change in price leads to a huge change in quantity. in particular a very small percentage change in price leads to a huge percent change in quantity. so let's say that -- that some government official decides, ""you know what? [i] don't like the idea of american flags being made in china."" so they decide to tax american flags made in china. so what they do is that they place a tax, they place a tax -- and once again i'll do a fixed dollar tax. it could be a percentage and if a percentage then it'll change the sup -- the supply plus tax curve it'll be -- the shift will will be a percentage change instead of a fixed change. but the fixed change is a little bit easier to draw, so i'll do that. so let's say that there is a tax -- let me do that in a different color let's say that there's a tax placed of ten dollars -- ten dollars per flag. ten dollars, actually -- let's do an even a smaller amount. let's say that there is a tax placed of of one dollar per flag -- one dollar per flag. i'll make it a little bit larger. let's say it's five dollars per flag -- five dollars per flag. so now what is the supply plus tax curve? so the supplier / just to make the flags in china and ship them to united states and get the story here even to get that first flag done even if is that in the most efficient way possible looks do you need at least looks like around fifty to fifty three dollars now now they're going nowthey're still going to need that plus there's going to be a five dollar tax on it so supply plus tax is going to be that plus five dollars is going to be right around there over here, you add five dollars. so at any given point, we're gonna add fivedollars to essentially what the consumer would have to see. \\so you would have a curve that looks something like this you would have a curve that looks something like this you would have a curve that looks something like this. that dotted line right over there is our supply is our supply plus tax. this right over here was just our supply --was just our supply. so you're essentially -- so let's think about what happens here. your equilibrium price was at seventy before. now our equilibrium price is still -- our equilibrium price is still pretty much at seventy. but our equilibrium quantity has gone down dramatically. our equilibrium quantity has gone down to -- our equilibrium quantity has gone down to -- i don't know. it looks like about eighteen thousand. eighteen thousand flags per year. so who bore -- who bore the bulk of this right over here? so let's think about the tax revenue so the tax revenue in this situation is going to be eighteen thousand times the five dollars. so this is the five dollars right over here. that is five dollars -- and then times eighteen thousand -- times eighteen thousand. so this right over here is the tax revenue. that right over there is a tax revenue. actually, let me draw a little bit more carefully so the tax revenue is this is going to be between this line right over here and five dollars. so just like that. so that's all the tax revenue. and notice. it all came out of the producer surplus. the original producer surplus -- the original producer surplus was -- especially if we assume perfect elasticity -- the original producer surplus was this green rectangle plus this and plus this. now this is going to be -- this little area right over here is going to be dead weight loss -- dead-weight loss. and all of that came from the producer's surplus. and then the all the tax revenue, also -- if you especially if you assume this top-line was horizontal -- also came out of the producer surplus. so in this situation where you had almost where you we could say, if if you do have perfect elasticity if you have perfect elasticity of demand for the product, the person who's going to bear the the brunt of the tax -- so -- is going to be the producer. the producer surplus is going to be eaten into from the tax. bears -- bears the actually that's not -- that's not (i'm not talking about the animal, ""bears."") the producer, -- you know -- i'm not -- well -- the producer gets the burden the producer the producer gets the burden in that situation. and this is an interesting thing to think about. because when you have almost perfectly elastic demand -- so a -- almost -- or if you said perfectly elastic demand -- a flat -- a flat demand curve right over here -- there's -- there's actually no consumer surplus, because the marginal benefit, even the incremental marginal or -- (i'm -- i'm being redundant with the words incremental and marginal.) but the marginal benefit at any point for the consumer for -- that -- for that next unit is equal to the price they're paying, when you have -- there's no -- there's -- especially if the the especially if the demand curve is perfectly elastic -- and it's perfectly horizontal -- there is no area between the demand curve and the price paid. so there's actually -- there's isn't any -- even any consumer surplus to take any -- to take any of the -- to take -- to eat into. it all gets eaten out of the out of the producer surplus.",t_9c74d57e6c82,other,0
c_609c0f76107e,"which of the masks below could have produced the following diffraction pattern?  answer  b will produce the diffraction pattern, since its dimensions correspond to the inverse relationship.  a's dimensions do not correspond to the inverse relationship.  c and d are cross-shaped apertures which will result in a more complex diffraction pattern.  increasing the spread of the diffraction pattern allows for more accurate measurement of the spot spacing. which one of these will achieve this?  --------------------------------------------------------------- | a | analysing the pattern in the back focal plane of a lens |  | b |                 moving the laser closer to the aperture |  | c |           using a blue light laser instead of a red one |  | d |                    moving the screen away from the mask |  ---------------------------------------------------------------  hint: take another look at diffraction pattern formation (https://www.doitpoms.ac.uk/tlplib/diffraction/formation.php).  answer  a is incorrect. the diffraction pattern visible in the back focal plane is smaller in size than the pattern produced on a screen without a lens.  b is incorrect. this will have no effect on the diffraction pattern (as long as the screen distance is unaffected).  c is incorrect. red light has a longer wavelength, and hence the spot spacing will be smaller with blue light.  d is correct. this increases the screen distance, and hence the separation between the spots.  when the diffraction pattern from a particular grating is projected onto a screen, the even diffraction spots are missing, i.e. the second, fourth, etc. what is the relationship between the width of the slits (w) of the grating and the distance between each slit (s)?  answer  diffraction pattern from a grating: the convolution theorem (https://www.doitpoms.ac.uk/tlplib/diffraction/convolution.php) shows how the intensity function depends on the slit width and the slit spacing. the second maxima of the pattern (i.e. the second diffraction spot) lie 2λl/s on either side of the central position. the first minima of the binding sinc function lie at λl/w on either side of the central position. if these overlap, then all the even diffraction spots will be missing, due to the periodic nature of the pattern. hence:  \[2 \lambda l / s=\lambda l / w\]  i.e.  \[s = 2w\]  the diffraction pattern from a single slit is projected onto a screen 0.90 m from the slit. seven spots are visible, with a bright central spot. the maxima of the outer spots are a distance of 15 cm apart. a he-ne laser is used, which produces light of a wavelength of 0.6328 μm. what is the width of the slit?  hint: \(w=7 \frac{\lambda l}{x}\)  answer  from the diagram of the intensity pattern shown in the diffraction 1 section it can be seen that the intensity is zero for  \[x=\frac{\lambda l}{w}, \frac{2 \lambda l}{w}\]  and so on. outside the central bright spot, the other bright spots occur almost exactly half way between the zeros, i.e. close to  \[\frac{3}{2} \frac{\lambda l}{w}, \frac{5}{2} \frac{\lambda l}{w}, \frac{7}{2} \frac{\lambda l}{w}\]  thus, if seven spots are visible, the distance x between the outermost pair on opposite sides of the central spot will be  \[2 \times \frac{7}{2} \frac{\lambda l}{w}\]  hence the width of the slit w will be given by  \[7 \frac{\lambda l}{x}\]  separation of outermost spots, x = 15 cm     screen distance, l = 90 cm     wavelength of diffracted light, λ = 0.6328 x 10-6 m     therefore slit width is  \[w \approx 7\left(\frac{\lambda l}{x}\right)=\frac{7 \times 0.6328 \times 90}{15}=26.6 \mu \mathrm{m}\]  a convex lens has a focal length of 150 mm. if it is placed 180 mm from a mask on an optical bench, where must the screen be placed in order to focus the diffracted light into a sharp image?  answer  object distance, u = 180 mm     focal distance, f = 150 mm  the lens equation is  \[\frac{1}{u}+\frac{1}{v}=\frac{1}{f}\]  therefore, image distance,  \[v=\left(\frac{1}{f}-\frac{1}{u}\right)^{-1}=\left(\frac{1}{150}-\frac{1}{180}\right)^{-1}=900 \mathrm{mm}\]  i.e. 1080 mm from the object.  as in the previous question, a convex lens has a focal length of 150 mm and is placed 180 mm from a mask on an optical bench. where must the screen be placed in order to observe the diffraction pattern?  answer  the diffraction pattern can be observed at the back focal plane, located at the focal distance away from the lens, on the opposite side from the aperture, i.e. 150 mm from the lens, on the opposite side from the aperture.  as in the previous questions, a convex lens has a focal length of 150 mm and is placed 180 mm from a mask on an optical bench, giving an image distance of 900 mm. what is the magnification of the object in this set-up?  hint: magnification, m = v / u  answer  image distance, v = 900 mm     object distance, u = 180 mm  therefore, magnification  m = v / u = 900 / 180 = 5  as in the previous questions, a convex lens has a focal length of 150 mm and is placed 180 mm from a mask on an optical bench, giving an image distance of 900 mm. if the above lens is 56 mm in diameter, what is the finest grating size that could be resolved theoretically using light of wavelength 0.6328 μm?  hint: in order to resolve the grating, the two first-order diffraction spots must be included in forming the image.  answer  screen distance, l = 0.90 m     pattern spacing, x = 0.5 x lens diameter = 28 mm (to include 2 diffracted spots)     wavelength, λ = 0.6328 μm  therefore  \[s_{\min } h^{\prime \prime} \lambda l / x=0.6328 \times 10^{-6} \times 0.90 / 0.028=20.03 \mathrm{mm}\]  the theoretical resolution of a microscope is given by  \[d_{\min }=\frac{\lambda}{n \sin \alpha}\]  where n is the refractive index of the medium (n = 1 for air) and sinα is known as the numerical aperture, n.a. (commonly printed on the side of a lens). if a microscope can just resolve a ""400 lines per mm"" grating, what would the n.a. of the lens be?  answer  resolution,  \[d_{\min }=\left(400 \mathrm{mm}^{-1}\right)^{-1}=2.5 \mathrm{mm}\]  therefore, n.a.  \[\sin \alpha=\lambda\left(n d_{\min }\right)=0.6328 \times 10^{-6} /\left(1 \times 2.5 \times 10^{-6}\right)=0.253\]  a diffraction pattern shows just two-fold symmetry. which one of these apertures could not have produced such a pattern?  answer  b. this aperture will produce a four-fold symmetry diffraction pattern, whereas the others will produce two-fold patterns. diffraction patterns always have at least two-fold symmetry, even if the aperture has no symmetry. this can be seen mathematically in the nature of the fourier transform.  the following heart-shaped aperture produces the adjacent diffraction pattern.  which of the following masks should be placed in the back focal plane in order to best study the horizontal stripes of the aperture in the image? dashed lines are shown to identify location of central diffraction spot with respect to mask.  answer  c will be best. this will give a dark field image with respect to the horizontal stripes of the aperture, but with higher detail than b since more diffracted spots are going into making up the image.  a will give the bright field image in which the contrast of the strips will not be optimal.  b will give the dark field image with respect to the horizontal stripes of the aperture, with high contrast.  d will give a dark field image with respect to the vertical stripes of the aperture.",t_a8be23fd0b02,other,0
c_571b07b43249,"using shell model diagram to relate absorption to emission. derives relationship between emitted photon and energy levels, the balmer-rydberg equation.  - we've been talking about the bohr model for the hydrogen atom, and we know the hydrogen atom has one positive charge in the nucleus, so here's our positively charged nucleus of the hydrogen atom and a negatively charged electron. if you're going by the bohr model, the negatively charged electron is orbiting the nucleus at a certain distance. so, here i put the negatively charged electron a distance of r1, and so this electron is in the lowest energy level, the ground state. this is the first energy level, e1. we saw in the previous video that if you apply the right amount of energy, you can promote that electron. the electron can jump up to a higher energy level. if we add the right amount of energy, this electron can jump up to a higher energy level. so now this electron is a distance of r3, so we're talking about the third energy level here. this is the process of absorption. the electron absorbs energy and jumps up to a higher energy level. this is only temporary though, the electron is not going to stay there forever. it's eventually going to fall back down to the ground state. let's go ahead and put that on the diagram on the right. here's our electron, it's at the third energy level. it's eventually going to fall back down to the ground state, the first energy level. here's the electron going back to the first energy level here. when it does that, it's going to emit a photon. it's going to emit light. when the electron drops from a higher energy level to a lower energy level, it emits light. this is the process of emission. i could represent that photon here. this is how you usually see it in textbooks. we emit a photon, which is going to have a certain wavelength. lambda is the symbol for wavelength. we need to figure out how to relate lambda to those different energy levels. the energy of the photon is, the energy of the emitted photon is equal to the difference in energy between those two energy levels. we have energy with the third energy level and the first energy level. the difference between those... so, the energy of the third energy level minus the energy of the first energy level. that's equal to the energy of the photon. this is equal to the energy of that photon here. we know the energy of a photon is equal to h nu. let me go ahead and write that over here. energy of a photon is equal to h nu. h is planck's constant, this is planck's constant. nu is the frequency. we want to think about wavelength. we need to relate the frequency to the wavelength. the equation that does that is of course, c is equal to lambda nu. so, c is the speed of light, lambda is the wavelength, and nu is the frequency. so, if we solve for the frequency, the frequency would be equal to the speed of light divided by lambda. then, we're going to take all of that and plug this in to here. we get the energy of a photon is equal to planck's constant, h, i'll write that in here, times the frequency, and the frequency is equal to c over lambda. now we have the energy of the photon is equal to hc over lambda. instead of using e3 and e1, let's think about a generic high energy level. let's call this ej now, so this is just a higher energy level, ej. the electron falls back down to a lower energy level, which we'll call ei. instead of using e3 and e1, let's make it more generic, let's do ej and ei. let's go ahead and plug that in now. the energy of the photon would be equal to the higher energy level, ej minus the lower energy which is ei. so now we have this equation, let me go and highlight it here. we have hc over lambda is equal to ej minus ei. let's get some more room, and let's see if we can solve that a little bit better here. so let me write this down here. we have hc over lambda is equal to the energy of the higher energy level, minus the energy of the lower energy level, like that. alright, so in an earlier video, i showed you how you can calculate the energy at any energy level. we derived this equation. the energy at any energy level, n, is equal to e1 divided by n squared. so, if we wanted to know the energy when n is equal to j, that would be just e1 over j squared. we could take that and we could plug it in to here. alright, if i wanted to know the energy for the lower energy level, that was ei, and that's equal to e1 divided by i squared. i could take all of this, i could take this and i could plug it into here. let's, once again, get some more room. let's write what we have so far. we have hc over lambda is equal to ej was e1 over j squared and ei was e1 over i squared. okay, we could pull out an e1 on the right. so we have hc over lambda is equal to e1, and so that would give us one over j squared minus one over i squared, like that. we could divide both sides by hc, so let's do that. so on the left, we could have one over the wavelength is equal to e1 divided by hc, one over j squared minus one over i squared. again, from an earlier video, we calculated what that e1 is equal to. so, one over lambda is equal to e1 was negative 2.17 times 10 to the negative 18 joules. so once again, you can see that calculation in an earlier video. it took us a while to get there. we are going to divide by hc, and this is one over j squared minus one over i squared. well let's look a little bit more closely at what we have right here. so, if i, for right now, not worry about the negative sign, and just think about what we have. this is all equal to a constant. h is planck's constant, and c is the speed of light, so we have all these constants here. we could rewrite all of these as just r. i'm going to rewrite this as r, so this would be one over lambda is equal to negative r times one over j squared minus one over i squared. so, r is called the rydberg constant so let's see if we can solve for that. over here r would be equal to 2.17, times 10 to the negative 18, over h is planck's constant, that's 6.626 times 10 to the negative 34, and then c is the speed of light. so we could use 2.9979 times 10 to the eighth meters per second as the speed of light. if you do all that math, i won't do it here just to save time, but if you do all that, you'll get 1.09 times 10 to the seventh and this is one over meters. i think i might have, it's possible i had a rounding issue in here, because if you use 2.18, you get a better number. it's 1.097 times 10 to the seventh, which is the rydberg constant. this is just, again i'm just trying to show you the idea behind the rydberg constant here so we get this value for the rydberg constant. so you could plug that in for r if you needed to, and we're going to be doing that in the next video. you could stop right there, and you have related the wavelength, right to your different energy levels. you could go a little bit further, let's just go a little bit further here. so, one over lambda is equal to negative r. if we pull out a negative one, that would give us one over i squared minus one over j squared. now we have these two negative signs, right? these two negative signs out here which gives up a positive. this is now equal to one over lambda, one over the wavelength is equal to positive r, the rydberg constant, times one over i squared minus one over j squared. remember what i and j represented. i represented the lower energy level, and j represented the higher energy level. this is an extremely useful equation, so usually you see this called the balmer-rydberg equation. we've derived this equation using the assumptions of the bohr model, and this equation is extremely useful because it explains the entire emission spectrum of hydrogen. this is again, this is why we were exploring the bohr model in the first place. we got this equation, and in the next video we're going to see how this explains the emissions spectrum of hydrogen. think about lambda or the wavelength, right as the light is emitted when the electron falls back down to a lower energy state.",t_f1c2c1a582f1,other,0
c_24c975d45653,"skills to develop  distinguish between kinematics and dynamics  understand the definition of force  identify simple free-body diagrams  define the si unit of force, the newton  describe force as a vector  the study of motion is called kinematics, but kinematics only describes the way objects move—their velocity and their acceleration. dynamics is the study of how forces affect the motion of objects and systems. it considers the causes of motion of objects and systems of interest, where a system is anything being analyzed. the foundation of dynamics are the laws of motion stated by isaac newton (1642–1727). these laws provide an example of the breadth and simplicity of principles under which nature functions. they are also universal laws in that they apply to situations on earth and in space.  newton’s laws of motion were just one part of the monumental work that has made him legendary (figure 5.2). the development of newton’s laws marks the transition from the renaissance to the modern era. not until the advent of modern physics was it discovered that newton’s laws produce a good description of motion only when the objects are moving at speeds much less than the speed of light and when those objects are larger than the size of most molecules (about 10−9 m in diameter). these constraints define the realm of newtonian mechanics. at the beginning of the twentieth century, albert einstein (1879–1955) developed the theory of relativity and, along with many other scientists, quantum mechanics. quantum mechanics does not have the constraints present in newtonian physics. all of the situations we consider in this chapter, and all those preceding the introduction of relativity in relativity (http://cnx.org/content/m58555/latest/), are in the realm of newtonian physics.  figure  \(\pageindex{1}\): isaac newton (1642–1727) published his amazing work, philosophiae naturalis principia mathematica, in 1687. it proposed scientific laws that still apply today to describe the motion of objects (the laws of motion). newton also discovered the law of gravity, invented calculus, and made great contributions to the theories of light and color.  working definition of force  dynamics is the study of the forces that cause objects and systems to move. to understand this, we need a working definition of force. an intuitive definition of force—that is, a push or a pull—is a good place to start. we know that a push or a pull has both magnitude and direction (therefore, it is a vector quantity), so we can define force as the push or pull on an object with a specific magnitude and direction. force can be represented by vectors or expressed as a multiple of a standard force.  the push or pull on an object can vary considerably in either magnitude or direction. for example, a cannon exerts a strong force on a cannonball that is launched into the air. in contrast, earth exerts only a tiny downward pull on a flea. our everyday experiences also give us a good idea of how multiple forces add. if two people push in different directions on a third person, as illustrated in figure 5.3, we might expect the total force to be in the direction shown. since force is a vector, it adds just like other vectors. forces, like other vectors, are represented by arrows and can be added using the familiar head-to-tail method or trigonometric methods. these ideas were developed in vectors (https://phys.libretexts.org/bookshelves/university_physics/book%3a_university_physics_(openstax)/map%3a_university_physics_i_-_mechanics%2c_sound%2c_oscillations%2c_and_waves_(openstax)/2%3a_vectors).  figure \(\pageindex{2}\): (a) an overhead view of two ice skaters pushing on a third skater. forces are vectors and add like other vectors, so the total force on the third skater is in the direction shown. (b) a free-body diagram representing the forces acting on the third skater.  figure 5.3(b) is our first example of a free-body diagram, which is a sketch showing all external forces acting on an object or system. the object or system is represented by a single isolated point (or free body), and only those forces acting on it that originate outside of the object or system—that is, external forces—are shown. (these forces are the only ones shown because only external forces acting on the free body affect its motion. we can ignore any internal forces within the body.) the forces are represented by vectors extending outward from the free body.  free-body diagrams are useful in analyzing forces acting on an object or system, and are employed extensively in the study and application of newton’s laws of motion. you will see them throughout this text and in all your studies of physics. the following steps briefly explain how a free-body diagram is created; we examine this strategy in more detail in drawing free-body diagrams (https://phys.libretexts.org/bookshelves/university_physics/book%3a_university_physics_(openstax)/map%3a_university_physics_i_-_mechanics%2c_sound%2c_oscillations%2c_and_waves_(openstax)/5%3a_newton's_laws_of_motion/5.7%3a_drawing_free-body_diagrams).  problem-solving strategy: drawing free-body diagrams  draw the object under consideration. if you are treating the object as a particle, represent the object as a point. place this point at the origin of an xy-coordinate system.  include all forces that act on the object, representing these forces as vectors. however, do not include the net force on the object or the forces that the object exerts on its environment.  resolve all force vectors into x- and y-components.  draw a separate free-body diagram for each object in the problem.  we illustrate this strategy with two examples of free-body diagrams (figure 5.4). the terms used in this figure are explained in more detail later in the chapter.  figure  \(\pageindex{3}\): in these free-body diagrams, \(\vec{n}\) is the normal force, \(\vec{w}\) is the weight of the object, and \(\vec{f}\) is the friction.  the steps given here are sufficient to guide you in this important problem-solving strategy. the final section of this chapter explains in more detail how to draw free-body diagrams when working with the ideas presented in this chapter.  development of the force concept  a quantitative definition of force can be based on some standard force, just as distance is measured in units relative to a standard length. one possibility is to stretch a spring a certain fixed distance (figure 5.5) and use the force it exerts to pull itself back to its relaxed shape—called a restoring force—as a standard. the magnitude of all other forces can be considered as multiples of this standard unit of force. many other possibilities exist for standard forces. some alternative definitions of force will be given later in this chapter.  figure  \(\pageindex{4}\): the force exerted by a stretched spring can be used as a standard unit of force. (a) this spring has a length x when undistorted. (b) when stretched a distance \(\delta\)x , the spring exerts a restoring force \(\vec{f}\) restore, which is reproducible. (c) a spring scale is one device that uses a spring to measure force. the force \(\vec{f}\) restore is exerted on whatever is attached to the hook. here, this force has a magnitude of six units of the force standard being employed.  let’s analyze force more deeply. suppose a physics student sits at a table, working diligently on his homework (figure 5.6). what external forces act on him? can we determine the origin of these forces?  figure  \(\pageindex{5}\ : (a) the forces acting on the student are due to the chair, the table, the floor, and earth’s gravitational attraction. (b) in solving a problem involving the student, we may want to consider the forces acting along the line running through his torso. a free-body diagram for this situation is shown.  in most situations, forces are grouped into two categories: contact forces and field forces. as you might guess, contact forces are due to direct physical contact between objects. for example, the student in figure 5.6 experiences the contact forces \(\vec{c}\), \(\vec{f}\), and \(\vec{t}\), which are exerted by the chair on his posterior, the floor on his feet, and the table on his forearms, respectively. field forces, however, act without the necessity of physical contact between objects. they depend on the presence of a “field” in the region of space surrounding the body under consideration. since the student is in earth’s gravitational field, he feels a gravitational force \(\vec{w}\); in other words, he has weight.  you can think of a field as a property of space that is detectable by the forces it exerts. scientists think there are only four fundamental force fields in nature. these are the gravitational, electromagnetic, strong nuclear, and weak fields (we consider these four forces in nature later in this text). as noted for \(\vec{w}\) in figure 5.6, the gravitational field is responsible for the weight of a body. the forces of the electromagnetic field include those of static electricity and magnetism; they are also responsible for the attraction among atoms in bulk matter. both the strong nuclear and the weak force fields are effective only over distances roughly equal to a length of scale no larger than an atomic nucleus (10−15 m). their range is so small that neither field has influence in the macroscopic world of newtonian mechanics.  contact forces are fundamentally electromagnetic. while the elbow of the student in figure 5.6 is in contact with the tabletop, the atomic charges in his skin interact electromagnetically with the charges in the surface of the table. the net (total) result is the force \(\vec{t}\). similarly, when adhesive tape sticks to a piece of paper, the atoms of the tape are intermingled with those of the paper to cause a net electromagnetic force between the two objects. however, in the context of newtonian mechanics, the electromagnetic origin of contact forces is not an important concern.  vector notation for force  as previously discussed, force is a vector; it has both magnitude and direction. the si unit of force is called the newton (abbreviated n), and 1 n is the force needed to accelerate an object with a mass of 1 kg at a rate of 1 m/s2: 1 n = 1 kg • m/s2. an easy way to remember the size of a newton is to imagine holding a small apple; it has a weight of about 1 n.  we can thus describe a two-dimensional force in the form \(\vec{f}\) = a \(\hat{i}\) + b \(\hat{j}\) (the unit vectors \(\hat{i}\) and \(\hat{j}\) indicate the direction of these forces along the x-axis and the y-axis, respectively) and a three-dimensional force in the form \(\vec{f}\) = a \(\hat{i}\) + b \(\hat{j}\) + c \(\hat{k}\). in figure 5.3, let’s suppose that ice skater 1, on the left side of the figure, pushes horizontally with a force of 30.0 n to the right; we represent this as \(\vec{f}_{1}\) = 30.0 \(\hat{i}\) n. similarly, if ice skater 2 pushes with a force of 40.0 n in the positive vertical direction shown, we would write \(\vec{f}_{2}\) = 40.0 \(\hat{j}\) n. the resultant of the two forces causes a mass to accelerate—in this case, the third ice skater. this resultant is called the net external force \(\vec{f}_{net}\) and is found by taking the vector sum of all external forces acting on an object or system (thus, we can also represent net external force as \(\sum\vec{f}\)):  $$\vec{f}_{net} = \sum\vec{f} = \vec{f}_{1} + \vec{f}_{2} + \ldots \tag{5.1}$$  this equation can be extended to any number of forces.  in this example, we have \(\vec{f}_{net}\) = \(\sum \vec{f}\) = \(\vec{f}_{1}\) + \(\vec{f}_{2}\) = 30.0 \(\hat{i}\) + 40.0 \(\hat{j}\). the hypotenuse of the triangle shown in figure 5.3 is the resultant force, or net force. it is a vector. to find its magnitude (the size of the vector, without regard to direction), we use the rule given in vectors (https://phys.libretexts.org/bookshelves/university_physics/book%3a_university_physics_(openstax)/map%3a_university_physics_i_-_mechanics%2c_sound%2c_oscillations%2c_and_waves_(openstax)/2%3a_vectors), taking the square root of the sum of the squares of the components:  $$\vec{f}_{net} = \sqrt{(30.0\; n)^{2} + (40.0\; n)^{2}} = 50.0\; n \ldotp$$  the direction is given by  $$\theta = \tan^{-1} \left(\dfrac{f_{2}}{f_{1}}\right) = \tan^{-1} \left(\dfrac{40.0}{30.0}\right) = 53.1^{o},$$  measured from the positive x-axis, as shown in the free-body diagram in figure 5.3(b).  let’s suppose the ice skaters now push the third ice skater with \(\vec{f}_{1}\) = 3.0 \(\hat{i}\) + 8.0 \(\hat{j}\) n and \(\vec{f}_{2}\) = 5.0 \(\hat{i}\) + 4.0 \(\hat{j}\) n. what is the resultant of these two forces? we must recognize that force is a vector; therefore, we must add using the rules for vector addition:  $$\vec{f}_{net} = \vec{f}_{1} + \vec{f}_{2} = \big(3.0 \hat{i} + 8.0 \hat{j} \big) + \big(5.0 \hat{i} + 4.0 \hat{j} \big) = 8.0 \hat{i} + 12 \hat{j}\; n$$  check your understanding 5.1  find the magnitude and direction of the net force in the ice skater example just given.  simulation  view this interactive simulation (https://openstaxcollege.org/l/21addvectors) to learn how to add vectors. drag vectors onto a graph, change their length and angle, and sum them together. the magnitude, angle, and components of each vector can be displayed in several formats.  contributors  samuel j. ling (truman state university), jeff sanny (loyola marymount university), and bill moebs with many contributing authors. this work is licensed by openstax university physics under a creative commons attribution license (by 4.0) (http://creativecommons.org/licenses/by/4.0/).",t_e68a0099d050,other,0
c_974b600dd036,"kinematic equations help solve for an unknown in a problem when an object has either a constant velocity or constant acceleration. this video will help you choose which kinematic equations you should use, given the type of problem you're working through.  - [instructor] in this video we're going to go through a few examples of setting up some problems with constant acceleration. we're not going to solve them, we're just going to look at what we know and what the question is asking for and then identify which one of these equations over here will be the most useful for helping us solve it. so before we jump into the examples, i wanna say that it is very important to understand where these equations come from to really develop a strong understanding of position and velocity and acceleration and time and how they're all related to one another. and sal has a lot of videos that go through that and can help you build that understanding. but once you have that understanding, these equations are kind of like using a calculator where they help you save time. it's important to know how to add, subtract, to multiply and divide, so you know what a calculator is doing when you use it. but once you understand that, the calculator is a really valuable tool. and that's what these equations are like, they're tools that we can use when we understand where they come from. with that out of the way, let's dive into our example here. so the question says, ""a light rail commuter train ""accelerates at a rate of 1.35 meters per second squared. ""how long does it take to reach its top speed ""of 80 kilometers per hour starting from rest?"" all right, so let's unpack this and see what it's saying. so let's just start at the beginning. a light rail commuter train accelerates at a rate of 1.35 meters per second squared. so that's pretty direct, it's just telling us what the acceleration is. so let's write that down. the acceleration is 1.35 meters per second squared. all right, there's one thing. okay, so let's keep going. how long does it take to reach its top speed of 80 kilometers per hour starting from rest? so that one's a little bit more complicated, there's more going on in here. but if we just start at the beginning and say, ""how long does it take?"" that by itself is a question. there's some more stuff afterward, but that by itself is just asking about the time, how long does it take? all right, so let's note that by circling this time here. we don't know what it is yet, but this is our question, we're being asked about the time. all right, so if we keep going here, we get, all right, how long does it take to reach its top speed of 80 kilometers per hour? that's saying its top speed is 80 kilometers per hour. when it's done speeding up, it'll be going at 80 kilometers per hour. so that's the final velocity or just our velocity at the time here. so that's 80 kilometers per hour. 80.0 kilometers per hour. and sometimes you'll see this right here written as v sub f to really explicitly say it's the final velocity. so the notation might vary in your physics class. whatever notation you use, that's fine, but make sure to ask yourself what is this symbol really talking about. so anyway, 80 kilometers per hour, per hour. okay. and so we have that. and then if we keep going, it says, ""starting from rest."" so that's saying that at the beginning when it starts, it's at rest, which means it has zero for it's initial velocity, it's just sitting there. so let's fill that in, that's zero meters per second. okay. so we had analyzed this question and we see that, actually, the change in distance didn't appear anywhere in this question, it's just these four values right here. so let's see if we can look at these equations and identify one that has all of these things and doesn't have delta x, since we don't know delta x and we're not looking for it either. so we see these two have delta x here so we can rule those out. and this one also has a delta x so we can rule that out. so that leaves this one. let's see, it has velocity, the final velocity here, it has the initial velocity here, it has acceleration here, and then it also has time which is what we're looking for. so we can use this. we've figured out that for this question right here, we can just use that top equation. all right, and then to continue this we would plug in numbers and then solve for t and see what that time indeed is. so for this video, we're not going to have to go through that, we're just going to go through another example of setting things up. so let's go down to this question right here. while entering a freeway, a car accelerates from rest at a rate of 2.40 meters per second squared for 12.0 seconds. how far does the car travel during those 12 seconds and what is the car's final velocity? so this one actually asks two questions. let's just focus on the first one to begin with, and also let's see what we know. so while entering a freeway, a car accelerates from rest at a rate of 2.40 meter per second for 12 seconds. so there's a lot of information here in this first sentence. so let's see, it says, ""accelerates from rest,"" right here, accelerates from rest. that tells us that the initial velocity is zero, right? from rest, it wasn't moving initially, it was at rest. so let's write that down. this also, just like the previous example, had an initial velocity of zero meters per second. that's not always the case, but it happens that in these two examples it was. so let's keep going. so it accelerates from rest at a rate of 2.40 meters per second squared. so that's telling us what the acceleration is, 2.40 meters per second squared. so let's write that down, 2.40 meters per second squared, meters per second squared. and in all of these problems, it's important to think about whether something is moving in the positive direction or in the negative direction or if it's accelerating in the positive direction or the negative direction. it actually looks like for these examples we've chosen everything is moving in the positive direction and accelerating in that same direction. so we won't have any negative signs pop up, but it is important to think about that when you're doing these kinds of things, just in case something is negative and that does affect your answer and what's going on. but anyway, so it's accelerating forward, everything is going in the same direction. so we're thinking of the forward as the positive direction and they're accelerating, this car, is accelerating at 2.40 meters per second squared. all right, and it says also that it's doing that for 12.0 seconds. so we can write that down as well, 12.0 seconds. all right, so we know three things here. and you'll find that in problems like this, that's the magic number. once you have three of these, you can find out the other pieces using these equations. anyway, so the first question says, ""how far does the car travel during those 12.0 seconds?"" well, it's asking how far, so that's going to be the delta x here, this change in position. how far does it travel during those 12 seconds? it's going to be this value right here. so this is our question, circle it here. so now notice we don't have this, so we can look for an equation that doesn't have this final velocity value in it and then that will be an equation that will hopefully have these other four, but we'll have to check that. this one has that final velocity in it, so we can rule that out. i see this one also has the final velocity. this one doesn't have the final velocity. so let's look at that. so it has the position, the change in position, that's what we're looking for, it has it right there. the initial velocity is right here, so we have that as well. let's see, it has time in it and we have time, so we will be able to plug that in. and then finally, it also has acceleration. so it has everything we need, it has the thing we're looking for, and it doesn't include anything that we just don't know, that we're not even looking for. so we found that for this problem right here. this second equation here is going to be the one that is most useful for answering the question, ""how far does the car travel during those 12 seconds?"" so that's for that question, but this block here actually has a second question. maybe i'll switch to green. let's look at this question. what is the car's final velocity? all right, so that means we're looking for this now. right here, what's this? well, we've already identified these different pieces that we know, and if we did the first part of the problem, we would actually have a value for delta x here. but assuming we didn't find that yet, we could look at this and say, ""what's the car's final velocity? ""i want to look for something that has v in it ""and has these other three things that i know."" and if you look and you check through here, let's see, what is it? so, yeah, it would actually end up being this one again. this is that equation that doesn't have the change in position in it. and so just using the green color, i'll underline this here to say that this equation is useful for this question. and actually, now that we have this value, we could've used really any of them that had our v in it. so our options open up once we know more than three different things. but anyway, hopefully going through a couple of these examples will be helpful for you when you run into your own questions and have to think through, ""okay, what do i have, ""what am i looking for, ""and which equation will help me ""move forward and solve this question?""",t_59b31eb3a1a6,other,0
c_cbe1eef712ef,"sal proves the quadratic formula using the method of completing the square.  in the last video, i told you that if you had a quadratic equation of the form ax squared plus bx, plus c is equal to zero, you could use the quadratic formula to find the solutions to this equation. and the quadratic formula was x. the solutions would be equal to negative b plus or minus the square root of b squared minus 4ac, all of that over 2a. and we learned how to use it. you literally just substitute the numbers a for a, b for b, c for c, and then it gives you two answers, because you have a plus or a minus right there. what i want to do in this video is actually prove it to you. prove that using, essentially completing the square, i can get from that to that right over there. so the first thing i want to do, so that i can start completing the square from this point right here, is-- let me rewrite the equation right here-- so we have ax-- let me do it in a different color-- i have ax squared plus bx, plus c is equal to 0. so the first i want to do is divide everything by a, so i just have a 1 out here as a coefficient. so you divide everything by a, you get x squared plus b over ax, plus c over a, is equal to 0 over a, which is still just 0. now we want to-- well, let me get the c over a term on to the right-hand side, so let's subtract c over a from both sides. and we get x squared plus b over a x, plus-- well, i'll just leave it blank there, because this is gone now; we subtracted it from both sides-- is equal to negative c over a i left a space there so that we can complete the square. and you saw in the completing the square video, you literally just take 1/2 of this coefficient right here and you square it. so what is b over a divided by 2? or what is 1/2 times b over a? well, that is just b over 2a, and, of course, we are going to square it. you take 1/2 of this and you square it. that's what we do in completing a square, so that we can turn this into the perfect square of a binomial. now, of course, we cannot just add the b over 2a squared to the left-hand side. we have to add it to both sides. so you have a plus b over 2a squared there as well. now what happens? well, this over here, this expression right over here, this is the exact same thing as x plus b over 2a squared. and if you don't believe me, i'm going to multiply it out. that x plus b over 2a squared is x plus b over 2a, times x plus b over 2a. x times x is x squared. x times b over 2a is plus b over 2ax. you have b over 2a times x, which is another b over 2ax, and then you have b over 2a times b over 2a, that is plus b over 2a squared. that and this are the same thing, because these two middle terms, b over 2a plus b over 2a, that's the same thing as 2b over 2ax, which is the same thing as b over ax. so this simplifies to x squared plus b over ax, plus b over 2a squared, which is exactly what we have written right there. that was the whole point of adding this term to both sides, so it becomes a perfect square. so the left-hand side simplifies to this. the right-hand side, maybe not quite as simple. maybe we'll leave it the way it is right now. actually, let's simplify it a little bit. so the right-hand side, we can rewrite it. this is going to be equal to-- well, this is going to be b squared. i'll write that term first. this is b-- let me do it in green so we can follow along. so that term right there can be written as b squared over 4a square. and what's this term? what would that become? this would become-- in order to have 4a squared as the denominator, we have to multiply the numerator and the denominator by 4a. so this term right here will become minus 4ac over 4a squared. and you can verify for yourself that that is the same thing as that. i just multiplied the numerator and the denominator by 4a. in fact, the 4's cancel out and then this a cancels out and you just have a c over a. so these, this and that are equivalent. i just switched which i write first. and you might already be seeing the beginnings of the quadratic formula here. so this i can rewrite. this i can rewrite. the right-hand side, right here, i can rewrite as b squared minus 4ac, all of that over 4a squared. this is looking very close. notice, b squared minus 4ac, it's already appearing. we don't have a square root yet, but we haven't taken the square root of both sides of this equation, so let's do that. so if you take the square root of both sides, the left-hand side will just become x plus-- let me scroll down a little bit-- x plus b over 2a is going to be equal to the plus or minus square root of this thing. and the square root of this is the square root of the numerator over the square root of the denominator. so it's going to be the plus or minus the square root of b squared minus 4ac over the square root of 4a squared. now, what is the square root of 4a squared? it is 2a, right? 2a squared is 4a squared. the square root of this is that right here. so to go from here to here, i just took the square root of both sides of this equation. now, this is looking very close to the quadratic. we have a b squared minus 4ac over 2a, now we just essentially have to subtract this b over 2a from both sides of the equation and we're done. so let's do that. so if you subtract the b over 2a from both sides of this equation, what do you get? you get x is equal to negative b over 2a, plus or minus the square root of b squared minus 4ac over 2a, common denominator. so this is equal to negative b. let me do this in a new color. so it's orange. negative b plus or minus the square root of b squared minus 4ac, all of that over 2a. and we are done! by completing the square with just general coefficients in front of our a, b and c, we were able to derive the quadratic formula. just like that. hopefully you found that as entertaining as i did.",t_16e6b02dcd8f,other,0
c_ce4f96a7bfa0,"sal models a context about space travel with a direct variation equation.  so, in this problem, they're telling us in outer space, the distance an object travels varies directly with the amount of time that it travels. and, that's of course assuming that it's not accelerating, and there's no net force, and all of that on it. so, i guess they're talking about a specific object. so, some specific object, the amount, the distance that it travels is directly, it varies directly, it varies directly with the amount of time that it travels. so, if we think of in, in, in terms of constants of proportionality, and direct variation, we could say that the distance, we could say that the distance is equal to some constant, times the time, times the time that it travels. the distance varies directly with the amount of time that travels for this particular object. if an asteroid travels 3000 miles, in, if the asteroid travels 3000 miles in 6 hours, what is the constant of variation? so the distance is 3000, so we have d is equal to 3000 miles. we have 3,000 miles is the distance, and that's going to be equal to the constant of variation. the constant of variation times the time, times 6 hours. so, if we wanna solve for the constant of variation, we can just divide both sides by 6 hours. 6 hours, and we divide the right-hand side by 6 hours. and, so, 3,000 divided by 6 is 500, and 6 divided by 6 is 1. the hours also cancel out if you care about the units. and, so, the concept of proportionality, the left-hand side is just 500, 500, and then we have miles per hour, miles per hour. fired 500 miles per hour, and that is equal to k. so, the constant proportionality is 500 miles per hour, or you could say 500 if you're not too worried about the units. or, we should say, the constant of variation, to use the terminology that they actually use in the question.",t_c871b7927a3c,other,0
c_9505ce0e67ab,"definition 6.3.1.  let \(t:v\to w \) be a linear map. the range of \(t \), denoted by \(\range(t) \), is the subset of vectors in \(w \) that are in the image of \(t \). i.e.,  \[  \range(t) = \{ tv \mid v\in v\} = \{ w\in w \mid \rm{~ there~ exists~} v \in v \rm{~ such~ that~} tv=w\}.\]  example 6.3.2.  the range of the differentiation map \(t:\mathbb{f}[z] \to \mathbb{f}[z] \) is \(\range(t) =\mathbb{f}[z]\) since, for every polynomial \(q\in \mathbb{f}[z] \), there is a \(p\in \mathbb{f}[z] \) such that \(p'=q \).  example 6.3.3.  the range of the linear map \(t(x,y)=(x-2y,3x+y) \) is \(\mathbb{r}^2 \) since, for any \((z_1,z_2)\in \mathbb{r}^2 \), we have \(t(x,y)=(z_1,z_2) \) if \((x,y)=\frac{1}{7}(z_1+2z_2,-3z_1+z_2) \).  proposition 6.3.4. let \(t:v\to w \) be a linear map. then \(\range(t) \) is a subspace of \(w \).  proof.  we need to show that \(0\in \range(t) \) and that \(\range(t) \) is closed under addition and scalar multiplication. we already showed that \(t0=0 \) so that \(0\in \range(t) \).  for closure under addition, let \(w_1,w_2\in \range(t) \). then there exist \(v_1,v_2\in v\) such that \(tv_1=w_1 \) and \(tv_2=w_2 \). hence \begin{equation*}     t(v_1+v_2) = tv_1 + tv_2 = w_1 + w_2, \end{equation*} and so \(w_1+w_2\in \range(t) \).  for closure under scalar multiplication, let \(w\in \range(t) \) and \(a\in \mathbb{f} \). then there exists a \(v\in v \) such that \(tv=w \). thus \begin{equation*}     t(av)=atv=aw, \end{equation*} and so \(aw \in \range(t) \).  definition 6.3.5.  a linear map \(t:v\to w \) is called surjective if \(\range(t)=w \). a linear map \(t:v\to w \) is called bijective if \(t \) is both injective and surjective.  example 6.3.6.  the differentiation map \(t:\mathbb{f}[z] \to \mathbb{f}[z] \) is surjective since \(\range(t) = \mathbb{f}[z] \). however, if we restrict ourselves to polynomials of degree at most \(m \), then the differentiation map \(t:\mathbb{f}_m[z] \to \mathbb{f}_m[z] \) is not surjective since polynomials of degree \(m \) are not in thecrange of \(t \).  the identity map \(i:v\to v \) is surjective.  the linear map \(t:\mathbb{f}[z] \to \mathbb{f}[z] \) given by \(t(p(z)) = z^2 p(z) \) is not surjective since, for example, there are no linear polynomials in the range of \(t \).  the linear map \(t(x,y)=(x-2y,3x+y) \) is surjective since \(\range(t)=\mathbb{r}^{2} \), as we calculated in example 6.3.3.  contributors  isaiah lankham,  (http://www.math.ucdavis.edu/%7eissy/contact_info.html)mathematics department at uc davis (http://www.math.ucdavis.edu/)  bruno nachtergaele,  (http://www.math.ucdavis.edu/%7ebxn/)mathematics department at uc davis (http://www.math.ucdavis.edu/)  anne schilling,  (http://www.math.ucdavis.edu/%7eanne/)mathematics department at uc davis (http://www.math.ucdavis.edu/)  both hardbound and softbound versions of this textbook are available online at worldscientific.com. (http://www.worldscientific.com/worldscibooks/10.1142/9808)",t_5880dd399363,other,0
c_0b9d92be7f0e,"this is one of the most frequently-confused trios in the english language. follow along, and learn to suss out the differences between these three words.  - hello grammarians! today i want to talk about one of the absolute thorniest issues in usage of english. and it's the difference between there, their and they're. and if you can't tell the difference from the way i'm saying it that's because it's really confusing and evil. and that is why i'm here. is to help you make a distinction between these three sound alike words. now, first of all we have there t-h-e-r-e which we're gonna use orange for is an adverb and an adjective. and it's used to signify where something is. so the way to remember that this one is all about location is just to take the ""t"" and replace it with a ""w"". the question is ""where?"" and the answer is ""there"". so, ""have you been to greece? yes, i went there."" i have not gone there. ""have you seen my dog? yes, there's my dog!"" so you asked the question, ""where did you go? i went there. ""where is my dog? there is my dog."" and technically this is an adverbial use, here. ""there"" is modifying ""went"". and here is an adjectival use. because ""there"" is modifying ""dog"". the second member of this confusing trio is their t-h-e-i-r which is a possessive determiner. let's just call that a possessive. so this is when something belongs to a ""they"" and it's an adjective. so let's just call this a possessive adjective for some, for a ""they"". ""sue and frieda ate their ice cream cones."" so t-h-e-i-r, the possessive answers the question ""who does that belong to?"" so rounding out our trio, the last member of the there, their, they're riders of the apocalypse is t-h-e-y-'-r-e which is a contraction of ""they are"". so anywhere you would want to say ""they are"" you can smosh that together and say ""they're"". so, ""hey kid, are your parents home? ""no, they're not home right now, can i take a message?"" so you can see in this sentence ""they're not home right now, can i take a message?"" they're, t-h-e-y-'-r-e, is replacing ""they are"". both of these things would work equally well in the sentence. they're both grammatical, one's just shorter. and as we know, english as with most languages likes to take the easy route. finding the shortest possible or most efficient option if you prefer. so as a writer and speaker of english you're going to come across this situation a lot. which one of these things do you use? and so when you come across this thorny little issue ""do i use there, their or they're?"" you have to ask yourself a series of questions. questions #1, ""does it answer the question 'where is it'?"" if so, use t-h-e-r-e. if the use answers the question, ""who does it belong to?"" then you use t-h-e-i-r. if what you're trying to say is a contraction of ""they are"" then what you're looking for is t-h-e-y-'-r-e. i know it's confusing but you can learn anything. david out!",t_629c39c1af7f,other,0
c_665717e5ba9a,"learn valuable tips on how to stay safe on the construction site. safety on a construction sites safety tips on construction sites construction sites can be hazardous places. it is essential to strictly observe safety precautions in order to avoid injury, accidents and health problems at the workplace. typical causes of danger at the construction site include: -falling from heights, tripping over objects, stumbling into gaps and holes or slipping on wet surfaces, electric shocks and tools or building materials falling from overhead. to ensure a safe environment at the construction site, strictly observe the following rules: -clean the construction site every day and maintain an uncluttered surrounding. dispose of all dust, debris or loose nails that may be scattered on the floor. do not leave tools lying around and unplug any lights or electrical appliances that are not in use. -do not leave uncovered, stagnant water lying around. at the end of each day, water stored in containers should be thrown away. -trenches, gaps and holes found at the construction site should be covered with wood, to avoid accidents or mishaps. build a fence around the area under construction and install a signboard to inform nearby civilians of possible risk. this can help prevent unforeseen disasters. always use personal protective equipment while working. you have now learned about construction site safety.",t_c8c7ecb67081,other,0
c_c0014be8dbd7,"the standard form for linear equations in two variables is ax+by=c. for example, 2x+3y=5 is a linear equation in standard form. when an equation is given in this form, it's pretty easy to find both intercepts (x and y). this form is also very useful when solving systems of two linear equations.  - [voiceover] we've already looked at several ways of writing linear equations. you could write it in slope-intercept form, where it would be of the form of y is equal to mx plus b, where m and b are constants. m is the coefficient on this mx term right over here and m would represent the slope. and then from b you're able to figure out the y-intercept. the y, you're able to figure out the y-intercept from this. literally the graph that represents the xy pairs that satisfy this equation, it would intersect the y-axis at the point x equals zero, y is equal to b. and it's slope would be m. we've already seen that multiple times. we've also seen that you can also express things in point-slope form. so let me make it clear. this is slope-intercept. slope- intercept. and these are just different ways of writing the same equations. you can algebraically manipulate from one to the other. another way is point-slope. point-slope form. and in point-slope form, if you know that some, if you know that there's an equation where the line that represents the solutions of that equation has a slope m. slope is equal to m. and if you know that x equals, x equals a, y equals b, satisfies that equation, then in point-slope form you can express the equation as y minus b is equal to m times x minus a. this is point-slope form and we do videos on that. but what i really want to get into in this video is another form. and it's a form that you might have already seen. and that is standard form. standard. standard form. and standard form takes the shape of ax plus by is equal to c, where a, b, and c are integers. and what i want to do in this video, like we've done in the ones on point-slope and slope-intercept is get an appreciation for what is standard form good at and what is standard form less good at? so let's give a tangible example here. so let's say i have the linear equation, it's in standard form, 9x plus 16y is equal to 72. and we wanted to graph this. so the thing that standard form is really good for is figuring out, not just the y-intercept, y-intercept is pretty good if you're using slope-intercept form, but we can find out the y-intercept pretty clearly from standard form and the x-intercept. the x-intercept isn't so easy to figure out from these other forms right over here. so how do we do that? well to figure out the x and y-intercepts, let's just set up a little table here, x comma y, and so the x-intercept is going to happen when y is equal to zero. and the y-intercept is going to happen when x is equal to zero. so when y is zero, what is x? so when y is zero, 16 times zero is zero, that term disappears, and you're left with 9x is equal to 72. so if nine times x is 72, 72 divided by nine is eight. so x would be equal to eight. so once again, that was pretty easy to figure out. this term goes away and you just have to say hey, nine times x is 72, x would be eight. when y is equal to zero, x is eight. so the point, let's see, y is zero, x is one, two, three, four, five, six, seven, eight. that's this point, that right over here. this point right over here is the x-intercept. when we talk about x-intercepts we're referring to the point where the line actually intersects the x-axis. now what about the y-intercept? well, we said x equals zero, this disappears. and we're left with 16y is equal to 72. and so we could solve, we could solve that. so we could say, alright 16y is equal to 72. and then divide both sides by 16. we get y is equal to 72 over 16. and let's see, what is that equal to? that is equal to, let's see, they're both divisible by eight, so that's nine over two. or we could say it's 4.5. so when x is zero, y is 4.5. and so, we could plot that point as well. x is zero, y is one, two, three, 4.5. and just with these two points, two points are enough to graph a line, we can now graph it. so let's do that. so let me, oops, though i was using the tool that would draw a straight line. let me see if i can... so the line will look something like that. there you have it. i've just graphed, i've just graphed, this is the line that represents all the x and y pairs that satisfy the equation 9x plus 16y is equal to 72. now, i mentioned standard form's good at certain things and the good thing that standard form is, where it's maybe somewhat unique relative to the other forms we looked at, is it's very easy to figure out the x-intercept. it was very easy to figure out the x-intercept from standard form. and it wasn't too hard to figure out the y-intercept either. if we looked at slope-intercept form, the y-intercept just kinda jumps out at you. at point-slope form, neither the x nor the y-intercept kind of jump out at you. the place where slope-intercept or point-slope form are frankly better is that it's pretty easy to pick out the slope here, while in standard form you would have to do a little bit of work. you could use these two points, you could use the x and y-intercepts as two points and figure out the slope from there. so you can literally say, ""okay, if i'm going from ""this point to this point, my change in x ""to go from eight to zero is negative eight. ""and to go from zero to 4.5,"" i wrote that little delta there unnecessarily. let me. so when you go from eight to zero, your change in x is equal to negative eight. and to go from zero to 4.5, your change in y is going to be 4.5. so your slope, once you've figured this out, you could say, ""okay, this is going to be ""change in y, 4.5, over change in x, ""over negative 8."" and since i, at least i don't like a decimal up here, let's multiply the numerator and the denominator by two. you get negative nine over 16. now once again, we had to do a little bit of work here. we either use these two points, it didn't just jump immediately out of this, although you might see a little bit of a pattern of what's going on here. but you still have to think about is it negative? is it positive? you have to do a little bit of algebraic manipulation. or, what i typically do if i'm looking for the slope, i actually might put this into, into one of the other forms. especially slope-intercept form. but standard form by itself, great for figuring out both the x and y-intercepts and it's frankly not that hard to convert it to slope-intercept form. let's do that just to make it clear. so if you start with 9x, let me do that in yellow. if we start with 9x plus 16y is equal to 72 and we want to put it in slope-intercept form, we can subtract 9x from both sides. you get 16y is equal to negative 9x, plus 72. and then divide both sides by 16. so divide everthing by 16. and you'll be left with y is equal to negative 9/16x, that's the slope, you see it right there, plus 72 over 16, we already figured out that's 9/2 or 4.5. so i could write, oh i'll just write that as 4.5. and this form over here, much easier to figure out the slope and, actually, the y-intercept jumps out at you. but the x-intercept isn't as obvious.",t_25e8ce7fb9dc,other,0
c_7ea39911c70e,"adrienne watt  the way in which computers manage data has come a long way over the last few decades. today’s users take for granted the many benefits found in a database system. however, it wasn’t that long ago that computers relied on a much less elegant and costly approach to data management called the file-based system.  file-based system  one way to keep information on a computer is to store it in permanent files. a company system has a number of application programs; each of them is designed to manipulate data files. these application programs have been written at the request of the users in the organization. new applications are added to the system as the need arises. the system just described is called the file-based system.  consider a traditional banking system that uses the file-based system to manage the organization’s data shown in figure 1.1. as we can see, there are different departments in the bank. each has its own applications that manage and manipulate different data files. for banking systems, the programs may be used to debit or credit an account, find the balance of an account, add a new mortgage loan and generate monthly statements.  figure 1.1. example of a file-based system used by banks to manage data.  disadvantages of the file-based approach  using the file-based system to keep organizational information has a number of disadvantages. listed below are five examples.  data redundancy  often, within an organization, files and applications are created by different programmers from various departments over long periods of time. this can lead to data redundancy, a situation that occurs in a database when a field needs to be updated in more than one table. this practice can lead to several problems such as:  inconsistency in data format  the same information being kept in several different places (files)  data inconsistency, a situation where various copies of the same data are conflicting, wastes storage space and duplicates effort  data isolation  data isolation  is a property that determines when and how changes made by one operation become visible to other concurrent users and systems. this issue occurs in a concurrency situation. this is a problem because:  it is difficult for new applications to retrieve the appropriate data, which might be stored in various files.  integrity problems  problems with data integrity is another disadvantage of using a file-based system. it refers to the maintenance and assurance that the data in a database are correct and consistent. factors to consider when addressing this issue are:  data values must satisfy certain consistency constraints that are specified in the application programs.  it is difficult to make changes to the application programs in order to enforce new constraints.  security problems  security can be a problem with a file-based approach because:  there are constraints regarding accessing privileges.  application requirements are added to the system in an ad-hoc manner so it is difficult to enforce constraints.  concurrency access  concurrency is the ability of the database to allow multiple users access to the same record without adversely affecting transaction processing. a file-based system must manage, or prevent, concurrency by the application programs. typically, in a file-based system, when an application opens a file, that file is locked. this means that no one else has access to the file at the same time.  in database systems, concurrency is managed thus allowing multiple users access to the same record. this is an important difference between database and file-based systems.  database approach  the difficulties that arise from using the file-based system have prompted the development of a new approach in managing large amounts of organizational information called the database approach.  databases and database technology play an important role in most areas where computers are used, including business, education and medicine. to understand the fundamentals of database systems, we will start by introducing some basic concepts in this area.  role of databases in business  everybody uses a database in some way, even if it is just to store information about their friends and family. that data might be written down or stored in a computer by using a word-processing program or it could be saved in a spreadsheet. however, the best way to store data is by using database management software. this is a powerful software tool that allows you to store, manipulate and retrieve data in a variety of different ways.  most companies keep track of customer information by storing it in a database. this data may include customers, employees, products, orders or anything else that assists the business with its operations.  the meaning of data  data are factual information such as measurements or statistics about objects and concepts. we use data for discussions or as part of a calculation. data can be a person, a place, an event, an action or any one of a number of things. a single fact is an element of data, or a data element.  if data are information and information is what we are in the business of working with, you can start to see where you might be storing it. data can be stored in:  filing cabinets  spreadsheets  folders  ledgers  lists  piles of papers on your desk  all of these items store information, and so too does a database. because of the mechanical nature of databases, they have terrific power to manage and process the information they hold. this can make the information they house much more useful for your work.  with this understanding of data, we can start to see how a tool with the capacity to store a collection of data and organize it, conduct a rapid search, retrieve and process, might make a difference to how we can use data. this book and the chapters that follow are all about managing information.  key terms  concurrency: the ability of the database to allow multiple users access to the same record without adversely affecting transaction processing  data element: a single fact or piece of information  data inconsistency: a situation where various copies of the same data are conflicting  data isolation: a property that determines when and how changes made by one operation become visible to other concurrent users and systems  data integrity: refers to the maintenance and assurance that the data in a database are correct and consistent  data redundancy: a situation that occurs in a database when a field needs to be updated in more than one table  database approach: allows the management of large amounts of organizational information  database management software: a powerful software tool that allows you to store, manipulate and retrieve data in a variety of ways  file-based system: an application program designed to manipulate data files  exercises  discuss each of the following terms:  data  field  record  file  what is data redundancy?  discuss the disadvantages of file-based systems.  explain the difference between data and information.  use figure 1.2 (below) to answer the following questions.  in the table, how many records does the file contain?  how many fields are there per record?  what problem would you encounter if you wanted to produce a listing by city?  how would you solve this problem by altering the file structure?  figure 1.2. table for exercise #5, by a. watt.",t_905e870feeb2,other,0
c_861543028452,"chapter 1 | welcome to economics!  1 | welcome to economics!  figure 1.1 do you use facebook? economics is greatly impacted by how well information travels through society. today, social media giants twitter, facebook, and instagram are major forces on the information super highway. (credit: johan larsson/flickr)  decisions ... decisions in the social media age to post or not to post? every day we are faced with a myriad of decisions, from what to have for breakfast, to which route to take to class, to the more complex—“should i double major and add possibly another semester of study to my education?” our response to these choices depends on the information we have available at any given moment; information economists call “imperfect” because we rarely have all the data we need to make perfect decisions. despite the lack of perfect information, we still make hundreds of decisions a day. and now, we have another avenue in which to gather information—social media. outlets like facebook and twitter are altering the process by which we make choices, how we spend our time, which movies we see, which products we buy, and more. how many of you chose a university without checking out its facebook page or twitter stream first for information and feedback? as you will see in this course, what happens in economics is affected by how well and how fast information is disseminated through a society, such as how quickly information travels through facebook. “economists love nothing better than when deep and liquid markets operate under conditions of perfect information,” says jessica irvine, national economics editor for news corp australia.  7  8  chapter 1 | welcome to economics!  this leads us to the topic of this chapter, an introduction to the world of making decisions, processing information, and understanding behavior in markets —the world of economics. each chapter in this book will start with a discussion about current (or sometimes past) events and revisit it at chapter’s end—to “bring home” the concepts in play.  introduction in this chapter, you will learn about: • what is economics, and why is it important? • microeconomics and macroeconomics • how economists use theories and models to understand economic issues • how economies can be organized: an overview of economic systems what is economics and why should you spend your time learning it? after all, there are other disciplines you could be studying, and other ways you could be spending your time. as the bring it home feature just mentioned, making choices is at the heart of what economists study, and your decision to take this course is as much as economic decision as anything else. economics is probably not what you think. it is not primarily about money or finance. it is not primarily about business. it is not mathematics. what is it then? it is both a subject area and a way of viewing the world.  1.1 | what economics is and why it's important by the end of this section, you will be able to: • discuss the importance of studying economics • explain the relationship between production and division of labor • evaluate the significance of scarcity economics is the study of how humans make decisions in the face of scarcity. these can be individual decisions, family decisions, business decisions or societal decisions. if you look around carefully, you will see that scarcity is a fact of life. scarcity means that human wants for goods, services and resources exceed what is available. resources, such as labor, tools, land, and raw materials are necessary to produce the goods and services we want but they exist in limited supply. of course, the ultimate scarce resource is time- everyone, rich or poor, has just 24 hours in the day to try to acquire the goods they want. at any point in time, there is only a finite amount of resources available. think about it this way: in 2015 the labor force in the united states contained over 158.6 million workers, according to the u.s. bureau of labor statistics. similarly, the total area of the united states is 3,794,101 square miles. these are large numbers for such crucial resources, however, they are limited. because these resources are limited, so are the numbers of goods and services we produce with them. combine this with the fact that human wants seem to be virtually infinite, and you can see why scarcity is a problem.  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  9  figure 1.2 scarcity of resources homeless people are a stark reminder that scarcity of resources is real. (credit: “daveynin”/flickr creative commons)  if you still do not believe that scarcity is a problem, consider the following: does everyone need food to eat? does everyone need a decent place to live? does everyone have access to healthcare? in every country in the world, there are people who are hungry, homeless (for example, those who call park benches their beds, as shown in figure 1.2), and in need of healthcare, just to focus on a few critical goods and services. why is this the case? it is because of scarcity. let’s delve into the concept of scarcity a little deeper, because it is crucial to understanding economics.  the problem of scarcity think about all the things you consume: food, shelter, clothing, transportation, healthcare, and entertainment. how do you acquire those items? you do not produce them yourself. you buy them. how do you afford the things you buy? you work for pay. or if you do not, someone else does on your behalf. yet most of us never have enough to buy all the things we want. this is because of scarcity. so how do we solve it?  visit this website (http://openstaxcollege.org/l/drought) to read about how the united states is dealing with scarcity in resources.  every society, at every level, must make choices about how to use its resources. families must decide whether to spend their money on a new car or a fancy vacation. towns must choose whether to put more of the budget into police and fire protection or into the school system. nations must decide whether to devote more funds to national defense or to protecting the environment. in most cases, there just isn’t enough money in the budget to do everything. so why do we not each just produce all of the things we consume? the simple answer is most of us do not know how, but that is not the main reason. (when you study economics, you will discover that the obvious choice is not always the right answer—or at least the complete answer. studying economics teaches you to think in a different of way.) think back to pioneer days, when individuals knew how to do so much more than we do today, from building their homes, to growing their crops, to hunting for food, to repairing their equipment. most of us do not know how to do all—or  10  chapter 1 | welcome to economics!  any—of those things. it is not because we could not learn. rather, we do not have to. the reason why is something called the division and specialization of labor, a production innovation first put forth by adam smith, figure 1.3, in his book, the wealth of nations.  figure 1.3 adam smith adam smith introduced the idea of dividing labor into discrete tasks. (credit: wikimedia commons)  the division of and specialization of labor the formal study of economics began when adam smith (1723–1790) published his famous book the wealth of nations in 1776. many authors had written on economics in the centuries before smith, but he was the first to address the subject in a comprehensive way. in the first chapter, smith introduces the division of labor, which means that the way a good or service is produced is divided into a number of tasks that are performed by different workers, instead of all the tasks being done by the same person. to illustrate the division of labor, smith counted how many tasks went into making a pin: drawing out a piece of wire, cutting it to the right length, straightening it, putting a head on one end and a point on the other, and packaging pins for sale, to name just a few. smith counted 18 distinct tasks that were often done by different people—all for a pin, believe it or not! modern businesses divide tasks as well. even a relatively simple business like a restaurant divides up the task of serving meals into a range of jobs like top chef, sous chefs, less-skilled kitchen help, servers to wait on the tables, a greeter at the door, janitors to clean up, and a business manager to handle paychecks and bills—not to mention the economic connections a restaurant has with suppliers of food, furniture, kitchen equipment, and the building where it is located. a complex business like a large manufacturing factory, such as the shoe factory shown in figure 1.4, or a hospital can have hundreds of job classifications.  figure 1.4 division of labor workers on an assembly line are an example of the divisions of labor. (credit: nina hale/flickr creative commons)  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  11  why the division of labor increases production when the tasks involved with producing a good or service are divided and subdivided, workers and businesses can produce a greater quantity of output. in his observations of pin factories, smith observed that one worker alone might make 20 pins in a day, but that a small business of 10 workers (some of whom would need to do two or three of the 18 tasks involved with pin-making), could make 48,000 pins in a day. how can a group of workers, each specializing in certain tasks, produce so much more than the same number of workers who try to produce the entire good or service by themselves? smith offered three reasons. first, specialization in a particular small job allows workers to focus on the parts of the production process where they have an advantage. (in later chapters, we will develop this idea by discussing comparative advantage.) people have different skills, talents, and interests, so they will be better at some jobs than at others. the particular advantages may be based on educational choices, which are in turn shaped by interests and talents. only those with medical degrees qualify to become doctors, for instance. for some goods, specialization will be affected by geography—it is easier to be a wheat farmer in north dakota than in florida, but easier to run a tourist hotel in florida than in north dakota. if you live in or near a big city, it is easier to attract enough customers to operate a successful dry cleaning business or movie theater than if you live in a sparsely populated rural area. whatever the reason, if people specialize in the production of what they do best, they will be more productive than if they produce a combination of things, some of which they are good at and some of which they are not. second, workers who specialize in certain tasks often learn to produce more quickly and with higher quality. this pattern holds true for many workers, including assembly line laborers who build cars, stylists who cut hair, and doctors who perform heart surgery. in fact, specialized workers often know their jobs well enough to suggest innovative ways to do their work faster and better. a similar pattern often operates within businesses. in many cases, a business that focuses on one or a few products (sometimes called its “core competency”) is more successful than firms that try to make a wide range of products. third, specialization allows businesses to take advantage of economies of scale, which means that for many goods, as the level of production increases, the average cost of producing each individual unit declines. for example, if a factory produces only 100 cars per year, each car will be quite expensive to make on average. however, if a factory produces 50,000 cars each year, then it can set up an assembly line with huge machines and workers performing specialized tasks, and the average cost of production per car will be lower. the ultimate result of workers who can focus on their preferences and talents, learn to do their specialized jobs better, and work in larger organizations is that society as a whole can produce and consume far more than if each person tried to produce all of their own goods and services. the division and specialization of labor has been a force against the problem of scarcity.  trade and markets specialization only makes sense, though, if workers can use the pay they receive for doing their jobs to purchase the other goods and services that they need. in short, specialization requires trade. you do not have to know anything about electronics or sound systems to play music—you just buy an ipod or mp3 player, download the music and listen. you do not have to know anything about artificial fibers or the construction of sewing machines if you need a jacket—you just buy the jacket and wear it. you do not need to know anything about internal combustion engines to operate a car—you just get in and drive. instead of trying to acquire all the knowledge and skills involved in producing all of the goods and services that you wish to consume, the market allows you to learn a specialized set of skills and then use the pay you receive to buy the goods and services you need or want. this is how our modern society has evolved into a strong economy.  why study economics? now that we have gotten an overview on what economics studies, let’s quickly discuss why you are right to study it. economics is not primarily a collection of facts to be memorized, though there are plenty of important concepts to be learned. instead, economics is better thought of as a collection of questions to be answered or puzzles to be worked out. most important, economics provides the tools to work out those puzzles. if you have yet to be been bitten by the economics “bug,” there are other reasons why you should study economics. • virtually every major problem facing the world today, from global warming, to world poverty, to the conflicts  in syria, afghanistan, and somalia, has an economic dimension. if you are going to be part of solving those problems, you need to be able to understand them. economics is crucial.  12  chapter 1 | welcome to economics!  • it is hard to overstate the importance of economics to good citizenship. you need to be able to vote  intelligently on budgets, regulations, and laws in general. when the u.s. government came close to a standstill at the end of 2012 due to the “fiscal cliff,” what were the issues involved? did you know? • a basic understanding of economics makes you a well-rounded thinker. when you read articles about  economic issues, you will understand and be able to evaluate the writer’s argument. when you hear classmates, co-workers, or political candidates talking about economics, you will be able to distinguish between common sense and nonsense. you will find new ways of thinking about current events and about personal and business decisions, as well as current events and politics. the study of economics does not dictate the answers, but it can illuminate the different choices.  1.2 | microeconomics and macroeconomics by the end of this section, you will be able to: • describe microeconomics • describe macroeconomics • contrast monetary policy and fiscal policy economics is concerned with the well-being of all people, including those with jobs and those without jobs, as well as those with high incomes and those with low incomes. economics acknowledges that production of useful goods and services can create problems of environmental pollution. it explores the question of how investing in education helps to develop workers’ skills. it probes questions like how to tell when big businesses or big labor unions are operating in a way that benefits society as a whole and when they are operating in a way that benefits their owners or members at the expense of others. it looks at how government spending, taxes, and regulations affect decisions about production and consumption. it should be clear by now that economics covers a lot of ground. that ground can be divided into two parts: microeconomics focuses on the actions of individual agents within the economy, like households, workers, and businesses; macroeconomics looks at the economy as a whole. it focuses on broad issues such as growth of production, the number of unemployed people, the inflationary increase in prices, government deficits, and levels of exports and imports. microeconomics and macroeconomics are not separate subjects, but rather complementary perspectives on the overall subject of the economy. to understand why both microeconomic and macroeconomic perspectives are useful, consider the problem of studying a biological ecosystem like a lake. one person who sets out to study the lake might focus on specific topics: certain kinds of algae or plant life; the characteristics of particular fish or snails; or the trees surrounding the lake. another person might take an overall view and instead consider the entire ecosystem of the lake from top to bottom; what eats what, how the system stays in a rough balance, and what environmental stresses affect this balance. both approaches are useful, and both examine the same lake, but the viewpoints are different. in a similar way, both microeconomics and macroeconomics study the same economy, but each has a different viewpoint. whether you are looking at lakes or economics, the micro and the macro insights should blend with each other. in studying a lake, the micro insights about particular plants and animals help to understand the overall food chain, while the macro insights about the overall food chain help to explain the environment in which individual plants and animals live. in economics, the micro decisions of individual businesses are influenced by whether the macroeconomy is healthy; for example, firms will be more likely to hire workers if the overall economy is growing. in turn, the performance of the macroeconomy ultimately depends on the microeconomic decisions made by individual households and businesses.  microeconomics what determines how households and individuals spend their budgets? what combination of goods and services will best fit their needs and wants, given the budget they have to spend? how do people decide whether to work, and if so, whether to work full time or part time? how do people decide how much to save for the future, or whether they should borrow to spend beyond their current means?  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  13  what determines the products, and how many of each, a firm will produce and sell? what determines what prices a firm will charge? what determines how a firm will produce its products? what determines how many workers it will hire? how will a firm finance its business? when will a firm decide to expand, downsize, or even close? in the microeconomic part of this book, we will learn about the theory of consumer behavior and the theory of the firm.  macroeconomics what determines the level of economic activity in a society? in other words, what determines how many goods and services a nation actually produces? what determines how many jobs are available in an economy? what determines a nation’s standard of living? what causes the economy to speed up or slow down? what causes firms to hire more workers or to lay workers off? finally, what causes the economy to grow over the long term? an economy's macroeconomic health can be defined by a number of goals: growth in the standard of living, low unemployment, and low inflation, to name the most important. how can macroeconomic policy be used to pursue these goals? monetary policy, which involves policies that affect bank lending, interest rates, and financial capital markets, is conducted by a nation’s central bank. for the united states, this is the federal reserve. fiscal policy, which involves government spending and taxes, is determined by a nation’s legislative body. for the united states, this is the congress and the executive branch, which originates the federal budget. these are the main tools the government has to work with. americans tend to expect that government can fix whatever economic problems we encounter, but to what extent is that expectation realistic? these are just some of the issues that will be explored in the macroeconomic chapters of this book.  1.3 | how economists use theories and models to understand economic issues by the end of this section, you will be able to: • interpret a circular flow diagram • explain the importance of economic theories and models • describe goods and services markets and labor markets  figure 1.5 john maynard keynes one of the most influential economists in modern times was john maynard keynes. (credit: wikimedia commons)  john maynard keynes (1883–1946), one of the greatest economists of the twentieth century, pointed out that economics is not just a subject area but also a way of thinking. keynes, shown in figure 1.5, famously wrote in the introduction to a fellow economist’s book: “[economics] is a method rather than a doctrine, an apparatus of the mind, a technique of thinking, which helps its possessor to draw correct conclusions.” in other words, economics teaches you how to think, not what to think.  14  chapter 1 | welcome to economics!  watch this video (http://openstaxcollege.org/l/keynes) about john maynard keynes and his influence on economics.  economists see the world through a different lens than anthropologists, biologists, classicists, or practitioners of any other discipline. they analyze issues and problems with economic theories that are based on particular assumptions about human behavior, that are different than the assumptions an anthropologist or psychologist might use. a theory is a simplified representation of how two or more variables interact with each other. the purpose of a theory is to take a complex, real-world issue and simplify it down to its essentials. if done well, this enables the analyst to understand the issue and any problems around it. a good theory is simple enough to be understood, while complex enough to capture the key features of the object or situation being studied. sometimes economists use the term model instead of theory. strictly speaking, a theory is a more abstract representation, while a model is more applied or empirical representation. models are used to test theories, but for this course we will use the terms interchangeably. for example, an architect who is planning a major office building will often build a physical model that sits on a tabletop to show how the entire city block will look after the new building is constructed. companies often build models of their new products, which are more rough and unfinished than the final product will be, but can still demonstrate how the new product will work. a good model to start with in economics is the circular flow diagram, which is shown in figure 1.6. it pictures the economy as consisting of two groups—households and firms—that interact in two markets: the goods and services market in which firms sell and households buy and the labor market in which households sell labor to business firms or other employees.  figure 1.6 the circular flow diagram the circular flow diagram shows how households and firms interact in the goods and services market, and in the labor market. the direction of the arrows shows that in the goods and services market, households receive goods and services and pay firms for them. in the labor market, households provide labor and receive payment from firms through wages, salaries, and benefits.  of course, in the real world, there are many different markets for goods and services and markets for many different types of labor. the circular flow diagram simplifies this to make the picture easier to grasp. in the diagram, firms  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  15  produce goods and services, which they sell to households in return for revenues. this is shown in the outer circle, and represents the two sides of the product market (for example, the market for goods and services) in which households demand and firms supply. households sell their labor as workers to firms in return for wages, salaries and benefits. this is shown in the inner circle and represents the two sides of the labor market in which households supply and firms demand. this version of the circular flow model is stripped down to the essentials, but it has enough features to explain how the product and labor markets work in the economy. we could easily add details to this basic model if we wanted to introduce more real-world elements, like financial markets, governments, and interactions with the rest of the globe (imports and exports). economists carry a set of theories in their heads like a carpenter carries around a toolkit. when they see an economic issue or problem, they go through the theories they know to see if they can find one that fits. then they use the theory to derive insights about the issue or problem. in economics, theories are expressed as diagrams, graphs, or even as mathematical equations. (do not worry. in this course, we will mostly use graphs.) economists do not figure out the answer to the problem first and then draw the graph to illustrate. rather, they use the graph of the theory to help them figure out the answer. although at the introductory level, you can sometimes figure out the right answer without applying a model, if you keep studying economics, before too long you will run into issues and problems that you will need to graph to solve. both micro and macroeconomics are explained in terms of theories and models. the most well-known theories are probably those of supply and demand, but you will learn a number of others.  1.4 | how economies can be organized: an overview of economic systems by the end of this section, you will be able to: • contrast traditional economies, command economies, and market economies • explain gross domestic product (gdp) • assess the importance and effects of globalization think about what a complex system a modern economy is. it includes all production of goods and services, all buying and selling, all employment. the economic life of every individual is interrelated, at least to a small extent, with the economic lives of thousands or even millions of other individuals. who organizes and coordinates this system? who insures that, for example, the number of televisions a society provides is the same as the amount it needs and wants? who insures that the right number of employees work in the electronics industry? who insures that televisions are produced in the best way possible? how does it all get done? there are at least three ways societies have found to organize an economy. the first is the traditional economy, which is the oldest economic system and can be found in parts of asia, africa, and south america. traditional economies organize their economic affairs the way they have always done (i.e., tradition). occupations stay in the family. most families are farmers who grow the crops they have always grown using traditional methods. what you produce is what you get to consume. because things are driven by tradition, there is little economic progress or development.  16  chapter 1 | welcome to economics!  figure 1.7 a command economy ancient egypt was an example of a command economy. (credit: jay bergesen/ flickr creative commons)  command economies are very different. in a command economy, economic effort is devoted to goals passed down from a ruler or ruling class. ancient egypt was a good example: a large part of economic life was devoted to building pyramids, like those shown in figure 1.7, for the pharaohs. medieval manor life is another example: the lord provided the land for growing crops and protection in the event of war. in return, vassals provided labor and soldiers to do the lord’s bidding. in the last century, communism emphasized command economies. in a command economy, the government decides what goods and services will be produced and what prices will be charged for them. the government decides what methods of production will be used and how much workers will be paid. many necessities like healthcare and education are provided for free. currently, cuba and north korea have command economies.  figure 1.8 a market economy nothing says “market” more than the new york stock exchange. (credit: erik drost/ flickr creative commons)  although command economies have a very centralized structure for economic decisions, market economies have a very decentralized structure. a market is an institution that brings together buyers and sellers of goods or services, who may be either individuals or businesses. the new york stock exchange, shown in figure 1.8, is a prime example of market in which buyers and sellers are brought together. in a market economy, decisionmaking is decentralized. market economies are based on private enterprise: the means of production (resources and businesses) are owned and operated by private individuals or groups of private individuals. businesses supply goods and services based on demand. (in a command economy, by contrast, resources and businesses are owned by the government.) what goods and services are supplied depends on what is demanded. a person’s income is based on his or her ability to convert resources (especially labor) into something that society values. the more society values the person’s output, the higher the income (think lady gaga or lebron james). in this scenario, economic decisions are determined by market forces, not governments. most economies in the real world are mixed; they combine elements of command and market (and even traditional) systems. the u.s. economy is positioned toward the market-oriented end of the spectrum. many countries in europe and latin america, while primarily market-oriented, have a greater degree of government involvement in economic decisions than does the u.s. economy. china and russia, while they are closer to having a market-oriented system  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  17  now than several decades ago, remain closer to the command economy end of the spectrum. a rich resource of information about countries and their economies can be found on the heritage foundation’s website, as the following clear it up feature discusses.  what countries are considered economically free? who is in control of economic decisions? are people free to do what they want and to work where they want? are businesses free to produce when they want and what they choose, and to hire and fire as they wish? are banks free to choose who will receive loans? or does the government control these kinds of choices? each year, researchers at the heritage foundation and the wall street journal look at 50 different categories of economic freedom for countries around the world. they give each nation a score based on the extent of economic freedom in each category. the 2015 heritage foundation’s index of economic freedom report ranked 178 countries around the world: some examples of the most free and the least free countries are listed in table 1.1. several countries were not ranked because of extreme instability that made judgments about economic freedom impossible. these countries include afghanistan, iraq, syria, and somalia. the assigned rankings are inevitably based on estimates, yet even these rough measures can be useful for discerning trends. in 2015, 101 of the 178 included countries shifted toward greater economic freedom, although 77 of the countries shifted toward less economic freedom. in recent decades, the overall trend has been a higher level of economic freedom around the world.  most economic freedom  least economic freedom  1. hong kong  167. timor-leste  2. singapore  168. democratic republic of congo  3. new zealand  169. argentina  4. australia  170. republic of congo  5. switzerland  171. iran  6. canada  172. turkmenistan  7. chile  173. equatorial guinea  8. estonia  174. eritrea  9. ireland  175. zimbabwe  10. mauritius  176. venezuela  11. denmark  177. cuba  12. united states  178. north korea  table 1.1 economic freedoms, 2015 (source: the heritage foundation, 2015 index of economic freedom, country rankings, http://www.heritage.org/index/ranking)  18  chapter 1 | welcome to economics!  regulations: the rules of the game markets and government regulations are always entangled. there is no such thing as an absolutely free market. regulations always define the “rules of the game” in the economy. economies that are primarily market-oriented have fewer regulations—ideally just enough to maintain an even playing field for participants. at a minimum, these laws govern matters like safeguarding private property against theft, protecting people from violence, enforcing legal contracts, preventing fraud, and collecting taxes. conversely, even the most command-oriented economies operate using markets. how else would buying and selling occur? but the decisions of what will be produced and what prices will be charged are heavily regulated. heavily regulated economies often have underground economies, which are markets where the buyers and sellers make transactions without the government’s approval. the question of how to organize economic institutions is typically not a black-or-white choice between all market or all government, but instead involves a balancing act over the appropriate combination of market freedom and government rules.  figure 1.9 globalization cargo ships are one mode of transportation for shipping goods in the global economy. (credit: raul valdez/flickr creative commons)  the rise of globalization recent decades have seen a trend toward globalization, which is the expanding cultural, political, and economic connections between people around the world. one measure of this is the increased buying and selling of goods, services, and assets across national borders—in other words, international trade and financial capital flows. globalization has occurred for a number of reasons. improvements in shipping, as illustrated by the container ship shown in figure 1.9, and air cargo have driven down transportation costs. innovations in computing and telecommunications have made it easier and cheaper to manage long-distance economic connections of production and sales. many valuable products and services in the modern economy can take the form of information—for example: computer software; financial advice; travel planning; music, books and movies; and blueprints for designing a building. these products and many others can be transported over telephones and computer networks at ever-lower costs. finally, international agreements and treaties between countries have encouraged greater trade. table 1.2 presents one measure of globalization. it shows the percentage of domestic economic production that was exported for a selection of countries from 2010 to 2013, according to an entity known as the world bank. exports are the goods and services that are produced domestically and sold abroad. imports are the goods and services that are produced abroad and then sold domestically. the size of total production in an economy is measured by the gross domestic product (gdp). thus, the ratio of exports divided by gdp measures what share of a country’s total economic production is sold in other countries. country  2010  2011  2012  2013  higher income countries table 1.2 the extent of globalization (exports/gdp) (source: http://databank.worldbank.org/data/)  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  19  country  2010  2011  2012  2013  united states  12.4  13.6  13.6  13.5  belgium  76.2  81.4  82.2  82.8  canada  29.1  30.7  30.0  30.1  france  26.0  27.8  28.1  28.3  brazil  10.9  11.9  12.6  12.6  mexico  29.9  31.2  32.6  31.7  south korea  49.4  55.7  56.3  53.9  chad  36.8  38.9  36.9  32.2  china  29.4  28.5  27.3  26.4  india  22.0  23.9  24.0  24.8  nigeria  25.3  31.3  31.4  18.0  middle income countries  lower income countries  table 1.2 the extent of globalization (exports/gdp) (source: http://databank.worldbank.org/data/)  in recent decades, the export/gdp ratio has generally risen, both worldwide and for the u.s. economy. interestingly, the share of u.s. exports in proportion to the u.s. economy is well below the global average, in part because large economies like the united states can contain more of the division of labor inside their national borders. however, smaller economies like belgium, korea, and canada need to trade across their borders with other countries to take full advantage of division of labor, specialization, and economies of scale. in this sense, the enormous u.s. economy is less affected by globalization than most other countries. table 1.2 also shows that many medium and low income countries around the world, like mexico and china, have also experienced a surge of globalization in recent decades. if an astronaut in orbit could put on special glasses that make all economic transactions visible as brightly colored lines and look down at earth, the astronaut would see the planet covered with connections. so, hopefully, you now have an idea of what economics is about. before you move to any other chapter of study, be sure to read the very important appendix to this chapter called the use of mathematics in principles of economics. it is essential that you learn more about how to read and use models in economics.  20  chapter 1 | welcome to economics!  decisions ... decisions in the social media age the world we live in today provides nearly instant access to a wealth of information. consider that as recently as the late 1970s, the farmer’s almanac, along with the weather bureau of the u.s. department of agriculture, were the primary sources american farmers used to determine when to plant and harvest their crops. today, farmers are more likely to access, online, weather forecasts from the national oceanic and atmospheric administration or watch the weather channel. after all, knowing the upcoming forecast could drive when to harvest crops. consequently, knowing the upcoming weather could change the amount of crop harvested. some relatively new information forums, such as facebook, are rapidly changing how information is distributed; hence, influencing decision making. in 2014, the pew research center reported that 71% of online adults use facebook. facebook post topics range from the national basketball association, to celebrity singers and performers, to farmers. information helps us make decisions. decisions as simple as what to wear today to how many reporters should be sent to cover a crash. each of these decisions is an economic decision. after all, resources are scarce. if ten reporters are sent to cover an accident, they are not available to cover other stories or complete other tasks. information provides the knowledge needed to make the best possible decisions on how to utilize scarce resources. welcome to the world of economics!  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  21  key terms circular flow diagram a diagram that views the economy as consisting of households and firms interacting in a goods and services market and a labor market command economy an economy where economic decisions are passed down from government authority and where resources are owned by the government division of labor the way in which the work required to produce a good or service is divided into tasks performed by different workers economics the study of how humans make choices under conditions of scarcity economies of scale when the average cost of producing each individual unit declines as total output increases exports products (goods and services) made domestically and sold abroad fiscal policy economic policies that involve government spending and taxes globalization the trend in which buying and selling in markets have increasingly crossed national borders goods and services market a market in which firms are sellers of what they produce and households are buyers gross domestic product (gdp) measure of the size of total production in an economy imports products (goods and services) made abroad and then sold domestically labor market the market in which households sell their labor as workers to business firms or other employers macroeconomics the branch of economics that focuses on broad issues such as growth, unemployment, inflation, and trade balance. market interaction between potential buyers and sellers; a combination of demand and supply market economy an economy where economic decisions are decentralized, resources are owned by private individuals, and businesses supply goods and services based on demand microeconomics the branch of economics that focuses on actions of particular agents within the economy, like households, workers, and business firms model see theory monetary policy policy that involves altering the level of interest rates, the availability of credit in the economy, and the extent of borrowing private enterprise system where the means of production (resources and businesses) are owned and operated by private individuals or groups of private individuals scarcity when human wants for goods and services exceed the available supply specialization when workers or firms focus on particular tasks for which they are well-suited within the overall production process theory a representation of an object or situation that is simplified while including enough of the key features to help us understand the object or situation traditional economy typically an agricultural economy where things are done the same as they have always been done  22  chapter 1 | welcome to economics!  underground economy a market where the buyers and sellers make transactions in violation of one or more government regulations  key concepts and summary 1.1 what economics is and why it's important economics seeks to solve the problem of scarcity, which is when human wants for goods and services exceed the available supply. a modern economy displays a division of labor, in which people earn income by specializing in what they produce and then use that income to purchase the products they need or want. the division of labor allows individuals and firms to specialize and to produce more for several reasons: a) it allows the agents to focus on areas of advantage due to natural factors and skill levels; b) it encourages the agents to learn and invent; c) it allows agents to take advantage of economies of scale. division and specialization of labor only work when individuals can purchase what they do not produce in markets. learning about economics helps you understand the major problems facing the world today, prepares you to be a good citizen, and helps you become a well-rounded thinker. 1.2 microeconomics and macroeconomics microeconomics and macroeconomics are two different perspectives on the economy. the microeconomic perspective focuses on parts of the economy: individuals, firms, and industries. the macroeconomic perspective looks at the economy as a whole, focusing on goals like growth in the standard of living, unemployment, and inflation. macroeconomics has two types of policies for pursuing these goals: monetary policy and fiscal policy. 1.3 how economists use theories and models to understand economic issues economists analyze problems differently than do other disciplinary experts. the main tools economists use are economic theories or models. a theory is not an illustration of the answer to a problem. rather, a theory is a tool for determining the answer. 1.4 how economies can be organized: an overview of economic systems societies can be organized as traditional, command, or market-oriented economies. most societies are a mix. the last few decades have seen globalization evolve as a result of growth in commercial and financial networks that cross national borders, making businesses and workers from different economies increasingly interdependent.  self-check questions 1. what is scarcity? can you think of two causes of scarcity? 2. residents of the town of smithfield like to consume hams, but each ham requires 10 people to produce it and takes a month. if the town has a total of 100 people, what is the maximum amount of ham the residents can consume in a month? 3. a consultant works for $200 per hour. she likes to eat vegetables, but is not very good at growing them. why does it make more economic sense for her to spend her time at the consulting job and shop for her vegetables? 4. a computer systems engineer could paint his house, but it makes more sense for him to hire a painter to do it. explain why. 5. what would be another example of a “system” in the real world that could serve as a metaphor for micro and macroeconomics? 6. suppose we extend the circular flow model to add imports and exports. copy the circular flow diagram onto a sheet of paper and then add a foreign country as a third agent. draw a rough sketch of the flows of imports, exports, and the payments for each on your diagram. 7. what is an example of a problem in the world today, not mentioned in the chapter, that has an economic dimension?  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!  23  8. the chapter defines private enterprise as a characteristic of market-oriented economies. what would public enterprise be? hint: it is a characteristic of command economies. 9. why might belgium, france, italy, and sweden have a higher export to gdp ratio than the united states?  review questions 10. give the three reasons that explain why the division of labor increases an economy’s level of production.  16. are households primarily buyers or sellers in the goods and services market? in the labor market?  11. what are three reasons to study economics?  17. are firms primarily buyers or sellers in the goods and services market? in the labor market?  12. what is the difference between microeconomics and macroeconomics? 13. what are examples of individual economic agents? 14. what are the three main goals of macroeconomics?  18. what are the three ways that societies can organize themselves economically? 19. what is globalization? how do you think it might have affected the economy over the past decade?  15. how did john maynard keynes define economics?  critical thinking questions 20. suppose you have a team of two workers: one is a baker and one is a chef. explain why the kitchen can produce more meals in a given period of time if each worker specializes in what they do best than if each worker tries to do everything from appetizer to dessert. 21. why would division of labor without trade not work? 22. can you think of any examples of free goods, that is, goods or services that are not scarce? 23. a balanced federal budget and a balance of trade are considered secondary goals of macroeconomics, while growth in the standard of living (for example) is considered a primary goal. why do you think that is so? 24. macroeconomics is an aggregate of what happens at the microeconomic level. would it be possible for  what happens at the macro level to differ from how economic agents would react to some stimulus at the micro level? hint: think about the behavior of crowds. 25. why is it unfair or meaningless to criticize a theory as “unrealistic?” 26. suppose, as an economist, you are asked to analyze an issue unlike anything you have ever done before. also, suppose you do not have a specific model for analyzing that issue. what should you do? hint: what would a carpenter do in a similar situation? 27. why do you think that most modern countries’ economies are a mix of command and market types? 28. can you think of ways that globalization has helped you economically? can you think of ways that it has not?  24  this openstax book is available for free at http://cnx.org/content/col11627/1.10  chapter 1 | welcome to economics!",t_20b0ddb2ebeb,other,0
c_a1933f19328f,"sal introduces  _ **geometric sequences**_  and their main features, the  _ **initial term**_  and the  _ **common ratio**_.  in this video i want to introduce you to the idea of a geometric sequence. and i have a ton of more advanced videos on the topic, but it's really a good place to start, just to understand what we're talking about when someone tells you a geometric sequence. now a good starting point is just, what is a sequence? and a sequence is, you can imagine, just a progression of numbers. so for example, and this isn't even a geometric series, if i just said 1, 2, 3, 4, 5. this is a sequence of numbers. it's not a geometric sequence, but it is a sequence. a geometric sequence is a special progression, or a special sequence, of numbers, where each successive number is a fixed multiple of the number before it. let me explain what i'm saying. so let's say my first number is 2 and then i multiply 2 by the number 3. so i multiply it by 3, i get 6. and then i multiply 6 times the number 3, and i get 18. then i multiply 18 times the number 3, and i get 54. and i just keep going that way. so i just keep multiplying by the number 3. so i started, if we want to get some notation here, this is my first term. we'll call it a1 for my sequence. and each time i'm multiplying it by a common number, and that number is often called the common ratio. so in this case, a1 is equal to 2, and my common ratio is equal to 3. so if someone were to tell you, hey, you've got a geometric sequence. a1 is equal to 90 and your common ratio is equal to negative 1/3. that means that the first term of your sequence is 90. the second term is negative 1/3 times 90. which is what? that's negative 30, right? 1/3 times 90 is 30, and then you put the negative number. then the next number is going to be 1/3 times this. so negative 1/3 times this. 1/3 times 30 is 10. the negatives cancel out, so you get positive 10. then the next number is going to be 10 times negative 1/3, or negative 10/3. and then the next number is going to be negative 10/3 times negative 1/3 so it's going to be positive 10/3. and you could just keep going on with this sequence. so that's what people talk about when they mean a geometric sequence. i want to make one little distinction here. this always used to confuse me because the terms are used very often in the same context. these are sequences. these are kind of a progression of numbers. 2, then 6, then 18, 90, then negative 30, then 10, then negative 10/3. then, i'm sorry, this is positive 10/9, right? negative 1/3 times negative 10/3, negatives cancel out. right. 10/9. don't want to make a mistake here. these are sequences. you might also see the word a series. and you might even see a geometric series. a series, the most conventional use of the word series, means a sum of a sequence. so for example, this is a geometric sequence. a geometric series would be 90 plus negative 30, plus 10, plus negative 10/3, plus 10/9. so a general way to view it is that a series is the sum of a sequence. i just want to make that clear because that used to confuse me a lot when i first learned about these things. but anyway, let's go back to the notion of a geometric sequence, and actually do a word problem that deals with one of these. so they're telling us that anne goes bungee jumping off of a bridge above water. on the initial jump, the cord stretches by 120 feet. so on a1, our initial jump, the cord stretches by 120 feet. we could write it this way. we could write, jump, and then how much the cord stretches. so on the initial jump, on jump one, the cord stretches 120 feet. then it says, on the next bounce, the stretch is 60% of the original jump, and then each additional bounce stretches the rope 60% of the previous stretch. so here, the common ratio, where each successive term in our sequence is going to be 60% of the previous term. or it's going to be 0.6 times the previous term. so on the second jump, we're going to start 60% of that, or 0.6 times 120. which is equal to what? that's equal to 72. then on the third jump, we're going to stretch 0.6 of 72, or 0.6 times this. so it would be 0.6 times 0.6 times 120. notice, over here, so on the fourth jump we're going to have 0.6 times 0.6 times 0.6 times 120. 60% of this jump, so every time we're 60% of the previous jump. so if we wanted to make a general formula for this, just based on the way we've defined it right here. so the stretch on the nth jump, what would it be? so let's see, we start at 120 times 0.6 to the what? to the n minus 1. how did i get this? let me write this a little bit here. so this is equal to 0.6, actually let me write the 120 first. this is equal to 120 times 0.6 to the n minus 1. how did i get that? well we're defining the first jump as stretching 120 feet. so when you put n is equal to 1 here, you get 1 minus 1, 0. so you have 0.6 to the 0th power, and you've just got a 1 here. and that's exactly what happened on the first jump. then on the second jump, you put a 2 minus 1, and notice 2 minus 1 is the first power, and we have exactly one 0.6 here. so i figured it was n minus 1 because when n is 2, we have one 0.6, when n is 3, we have two 0.6's multiplied by themselves. when n is 4, we have 0.6 to the third power. so whatever n is, we're taking 0.6 to the n minus 1 power, and of course we're multiplying that times 120. now and the question they also ask us, what will be the rope stretch on the 12th bounce? and over here i'm going to use the calculator. and actually let me correct this a little bit. this isn't incorrect, but they're talking about the bounce, and we could call the jump the zeroth bounce. let me change that. this isn't wrong, but i think this is where they're going with the problem. so you can view the initial stretch as the zeroth bounce. so instead of labeling it jump, let me label it bounce. so the initial stretch is the zeroth bounce, then this would be the first bounce, the second bounce, the third bounce. and then our formula becomes a lot simpler. because if you said the stretch on nth bounce, then the formula just becomes 0.6 to the n times 120, right? on the zeroth bounce, that was our original stretch, you get 0.6 to the 0, that's 1 times 120. on the first bounce, 0.6 to the 1, one 0.6 right here. 0.6 times the previous stretch, or the previous bounce. so this has it in terms of bounces, which i think is what the questioner wants us to do. so what about the 12th bounce? using this convention right there. so if we do the 12th bounce, let's just get our calculator out. we're going to have 120 times 0.6 to the 12th power. and hopefully we'll get order of operations right, because exponents take precedence over multiplication, so it'll just take the 0.6 to the 12th power only. and so this is equal to 0.26 feet. so after your 12th bounce, she's going to be barely moving. she's going to be moving about 3 inches on that 12th bounce. well, hopefully you found this helpful. and i apologize for the slight divergence here, but i actually think on some level that's instructive. because you always have to make sure that your n matches well with what your results are. so when i talked about your first jump, i said, ok this is 1. and then i had 0.6 to the zeroth power, so i did n minus 1. but then when i relabeled things in terms of bounces, this was the zeroth bounce. this makes sense that this is 0.6 to the zeroth power. this is the first bounce, so this would be 0.6 to the first power. second bounce, 0.6 to the second power. it made our equation a little bit simpler. anyway, hopefully you found that interesting.",t_f648c6f32fd5,other,0
c_309f3fb267f3,"sal finishes the explanation of how a commutator will allow a loop of wire to continue spinning in a magnetic field, thereby allowing it to work as an electric motor.  so where i had left off is we had the circuit. we had these little leads here. this was kind of our innovation. and this is actually called a commutator, where this part that's connected to our rotating piece, that's the commutator. and these are the brushes. so you could imagine, you could design them as brushes that always stay in touch. kind of like the brushes on a, what was that? what are those cars at the amusement park? bumper cars, right? on the bumper cars you have a pole behind your bumper car. i'll draw that for fun. so let's say this is your bumper car. looks like a shoe a little bit. this is you driving your bumper car. and they have a pole. and at the top of the pole, you'll see these brushes that are touching the ceiling, right? you could view that as the same type of brush. and what it allows is a constant electric current to flow through the ceiling. i don't know what direction it's going in. but it allows a current to flow through the ceiling. and maybe your car is grounded so the current can flow down to ground, so that your car could be powered by the ceiling and not have to carry a battery in every car. which would be kind of a waste of energy and probably some type of a health hazard and safety risk, et cetera, et cetera. so those brushes on your bumper cars might not be all that different from the brushes that are touching the commutators here. just a little bit of terminology. and it never hurts to introduce bumper car references. i probably should have done them earlier when we were learning about momentum and things. but anyway. so what was happening here? so going back to our first video. we have the current going down like this. and then if you use your right hand rule with the cross product, you know that the net force from the magnetic field is going to be downwards on the left hand side, upward on the right hand side. so you have a net torque rotating it like that. rotating the right out of the page, the left into the page or into the video screen. up to the point that you've rotated 90 degrees and now you're looking kind of, so this side right here. let me do it in a different color so you can see it. this side is this side, right on top. and this side is on the bottom, below the page. this side is now above the page. if this distance is r, this side is now r units above the page. and i said ideally maybe your commutator loses touch with the brushes at this point, right? because they're popping out a little bit, so when you're vertical, you actually lose touch with the brushes. so you have no circuit flowing, so you save a little battery energy. and you just let a little bit of the angular momentum carry this whole rotating contraption further a little bit to the point that your configuration will look like this. so i know i keep changing colors, but the whole contraption will now look like this. ok, that's my positive, negative, positive, negative, current flows like this. now we assume that the commutator has gotten back in touch. and let me color code this. so if this side is this color, right? now this is when we're looking at top on, where it's popping out of the screen, where it's above the screen. and now we've rotated 180 degrees and this side is on this side, right? let me pick a suitable color. if this side was green. now this side, we flip the whole thing over 180 degrees. and now something interesting happens. remember, before we had this commutator and everything, if we just flipped it over, the current, because before when we didn't have the commutator, the current here was flowing down here, up here. and before the commutator, we had the current flowing down here and up here. and so we were switching directions. and so you would have had this thing that would never completely rotate. it would just keep flipping over, right? which may be useful for, i don't know, if you wanted to flip things. but it's not useful as a motor. so what happens here? now this side, all of a sudden instead of being connected to this lead, is now connected to this lead. and this green side is now connected to this lead. so something interesting happens. now the current on the left side is still flowing down, right, and the current on the right side is still flowing up. so we're back to this configuration except that this contraption has flipped over. the brown side is now on the left and the green side is now on the right. and what that allows is that those net torques are still going in that same rotational direction. use your right hand rule. the current is flowing down here. so if your magnetic field is coming to the left, then the net force is going to be down there and it's going to be up there. and so we can continue indefinite, and we solve our other problem. that we will never keep twisting these wires here. so now using the commutator, we have essentially created an electric motor. and remember i drew that little thing, that could be like the axle. maybe that turns the wheels or something. so if you have a constant magnetic field and you just by using this commutator which, as soon as you get to that kind of vertical point, it cuts the current, and then when you go a little bit past vertical, a little bit past 90 degrees, it switches the direction of the current. so on the left hand side you always have the current coming down, and on the right hand side you always have the current going up. so that the net torque is always going to be pushing, is always going to be rotating this contraption down on the left hand side and up on the right hand side. coming out of the page on the right hand side and then down on the left hand side. and you could actually turn a wheel now. you could create an electric car. so that is the basics really of how electric motors are created. well, there's another way you could have done it. you didn't have to use the commutator. one methodology you could have used is you could have had the magnetic field going until you get to this point, and then you turn off the magnetic field, right? and maybe you wait for this situation to go all the way 180 degrees and then you turn the magnetic field back on again, right? that's one possibility. but that's maybe not as efficient cause half of the cycle you're not powering it. or maybe you switch the direction of the magnetic field. or another option, you don't have to use a commutator. maybe you use some other contraption to switch the direction of the magnetic field. but this is probably the simplest way to do it. and i think it gives you a general idea of how an electric motor can be created. and then we could play around with the mechanics of innovations on it. but all electric motors are essentially some variation of what you have learned in this video. isn't it neat to learn something useful? see you in the next video.",t_ea422379608e,other,0
c_4034e7333723,"we need the sum of all the fractions to equal the given fraction. can you help us choose which ones to use?we're asked to select which fractions add together to make 25 over 22, or 25/22. you can use as many fractions as you need. put all unused fractions into the trash can. so let's think about how we could do this. so i actually want to use the largest fraction first, just so i can get pretty close. so i'm going to make 16/22. and let's see, if i add 8/22 to that, then that's going to get me to--let's see, 16 plus 8, that gets me to 24/22. this is 16/22 plus 8/22 is going to get me 24/22. and if i get one more, that gets me to 25/22. and then i could put these unused ones down here in the trash can. so i'm going to put these unused ones down here. and let's actually check our answer. got it right. and there's multiple ways that we could have actually done this. actually, it's not clear that there's multiple ways that we could have done this. let's see-- is there any other way? yeah, because even if we did the 2 and the 4 here, we would have to get to-- let's see, 8 would get us to-- this is 2/22 plus 4/22 is 6/22, plus 8/22 is going to be 14/22, yeah. and then if you put 16/22, there's going to be too many. so actually, the way we did it was the way that you've got to do it. so the 2 and the 4 i'm going to put in the trash can. and 16 of something plus 1 of something plus 8 of something is going to be 25 of that something. and in this case, the something that we're talking about are 22nds.",t_6fd43d696481,other,0
c_3034f1968855,"liquid crystals are characterised by their high orientational and low positional molecular order.  molecules capable of forming liquid crystals are always anisotropic – typically they will be calamitic (rod-shaped).  there are three types of calamitic liquid crystal: nematic, smectic and chiral nematic. they are defined by their differing degrees of positional order.  the degree of orientational order of a liquid crystal can be quantified using the \[\text { order parameter } q=\left(3\left\langle\cos ^{2} \theta\right\rangle-1\right) / 2\]orderparameterq=(3⟨cos2θ⟩−1)/2  defects in liquid crystals are given the name disclinations. each type of disclination is assigned a positive or negative number; the magnitude indicates its strength whilst the sign indicates which disclinations can cancel each other out.  disclinations can be viewed directly by polarised light microscopy. for example, in a nematic they appear as schlieren brushes.  liquid crystals also exhibit birefringence when viewed through crossed polars.  the most common modern commercial use of liquid crystals is in liquid crystal displays.  going further  books  peter j. collings &amp; michael hird, introduction to liquid crystals: chemistry and physics, taylor &amp; francis, 1997.  peter j. collings, liquid crystals: nature’s delicate phase of matter, 2nd edition, princeton university press, 2002.  websites  liquid crystals: a simple view on a complex matter     a presentation covering the different liquid crystalline mesophases and their appearance under polarised light microscopy.  plc virtual textbook     contains an introduction to liquid crystals and their phase transitions, including virtual experiments.  the basics about liquid crystals     a tutorial created by the liquid crystal and photonics group of ghent university, belgium.  liquid crystal disclinations seen through cross-polars (http://www.chem.reading.ac.uk/dept/staff/phys/ams/crosspolars.html)     a simulation of the movement of schlieren brushes for different types of disclination in a nematic liquid crystal.  introduction to anisotropy (https://www.doitpoms.ac.uk/tlplib/anisotropy/)     a doitpoms tlp describing the anisotropy found in liquid crystals and other materials in further detail.",t_eb34e6116499,other,0
c_9d04f638b64c,"housing costs are usually your biggest expense, so it's easy to get overextended. determine how much rent you can afford and how to plan for additional renting expenses. content brought to you by our partner, better money habits®. the material provided on this video is for informational use only and is not intended for financial or investment advice. bank of america and/or its affiliates assume noso you’re thinking about renting your own place. there are lots of decisions to make, like how close do you want to be to work or to your friends, or to your family? how much space do you need? are you going to live alone or with roommates? once you have a sense of where you want to live and how you want to live, it’s time to start thinking about what renting a place will actually cost you and what you can afford. now, the two biggest costs you’ll have are going to be your monthly expenses and your move-in costs. to start, you’ll want to figure out your monthly expenses, which will help you determine what you can afford to rent. then we’ll take a look at what your move-in expenses might be in another video. so first you need to decide what your budget will be. a decent guideline for figuring out what you can afford is something called the “thirty percent rule.” basically, you take thirty percent of your gross income – that is, your entire income, before taxes — and allocate that to your general housing expenses – that’s not just the rent, it’s also your utilities, insurance and other costs associated with your home. it is set at thirty percent so you can still have some money left over to cover your other expenses and hopefully even save something while you’re at it. now, everyone’s situation is different. for instance, if you have student loans or credit card debt to pay off, you might want to spend less on your housing. or, if you live in a city where rents are higher, you might be able to afford more because you can use public transportation and won’t have the typical costs that come with a car. but for this example, let’s stick to thirty percent. so, say we’re looking at an annual salary of forty thousand dollars. in this case, your budget will be forty thousand times point three, divided by twelve is one thousand per month. now, this doesn’t mean you are going to go right out and look at rentals listed at a thousand a month— or that really nice place you see for $1,050. first, let’s think about some other monthly expenses you’ll have in addition to your rent. the biggest monthly expenses you’re probably going to have are utilities. that’s your electric, gas, oil, or other fuels, water, and sewer bills. in some cases the landlord pays for some utilities, but not others. what you’re responsible for and what the landlord is responsible for should be spelled out in the lease. electric bills can vary dramatically. the price of electricity fluctuates throughout the year, or even the time of day. but, for this exercise, let’s say this averages out to ninety dollars a month over the course of a year. your fuel bill (typically your gas or oil) can also vary dramatically throughout the year— but for now, we’ll estimate it to be about ninety dollars a month as well. and if you have to pay for water, that bill might be around thirty dollars a month. you might also want to think about getting renter’s insurance. if there’s a fire, a bad leak, or a burglary, rental insurance can cover the cost of your belongings, and it can be as little as fifteen dollars a month. keep in mind, these are all general estimates— your local utility or insurance companies are usually the most accurate source for this information if you want to figure it out yourself. and, these are just a few of the basic monthly costs you might encounter with a rental. you might run into extra charges for other amenities as well. and again, depending on the lease agreement, you could even be responsible for additional things — like home repairs. in any case, adding this up gives us a total of two twenty five for general housing expenses. so, we want to take this and subtract it from the original budget of one thousand, which leaves seven hundred seventy five dollars for rent, which may or may not be enough. if it’s too low, one possibility would be splitting your housing expenses with roommates, leaving you more to spend on rent. so, you can see there are a variety of expenses you may want to think about in addition to the rent.",t_187e89c06266,other,0
c_81cd49e6d091,"we are ﬁnally moving into the modeling and analysis of complex systems. the number of variables involved in a model will jump drastically from just a few to tens of thousands! what happens if you have so many dynamical components, and moreover, if those components interact with each other in nontrivial ways? this is the core question of complex systems. key concepts of complex systems, such as emergence and self-organization, all stem from the fact that a system is made of a massive amount of interactive components, which allows us to study its properties at various scales and how those properties are linked across scales.  modeling and simulating systems made of a large number of variables pose some practical challenges. first, we need to know how to specify the dynamical states of so many variables and their interaction pathways, and how those  interactions affect the states of the variables over time. if you have empirical data for all of these aspects, lucky you— you could just use them to build a fairly detailed model (which might not be so useful without proper abstraction, by the way). however, such detailed information may not be readily available, and if that is the case, you have to come up with some reasonable assumptions to make your modeling effort feasible. the modeling frameworks we will discuss in the following chapters (cellular automata, continuous ﬁeld models, network models, and agent-based models) are, in some sense, the fruit that came out of researchers’ collective effort to come up with “best practices” in modeling complex systems, especially with the lack of detailed information available (at least at the time when those frameworks were developed). it is therefore important for you to know explicit/implicit model assumptions and limitations of each modeling framework and how you can go beyond them to develop your own modeling framework in both critical and creative ways.  another practical challenge in complex systems modeling and simulation is visualization of the simulation results. for systems made of a few variables, there are straightforward ways to visualize their dynamical behaviors, such as simple time series plots, phase space plots, cobweb plots, etc., which we discussed in the earlier chapters. when the number of variables is far greater, however, the same approaches won’t work. you can’t discern thousands of time series plots, or you can’t draw a phase space of one thousand dimensions. a typical way to address this difﬁculty is to deﬁne and use a metric of some global characteristics of the system, such as the average state of the system, and then plot its behavior. this is a reasonable approach by all means, but it loses a lot of information about the system’s actual state.  an alternative approach is to visualize the system’s state at each time point in detail, and then animate it over time, so that you can see the behavior of the system without losing information about the details of its states. this approach is particularly effective if the simulation is interactive, i.e., if the simulation results are visualized on the ﬂy as you operate the simulator. in fact, most complex systems simulation tools (e.g., netlogo, repast) adopt such interactive simulation as their default mode of operation. it is a great way to explore the system’s behaviors and become “experienced” with various dynamics of complex systems.",t_a1ea2e451286,other,0
c_fd187bf52ec8,"angelo talks about his work and compensation as a commercial airline pilot and other opportunities in the field.  my name is angelo bautista. i'm 29 years old. i'm a commercial airline pilot. i work for compass airlines, and they contract with delta and american airlines, and we fly their smaller planes, and their shorter routes to the hub of los angeles international airport. my number one responsibility as a captain of the airplane is safety. when i walk in the aircraft i check the maintenance log book and make sure the aircraft is air worthy. i check the weather, i check the flight plan and the fuel planning to our destination. i am also responsible for an on-time departure. with that being said, i have to communicate with a gate agent, the dispatcher, air traffic controller, ground crew members, flight attendants, and my first officer to keep everybody in the loop to make sure we push out on time. if there's any weather delays i make sure i promptly advise the gate agents and the air traffic controller, and also the passengers so they can be in the loop and be advised. my final responsibility is flying the airplane. once the doors are closed i actually make an announcement to the passengers to introducing myself and my crew, giving them an expectation of the flight, if it's gonna be smooth or pretty bumpy. i also give them an estimated time of arrival so they know if we're gonna be late or on time or early. the commercial airplane pilot makes roughly around 15,000 to up to $250,000 a year. the reason why there's wide spread for that is when you're starting off in the airline business you start off on a small airplane getting paid less, right and then you work your way up to be a captain of a large aircraft for international flights, and that's where you get the paid the big bucks of 250,000 a year. i roughly make about 90,000 a year, and in my position as a regional airline captain that's pretty average. benefits and perks of a commercial airline pilot is flight benefits. i can have my parents and my girlfriend fly for free anywhere in the us and anywhere international where a us carrier flies to, anywhere, anytime as long as there's a seat available. other benefits i get as a commercial airline pilot, i get 401k, medical benefit, dental benefits and life insurance. a typical day for me is arriving at the gate 45 minutes early. sometimes it's the mornings, sometimes it's the afternoon. it just depends on what schedule i was awarded with. i meet with the flight crew, with the first officer and two flight attendants and usually i have never flown with them before. and the reason behind that is i have a new crew every single time i fly in a series of flights. it could be a day trip meaning we go to los angeles and go to dallas and back. or i go to los angeles and we have five days worth of flying and we don't come back to los angeles until the fifth day. some of the traits that you have to have in order to be a successful pilot i think you have to have good judgment. also, you are stuck in the cockpit with somebody for an extended amount of time. you are flying with the flight attendants for extended amount of days, and i think you should be able to work as a team to solve problems, think on your feet, and fly the aircraft safely from point a to point b.",t_27fccf7b9cf6,other,0
c_2fdeb4624452,"[m0124_inductance_of_a_straight_coil]  in this section, we determine the inductance of a straight coil, as shown in figure [m0124_fcoil]. the coil is circular with radius \(a\) and length \(l\) and consists of \(n\) windings of wire wound with uniform winding density. also, we assume the winding density \(n/l\) is large enough that magnetic field lines cannot enter or exit between windings but rather must traverse the entire length of the coil. since the coil forms a cylinder, the problem is easiest to work in cylindrical coordinates with the axis of the coil aligned along the \(z\) axis.  inductance \(l\) in this case is given by (section [m0123_inductance]) \[l = \frac{n\phi}{i} \label{m0124_eldef}\] where \(i\) is current and \(\phi\) is the magnetic flux associated with one winding of the coil. magnetic flux in this case is given by \[\phi = \int_{\mathcal s}{\bf b}\cdot d{\bf s}\] where \({\bf b}\) is the magnetic flux density (units of t = wb/m\(^2\)), \({\mathcal s}\) is the surface bounded by a single current loop, and \(d{\bf s}\) points in the direction determined by the right hand rule with respect to the direction of positive current flow.  first, let’s determine the magnetic field. the magnetic flux density deep inside the coil is (section [m0120_magnetic_field_of_a_coil]): \[{\bf b} \approx \hat{\bf z}\frac{\mu ni}{l}  \label{m0124_ebapprox}\] is it reasonable to use this approximation here? since inductance pertains to energy storage, the question is really what fraction of the energy is stored in a field that is well-described by this approximation, as opposed to energy stored in the “fringing field” close to the ends of the coil. if we make \(l\) sufficiently large relative to \(a\), then presumably energy storage in the fringing field will be negligible in comparison. since the alternative leads to a much more complicated problem, we shall assume that equation [m0124_ebapprox] is valid for the interior of the coil.  next, we determine \(\phi\). in this case, a natural choice for \({\mathcal s}\) is the interior cross-section of the coil in a plane perpendicular to the axis. the direction of \(d{\bf s}\) must be \(+\hat{\bf z}\) since this is the direction in which the fingers of the right hand point when the current flows in the direction indicated in figure [m0124_fcoil]. thus, we have where \(a\) is the cross-sectional area of the coil.  finally from equation [m0124_eldef] we obtain \[\boxed{ l \approx \frac{\mu n^2 a}{l} ~~(l\gg a) } \label{m0124_ellsc}\] note that this is dimensionally correct; that is, permeability (units of h/m) times area (units of m\(^2\)) divided by length (units of m) gives units of h, as expected. also, it is worth noting that inductance is proportional to permeability and cross-sectional area, and inversely proportional to length. interestingly the inductance is proportional to \(n^2\) as opposed to \(n\); this is because field strength increases with \(n\), and independently there are \(n\) flux linkages. finally, we note that the inductance does not depend on the shape of the coil cross-section, but only on the area of the cross-section. summarizing:  the inductance of a long straight coil is given approximately by equation [m0124_ellsc].  again, this result is approximate because it neglects the non-uniform fringing field near the ends of the coil and the possibility that magnetic field lines escape between windings due to inadequate winding density. nevertheless, this result facilitates useful engineering analysis and design.  additional reading:  “inductance (https://en.wikipedia.org/wiki/inductance)” on wikipedia.",t_fac0f996b235,other,0
c_48e5adf40abe,"how electronegativity influences chemical shift in proton nmr.  - [voiceover] if we look at methane we have four equivalent protons, so we would expect one signal on an nmr spectrum, and here's the signal for the protons on methane. so this signal occurs at approximately one part per million. and remember from the first few videos on proton nmr, what that signal is talking about. it's talking about the energy difference between the alpha and the beta spin states. so if this is the alpha spin state and this is the beta spin state, there's an energy difference between those two spin states, right? and this energy difference corresponds to a frequency because e is equal to h nu. and the energy difference also corresponds to the effective magnetic field felt by a proton. so if i draw in a magnetic field here, right. so the effective magnetic field, right, controls the energy difference. so let's think about this. if i have a certain effective magnetic field, i get a certain difference in energy between the alpha and the beta spin states. the energy corresponds to a frequency that's absorbed and so this signal is a certain frequency. we said before this is a lower frequency. this is a lower frequency signal right here, so this is a lower frequency signal, and in an earlier video, we talked about how to compare frequency to chemical shift. so a low frequency gives a low chemical shift. so one is a low chemical shift, here. and so the protons in methane are shielded compared to the protons in chloromethane. so let's look at chloromethane next, down here. so for chloromethane, we have three equivalent protons, so one signal on our nmr spectrum and this signal occurs just past three, so approximately three point one parts per million. and let's see if we can understand why this occurs. so, we now have an electronegative atom, right? chlorine is much more electronegative than carbon so chlorine is going to withdraw some electron density, and so the chlorine gets partially negative. we give the carbon a partial positive, here. so the chlorine's withdrawing electron density from these protons. so, these protons are deshielded from the applied magnetic field. all right, so here we have deshielded protons. so deshielding protons, right? if the protons are deshielded from the applied magnetic field, that means those protons experience a greater effective magnetic field. let me go ahead and draw this in. i'm just going to exaggerate to get the point across. so, a greater effective magnetic field for a proton means a greater difference in energy between your alpha and your beta spin states. so, the alpha and beta spin states here. now, since we have a deshielded proton, right? we have a greater difference in energy between our spin states and energy corresponds to frequency, so a greater effective magnetic field means a greater energy difference which means a larger frequency, right? so a higher frequency absorbed. and so this, right, this would be a higher frequency compared to the previous example. so everything is relative here. so a higher frequency signal compared to the protons in methane. and therefore, we get a higher value for the chemical shift. so let's just sum this up really quickly. so, a shielded protons, right, are gonna give you a lower frequency signal and therefore a lower value for the chemical shift. a deshielded proton is going to give you a higher frequency signal and a higher chemical shift. all right, so once again, just comparing these two things, that's what electronegativity does, right? so the more, here we have an electronegative atom that's deshielding the protons, giving a higher chemical shift. so that's the idea and let's apply this to a chart that has a bunch of different functional groups, here. and let's think about the different chemical shifts for protons in different environments. all right, so we just said that if you deshield a proton, right, you're gonna get a higher frequency signal and therefore a higher chemical shift, and this is called downfield. so the left side of this nmr spectrum, right, these are more deshielded protons. to the right side of the nmr spectrum, we're talking about more shielded protons. therefore, a lower frequency signal, therefore a lower chemical shift and you could use the older term, upfield, if you wanted to as well. so we just talked about methane, all right, so we're talking about an alkane type environment, here. so the proton on a carbon in an alkane type environment, the chemical shift, this is a shielded proton, right? so we would expect a low frequency signal or a low chemical shift, so somewhere in the range of point five to two is where we would expect the signal for a proton in an alkane type environment, so somewhere in that range. all right, so those are more shielded. next, we talked about chloromethane, right? and chloromethane we had an electronegative atom on a carbon that was bonded to our proton. so that's this situation. let me use that, i'm gonna use yellow for this. so here we have y is an electronegative atom, so you could think about something like chlorine or fluorine, so a halogen, or you could think about oxygen, also electronegative, right? so if y is an electronegative atom, y withdraws electron density from this carbon and that deshields this proton that's directly on that carbon. so deshielding the proton gives you a higher chemical shift, and so you'd expect this shift to be approximately two point five to four point five. so if you see a signal in the two point five to four point five range, right, it could be a proton that's on a carbon that's directly bonded to an electronegative atom, like a halogen or like oxygen. all right, so in between those two examples. so the signal for this proton right here, this proton would show up approximately two to two point five and so this proton is directly bonded to a carbon, but this carbon is not directly bonded to an electronegative atom. but it is bonded to this carbon, which is a carbonyl, here. so this oxygen, right, is more electronegative. this oxygen withdraws some electron density, but not quite as much as in this example with this electronegative atom directly on this carbon and so the signal, the chemical shift is in between here. so a proton that's on a carbon that's next to a carbonyl look for that approximately two to two point five. again, all of these are just approximate ranges here. so i try to give nice, easy numbers to remember. next, let's look at the proton on an alcohol. so, right here. well, alcohols have hydrogen bonding and hydrogen bonding has a deshielding effect. so increased hydrogen bonding, increased deshielding. the problem is, the amount of hydrogen bonding depends on things like concentration and temperature and since those things can vary, right, you get different amounts of hydrogen bonding. you get different amounts of deshielding. you get a different range, you know, a pretty broad range here for your possible signals. so, approximately two to five for the signal on an alcohol, but it might not even be in that range, so just think about two to five for the proton on an alcohol as an approximate region. next, let's look at the proton on a double bond, here. so, proton, right, bonded to a carbon. proton on a double bond, the shift is approximately four point five to six point five. so let's see if we can understand why. one way to think about it is using electronegativity and so if we think about this carbon here, this carbon is s p two hybridized and if we compare that carbon to this carbon, this carbon is s p three hybridized. remember from hybridization videos that an s p two hybrid orbital has more s character than an s p three hybridized orbital. therefore, the electrons are held closer to the nucleus. so you can say that an s p two hybridized carbon is more electronegative than an s p three hybridized carbon. so if you wanna think about it that way, that's one way to think about it. and so, this s p two hybridized carbon is withdrawing more electron density from this proton. let me use a different color, here. so this s p two hybridized carbon is withdrawing more electron density, deshielding this proton and giving you a higher chemical shift than for a proton bonded to an s p three hybridized carbon. so that's one way to explain this, but it doesn't, that line of reasoning isn't exactly, doesn't hold up completely because if we next look at a proton on a triple bond, here. so if i draw a triple bond and this proton right here. so, you might think, okay, well, this carbon is s p hybridized and i know that s p hybridized carbon, an s p hybridized orbital has even more s character than an s p two hybridized orbital, so therefore, you can think about an s p hybridized carbon being more electronegative and these electrons are closer to this carbon. and so you might think, oh, that's going to deshield, right, that's going to deshield this proton and we would expect a signal that's an even higher chemical shift than for this proton. and that's not what we observe. so, the proton on a triple bond actually this shows up somewhere in this range, so somewhere around two to two point five approximately. and so it's not just electronegativity that you have to think about. so there's another effect that's causing the chemical shift for this proton that we'll talk about in the next video. and it's the same thing, it's actually the same thing for the proton on a benzene ring. so, we'll save that discussion for the next video. so we'll talk about this and we'll talk about this in the next video. if we move on to an aldehyde, right, so for an aldehyde we have this carbonyl here, the oxygen's withdrawing electron density, right, away from the proton on the aldehyde and so it's deshielding that proton, right, therefore, we'd expect the signal for that proton to occur at a higher chemical shift. so, somewhere around nine to ten is where we'd expect the shift for this proton. finally, let's look at a carboxylic acid. so, the signal for this proton, approximately ten to 12. so once again, we have this carbonyl here withdrawing electron density. we have another oxygen here withdrawing some electron density, so you could think about electronegativity effects, you could also think about resonance effects and you could also think about, there's some hydrogen bonding effects. so there's all kinds of things going on here with the carboxylic acid and pretty much, if you're just looking in the ten to 12 region and you see a signal, think the proton on a carboxylic acid.",t_7f51e2a3388e,other,0
c_bb410294c599,"as noted in section 2.5, magnetic fields arise in the presence of moving charge (i.e., current) and in the presence of certain materials. in this section, we address these “magnetic materials.”  a magnetic material may be defined as a substance that exhibits permeability \(\mu\) (section 2.6) that is significantly different from the permeability of free space \(\mu_0\). since the magnetic flux density \({\bf b}\) is related to the magnetic field intensity \({\bf h}\) via \({\bf b}=\mu{\bf h}\), magnetic materials may exhibit magnetic flux density in response to a given magnetic field intensity that is significantly greater than that of other materials. magnetic materials are also said to be “magnetizable,” meaning that the application of a magnetic field causes the material itself to become a source of the magnetic field.  magnetic media are typically metals, semiconductors, or heterogeneous media containing such materials. an example is ferrite, which consists of iron particles suspended in a ceramic. magnetic media are commonly classified according to the physical mechanism responsible for their magnetizability. these mechanisms include paramagnetism, diamagnetism, and ferromagnetism. all three of these mechanisms involve quantum mechanical processes operating at the atomic and subatomic level, and are not well-explained by classical physics. these processes are beyond the scope of this book (but information is available via “additional references” at the end of this section). however, it is possible to identify some readily-observable differences between these categories of magnetic media.  paramagnetic and diamagnetic materials exhibit permeability that is only very slightly different than \(\mu_0\) and typically by much less than 0.01%. these materials exhibit very weak and temporary magnetization. the principal distinction between paramagnetic and diamagnetic media is in the persistence and orientation of induced magnetic fields. paramagnetic materials – including aluminum, magnesium, and platinum – exhibit a very weak persistent magnetic field, and the magnetic field induced in the material is aligned in the same direction as the impressed (external) magnetic field. diamagnetic materials – including copper, gold, and silicon – do not exhibit a persistent magnetic field, and the magnetic field induced in the material is (counter to intuition!) aligned in the opposite direction as the impressed magnetic field. the magnetization of paramagnetic and diamagnetic media is typically so weak that it is not often a consideration in engineering analysis and design.  paramagnetic and diamagnetic media exhibit permeability only very slightly different than that of free space, with little or no magnetization.  ferromagnetic materials, on the other hand, exhibit permeability that can be many orders of magnitude greater than \(\mu_0\). (see appendix a.2 for some example values.) these materials can be readily and indefinitely magnetized, thus, permanent magnets are typically comprised of ferromagnetic materials. commonly-encountered ferromagnetic materials include iron, nickel, and cobalt.  ferromagnetic materials are significantly non-linear (see definition in section 2.8), exhibiting saturation and hysteresis. this is illustrated in figure \(\pageindex{1}\). in this plot, the origin represents a ferromagnetic material that is unmagnetized and in a region free of an external magnetic field. the external magnetic field is quantified in terms of \({\bf h}\), plotted along the horizontal axis. as the external field is increased, so to is \({\bf b}\) in the material, according to the relationship \({\bf b}=\mu{\bf h}\). right away we see the material is non-linear, since the slope of the curve – and hence \(\mu\) – is not constant.  figure \(\pageindex{1}\): non-linearity in a ferromagnetic material manifesting as saturation and hysteresis. ((modified) cc by sa 3.0 (https://creativecommons.org/licenses/by-sa/3.0/deed.en); ndthe)  once the external magnetizing field \({\bf h}\) exceeds a certain value, the response field \({\bf b}\) no longer significantly increases. this is saturation. once saturated, further increases in the external field result do not significantly increase the magnetization of the material, so there is no significant increase in \({\bf b}\).  from this state of saturation, let us now reduce the external field. we find that the rate of decrease in \({\bf b}\) with respect to \({\bf h}\) is significantly less than the rate that \({\bf b}\) originally increased with respect to \({\bf h}\). in fact, \({\bf b}\) is still greater than zero even when \({\bf h}\) has been reduced to zero. at this point, the magnetization of the material is obvious, and a device comprised of this material could be used as a magnet.  if we now apply an external field in the reverse direction, we find that we are eventually able to zero and then redirect the response field. as we continue to decrease \({\bf h}\) (that is, increase the magnitude in the reverse direction), we once again reach saturation.  the same behavior is observed when we once again increase \({\bf h}\). the material is eventually demagnetized, remagnetized in the opposite direction and then saturated in that direction. at this point, it is apparent that a return to the start condition (\({\bf h}={\bf b}=0\); i.e., demagnetized when there is no external field) is not possible.  hysteresis is the name that we apply to this particular form of non-linear behavior. hysteresis has important implications in engineering applications. first, as identified above, it is an important consideration in the analysis and design of magnets. in applications where a ferromagnetic material is being used because high permeability is desired – e.g., in inductors (section 7.12) and transformers (section 8.5) – hysteresis complicates the design and imposes limits on the performance of the device.  hysteresis may also be exploited as a form of memory. this is apparent from figure \(\pageindex{1}\). if \({\bf b}&gt;0\), then recent values of \({\bf h}\) must have been relatively large and positive. similarly, if \({\bf b}&lt;0\), then recent values of \({\bf h}\) must have been relatively large and negative. furthermore, the most recent sign of \({\bf h}\) can be inferred even if the present value of \({\bf h}\) is zero. in this sense, the material “remembers” the past history of its magnetization and thereby exhibits memory. this is the enabling principle for a number of digital data storage devices, including hard drives (see “additional reading” at the end of this section). summarizing:  ferromagnetic media exhibit permeability \(\mu\) that is orders of magnitude greater than that of free space and are readily magnetizable. these materials are also nonlinear in \(\mu\), which manifests as saturation and hysteresis.  contributors and attributions  ellingson, steven w. (2018) electromagnetics, vol. 1. blacksburg, va: vt publishing. https://doi.org/10.21061/electromagnetics-vol-1 (https://doi.org/10.21061/electromagnetics-vol-1) licensed with cc by-sa 4.0 https://creativecommons.org/licenses/by-sa/4.0 (https://creativecommons.org/licenses/by-sa/4.0). report adoption of this book here (http://bit.ly/vtpublishing-updates). if you are a professor reviewing, adopting, or adapting this textbook please help us understand a little more about your use by filling out this form. (http://bit.ly/vtpublishing-updates)",t_3d98af471b7e,other,0
c_2117331c1af8,"check the real-time values of your sensors  when configuring any sensor, it's important to understand how to poll them in real time, which means you grab their current reading and see what it is right inside the software. for example, i could grab any sensor, but i have the rotation sensor here. and now down in the settings, when i click on it and i make sure i select the correct port that the motor is plugged into, over on the left is the live reading window, and for every sensor you will have this. and in this case, it says rotation sensor, and there's a little box, which in real time as i move the motor, it updates with the current reading, which is the number of degrees of rotation. i position the motor in some state, and i can click reset, which zeros the reading. and then i could rotate my motor a certain amount, and then i can check this window to see how many degrees it has rotated. and you can do this for any sensor-- your current light reading, sound reading, et cetera. and if you're not getting a reading in real time and you've double checked your port and connection, what i do is save everything, close the software, and reopen it, and sometimes that will fix the problem.",t_d4dcfc2c85b9,other,0
c_d7853b3248c9,"discussion of the properties of water that make it essential to life as we know it: polarity, ""universal"" solvent, high heat capacity, high heat of vaporization, cohesion, adhesion and lower density when frozen.  - [instructor] when we look out into the cosmos for alien life, many folks look for signs of water on moons or planets. and that's because life as we know it is dependent on water. and to understand that, we just have to take a closer look at some of the properties of water. so what you see here are some molecules of water. this might be a review for you. every water molecule has one oxygen atom. and it is bonded to two hydrogens. so that is a hydrogen, and that is a hydrogen as well. and the nature of that bond, it is a covalent bond, which means that the oxygen shares electrons with each of the hydrogen atoms. but oxygen is more electronegative, and that's just a fancy way of saying that even though those electrons are shared, they're going to be spending more time around the oxygen than around the hydrogens. one way to think about it is oxygen likes to hog electrons more than hydrogen does. and since the electrons will spend more time around the oxygen than around the hydrogen, and because it's a bent molecule with the hydrogens on one side of the molecule, what happens is the side where the oxygen is, where the electrons spend more time, that gets a partially negative charge. so this is the lowercase greek letter delta. that just means partially negative charge. and then the sides where the hydrogens are, those acquire a partial positive charge. and so what you see here is that a water molecule is not charged in aggregate. but either side has a partial charge, so it is a polar molecule. and so you can imagine when you put a bunch of water molecules together what might happen? well, the partially positive side of one water molecule where the hydrogens are would be attracted to the partially negative side of another water molecule. and so they would be attracted, and this is known as a hydrogen, hydrogen, hydrogen bond. and i could keep drawing that. this is going to be partially positive here. this is going to be partially negative. they will attract. this oxygen end is going to be attracted to that hydrogen end. this oxygen end is going to be attracted to the that hydrogen end as well. and so it's this hydrogen bonding that gives water a lot of the properties that make it special that, as far as we know, for harboring life or for even allowing life to be possible. life as we understand it needs a fluid environment. things move around and bump into each other. and it's these hydrogen bonds, when the temperature and conditions are appropriate, that allow water to be in that liquid form where they're strong enough so that the water stays together, but they're weak enough so that they allow the water molecules to flow past each other. and not only does it provide a good fluid environment, it's a very good solvent. water is often known as the universal, universal solvent, but it's worth putting a disclaimer here. even though people say it is a universal solvent, that does not mean that it dissolves everything. water does dissolve more things in its liquid state than anything else we know about. but there are many molecules that it cannot dissolve well. the things that it does dissolve well are polar molecules or things that have a charge. for example, when sodium chloride dissolves in water, a sodium ion is positive, so that is positively charged. and so you can imagine it might be attracted to the side of the water molecules where the oxygen is. but it dissolves well. but things that don't have charge don't tend to dissolve well in water. but even the property that there's certain things that it does not dissolve is also good for life. later on in biology we're going to study phospholipid bilayers where you have these molecules where one end is hydrophilic, which means it's attracted to water molecules. and then the other ends are hydrophobic, which means they're not attracted to water molecules. and many evolutionary biologists believe that this property of having one side that's hydrophilic and one side that's hydrophobic would have allowed these molecules to start collecting into membranes, eventually forming these spherical membranes which could be the containers for early cellular life. now, another property of water which makes it very suitable for life is it's high heat capacity. sometimes you'll hear people say it has a high specific heat. the specific heat is the amount of energy needed to raise one gram of water by one degree celsius. and you might say why does that matter for life? well, many life forms can only operate within a certain range of temperatures. and so if it was really easy to raise the temperature of water really high or very low temperatures very fast, well, that would make it much harder for life to operate within water, or even life to be made up of water. a related idea to this is that water also has a high heat of vaporization. we talk more about this in detail in other videos, but this is talking about how much energy does it take for water to go from its liquid form to its gas form. and this has proven valuable in many life forms for a form of cooling where the vaporization of water, evaporative cooling, can take heat away from an organism so that it doesn't overheat. other properties that are important about water include cohesion and adhesion. cohesion is the property of water molecules that is attracted to other water molecules. and you saw it here with the hydrogen bonds. but then when you look at a macroscale, you'll see things like water droplets form. you've all seen water droplets, or dew droplets. these droplets couldn't form if not for the cohesion of water. and even one drop can be an environment in which thousands of microorganisms can live. adhesion is the property of water where it can adhere to other things. you might have seen this in a glass test tube where it looks like the water is kind of crawling up the top of the sides. and that's because some of the polarity of the glass molecules of the test tube. but this property, along with the cohesion, is what allows water to transport nutrients, say, from the roots of a tree all the way to the top of a tree. these properties are also an action in our own blood vessels, when you get to the really small blood vessels, the capillaries. and that is called capillaries 'cause you have capillary action of water, which is due to its cohesion and its adhesion. a last property of water, and this is not an exhaustive list, is that it is less dense as a solid. so another way to think about it is ice, which is solid water, is less, less dense than liquid water. now, you might be thinking why does that matter for life? well, imagine the environments where we think life first arose. if you imagine some type of a pond, and this is the cross-section of it, if ice was more dense than liquid water, and for many substances that is the case, a solid form tends to be more dense, then what would happen? if it's cold up here in the air, say, in the winter, then this part would freeze. but then as it got more dense it would sink to the bottom right over there. then the next surface water would freeze and sink to the bottom. and then over time, the entire lake or the entire pond would freeze over, and life would not be able to live in that pond. because when water freezes, it breaks membrane-bound structures as we know it. and so that would not be suitable for life. but because ice is less dense than water, what typically happens is just that top layer freezes. and then it'll freeze down as things get colder and colder. but you have an entire environment where life can continue to thrive even when the air is much colder than what is suitable for life. and because of water's high specific heat, that temperature variation in that water is going to be much less than the temperature variation outside of the water, either in the air or on the land. so this is just an introduction, but hopefully it makes you appreciate water a little more. and remember, and i've said this in other videos, we are mostly water. one way to think about it is that each of us is made up of trillions of cells which are primarily made up of water and exist in a water-based environment. they coordinate with each other and eventually have emergent complexity that thinks that it is a sentient being like each of us.",t_511645c364fc,other,0
c_eccdc66a89de,"14.6.1: analysis problems  1. a telephony system has a frequency range from 200 hz to 3.5 khz. determine the minimum acceptable pwm frequency.  2. a background music and paging system has a frequency range from 50 hz to 10 khz. determine the minimum acceptable pwm frequency.  3. determine the maximum rate of change of input voltage for a driver circuit capable of producing 50 ma with a load consisting of a 1.5 nf gate capacitance.  4. determine the maximum rate of change of input voltage for a driver circuit capable of producing 60 ma with a load consisting of a 3.5 nf gate capacitance.  5. a power e-mosfet has an \(r_{ds(on)}\) of 0.012 \(\omega\) and switches a 100 volt source to an 8 \(\omega\) load. determine the maximum load current and \(v_{ds}\).  6. four power e-mosfets drive a 4 \(\omega\) load via a full bridge network. if each device has an \(r_{ds(on)}\) of 0.02 \(\omega\) and they switch \(\pm\)75 volt sources to the load, determine the load current and \(v_{ds}\) of the devices.",t_254a7afea6ed,other,0
c_e004d6e277a3,"meiosis | genetics | biology | fuseschool  there are two types cell division processes:  mitosis & meiosis  the simpler one is mitosis - which produces two identical cells with exactly the same genetic information. you can think of them as clones of each other.  the other process, meiosis, is a much more complicated process creating not two but four cells, with only half the number of chromosomes and crucially all genetically different from each other.   both mitosis and meiosis include the same phases – prophase, metaphase, anaphase, and telophase.  except, in meiosis, they happen twice, so they’re usually referred to as 1 and 2.    the easiest way to remember these phase names is to remember ipmat: interphase, prophase, metaphase, anaphase, telophase.  so let’s look at meiosis in more detail...  as always, cellular division starts with a process called dna replication.   this involves making two identical copies of the original dna molecule.   the cell ends up temporarily with double the normal number of chromosomes.   in prophase i, the duplicated chromosomes join up with the pair from the other parent - so the mother’s pair bind with the father’s pair, forming a group of two chromosomes called ‘homologous’ chromosomes.    as each chromosome is lined-up next to it’s partner pair, one chromatid from each side gets entangled with the corresponding chromatid from the other side. this is called ‘crossing-over’.    during this brief period, the two chromatids swap certain sections of dna. this is called recombination. the sections that they trade correspond to the same location, so that each chromatid retains the correct number of genes.    recombination is really important because it creates variety. the new cells aren’t identical to their parents, and they also are different to one another as well.   there are new genetic combinations.  in fact that’s the whole point of sexual reproduction!!! … to increase genetic variability.   each chromatid is now different, and as each one will end up in a separate gamete, it means each sex cell is genetically different from all others! this explains why brothers and sisters are different despite having the same parents. only identical twins have the same genetic make-up as they both originated from the exact same egg and sperm!  now back to meiosis: next comes metaphase i as the chromosomes align themselves up in the middle of the cell.    in anaphase i, the spindle fibres pull the chromosomes apart, to opposite ends.    then during telophase i and cytokinesis, the cell pinches apart in the middle and the nuclear membrane reforms around the two new daughter cells.  that’s the end of meiosis 1.  we start with our ‘recombined’ daughter cells, each still with 46 chromosomes.   but sperm and eggs cells only have 23 chromosomes, so we need to cut these cells in half...  the process is exactly the same as before, except that there is no dna replication.   we start straight with prophase ii, with chromatin clumping again to form chromosomes. they align in the middle of the cell during metaphase ii, and chromatids are pulled apart during anaphase ii by the spindle fibres. telophase and cytokinesis pinch the cells together, with four new granddaughter cells being formed.  the end of meiosis gives us 4 different sex cells, each with only 23 chromosomes. ready for future fertilisation    ",t_cc793ab0157a,other,0
c_12949a5378e4,"how much a home might appreciate or depreciate is a factor in determining whether the best choice is to rent vs. buy.  welcome back. i now want to play a little bit of devil's advocate with myself. i made this argument where i show that for the exact identical house, if these are the numbers -- i mean you'd have to work it out based on your market, and what the numbers are at the time. but if this is the comparable rent for a $1 million house, i showed you that for the $1 million house you're burning $40,000 a year. this is not money that is going to build equity. this not money that's going to the principal of your house. this is money that just going out of your pocket, you'll never see again. in a way, and actually not in a way, in reality, you can view this $40,000 as rent on the money that you borrowed. interest is nothing but rent. so when you have an asset, if the asset is cash, the rent on it is interest. if the asset is a house, the rent on it is your monthly rent payment. so when you think of it this way, when people say home ownership, they really aren't homeowners yet. you're not a homeowner until you don't have debt. you are a money renter. so your choice is either to be a money renter here, or to be a house renter here. and i show that you are burning almost double the money. but then there's the argument of well, there are advantages, still, to buying this house. and what are they? well one example is, in this situation, if i did get a fixed-rate mortgage -- and we learned, when you look at all those adjustable-rate mortgages, we know that a lot of people didn't. but if i have a fixed-rate mortgage, i know what my payment is for the foreseeable future, for the next 30 years. while my landlord, in this case, they could keep raising my rent. so this might look good right now, but what if my landlord raised the rent to, i don't know, $3,500 a month. well then, out of your pocket, 0.5 times 12, you'd be spending $42,000 a year. and then of course you get the interest from the money that you put in the bank. plus 10. oh, minus 10 actually, sorry. so in that case, if the rent goes up, then out of your pocket is $32,000 every year. right? or what if the interest that you get on your cash in the bank goes down? then this $10,000 thousand will become lower. but as we can see, the rent would have to go up a lot to make up for $41,000, to make this a break-even situation. let's figure out how much it would have to go up. so in this first scenario, in order for your net outflow to be $41,500, assuming you're getting $10,000 from the money in the bank, your rent would have to be $51,500. right? because you're getting $10,000 from the bank. and so divided by 12, your rent would have to be $4,300 in this situation to make this a break-even proposition. this is another way to view it. if i were to buy the house, and if i were to move, how much would i have to rent this house out for, in order to not be losing money every month? well i would have to rent it out for $4,300 a month, even though maybe the market rents are only at $3,000. and there is another devil's advocate argument. and that's, well, housing -- and this is something that you heard a lot about three years ago. and a lot of these people aren't talking as much now. but they would say, housing has never -- housing has done nothing but gone up, and i will build equity just from housing appreciation. so how much does my house have to appreciate every year? well, to make up this difference-- $41,500 minus 26-- so to make up that $15,500 difference every year, this is $15,500 favorable. my house would have to appreciate by a comparable amount, right? so how much appreciation is that on my house? well that's a $1 million house, right? so $15,500 appreciation on a $1 million house. i'm doing everything in thousands, so 1,000 thousands is a million. so that's only 1.5% appreciation. so if my house appreciates by 1.5%, that's it-- 1.5%. if my house just appreciates by 1.5%, i'm going to make up this $15,500. and so it is worth it for me. it is worth it for me to blow this money by having kind of an increased -- by renting the money for more than i would have to pay to rent the house. and that might sound like a very reasonable proposition, that the house will appreciate by 1.5%. from 2001 to 2005, 2006, houses were appreciating like 10%, 15% a year. so it seemed -- and a real estate agent would often do this very math with you, and say, well, you're definitely going to get 1.5%. in fact, you're probably going to get 10% appreciation. and you're going to make much more than this. but think about, in the presentation of the balance sheet and leverage, what happens if housing prices go down by 1.5%? what happens if it's minus 1.5%? well, then you're going to spend this much to rent the money, right? and you're not going to gain this much. you're going to lose this much every year. and so the proposition becomes even worse. so this is a big deal. now that, i think, on a nationwide basis, a lot of the housing indices show that housing prices have gone down, i think by 6%. that's what the case-shiller index says. 6% is a lot. especially on a $1 million house, that's $60,000 a year that's just evaporating. that's wealth that someone thought they had, that's just disappearing out of their equity. so this is rationale of pay more to rent the money for a house than to rent the house is justified if housing prices go up. it becomes 10 times worse when housing prices are flat. or, god forbid, if housing prices actually go down. and now we see that housing prices actually go down. in the last couple of years especially, in the areas where, like the bay area, or florida, or california, especially southern california, where this is happening. and back even two or three years ago, when people used to make this argument. people used to make the argument, well you know, my house just has to go up 1% or 2% percent, and i'm going to make up the difference. i'd say well, why is your house going to go up 1% or 2% percent? i mean, there has to be some reason why next year someone's willing to pay 2% more for that house. is it because rents are going up 2% a year, so the income stream is going to be 2% higher? and actually in the bay area, from 2001 to roughly 2003, rents were going down. and there were actually people moving out. all the tech workers were getting laid off. you had a lot of programming jobs being outsourced to india and wherever else. so you had this whole situation where the population was actually decreasing. demand for housing was going down. but for some reason housing prices were going up. so people said well, they've been going up for the last five years, so they'll continue. and they've never gone down, et cetera, et cetera. but it didn't make an economic argument. and i'll show in a future video that the only reason why housing prices did go up is that it just became easier and easier and easier to buy a house. the standards that banks used for giving out a loan became lower and lower and lower. there are actually examples in southern california, and in san jose and some of the suburbs, where people who had incomes of $30,000 or $40,000 a year. the bank actually gave them a $1 million loan to buy a $1 million house, based on stated income. there's things called stated income loans, where you just tell the bank what you earn. you don't have to prove it to them. and so every year that went by, it just became easier and easier and easier. more and more people just thought that housing always appreciates. so that's why they want to pay more and more to essentially rent the money for a house. and this became a self-fulfilling prophecy. but as we see on the way down, it works completely against you. so in the situation where we are now, where nationwide housing prices are actually declining-- and actually they will decline until this rent-versus-buy equation starts to make a little bit more sense-- it really hurts the home buyer. and what's even worse, and this is kind of adding insult to injury, is that this guy, if i bought this house, and all of a sudden i lose my job, and i can't pay the house back, i might lose my entire $250,000 down payment because maybe i can't sell the house, or the house is selling for less. or maybe i want to move, and there's no one out there who can buy a house because the banks all of a sudden got smart again, and realized that they should become more serious in terms of who they give money to. and so i'm stuck holding this house, and my flexibility in terms of where i can move is limited. actually a friend of mine was telling me that they've actually done studies. and there's a correlation between unemployment and home ownership. because when you own a home, you have less flexibility in looking for a job. if i have a house in san jose but there's a job in la, i might not be able to take that job because i can't sell my house. or i might not even want to look for a job in la. while the renter, of course, my lease ends and i leave. so this is just a rough sense of the rent versus buy. and i know i get very impassioned about this. but that's just because i explain this a lot. and when i'm at parties and i start talking about the calculations, people's eyes glaze over. but i made this video now and i'll just tell people to watch it. see you in the next video.",t_562bdf1296f2,other,0
c_dae7ca2dcad0,"after learning about local linearizations of multivariable functions, the next step is to understand how to approximate a function even more closely with a quadratic approximation.  - [voiceover] in the last couple videos i talked about the local linearization of a function. and in terms of graphs, there's a nice interpretation here where if you imagine a graph of a function and you want to approximate it near a specific point, you picture that point somewhere on the graph, and it doesn't have to be there, you know i can choose to be anywhere else along the graph, but if you have some sort of point and you want to approximate the function near there you can have another function whose graph is just a flat plane, and specifically a plane which is tangent to your original graph at that point. and that's kind of visually how you think about the local linearization. and what i'm going to start doing here in this next video and in the ones following, is talking about quadratic approximations. so quadratic approximations, and these, these basically take these to the next level. and first i'll show what they look like graphically and then i'll show you what it actually means in formulas. but graphically instead of having a plane that's flat, you have a few more parameters to deal with, and you can give yourself some kind of surface that hugs the graph a little bit more closely. it's still going to be simpler in terms of formulas, it can still be notably simpler than the original function, but this actually hugs it closely. and as we move around the point that it's approximating here, the way that it hugs it can look pretty different. and if you want to think graphically what a quadratic approximation is, you can basically say if you slice this surface, this kind of ghostly white surface in any direction it'll look like a parabola of some kind. and notice that given that we're dealing in multiple dimensions that can make things look pretty complicated, like this right here, you know if you slice it kind of in this direction, whoa, if you look at it from this angle it kind of looks like a concave up parabola, but if you were looking at it from another direction it kind of looks concave down, and all-in-all you get a surface that actually has quite a bit of information carried within it. and you can see that by hugging the graph very closely this approximation is going to be, well, it's going to be even closer, because near the point where you're approximating you can go out, you know, you can take a couple steps away and the approximation is still going to be very close to what the graph is, and it's only when you step really far away from the original point that the approximation starts to deviate away from the graph itself. so this is going to be something that although it takes more information to describe than a local linearization it gives us a much closer approximation. so a linear function which, you know, one that just draws a plane like this, in terms of actual function what this means, so kind of a linear, this is going to be some kind of function of x and y, and what it looks like is some kind of constant, which i'll say a plus another constant times the variable x, plus another constant times the variable y, this is sort of the basic form of linear functions. and technically this isn't linear if one is going to be really pedantic and they would say that that's actually affine, because i'm strictly speaking linear functions shouldn't have this constant term, it should be purely x's and y's, but in the context of approximations people would usually call this a linear term. so quadratic term, what this is going to look like, quadratic, we are allowed to have all the same terms as that linear one, so you can have constant, you can have these two linear terms bx and cy, and then you're allowed to have anything that has two variables multiplied into it. so maybe i'll have d times x squared, and then you can also have something times xy, this is considered a quadratic term. which is a little bit weird at first, because usually we think of quadratics as associated with that exponent two, but really it's just saying any time you have two variables multiplied in, and then we can add some other constants, say f times y squared. where, you know, now we're multiplying two y's into it. so all of these guys, these are what you would call your quadratic terms. things that either x squared, y squared, or x times y, anything that has two variables in it. so you can see this gives us a lot more control because previously, as we tweaked the constants a, b, and c, you're able to give yourself, you know, that gives you control over all sorts of planes in space, and if you choose the most optimal one you'll get one that's tangent to your curve at this specific point, and kind of, it'll depend on where that point is, you'll get different planes, but they're all tangent. so what we're going to do in the next couple of videos, is talk about how you tweak all of these six different constants so that you can get functions that really closely hug the curve, right? and as you, and they're all going to depend on the original point because as you move that point around, what it takes to hug the curve is going to be different. it's going to have to do with partial differential information about your original function, the function whose graph this is, and it's going to look pretty similar to the local linearization case, just you know, added complexity so we have to add a few more steps in there. and i'll see you next video talking about that.",t_901441555ae0,other,0
c_5eb0af61185d,in this video you'll learn how to do a handstand in the swimming pool,t_3872e455fc40,other,0
c_7888242d12ed,"in this video, you will learn how to do a reverse crossover when facing a defender in a basketball game. the reverse crossover to do a good reverse crossover, work on these three steps: placing your feet, getting past your opponent and timing the crossover with the hands to do a good reverse crossover, work on these three steps: placing your feet, spinning past your opponent and timing the crossover with the hands first, placing your feet. approach the defender at a dribble. if you're dribbling with your right hand, place your left foot between your opponent's feet. your body should be perpendicular to your opponent, with your left shoulder forward. you need to put as much force as possible into your last dribble before turning so that you keep control of the ball. secondly, getting past your opponent. pivot on your left foot, turning your back on your opponent place your right foot, spinning out of your opponent's reach. thirdly, the crossover. while turning, drive the ball with your right hand to dribble close to your right foot. take the ball in your left hand after the dribble, once you've got past your opponent. this way, you are still protecting the ball by keeping the dribble away from your opponent. remember to keep as low as you can so that you spin faster. accelerate and change direction as soon as you've passed your opponent. if you're dribbling with your left hand, the movement is exactly the same but you'll need to turn the other way, using the opposite feet. practice running the length of the court doing reverse crossovers with both your dominant and your weaker hand. over to you!",t_bd02d77afb8e,other,0
c_1f4597ff621d,"sal finds several trigonometric identities for sine and cosine by considering horizontal and vertical symmetries of the unit circle.  voiceover:let's explore the unit circle a little bit more in depth. let's just start with some angle theta, and for the sake of this video, we'll assume everything is in radians. this angle right over here, we would call this theta. now let's flip this, i guess we could say, the terminal ray of this angle. let's flip it over the x and y-axis. let's just make sure we have labeled our axes. let's flip it over the positive x-axis. if you flip it over the positive x-axis, you just go straight down, and then you go the same distance on the other side. you get to that point right over there, and so you would get this ray. you would get this ray that i'm attempting to draw in blue. you would get that ray right over there. now what is the angle between this ray and the positive x-axis if you start at the positive x-axis? well, just using our conventions that counterclockwise from the x-axis is a positive angle, this is clockwise. instead of going theta above the x-axis, we're going theta below, so we would call this, by our convention, an angle of negative theta. now let's flip our original green ray. let's flip it over the positive y-axis. if you flip it over the positive y-axis, we're going to go from there all the way to right over there then we can draw ourselves a ray. my best attempt at that is right over there. what would be the measure of this angle right over here? what was the measure of that angle in radians? we know if we were to go all the way from the positive x-axis to the negative x-axis, that would be pi radians because that's halfway around the circle. this angle, since we know that that's theta, this is theta right over here, the angle that we want to figure out, this is going to be all the way around. it's going to be pi minus, it's going to be pi minus theta. notice, pi minus theta plus theta, these two are supplementary, and they add up to pi radians or 180 degrees. now let's flip this one over the negative x-axis. if we flip this one over the negative x-axis, you're going to get right over there, and so you're going to get an angle that looks like this, that looks like this. now what is going to be the measure of this angle? if we go all the way around like that, what is the measure of that angle? to go this far is pi, and then you're going another theta. this angle right over here is theta, so you're going pi plus another theta. this whole angle right over here, this whole thing, this whole thing is pi plus theta radians. pi plus theta, let me just write that down. this is pi plus theta. now that we've figured out these have different symmetries about them, let's think about how the sines and cosines of these different angles relate to each other. we already know that this coordinate right over here, that is sine of theta, sorry, the x-coordinate is cosine of theta. the x-coordinate is cosine of theta, and the y-coordinate is sine of theta. or another way of thinking about it is this value on the x-axis is cosine of theta, and this value right over here on the y-axis is sine of theta. now let's think about this one down over here. by the same convention, this point, this is really the unit circle definition of our trig functions. this point, since our angle is negative theta now, this point would be cosine of negative theta, comma, sine of negative theta. and we can apply the same thing over here. this point right over here, the x-coordinate is cosine of pi minus theta. that's what this angle is when we go from the positive x-axis. this is cosine of pi minus theta. and the y-coordinate is the sine of pi minus theta. then we could go all the way around to this point. i think you see where this is going. this is cosine of, i guess we could say theta plus pi or pi plus theta. let's write pi plus data and sine of pi plus theta. now how do these all relate to each other? notice, over here, out here on the right-hand side, our x-coordinates are the exact same value. it's this value right over here. so we know that cosine of theta must be equal to the cosine of negative theta. that's pretty interesting. let's write that down. cosine of theta is equal to ... let me do it in this blue color, is equal to the cosine of negative theta. that's a pretty interesting result. but what about their sines? well, here, the sine of theta is this distance above the x-axis, and here, the sine of negative theta is the same distance below the x-axis, so they're going to be the negatives of each other. we could say that sine of negative theta, sine of negative theta is equal to, is equal to the negative sine of theta, equal to the negative sine of theta. it's the opposite. if you go the same amount above or below the x-axis, you're going to get the negative value for the sine. we could do the same thing over here. how does this one relate to that? these two are going to have the same sine values. the sine of this, the y-coordinate, is the same as the sine of that. we see that this must be equal to that. let's write that down. we get sine of theta is equal to sine of pi minus theta. now let's think about how do the cosines relate. the same argument, they're going to be the opposites of each other, where the x-coordinates are the same distance but on opposite sides of the origin. we get cosine of theta is equal to the negative of the cosine of ... let me do that in same color. actually, let me make sure my colors are right. we get cosine of theta is equal to the negative of the cosine of pi minus theta. now finally, let's think about how this one relates. here, our cosine value, our x-coordinate is the negative, and our sine value is also the negative. we've flipped over both axes. let's write that down. over here, we have sine of theta plus pi, which is the same thing as pi plus theta, is equal to the negative of the sine of theta, and we see that this is sine of theta, this is sine of pi plus theta, or sine of theta plus pi, and we get the cosine of theta plus pi. cosine of theta plus pi is going to be the negative of cosine of theta, is equal to the negative of cosine of theta. even here, and you could see, you could keep going. you could try to relate this one to that one or that one to that one. you can get all sorts of interesting results. i encourage you to really try to think this through on your own and think about how all of these are related to each other based on essentially symmetries or reflections around the x or y-axis.",t_ddc03d1beb6a,other,0
c_1f4597ff621d,"sal finds several trigonometric identities for sine and cosine by considering horizontal and vertical symmetries of the unit circle.  voiceover:let's explore the unit circle a little bit more in depth. let's just start with some angle theta, and for the sake of this video, we'll assume everything is in radians. this angle right over here, we would call this theta. now let's flip this, i guess we could say, the terminal ray of this angle. let's flip it over the x and y-axis. let's just make sure we have labeled our axes. let's flip it over the positive x-axis. if you flip it over the positive x-axis, you just go straight down, and then you go the same distance on the other side. you get to that point right over there, and so you would get this ray. you would get this ray that i'm attempting to draw in blue. you would get that ray right over there. now what is the angle between this ray and the positive x-axis if you start at the positive x-axis? well, just using our conventions that counterclockwise from the x-axis is a positive angle, this is clockwise. instead of going theta above the x-axis, we're going theta below, so we would call this, by our convention, an angle of negative theta. now let's flip our original green ray. let's flip it over the positive y-axis. if you flip it over the positive y-axis, we're going to go from there all the way to right over there then we can draw ourselves a ray. my best attempt at that is right over there. what would be the measure of this angle right over here? what was the measure of that angle in radians? we know if we were to go all the way from the positive x-axis to the negative x-axis, that would be pi radians because that's halfway around the circle. this angle, since we know that that's theta, this is theta right over here, the angle that we want to figure out, this is going to be all the way around. it's going to be pi minus, it's going to be pi minus theta. notice, pi minus theta plus theta, these two are supplementary, and they add up to pi radians or 180 degrees. now let's flip this one over the negative x-axis. if we flip this one over the negative x-axis, you're going to get right over there, and so you're going to get an angle that looks like this, that looks like this. now what is going to be the measure of this angle? if we go all the way around like that, what is the measure of that angle? to go this far is pi, and then you're going another theta. this angle right over here is theta, so you're going pi plus another theta. this whole angle right over here, this whole thing, this whole thing is pi plus theta radians. pi plus theta, let me just write that down. this is pi plus theta. now that we've figured out these have different symmetries about them, let's think about how the sines and cosines of these different angles relate to each other. we already know that this coordinate right over here, that is sine of theta, sorry, the x-coordinate is cosine of theta. the x-coordinate is cosine of theta, and the y-coordinate is sine of theta. or another way of thinking about it is this value on the x-axis is cosine of theta, and this value right over here on the y-axis is sine of theta. now let's think about this one down over here. by the same convention, this point, this is really the unit circle definition of our trig functions. this point, since our angle is negative theta now, this point would be cosine of negative theta, comma, sine of negative theta. and we can apply the same thing over here. this point right over here, the x-coordinate is cosine of pi minus theta. that's what this angle is when we go from the positive x-axis. this is cosine of pi minus theta. and the y-coordinate is the sine of pi minus theta. then we could go all the way around to this point. i think you see where this is going. this is cosine of, i guess we could say theta plus pi or pi plus theta. let's write pi plus data and sine of pi plus theta. now how do these all relate to each other? notice, over here, out here on the right-hand side, our x-coordinates are the exact same value. it's this value right over here. so we know that cosine of theta must be equal to the cosine of negative theta. that's pretty interesting. let's write that down. cosine of theta is equal to ... let me do it in this blue color, is equal to the cosine of negative theta. that's a pretty interesting result. but what about their sines? well, here, the sine of theta is this distance above the x-axis, and here, the sine of negative theta is the same distance below the x-axis, so they're going to be the negatives of each other. we could say that sine of negative theta, sine of negative theta is equal to, is equal to the negative sine of theta, equal to the negative sine of theta. it's the opposite. if you go the same amount above or below the x-axis, you're going to get the negative value for the sine. we could do the same thing over here. how does this one relate to that? these two are going to have the same sine values. the sine of this, the y-coordinate, is the same as the sine of that. we see that this must be equal to that. let's write that down. we get sine of theta is equal to sine of pi minus theta. now let's think about how do the cosines relate. the same argument, they're going to be the opposites of each other, where the x-coordinates are the same distance but on opposite sides of the origin. we get cosine of theta is equal to the negative of the cosine of ... let me do that in same color. actually, let me make sure my colors are right. we get cosine of theta is equal to the negative of the cosine of pi minus theta. now finally, let's think about how this one relates. here, our cosine value, our x-coordinate is the negative, and our sine value is also the negative. we've flipped over both axes. let's write that down. over here, we have sine of theta plus pi, which is the same thing as pi plus theta, is equal to the negative of the sine of theta, and we see that this is sine of theta, this is sine of pi plus theta, or sine of theta plus pi, and we get the cosine of theta plus pi. cosine of theta plus pi is going to be the negative of cosine of theta, is equal to the negative of cosine of theta. even here, and you could see, you could keep going. you could try to relate this one to that one or that one to that one. you can get all sorts of interesting results. i encourage you to really try to think this through on your own and think about how all of these are related to each other based on essentially symmetries or reflections around the x or y-axis.",t_56e1ef0a7182,other,0
c_94e40c7fb546,"nadph is found not only in plants, but in animal cells as well. although our first discussion of nadph was in the context of photosynthesis, it is also a general reducing agent in any cell. it is also crucial to note that though introductory texts often consider nad+/nadh and nadp/nadph similarly as high energy electron carriers, and although they are structurally differentiated only by a phosphate group (on the 2’-oh of adenosine), they are not interchangeable in the metabolic pathways of a cell. nadp/nadph is used in reductive metabolic pathways, whereas nad+/nadh is used in oxidative pathways. with such an important role in biosynthesis, it is no surprise that its production is part of a major metabolic pathway, the pentose phosphate pathway (figure 7), also called the phosphogluconate pathway, and the hexose monophosphate shunt.  in step 1 of this pathway, glucose-6-phosphate and nadp+ are bound to glucose-6-phosphate dehydrogenase, which transfers a hydride ion from glucose-6-phosphate to nadp+ to form 6-phosphoglucono-d-lactone and nadph.  in step 2, the 6-phosphoglucono-d-lactone is hydrolyzed to 6-phosphogluconate using 6-phosphogluconolactonase. this reaction actually proceeds fairly quickly even without the enzyme.  in step 3, the 6-phosphogluconate is decarboxylated by 6-phosphogluconate dehydrogenase, in the process producing more nadph, as well as the five-carbon sugar, ribulose-5-phosphate. this metabolite is used by the cell as the basis for nucleotide synthesis. this concludes the nadph-producing portion of the pentose phosphate pathway.  however, it is useful, in the context of this chapter, to also consider the fate the ru5p, which is converted to ribose-5-p by ribulose-5-p isomerase or it is converted to xylulose-5-phosphate using ribulose-5-p epimerase. the ribose-5-phosphate is used in nucleotide synthesis, so plays an important role in not only nucleic acid production, but general metabolism (e.g. for atp).  ribulose-5-phosphate and nadph are the most significant products of this pathway. as mentioned earlier, nadph is important as a general reducing agent. the mechanism for this involves glutathione and glutathione reductase. glutathione is the primary scavenger of reactive oxygen species such as oxides and peroxides, and the key regulator of cellular oxidative stress. the reduced form of the glutathione tripeptide (glu-cys-gly) dimerizes with another glutathione via disulfide bond as they donate electrons to oxidizers, and is regenerated by glutathione reductase. nadph is a necessary cofactor for glutathione reductase activity, providing the electrons to reduce the g-s-s-g dimer.  figure 7. the pentose phosphate pathway. the first three reactions generate the energy carrier nadph in the process of converting glucose-6-phosphate to ribulose-5-phosphate. the ru5p is important as a precursor to nucleotide synthesis, as well as for production of other sugars and important metabolic intermediates, such as fructose-6-phosphate and glyceraldehyde-3-phosphate. transketolase then transfers the terminal two carbons of ribulose-5-p to xylulose-5-p, making sedoheptulose-7-phosphate and g3p. transaldolase comes up next. it transfers a 3-carbon unit from sedoheptulose-7-p to the g3p, forming erythrose-4-phosphate and fructose-6-phosphate.transketolase is used again at this point, transferring a 2-carbon unit from xylulose-5-phosphate - to erythrose-4-phosphate and generating more g3p and fructose-6-p.",t_317baab915ff,other,0
c_f26b90380843,"how do we know a patient has pneumonia? learn what the lungs in chest x-rays look like, what a bronchoscopy is, and what certain blood tests mean!  voiceover: so it's not hard to tell that our buddy here is not feeling so well, right? he's kinda look like he's seen better days. let's just pretend for a second, we're going to use our imagination to work through diagnosing and treating a pneumonia. let's say that you're working in a doctor's office, and this guy walks in. i think we should give him a name, let's call him paul. i just feel like when you give an animation a name somehow it becomes real. let's say that paul comes in to see you, and paul says, ""i've been having this cough,"" so here's his coughs. ""i've been having this terrible cough, ""and sometimes i bring up something with it."" ""sometimes i have some nasty stuff ""that comes out of it,"" so i'm going to draw some sputum there so you can sometimes he's coughing out some mucus, and sometimes it's dry. then let's say, you know what, he says that ""oh gosh, i can't breathe."" ""i'm really having a hard time breathing, ""and i'm really short of breath."" you get this information from paul, and you start to think to yourself you know what? this sounds a lot like pneumonia. if you suspect that, based off of the information that he's given you based off of these clues and this data, well how do we go about diagnosing pneumonia? that's what we're going to talk about. we're going to talk about diagnosing pneumonia. i'm actually going to make two little lists down here. we're going to have a diagnostic, so diagnostic tests that we can do, check for pneumonia, and labs. by labs i really mean collecting specimens whereas diagnostics would be a procedure, right? before we get into that, let's just make sure that our brains are ready to talk about pneumonia, so i'm going to come over here, and i'm just going to erase away a pair of lungs. let's pretend that these are paul's lungs. what do we know about pneumonia? remember that pneumonia's a lung infection, right? i have his right, his left lung, i got my trachea here, right? that branches off into my right and to my left bronchus, or main airway. then that branches off to even smaller airways and even smaller airways, and those are our broncials, and then we can see at the very end of all of this we have these tiny air sacs, and we call those alveoli. i'm going to write that because it's certainly not a term that we see too often. these tiny air sacs, this is actually where all the gas exchange happens. what does that mean? that means that as we're breathing in, and let's make this a nice color blue, so as we're breathing in, i don't think you can see that too well. let me go for a darker blue. that's better, so as we're breathing in air, right? breathing breathing breathing, it's going to get all the way to the end, to our alveoli. well what happens here is that the oxygen is absorbed into our blood system because we've got these tiny capillaries that run beneath our, and around, beneath and around i should say, our alveoli. that oxygen is absorbed into our blood system, and then we actually have an exchange. then we're going to have some, let me pick a different color. then we're going to have carbon dioxide being picked up and excreted out. the process is that we breathe in the oxygen, right? we breathe in o2, and we're going to exhale co2. that happens here; that happens in our alveoli. as you can see, i've painted these green so you can imagine that it's filled with this fluid, and this is infected fluid, and that's infected fluid secondary to an organism that's caused us to be ill. that can either be a virus, that could be a bacteria, that could be a fungus, it could be any organism that can cause disease, and we call that pathogens. the long and short of pneumonia is that it really is an infection of our lung, however the infection is occurring here in our air sacks or alveoli, and that infection causes an inflammatory response that fills up those air sacks with this nasty material. the nasty material's taking up the space where we should have air exchange happening. now with that said, and his symptoms, you can see that they go hand in hand and it's making sense. this is what lead us to believe he might have pneumonia. let's talk about some diagnostic tests. the first thing that we can do, now i'm going to abbreviate this. cxr would be a chest x-ray, and a chest x-ray is going to allow us to actually look inside paul's chest so just like i can see here, right? with the naked eye, i can't see inside of his chest, i can't see his lungs at all, but with a chest x-ray i can actually see inside and i'll be able to visualize his lungs. what we'd be doing is looking for some type of fluid or inflammation in the lungs. another thing that we can do to visualize would be a ct scan. this is very similar to a chest x-ray, and i'm just going to write this here, a ct scan except the difference is that this is a more detailed visualization of the lungs. an x-ray will give us a black and white image just some dense areas and less dense areas, so like bone and air and fluid as well, whereas a ct scan i'd be able to see tissues. if we wanted to move forward and do some things that were a little bit more invasive, we can do a bronchoscopy. i'm writing these terms because it's not too often that we actually see them, and i think it's important that we get familiar with it if we're going to talk about diagnosing and treating pneumonia. i'm going to show you what a bronchoscopy looks like but first i want to erase this stuff because we already talked about his cough, right? we talked about his [protective] cough, we talked about his symptoms. a bronchoscopy is a procedure where we actually take a thin flexible tube, and this is a device, and we feed this device either through the mouth, so through paul's mouth, down through his trachea, and into his main airway, or we could do it through the nose as well and end up in the same place. of course paul's going to be asleep for this. at the end of this device we have a camera, so i'm going to make this little black dot and that's going to be my camera. what a bronchoscopy is going to allow is that the person on the other end, or in this case it's going to be the physician, is actually going to be able to see inside of the airway. they can tell if there's excess mucus present, if there's a blockage, if there's a tumor, so a bronchoscopy really is the method for us to visualize what's happening in the lungs. a fourth thing we can do which i also say is invasive because it involves actually going inside the body is a bronchoalveolar, talk about a big word, lavage. this is done in the same manner as a bronchosocopy however the difference is instead of us just going in here to look, we're actually going in there to collect, and so instead of this camera, we're actually going to instill some fluids. you see these blue lines? that's normal saline. we're going to instill fluid into the airway, and we're going to then collect that fluid because what's happened is that fluid was able to mix with all the other substances and the content of the airway. we can collect the fluid, and we can test it to see if there's any organisms present. that's going to help us to indicate what's causing this infection. now if we come down here we can talk a little bit more about labs. now remember paul said that he was coughing up some nasty sputum? well we can actually test that sputum. here's my sputum. he said that he was coughing up some sputum, and we can actually test that to see what grows. we call that a sputum culture. another lab that we can do would be to do a blood culture. i'm just making these little red droplets here to indicate blood. just as we do a sputum culture to check the sputum for organisms, we're going to check the blood for organism. again, both of these things are going to let us know what exactly is causing the problem. is it a virus that's causing the problem? is it a bacteria that's causing a problem? what's the organism that's causing a problem? just as a side note, viral pneumonia is the most common cause of all pneumonias. now that we've done these diagnostic tests, and now that we've done these labs, we're actually now ready to treat it, so let's make a treat column. how do we treat it, right? if it's caused by a bacteria, our treatment choice is going to be an antibiotic, so these here are just going to represent some pills. we're going to give an antibiotic medication to paul to help kill that bacteria. if it's caused by a virus, unfortunately there's no treatment for a viral infection. we're really just treating the symptoms, so that means that we want to keep paul as comfortable as possible. there are some ways that we can do that. one of the ways we want to treat the symptoms is to promote and to encourage hydration. that means we really want paul to be drinking as much fluids as possible. there's my glass of water. in addition to keeping him hydrated, drinking a lot of fluids is going to help thin out the secretions. remember this glob of sputum that i made? well by increase the amount of fluid that we intake we can actually thin this out and that's a good thing because the thinner it is the easier it's going to be for paul to cough it out of his airway. another thing that we can do is we can provide oxygen. i'm going to make a cloud, and this cloud's going to represent oxygen. in cases that pneumonia is severe enough, oxygen absorption can be severely impaired, so it's really important that we can provide supplemental oxygen to make sure the body has the o2 that it needs to function. then one last thing that i want to add is something that we call cpt. i'm going to come over here and i'm going to write ""cpt,"" and we can make that our number three thing. i'm going to go ahead, i'm going to make these vibration marks next to it. that's what i want you to think of when you hear cpt. now cpt stands for chest physiotherapy. what happens in this case is that a trained professional is actually going to use their hands, and then cup their hands, did i make the right amount of fingers? i hope so. they're going to cup their hands, and they're going to tap on the patient's back and their chest, and you know what this is for? this is actually to help break up the secretions that they have in their airway so that it's easier for the patient to cough it out.",t_7c40255f6b43,other,0
c_d792d46790b1,"what is the limit of computer memory?  voiceover: when we perform calculations with a pen and paper, we often need to save intermediate results. and we may do this with, say, scrap paper, and in this case, the paper is acting as a form of external memory. and memory no matter the form, takes up physical space. computers contain memory, we can think of it as the scrap paper for the computer. and, say, when you construct an array to store values in your program, you require memory. and, at the lowest level, computers read and store all instructions as a string of numbers. but, how do you store numbers in a machine? this was a very difficult problem originally, especially when you need computers to hold their memory after the access to power is lost. this is known as nonvolatile memory. the easiest difference for a machine to detect is simply a presence versus an absence of something. and this is how old punch cards would work. along the top, we have some data and the vertical columns contain a series of punched holes which represent each character. so, computers really have 2 fingers, base 2, same as a light switch being ""on"" for 1, and ""off"" for 0. this is the smallest amount of information, a single difference, which we call a bit. but bits are powerful for storage because the amount of unique states grows exponentially as we add bits together. remember, one light switch is one bit and it can store 2 states, but 2 light switches can store 4 unique states. and 8 light switches or 8 bits can store 256 unique states. and space is measured in bits, but the physical size of a bit depends on your method of storage. so how do computer store zero's and one's internally? (gentle music) man in uniform: modern data processing systems like these use thousands of magnetic cores. what are magnetic cores? they are tiny rings of nickel alloy or other magnetic materials. they have replaced vacuum tubes for many important functions in data processing systems. voiceover: and it allowed computers to store bits as clockwise versus counter-clockwise magnetization direction. because the each core could be magnetized in 2 different ways, depending which direction the current was applied. man in uniform: because a bit can be represented by any bi-stable device and a magnetic core is a bi-stable device. voiceover: later on, this was done using thin film magnetic disk where we can think of as each bit as a tiny magnetic cell, which can be charged to store either a 1 or a 0. so, long story short, the size of a bit has been rapidly shrinking since the days of punch cards. a hard drive in a modern computer can be thought of as billions of tiny magnetic cells. now, you may wonder, well how small can these little magnetic cells be? and current research at ibm is pushing this to the atomic level where they have shown 12 iron atoms can work together as a stable magnetic unit, where they are able to store a 1 or a 0, depending how they are oriented. and this is approaching a theoretical limit where we would hold a single bit on a single atom! and interestingly, ibm estimates that we can put around one quadrillion bits of information in a handheld device, the size of an ipod, with atomic storage. and, let's call this a super drive, it doesn't even exists yet, as a hypothetical example. a small handheld super drive using atomic storage would hold one thousand terabits, which is one thousand trillion switches or more commonly known as 125 terabytes in the palm of your hand, or to use an example everyone can understand, 125 terabytes is the same as having a 1250 kilometer long book shelf in the palm of your hand. and this is what the future of memory looks like, or we ever be able to store a bit on something smaller than an atom?",t_83fedce529d6,other,0
c_4ab07272a1d7,"translated by volunteer olivia wilson on sikana factory  sikana is an ngo from paris, france that wants to revolutionise education and make practical skills available to all, for free.  we make videos on a whole host of topics which are translated by a community of volunteer translators via our custom-built translation platform the factory.   to join our translation efforts, please sign up at: https://factory.sikana.tv how to make beurre noisette the techniques explained in this video are suitable for beginner-level cooks cooking time: 10 minutes in this video you will learn to prepare a beurre noisette this will add a hazelnut flavour to any dishes or cakes you make. follow the instructions and you will quickly learn this technique. butter is a mixture of fat, water, protein and sugar. the goal of this technique is to cook the protein which will give it a lovely brown colour and will develop a hazelnut aroma in order to make your hazelnut butter you will need a block of butter and a saucepan. first step: melt the butter melt the butter put the piece of butter in the saucepan, then put the saucepan on a medium heat. the butter will melt. when it reaches 30°c/85°f it will be completely liquid. second step: let the butter froth. froth the butter leave the butter to heat. the water contained in the butter boils and will turn into a froth. it will now be at 100°c/212°f in temperature third step: brown the butter. brown the butter leave the butter to continue to heat. it will contain no more water and will stop boiling. the white deposits on the surface are the butter's proteins and sugar  the white deposits will start browning when the butter reaches a temperature of 120°c/250°f. you will now start to smell the first hints of hazelnut. when the surface has turned brown turn the heat off. your hazelnut butter is now ready. if you continue to heat it the proteins will burn and smoke. the butter will turn black. if this happens throw it away as it will be harmful to eat you now know how to prepare hazelnut butter! it will be very easy for you to do again!",t_79e2238612cb,other,0
c_ed51870d21a1,"the market demand for a good describes the quantity demanded at every given price for the entire market. remember that the entire market is made up of individual buyers with their own demand curves. this means that the market demand is the sum of all of the individual buyer's demand curve.  in this video, you can visualize why this is true.  - [instructor] in this video, were going to think about the market for apples, but the more important thing isn't the apples, it's to appreciate that the demand curves for a market are really the sum of the individual demand curves for every member of that market, and most markets will have many tens or hundreds of thousands of actors in it, maybe millions or tens of millions of actors in it, but for the sake of simplifying things, we're going to assume that the apple market has only two buyers, and we have their demand curves right over here. this is the demand curve for buyer one, and this is the demand curve for buyer two, and so if the vertical axis is price, and maybe this is price per pound of apples, and quantity, let's just say that's pounds per time period, maybe pounds per week, we can see that from buyer one's demand curve that at a price of one, two, three, four, five dollars per pound, they don't wanna buy any pounds. at a price of three dollars per pound, they're willing to buy one pound per week. at a price of one dollar per pound, they're willing to buy two pounds per week. we can similarly look at the demand curve for buyer two, and sometimes you'll see this in table form where it's called a demand schedule, but you can see at one, two, three, four, five, six, seven, at seven dollars, buyer two is not interested in apples at seven dollars a pound. at five dollars a pound, they are interested in buying two pounds of apples per week. at three dollars per pound, they're interested in buying, so let's see this is one, two, three, four, five pounds per week, and at one dollar per pound, they're interested in buying six, seven, eight pounds per week. so based on this data here, buyer one and buyer two are the only individuals in this market. once again, a huge oversimplification. what would the market demand curve look like? pause this video and try to think that through. well, if we go to the various prices, so let's see, at a price of seven dollars, there is not going to be any interest in any apples. so, i could maybe put that right over there at a price of seven dollars, but what happens is the prices goes down and we could just sample what happens when we get to a price of five dollars? buyer one is still not interested, but buyer two is now willing to buy two pounds per week. and so, at a price of five dollars, the market as a whole is willing to buy two pounds from buyer two and zero pounds from buyer one, so we'll have a total of two pounds. so we're right over there. so that is at five dollars per pound. the market is willing to, is demanding a quantity of two pounds per week. and then let's go to three dollars. at three dollars, now, buyer one would buy one pound per week and buyer two would buy five pounds per week. so in total, there would be six pounds demanded or the quantity demanded would be six pounds. so three dollars, the quantity demanded is three, four, five, six. so that would put us right about there. and then last but not least, and once again, i'm just sampling these points to make the point to you that we really would just add, we would take the sum of these curves but we're kind of stacking them, we are stacking them horizontally as opposed to vertical because for any given price, we're adding up the quantities. so let's go to one dollar a pound. at one dollar a pound, buyer one is willing to buy two pounds, and at one dollar a pound, buyer two is willing to buy eight pounds. you put those together, two plus eight, you get to 10 pounds. so this was two, three, four, five, six, seven, eight and then nine and ten, we're going a little bit off the screen here, i could have planned better for it, but let me go all the way over here so i'll extend my axis so that's nine and then this is ten so that at one dollar, the market would be willing to buy ten pounds per week. and you could sum at any other point or any other points in between and what you would do is you would get a market demand curve that looks a little something like this. and you can see, visually, what has happened here. for any price value, we are summing the quantities for all of the buyers in the market. now here, there's only two buyers. now if you were doing this in the real world, you might be dealing with millions of buyers, but this is just to understand how a market or where a market demand curve is actually coming from.",t_2f61c639339f,other,0
c_043f1f5f86b8,"sal factors 25x^2-30x+9 as (5x-3)^2 or as (-5x+3)^2.  factor 25x squared minus 30x plus 9. and we have a leading coefficient that's not a 1, and it doesn't look like there are any common factors. both 25 and 30 are divisible by 5, but 9 isn't divisible by 5. we could factor this by grouping. but if we look a little bit more carefully here, see something interesting. 25 is a perfect square, and 25x squared is a perfect square. it's the square of 5x. and then nine is also a perfect square. it's the square of 3, or actually, it could be the square of negative 3. this could also be the square of negative 5x. maybe, just maybe this could be a perfect square. let's just think about what happens when we take the perfect square of a binomial, especially when the coefficient on the x term is not a 1. if we have ax plus b squared, what will this look like when we expand this into a trinomial? well, this is the same thing as ax plus b times ax plus b, which is the same thing as ax times ax. ax times ax is a squared x squared plus ax times b, which is abx plus b times ax, which is another. you you could call it bax or abx, plus b times b, so plus b squared. this is equal to a squared x squared plus-- these two are the same term-- 2abx plus c squared. this is what happens when you square a binomial. now, this pattern seems to work out pretty good. let me rewrite our problem right below it. we have 25x squared minus 30x plus 9. if this is a perfect square, then that means that the a squared part right over here is 25. and then that means that the b squared part-- let me do this in a different color-- is 9. that tells us that a could be plus or minus 5 and that b could be plus or minus 3. now let's see if this gels with this middle term. for this middle term to work out-- i'm trying to look for good colors-- 2ab, this part right over here, needs to be equal to negative 30. or another way-- let me write it over here-- 2ab needs to be equal to negative 30. or if we divide both sides by 2, ab needs to be equal to negative 15. that tells us that the product is negative. one has to be positive, and one has to be negative. now, lucky for us the product of 5 and 3 is 15. if we make one of them positive and one of them negative, we'll get up to negative 15. it looks like things are going to work out. we could select a is equal to positive 5, and b is equal to negative 3. those would work out to ab being equal to negative 15. or we could make a is equal to negative 5, and b is equal to positive 3. either of these will work. if we factor this out, this could be either a is negative-- let's do this first one. it could either be a is 5, b is negative 3. this could either be 5x minus 3 squared. a is 5, b is negative 3. it could be that. or you could have-- we could switch the signs on the two terms. or a could be negative 5, and b could be positive 3. or it could be negative 5x plus 3 squared. either of these are possible ways to factor this term out here. and you say wait, how does this work out? how can both of these multiply to the same thing? well, this term, remember, this negative 5x plus 3, we could factor out a negative 1. so this right here is the same thing as negative 1 times 5x minus 3, the whole thing squared. and that's the same thing as negative 1 squared times 5x minus 3 squared. and negative 1 squared is clearly equal to 1. that's why this and this are the same thing. this comes out to the same thing as 5x minus 3 squared, which is the same thing as that over there. either of these are possible answers.",t_e3f1f39be5db,other,0
c_0865a3e159f2,"introduction to acid-base titrations using example of titrating 20.0 ml of hcl of unknown concentration with 0.100 m naoh. covers indicators, endpoint, equivalence point, and calculating the unknown concentration.  titration is a procedure for determining the concentration of a solution. and so let's say we're starting with an acidic solution. so in here let's say we have some hydrochloric acid. so we have come hcl. and we know the volume of hcl, let's say we're starting with 20.0 milliliters of hcl. but we don't know the concentration right? so question mark here for the concentration of hcl. we can find out that concentration by doing a titration. next we need to add a few drops of an acid base indicator. so to this flask we're also going to add a few drops of an acid base indicator. we're gonna use phenolphthalein. and phenolphthalein is colorless in acid but turns pink in the presence of base. and since we have our phenolphthalein in acid right now we have a clear solution. there's no color to it. up here we're gonna have our standard solution right? we're gonna have a known concentration of sodium hydroxide. so let's say we have a solution of sodium hydroxide and the concentration is zero point one zero zero molar. and we're ready to start our titration. so we allow the sodium hydroxide to drip into our flask containing our hcl and our indicator. and the acid in the base will react, right? so we get an acid base neutralization reaction. hcl plus naoh right? if we think about the products, this would be oh minus, this would be h plus, h plus and oh minus give us h2o. and our other product we would have na plus and cl minus, which give us nacl, or sodium chloride. so let's say we add a certain volume of base right? so now this would be higher, and we see our solution turn light pink. alright so let's say we see our solution turn light pink and it stays light pink. that means that all of the acid has been neutralized by the base. and we have a tiny amount of excess base present, and that's causing the acid base indicator to remain pink. so a tiny excess of base means we've neutralized all of the acid present. and where the indicator changes color, this is called the end point of a titration, alright? so when our solution changes color, that's the end point of our titration. and here we stop and we check and see the volume of base that we used in our titration. so if we started right here, if we started with that much base, let's say we ended down here, alright? so we still have a little bit of base left. and this would be the volume of base that we used in the titration. alright so we have a change in volume here, and let's say that it's 48.6 milliliters. so it took 48.6 milliliters of our base to completely neutralize the acid that we had present. and so we can now calculate the concentration of the hcl. alright so let's go ahead and do that, and let's start with the concentration of sodium hydroxide. alright we know that we started with point one zero zero molar solution of sodium hydroxide. so point one zero zero molar. and molarity is equal to mols over liters. alright so this is equal to mols over liters. and our goal is to figure out how many mols of base that we used to neutralize the acid that was present. alright so we can take our volume here, 48.6 mililiters and we can convert that into liters. alright so just move your decimal place three places to the left. so one, two, three. so that's point zero four eight six liters. so this is equal to mols over zero point zero four eight six liters. and so let's get some more space. alright let me just rewrite this really quickly. zero point one zero zero is equal to x over zero point zero four eight six. so we're just solving for x, and x represents the mols of sodium hydroxide that were necessary to neutralize the acid that we had present. alright so when you solve for x, you get zero point zero zero four eight six mols of sodium hydroxide used in our titration. next you look at the balanced equation for what happened . so if i look at my balanced equation alright there's a one here and there's a one here. so we have a one to one mol ratio. and the equivalence point is where just enough of your standard solution has been added to completely react with the solution that's being titrated. and at the equivalence point, all of the acid has been neutralized. right? so it's completely reacted. and since we have a one to one mol ratio, if i used this many mols of sodium hydroxide, that must be how many mols of hcl that we had present in our original solution. so therefore, i can go ahead and write that i must have had zero point zero zero four eight six mols of hcl present in the flask before we started our titration. right and i knew that because of the one to one mol ratio. remember our goal was to find the concentration of hcl. the original concentration. and concentration, molarity is equal to mols over liters. so now i know how many mols of hcl i had, and my original volume of hcl was 20 milliliters right? so right up here we had 20 milliliters. so i need to convert that into liters. so i move my decimal place one two three. so i get point zero two liters. so now our final step here to calculate the concentration of hcl, right so the concentration of hcl is equal to how many mols of hcl we have, which is zero point zero zero four eight six mols, over liters of solution. and we had 20 milliliters which is equal to zero point zero two zero zero liters. alright so now we can take out our calculator and do this calculation to find the concentration of hcl that we started with. point zero zero four eight six, all right and we're gonna divide that by point zero two zero zero. and we get zero point two four three for our answer. so the concentration of hcl is equal to zero point two four three molar. so we've solved for the original concentration of hcl. there's a shortcut way to do this problem, and the shortcut way would be to do the molarity times the volume of the acid is equal to the molarity times the volume of the base used. so mv is equal to mv. so let's say we have the acid over here on the left, and the base over here on the right. so the molarity of the acid is what we're trying to find. so i'll just make that x. the volume of the acid that we started with, you can just leave this in milliliters if you want, 20 point zero milliliters is how much of the acid we started with. and for the base, we knew the concentration of the base that we used in our titration right? it was zero point one zero zero molar. and we also knew the volume of base that we used to completely neutralize the acid. we used 48.6 milliliters. and notice how the mls would cancel out here. right and we can just go ahead and do the math and solve for x. so we get out the calculator, and we need to multiply 48.6 times point one zero zero. alright and so we get four point eight six obviously. and then if we divide by 20 we will get our answer of zero point two four three. so x is equal to zero point two four three molar. and this shortcut way works pretty well when you're dealing with a strong acid and a strong base and a one to one molar relationship. alright in the next video we'll do a problem where the mol ratio is no longer one to one.",t_e5e801f310b3,other,0
c_9b27a93c0afe,"in this video we take a slightly different approach to understanding the difference between real and nominal values: find the value of an asset in a previous year's dollars.  male voice: in the last video, we were able to calculate the real return by putting everything in today's dollars. put that $100 we invested a year ago in today's dollars, figure out what our actual return was, our dollar return is in today dollars, then we got our real return. what i want to think about in this video is how we can do it another way. we can actually put everything in last year's money. we got $110. let's put $110, of today's money in last year's money. to think about this, we could do a little algebra, or you don't have to do algebra, but maybe that makes it a little bit more intuitive. there's some amount of money last year, there's some amount of money, let's call that x, that if we multiply it by the inflation rate, so if we grow it by 2%, that's going to be worth $110 today. or, to just solve for x, you divide both sides by 1.02 and we get the amount of money that if you grow it by inflation, or that had the same amount of purchasing power as $110 today, would be 110 divided by 1.02 which is, let me move over to the right at little bit, this would be 110 divided by 1.02. this would be equal to $107.8 just roughly, just to round it. this is equal to $107.8. so $110 today buys us the exact same thing, if you believe the whole cpi index, as $107.80, maybe i can even add another digit, 84 cents, would have bought us last year. what is our dollar return in last year's money? dollar return in last year's money. last year's money. well, we ended up with $107.84 in last year's money. so 107.84, or $107.84. we had originally invested, in last year's money, $100. we had originally invested $100. so our dollar return is $7.84, or if you want to calculate the real return, how much did our actual purchasing power increase? well, we got a $7.84 return off of a $100 investment, so this is pretty easy to calculate. we once again get to the same 7.8% for the real return.",t_eef6f9d669a3,other,0
c_a1bed8ae9050,"the placebo effect  if you believe you're taking medicine it can sometimes 'work' even if it's fake.  the placebo effect can work for stuff that our mind influences (such as pain) but not so much for things like viruses or broken bones. things like the size and color of pills can have an influence on how strong the effect is and may even result in real physiological outcomes. we can also falsely attribute getting better to an inert substance simply because our immune system has fought off an infection i.e. we would have recovered in the same amount of time anyway.  homeopathy, acupuncture, and many other forms of natural 'medicine' have been proven to be no more effective than placebo. keep a healthy body and bank balance by using evidence-based medicine from a qualified doctor.  further reading                     wikipedia                    |                    you are not so smart  your free poster is downloading now.  pay it forward by helping to spread the rational word on facebook:",t_dc8fe1fdb261,other,0
c_5bf5610c3521,"1. this organism seen in the above electron micrograph is: a. eukaryotic b. prokaryotic c. viral  2. a cell possesses a nuclear membrane and nucleolus, mitochondria, an endoplasmic reticulum, and golgi complexes. this cell is:  a. eukaryotic b. prokaryotic c. viral  3. fungal and protozoan cells are: a. prokaryotic b. eukaryotic c. neither  4. which best describes a virus? a. prokaryotic b. eukaryotic c. acellular  5. this organism seen in the above electron micrograph is: a. eukaryotic b. prokaryotic c. viral  6. bacteria are able to be much smaller than most eukaryotic cells because: a. they have a small surface area to volume ratio so diffusion can easily deliver nutrients and energy to all parts of the cell. b. they have a large surface area to volume ratio so diffusion can easily deliver nutrients and energy to all parts of the cell. c. they are acellular.",t_a03169900a94,other,0
c_9bb05eea3833,"sal discusses what it means for two ratios to be equivalent.  - [voiceover] we're told that burger barn makes dipping sauce by mixing two spoonfuls of honey with one half spoonful of mustard. sandwich town makes dipping sauce by mixing four spoonfuls of honey with one spoonful of mustard. which dipping sauce has a stronger mustard flavor? so pause this video and see if you can work through that on your own. all right, now let's think about the ratios of honey to mustard at each of these restaurants. so first let's think about the scenario with burger barn. so i'll just say bb for short, for burger burn. so they have two spoonfuls of honey for every one half spoonful of mustard, so the ratio of honey to mustard in terms of spoonfuls is two spoonfuls of honey for every one half spoonful of mustard, so this is the ratio of honey to mustard. let me write this. this is honey, and this right over here is mustard. now, let's look at sandwich town, so i'll call that st. so sandwich town makes dipping sauce by having four spoonfuls of honey for every one spoonful of mustard. so the ratio of honey to mustard is four spoonfuls to one spoonful, so once again, that is honey and that is mustard. now, can we make these equivalent ratios or can we compare them somehow? well, let's see. we have one half spoonful of mustard here. we have one spoon of mustard here, so what if we multiplied both the mustard and the honey spoonfuls by two? that still would be an equivalent ratio because we're multiplying by the same amount. so if we multiply by two in both situations, you have four spoonfuls of honey for every one spoonful of mustard. well, that's the exact same ratio that we have at sandwich town. so it actually turns out that they have the same concentration of mustard. they have the same ratio of honey to mustard. four spoonfuls of honey for every spoonful of mustard in either situation. let's do another example. so here, we are asked or we are told, we are told, patrick's favorite shade of purple paint is made with four ounces of blue paint, so underline that in blue, four ounces of blue paint, for every three ounces of red paint, for every three ounces of red paint. so the ratio of blue paint to red paint is four ounces of blue, four ounces of blue, for every three ounces of red, so four to three. which of the following paint mixtures will create the same shade of purple? all right, pause this video and see if you can figure it out on your own. so this is three ounces of blue paint mixed with four ounces of red paint. well, this is a ratio here of three to four, and even though it's dealing with the same numbers, this is a different ratio. the order matters. this is four ounces of blue for every three ounces of red. this is saying three ounces of blue for every four ounces of red, so we could rule this one out. eight ounces of blue paint mixed with six ounces of red paint. so here, this ratio is eight ounces of blue for every six ounces of red. well, are these equivalent ratios? well, the difference, or you can go, if you multiply by two in either case, you will get to eight to six. four times two is eight, three times two is six. so this is indeed an equivalent ratio, so we would select this one. all right, here they say six ounces of blue paint mixed with eight ounces of red paint. so this is, they've swapped the blues and the red relative to this one, so this is a ratio of six to eight, so let me write this down. so this is a ratio, six ounces of blue paint for every eight ounces of red paint. so just like we ruled out that first one, this is dealing with the same numbers but in a different order and the order matters, so we'll rule that out. 20 ounces of blue paint, 20 ounces of blue paint, for every 15 ounces of red paint. so are these equivalent? well, let's think about it. to go from four to 20, you can multiply by five, and to go from three to 15, you could multiply by five, so we can multiply by the same factor to go from four to three to 20 to 15, so this is indeed an equivalent ratio. 12 ounces of blue paint mixed with 16 ounces of red paint. all right, so this is a ratio here of 12 ounces of blue for every 16 ounces of red. so let's think about this. to go from four to 12, you would multiply by three. now, if you multiplied three by three, you would have a nine here, not a 16, so this is definitely not an equivalent ratio. another way of thinking about it, you have, in terms of ounces, you have more ounces of blue than you have of red for any of the equivalent ratios, but here you have more ounces of red than blue, so once again, another way of realizing that that is not equivalent, so only b and d are the equivalent mixtures that will provide the same shade of purple. to have that same shade, you need the same ratio of blue to red.",t_11a3f1447591,other,0
c_ca194dec590b,"example solving for the eigenvalues of a 2x2 matrix  in the last video we were able to show that any lambda that satisfies this equation for some non-zero vectors, v, then the determinant of lambda times the identity matrix minus a, must be equal to 0. or if we could rewrite this as saying lambda is an eigenvalue of a if and only if-- i'll write it as if-- the determinant of lambda times the identity matrix minus a is equal to 0. now, let's see if we can actually use this in any kind of concrete way to figure out eigenvalues. so let's do a simple 2 by 2, let's do an r2. let's say that a is equal to the matrix 1, 2, and 4, 3. and i want to find the eigenvalues of a. so if lambda is an eigenvalue of a, then this right here tells us that the determinant of lambda times the identity matrix, so it's going to be the identity matrix in r2. so lambda times 1, 0, 0, 1, minus a, 1, 2, 4, 3, is going to be equal to 0. well what does this equal to? this right here is the determinant. lambda times this is just lambda times all of these terms. so it's lambda times 1 is lambda, lambda times 0 is 0, lambda times 0 is 0, lambda times 1 is lambda. and from that we'll subtract a. so you get 1, 2, 4, 3, and this has got to equal 0. and then this matrix, or this difference of matrices, this is just to keep the determinant. this is the determinant of. this first term's going to be lambda minus 1. the second term is 0 minus 2, so it's just minus 2. the third term is 0 minus 4, so it's just minus 4. and then the fourth term is lambda minus 3, just like that. so kind of a shortcut to see what happened. the terms along the diagonal, well everything became a negative, right? we negated everything. and then the terms around the diagonal, we've got a lambda out front. that was essentially the byproduct of this expression right there. so what's the determinant of this 2 by 2 matrix? well the determinant of this is just this times that, minus this times that. so it's lambda minus 1, times lambda minus 3, minus these two guys multiplied by each other. so minus 2 times minus 4 is plus eight, minus 8. this is the determinant of this matrix right here or this matrix right here, which simplified to that matrix. and this has got to be equal to 0. and the whole reason why that's got to be equal to 0 is because we saw earlier, this matrix has a non-trivial null space. and because it has a non-trivial null space, it can't be invertible and its determinant has to be equal to 0. so now we have an interesting polynomial equation right here. we can multiply it out. we get what? let's multiply it out. we get lambda squared, right, minus 3 lambda, minus lambda, plus 3, minus 8, is equal to 0. or lambda squared, minus 4 lambda, minus 5, is equal to 0. and just in case you want to know some terminology, this expression right here is known as the characteristic polynomial. just a little terminology, polynomial. but if we want to find the eigenvalues for a, we just have to solve this right here. this is just a basic quadratic problem. and this is actually factorable. let's see, two numbers and you take the product is minus 5, when you add them you get minus 4. it's minus 5 and plus 1, so you get lambda minus 5, times lambda plus 1, is equal to 0, right? minus 5 times 1 is minus 5, and then minus 5 lambda plus 1 lambda is equal to minus 4 lambda. so the two solutions of our characteristic equation being set to 0, our characteristic polynomial, are lambda is equal to 5 or lambda is equal to minus 1. so just like that, using the information that we proved to ourselves in the last video, we're able to figure out that the two eigenvalues of a are lambda equals 5 and lambda equals negative 1. now that only just solves part of the problem, right? we know we're looking for eigenvalues and eigenvectors, right? we know that this equation can be satisfied with the lambdas equaling 5 or minus 1. so we know the eigenvalues, but we've yet to determine the actual eigenvectors. so that's what we're going to do in the next video.",t_fb0a1b9e4efa,other,0
c_b4b8fe256bce,"how to feed a baby with a cup of breast milk founded in 2014, sikana health is one of 12 programmes created by the ngo sikana. it works at transmitting knowledge in order to allow everyone to acquire positive health reflexes. from healthy eating to music, respecting nature, health, improving one's environment, or learning a new sport, our many programs aim to encourage a simple and healthy life. to discover our programmes see: www.sikana.tv to help with the translation and diffusion of our videos globally see: factory.sikana.tvwe make videos on a whole host of topics which are translated by a community of volunteer translations via our custom-built translation platform the factory. to join our translation efforts, please sign up at: https://factory.sikana.how",t_307fd735c1a0,other,0
c_217a44f097d6,"discover why your favorite cat videos don't leak out of optical fibers.critical angle  discover why your favorite cat videos don't leak out of optical fibers.  a transparent material, such as glass or water, can actually reflect light better than any mirror. all you have to do is look at it from the proper angle.  subjects:                  keywords:  mathematics  physics  light  waves  reflections  laser  water  angle  refraction  tools and materials  a rectangular aquarium  a few drops of milk (or some powdered milk) to add to the aquarium water to make the beam visible  a light source with a well-defined beam (a laser is best, if one is available; otherwise, you can use a mini maglite flashlight focused to make a beam)  assembly  fill the aquarium with water.  hold your laser or flashlight up to the side of the aquarium so the light is shining into the water.  add the milk one drop at a time, stirring after each drop, until you can see the light beam passing through the water. if you use powdered milk, add a pinch at a time.  to do and notice  direct the light beam upward through the water so that it hits the surface of the water from underneath. you can shine the beam into the water through the transparent bottom of the aquarium, or in through a side wall. (with the mini maglite, you can seal the light in a watertight plastic bag and place the light right in the water!) the beam will be more visible if you can dim the room lights.  point the beam so that it hits the surface of the water at just about a right angle. in the aquarium, you may be able to see both the reflected beam, which bounces back into the water, and the refracted beam, which comes out of the water and into the air. (dust in the air helps you see the refracted beam. you can add chalk dust to the air. you can also search for the beam and track it with a piece of paper.)  notice that most of the beam leaves the water and only a faint beam is reflected back down into the water (click to enlarge the illustration below).  slowly change the angle at which the beam of light hits the surface of the water.  notice that the beam reflected into the water grows brighter as the beam transmitted into the air becomes dimmer. also notice that the transmitted beam is bent, or refracted.  experiment until you find the angle at which the transmitted beam completely disappears. at this angle, called the critical angle, all the light is reflected back into the water.  what’s going on?  in general, when a beam of light (the incident beam) hits the interface between two transparent materials, such as air and water, part of the beam is reflected and part of it continues through the interface and on into the other material. the light beam is bent, or refracted, as it passes from one material into the next (click to enlarge the diagrams below).  the farther the beam is from perpendicular when it hits the surface, the more strongly it is bent. if the light is moving from a material with a low speed of light into a material with a higher speed of light (for example, from water into air), the bending is toward the surface. at some angle, the bending will be so strong that the refracted beam will be directed right along the surface; that is, none of it will get out into the air.  beyond that angle (the critical angle), all the light is reflected back into the water, so the reflected beam is as bright as the incident beam. this phenomenon is called                 total internal reflection,                because very nearly 100 percent of the beam is reflected, which is better than the very best mirror surfaces.  the critical angle for water is measured between the beam and a line perpendicular to the surface, and is 49 degrees.  going further  total internal reflection helps transmit telecommunications data along optical fibers. any light that is not aligned parallel to the axis of the fiber hits the wall of the fiber and is reflected (totally!) back inward, since the angle of incidence with which the light hits the wall is much larger than the critical angle (click to enlarge the diagram below).  this helps prevent the signal from weakening too rapidly over long distances, or from leaking out when the fiber goes around a curve. this demonstration can also be done by replacing the aquarium and water with a small transparent plastic block, which can be bought at a local plastics supply store.     back        download the file below",t_dd1ae4859182,other,0
c_312b00c983d6,"chapter from a guide to becoming a 21st century teacher21st century skills  pointb/unicef/pearson/mawlamyine university  skillsbuilding  94  21st century skills  st  skills-building for teachers  in this section, we share some of the background knowledge  in this section, teachers will learn about:  and skills necessary for teachers to enable 21st century skills in their classroom.  1. teacher as a... (roles of a teacher) 96-99  we’ve also sprinkled in some fun activities to help teachers  2. classroom management 100-101  and students to experience these skills first-hand and then  3. the experiential learning cycle 102-103  reflect on their experiences together.  4. question formulation technique (qft) 104-105 5. collaborative learning 106-107  95  21st century skills  pointb/unicef/pearson/mawlamyine university  teacher as a... 8 r ole s o f a n e ffec tive 21 st c e n tu ry teac her what does it mean to be an effective 21st century teacher? a concise or condensed answer to the question above might be: “when the teacher connects individually with each student in learning and when all decisions concerning what is taught and how it is taught are made based on this connection with the students in the learning process.” to get a little closer to effectiveness we have performance indicators for teachers who spark the 5cs in their students (see pages 64-65). these performance indicators are based on 8 specific roles the teacher needs to assume in order to help students acquire 21st century skill sets.  96  21st century skills  role #1  role #2  role #3  teacher as a facilitator  teacher as a presenter  teacher as a person  a 21st century teacher is a guide —  a 21st century teacher knows and uses  a 21st century teacher connects to  assisting students in learning how to  different ways to present information.  his or her students as another human  learn for themselves through analysis  through lecture, asking question,  being. not as a boss or caretaker. a  of ideas, forming their own thoughts  framing information in different ways,  teacher is authentic, admitting when  and opinions, and taking ownership  and emphasizing different skills (5cs)  she does not know something or if she  of their own learning through self-  and techniques in a lesson a teacher  has made a mistake.  exploration and dialogue. in addition, a  sparks curiosity and self-motivation in  teacher will change what is happening  her 21st century learning classroom. a  in the class when he or she sees that  teacher does not separate knowledge  learning is not taking place.  acquisition from knowledge application, but instead integrates them into the same lesson.  97  21st century skills  pointb/unicef/pearson/mawlamyine university  8 roles of an effective 21st century teachers continued  role #4  role #5  role #6  teacher as a  teacher as a skills-builder  teacher as a professional  lifelong learner  a teacher is committed to knowledge  a professional does not work  according to education researcher  acquisition and application of that  according to the clock. he or she  john hattie, “the greatest effects on  knowledge through specific skills  works connected to the deliverables  student learning occur when teachers  needed especially within the 21st  expected. professionals connect with  become learners of their own teaching,  century. a 21st century teacher is  other professionals to enhance the  and when students become their own  also aware of mindset, dispositions or  quality of their work. professionals  teachers.” a 21st century teacher is  habits of students and is always aware  are prepared always to do the best  100% a 21st century learner —  that true learning is the development  work possible under the specific  he or she models all of the 5cs  of knowledge, skills and dispositions.  circumstances. professionals focus on  and learns with students.  opportunities (even if they’re small) and don’t get stuck on problems.  98  21st century skills  role #7  role #8  teacher as a mentor  teacher as a creator  a 21st century teacher works closely  no matter how many teacher guides  students in hands-on learning. in this  with her students to develop their  are produced, no matter how many  way, creative teachers are constantly  potential as learners, human beings,  skills and activities are demonstrated,  finding new ways to improve learning,  citizens, future professionals and  learning still comes down to the  create activities, group discussions  potential leaders. he or she sees that  connection and interaction between  and small projects, which help to  to be successful in the 21st century  a teacher and a student. teacher as  engage students in the learning  world each student needs to be  a creator opens up the classroom  process. creative teachers apply  a lifelong learner. a teacher takes  to the world to create opportunities  intuition to find and draw out the  the time to mentor students and to  for students to work with materials  “teachable moments” in a lesson  develop their mindsets, knowledge,  and activities. creative teachers help  or activity. in doing so, a creative  skills, dispositions, habits to be  students discover not only the world  teacher builds skills in being able to  engaged with the 21st century world  but also themselves. teachers engaged  understand when is the right time to  and to make a difference in that world.  students’ minds in discovering deeper  praise effort, to challenge the students  truths, speculations, assumptions,  further, to leave a student or group  beliefs, theories, and hypothesis  alone to work through challenges or to  analyzing and questioning what we  step in and lend a helping hand.  call truths. they do this by engaging  99  21st century skills  pointb/unicef/pearson/mawlamyine university  classroom management d es i g n i n g a 2 1 st c en tu ry l ear n i n g e n v iro n men t 2 basic ground rules: 1) for teachers, know your students and adjust the classroom environment accordingly. 2) for students, respect each other and each person’s learning, and be safe.  100  21st century skills  “if i had a learning classroom...” activity learning objective: unpack the most basic rules of classroom management for the teacher and the behaviors of students. this activity may be done with groups of teachers or students: part 1 objective identify the student behaviors that contribute to a learning classroom.  part 2 objective identify teacher strategies and behaviors that contribute to a learning classroom.  how discuss and answer the question: if we had a learning classroom, what would the students be doing?  how in the same groups discuss and answer the question: if we had a learning classroom what would the teacher be doing?  divide into small groups of 4-6 students and identified student behaviors, which would contribute to a learning classroom. focus on behaviors between: student and student, teacher and student, and student to learning work.  divide into small groups of 4-6 students and identify teacher behaviors which would contribute to a learning classroom. these can include teacher behaviors toward students, and instructional behaviors.  present group work and discuss within class. then, move on to part 2.  reflection • what is most important to create a learning environment for everyone? • how do we create an environment so that everyone of us can learn? • what is the role of the teacher and the student in the creation of a 21st century environment for learning?  101  21st century skills  pointb/unicef/pearson/mawlamyine university  the experiential learning cycle le a r n by d o in g too often when we think about teaching and learning we only think  experience  about what information is covered and how it is taught. we forget that a student learns best by taking in knowledge from the outside world and connecting it to his or her inner self. the inner self includes who you are, how you understand, and what  a p p ly (now what can you do with what you learned?)  reflect  you already know, or think you know.  (what did you do?) in experiential learning, the teacher becomes a facilitator. first, helping the students have an authentic or structured learning experience (sle) and then, helping them to unpack their  learn (so what did you learn?)  experiences by reflecting on what they did, what they learned and how they can apply this to a future experience.  102  21st century skills  overview the experiential learning cycle is a model of adult learning developed by david a. kolb, professor of organizational behavior, which involves four sequential stages: 1. concrete experience: learning starts with some experience of an event, incident, or occurrence. 2. reflective observation: when people reflect and think about their experiences, they raise their awareness and personal learning. 3. abstract learning: reflection leads to a sorting and understanding of earlier experiences from which the person can draw conclusions and generalizations. these abstract conceptualizations help to provide a framework in understanding an experience. 4. application: using the framework developed from earlier experiences, a person can test out his earlier conclusions, either to confirm the learning already achieved or to generate more evidence. such testing out leads to more experiences in the real world, which in turn, set the learning cycle in motion again.  experiential learning cycle activity learning objective: to practice the experiential learning cycle of experience, reflect, learn, and apply. how use any authentic activity, for example place yourself in the situation of being faced with teaching another group how to tie a shoe. your task is to work together with a partner to outline an experiential learning lesson on shoe tying. you will have 10 minutes to outline and practice your lesson before presenting to another group. use the following parts of the experiential learning cycle: 1. experience the students experience the activity through direct,hands-on participation (i.e., learning by doing). 2. reflect (what did you do?) the students discuss the experience(s) they had doing the activity. the results of the activity are discussed by the students; there is evidence of active reflection in small or large groups. 3. learn (so what did you learn?) connections between the activity and real-world examples are made by the students and/or the facilitator.  4. apply (now what can you do with what you learned?) the outcomes of the activity are applied to one or more independent situations. once you have outlined your shoe tying lesson using the four sequential stages of the experiential learning cycle, take a few minutes to practice presenting it with the group closest to you. teach them to tie a shoe using your lesson. after 5 to 10 minutes switch roles. after all groups have gone, use the following reflection questions to guide your discussion. reflection • what did you do? • what was easy to learn? • what was difficult to learn? • what did you learn? • now, what can we do with our learning? • how was it to create a lesson with the experiential learning cycle? • how could you improve your lesson for next time?  103  21st century skills  pointb/unicef/pearson/mawlamyine university  question formulation technique (qft) teac h i n g stu d en ts to ask t h e i r own q uestio n s the right question institute have developed a step-by-step process called the question formulation technique (qft). this technique helps students learn how to produce their own questions, improve them, and strategize on how to use them.  qft has been used effectively in a  to see how students can, with new  wide range of fields. in the classroom,  knowledge, set a fresh learning agenda  teachers have seen how the qft  for themselves. the technique can be  process manages to develop students’  used for all ages.  divergent (brainstorming), convergent (categorizing and prioritizing), and  students have used the qft to develop  metacognitive (reflective) thinking  science experiments, create their own  abilities in a very short period of time.  research projects, begin research on a teacher-assigned topic, prepare to  teachers can use the qft at different  write an essay, analyze a word problem,  points: to introduce students to a new  think more deeply about a challenging  unit, to assess students’ knowledge  reading assignment, prepare an  to see what they need to understand  interview, or simply get themselves  better, and even to conclude a unit  “unstuck.”  104  21st century skills  question formulation technique (qft) learning objective: to learn how to produce your own questions, improve them and strategize on how to use them. source: the right question institute/ dan rothstein & luz santana 1. produce your questions four essential rules for producing your own questions: • ask as many questions as you can. • do not stop to discuss, judge, or answer the questions. • write down every question exactly as it is stated. • change any statement into a question.  2. improve your questions • categorize the questions as closedor open-ended. • name the advantages and  disadvantages of each type of question. change questions from one type to another.  3. prioritize the questions • choose your three most important questions. • why did you choose these three as the most important?  4. next steps • how are you going to use your questions?  most significant change according to dan rothstein and luz santana, codirectors of the right question institute and authors of the book make just one change: teach students to ask their own questions: “for teachers, using the qft requires one small but significant shift in practice: students will be asking all the questions. a teacher’s role is simply to facilitate that process. this is a significant change for students as well. it may take a minimum of 45 minutes for students to go through all the steps the first time it is introduced in a classroom; but as they gain experience using the qft, teachers find that the students can run through the process very quickly, in 10 to 15 minutes, even when working in groups.  materials white/chalk board, newsprint colored paper (a4 cut into 8 pieces), and markers may be used.  the qft provides a deliberate way to help students cultivate a skill that is fundamentally important for all learning. teaching this skill in every classroom can help successful students to go deeper in their thinking and encourage struggling students to develop a new thirst for learning. their questions will have much to teach us.” for more information, check out www.rightquestion.org  105  21st century skills  pointb/unicef/pearson/mawlamyine university  c o l l a b o r at i v e learning group work  essential understanding collaborative learning is based on the idea that learning is a social process. in education, groups of students work together to solve problems, accomplish a task or create a product. collaborative learning follows a set of principles which include: learning is an active process time 25 minutes difficulty medium materials newsprint rolled and lightly taped into a 2 meter long stick, markers, newsprint or white board. 21cs focus collaboration communication critical thinking creative thinking curiosity empathy growth appreciation systems thinking  that requires a challenge and flourishes in a social setting. learners benefit when exposed to diverse viewpoints and the rich environment of collaborative learning. learners are challenged beyond the normal cognitive challenge of learning. in addition, they are challenged both socially and emotionally.  106  21st century skills  helium stick activity learning objective: to create a classroom culture as a learning system with students working together and responding to each other. how divide the class into groups of 8 people or more. each group must form two lines, facing each other and support the helium stick on their index fingers. a helium stick is a 1-2 meter long rolled up newsprint that is lightly taped together. students must keep their index fingers touching the helium stick at all times. the goal is to try to work together as a team to lower the helium stick onto the ground. this sounds easy for the team to achieve, but they will soon discover it isn’t. typically, the helium stick goes up rather than down, until the team organizes themselves. (there is no helium in the stick; it is the way the team works that makes the stick rise or fall, and it feels to the teams like there is helium in the stick.) this game can demonstrate the challenge of working together as a team.  give the teams 5-7 minutes to try to accomplish the goal. when you are finished, gather the students together to reflect and discuss. reflection • what causes difficulty with teamwork? • sometimes even the best plans do not work and we might look at the coordination between the team members. what kind of qualities does a team need to perform well especially with a difficult task like helium stick? • how do teams get better? what makes a good team? • describe a team you have been on or group that you have been part of that was especially effective. what made them so effective? how did working with that team feel? • how can collaboration and working together help as we move forward? how can we apply what we learned in the future?  107",t_dccde056f57c,other,0
c_ed766c8587ca," origami heart how do you make an origami heart? first take a square sheet of paper. fold it diagonally. make a crease along the center line. turn the paper, and fold the two corners upwards. turn it over and fold the top down, like this. then fold over the top flaps. the next fold is the most complicated. open the top flaps and fold them inwards. fold the flaps downwards on both sides. fold all four corners, like this. fold up one layer on the bottom to make a stand.",t_33be4c9ace49,other,0
c_ed06bcbfba1a,"my digital life  student information sheet  we all spend a lot of time online doing things like chatting with friends, watching videos, playing games, sharing photos. the internet is a great place to stay connected with people, learn about anything we can think of and it has transformed the way we live. as we spend so much time online it's important that we know what to do if someone is nasty to us online or shares something on the internet that upsets us or makes us feel uncomfortable. follow our quick tips below to make the most of the opportunities the internet brings:  some of the stuff you find online might offend or upset you. whether that’s a website, video, or post that you don’t agree with. it can make you feel uncomfortable to come across something you definitely didn’t want to see or didn’t feel ready for. it’s normal to feel this way: don’t forget you can always talk to an adult such as a parent, family member, friend or teacher for advice. you can also use the ‘report’ tool on social media to report posts you don’t think are appropriate. finally, remember that anyone can post things on the internet and just because something is online, it doesn’t mean it’s true.  it’s important to treat others online as you would in real life. protect your online reputation and think before you post, as once you post something online it can be very hard to get rid of. avoid sharing personal information about yourself online – things you post online could be shared publicly by anyone.  if you receive messages that hurt or upset you, this is cyberbullying. from inappropriate texts or blog posts, to sending offensive images over the internet and excluding people from group chats, cyberbullying can take a number of forms – but there are things you can do to stop it. use the block and report tools on social media sites, don’t retaliate, and tell an adult you trust. for more advice on cyberbullying visit our website: www.antibullyingpro.com/how-to-stay-safe-online.  ever been shocked by the bill for using your mobile phone or tablet? texts, downloads and apps can all add up and, if you’re on a ‘pay monthly’ contract, you might not even notice the costs mounting until it’s too late. talk to your parent or guardian about your monthly bill so that everyone’s clear what the money is being  1  my digital life  student information sheet  spent on. be aware of potential hidden costs when paying for products, in-app purchases and services directly from your device. you should also bear in mind that whilst social media sites are free to use, one of the reasons they are able to make a profit is because they have access to information about its users. other apps and services which are free may ask for your data, such as email address, name, or age to register, but sell this on to make a profit. think about the data you’re making available when you sign up to services and apps, and talk to a parent or guardian if you’re unsure.  more information www.antibullyingpro.com www.antibullyingpro.com/how-to-stay-safe-online. http://www.saferinternet.org.uk/advice-and-resources/young-people/11-19s www.vodafone.com/parents  2",t_9ee87bc8ced1,other,0
c_b80a765f979e,"in a famous lecture entitled the two cultures given in 1959, the novelist c. p. snow commented on a common intellectual attitude of the day - that true education consisted of familiarity with the humanities, literature, arts, music and classics, and that scientists were mere uncultured technicians and ignorant specialists who never read any of the great works of literature. he described how he had often been provoked by such an attitude into asking some of the self-proclaimed intellectuals if they could describe the second law of thermodynamics – a question to which he invariably received a cold and negative response. yet, he said, he was merely asking something of about the scientific equivalent of ""have you read a work of shakespeare?""  so i suggest that, if you have never read a work of shakespeare, take a break for a moment from thermodynamics, go and read a midsummer night's dream, and come back refreshed and ready to complete your well-rounded education by learning the second law of thermodynamics.  we have defined entropy in such a manner that if a quantity of heat dq is added reversibly to a system at temperature t, the increase in the entropy of the system is ds = dq/t. we also pointed out that if the heat is transferred irreversibly, ds &gt; dq/t.  now consider the following situation (figure vii.1).  an isolated system consists of two bodies, a at temperature t1 and b at temperature t2, such that t2 &gt;t1. heat will eventually be exchanged between the two bodies, and on the whole more heat will be transferred from b to a than from a to b. that is, there will be a net transference of heat, dq, from b to a. perhaps this heat is transferred by radiation. each body is sending forth numerous photons of energy, but there is, on the whole, a net flow of photons from b to a. or perhaps the two bodies are in contact, and heat is being transferred by conduction. the vibrations in the hot body are more vigorous than those in the cool body, so there will be a net transfer of heat from b to a. however, since the emission of photons in the first case, and the vibrations in the second place, are random, it will be admitted that it is not impossible that at some time more photons may move from a to b than from b to a. or, in the case of conduction, most of the atoms in a happen to be moving to the right while only a few atoms in b are moving to the left in the course of their oscillations. but, while admitting that this is in principle possible and not outside the laws of physics, it is exceedingly unlikely to happen in practice; indeed so unlikely as hardly to be taken seriously. thus, in any natural, spontaneous process, without the intervention of an external intelligence, it is almost certain that there will be a net transfer of heat from b to a. and this process, barring the most unlikely set of circumstances, is irreversible.  the hot body will lose an amount of entropy dq/t2, while the cool body will gain an amount of entropy dq/t1, which is greater than dq/t2. thus the entropy of the isolated system as a whole increases by dq/t1 − dq/t2.  from this argument, we readily conclude that any natural, spontaneous and irreversible thermodynamical processes taking place within an isolated system are likely to lead to an increase in entropy of the system. this is perhaps the simplest statement of the second law of thermodynamics.  i have used the phrase ""is likely to"", although it will be realised that in practice the possibility that the entropy might decrease in a natural process is so unlikely as to be virtually unthinkable, even though it could in principle happen without violating any fundamental laws of physics.  you could regard the universe as an isolated system. think of a solid body sitting somewhere in the universe. if the body is hot, it may spontaneously lose heat to the rest of the universe. if it is cold, it may spontaneously absorb heat from the rest of the universe. either way, during the course of a spontaneous process, the entropy of the universe increases.  the transference of heat from a hot body to a cooler body, so that both end at the same intermediate temperature, involves, in effect, the mixing of a set of fast-moving molecules and a set of slow-moving molecules. a similar situation arises if we start with a box having a partition down the middle, and on one side of the partition there is a gas of blue molecules and on the other there is a gas of red molecules. if we remove the partition, eventually the gases will mix into one homogeneous gas. by only a slight extension of the idea of entropy discussed in courses in statistical mechanics, this situation can be described as an increase of entropy – called, in fact, the entropy of mixing. if you saw two photographs, in one of which the blue and red molecules were separated, and in the other the two colours were thoroughly mixed, you would conclude that the latter photograph was probably taken later than the former. but only ""probably""; it is conceivable, within the laws of physics, that the velocities of the blue and red molecules separated themselves out without external intervention. this would be allowed perfectly well within the laws of physics. indeed, if the velocities of all the molecules in the mixed gases were to be reversed, the gases would eventually separate into their two components. but this would seem to be so unlikely as never in practice to happen. the second law says that the entropy of an isolated system is likely (very likely!) to increase with time. indeed it could be argued that the increase of entropy is the criterion that defines the direction of the arrow of time. (for more on the arrow of time, see section 15.12 of the notes on electricity and magnetism of this series. also read the article on the arrow of time by paul davis, astronomy &amp; geophysics (royal astronomical society) 46, 26 (2005). you’ll probably also enjoy h. g. wells’s the time machine.)  note that, in the example of our two bodies exchanging heat, one loses entropy while the other gains entropy; but the gain by the one is greater than the loss from the other, with the result that there is an increase in the entropy of the system as a whole. the principle of the increase of entropy applies to an isolated system.  in case you have ever wondered (who hasn’t?) how life arose on earth, you now have a puzzle. surely the genesis and subsequent evolution of life on earth represents an increase in order and complexity, and hence a decrease in the entropy of mixing. you may conclude from this that the genesis and subsequent evolution of life on earth requires divine intervention, or intelligent design, and that the second law of thermodynamics provides proof of the existence of god. or you may conclude that earth is not an isolated thermodynamical system. your choice.",t_ed08a74aadd1,other,0
c_6e7237ebf4c8,"chapter 8 | media and technology  8 media and technology  figure 8.1 facebook, twitter, and instagram are just a few examples of social media that increasingly shape how we interact with the world. (photo courtesy of khalid albaih/flickr)  155  156  chapter 8 | media and technology  learning objectives 8.1. technology today • define technology and describe its evolution • understand technological inequality and issues related to unequal access to technology • describe the role of planned obsolescence in technological development 8.2. media and technology in society • describe the evolution and current role of different media, like newspapers, television, and new media • understand the function of product advertising in media • demonstrate awareness of the social homogenization and social fragmentation that occur via modern society’s use of technology and media 8.3. global implications of media and technology • explain the advantages and concerns of media globalization • understand the globalization of technology 8.4. theoretical perspectives on media and technology • understand and discuss how we analyze media and technology through various sociological perspectives  introduction to media and technology how many good friends do you have? how many people do you meet up with for coffee or a movie? how many would you call with news about an illness or invite to your wedding? now, how many “friends” do you have on facebook? how often do you post a ""selfie"" online? how often do you check e-mail? how often do you meet friends for a meal and spend your time texting other people instead of talking to each other? technology has changed how we interact with each other. it has turned “friend” into a verb and has made it possible to share mundane news (“my dog just threw up under the bed! ugh!”) with hundreds or even thousands of people who might know you only slightly, if at all. you might be glued to your cell phone, even when you should be focused on driving your car, or you might text in class instead of listening to the professor's lecture. when we have the ability to stay constantly connected to a data stream, it is easy to lose focus on the here and now. at the same time that technology is expanding the boundaries of our social circles, various media are also changing how we perceive and interact with each other. we don’t only use facebook to keep in touch with friends; we also use it to “like” certain television shows, products, or celebrities. even television is no longer a one-way medium; it is an interactive one. we are encouraged to tweet, text, or call in to vote for contestants in everything from singing competitions to matchmaking endeavors—bridging the gap between our entertainment and our own lives. how does technology change our lives for the better? or does it? when you tweet a social cause, share an ice bucket challenge video on youtube, or cut and paste a status update about cancer awareness on facebook, are you promoting social change? does the immediate and constant flow of information mean we are more aware and engaged than any society before us? or are keeping up with the kardashians and the real housewives franchise today’s version of ancient rome’s “bread and circuses”––distractions and entertainment to keep the working classes complacent about the inequities of their society? these are some of the questions that interest sociologists. how might we examine these issues from a sociological perspective? a functionalist would probably focus on what social purposes technology and media serve. for example, the web is both a form of technology and of media, and it links individuals and nations in a communication network that facilitates both small family discussions and global trade networks. a functionalist would also be interested in the manifest functions of media and technology, as well as their role in social dysfunction. someone applying the conflict perspective would probably focus on the systematic inequality created by differential access to media and technology. for example, how can middle-class u.s. citizens be sure the news they hear is an objective account of reality, unsullied by moneyed political interests? someone applying the interactionist perspective to technology and the media might seek to understand the difference between the real lives we lead and the reality depicted on “reality” television shows, such as the bachelor. throughout this chapter, we will use our sociological imagination to explore how media and technology impact society.  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  157  8.1 technology today  figure 8.2 technology is the application of science to address the problems of daily life, from hunting tools and agricultural advances, to manual and electronic ways of computing, to today’s tablets and smartphones. (photo (a) courtesy of wikimedia commons; photo (b) courtesy of martin pettitt/ flickr; photo (c) courtesy of whitefield d./flickr; photo (d) courtesy of andrew parnell/flickr; photo (e) courtesy of jemimus/flickr; photo (f) courtesy of kārlis dambrāns/flickr)  it is easy to look at the latest sleek apple product and think technology is a recent addition to our world. but from the steam engine to the most cutting-edge robotic surgery tools, technology has described the application of science to address the problems of daily life. we might look back at the enormous and clunky computers of the 1970s that had about as much storage as an ipod shuffle and roll our eyes in disbelief. but chances are thirty years from now our skinny laptops and ipods will look just as archaic.  what is technology? while most people probably picture computers and cell phones when the subject of technology comes up, technology is not merely a product of the modern era. for example, fire and stone tools were important forms that technology developed during the stone age. just as the availability of digital technology shapes how we live today, the creation of stone tools changed how premodern humans lived and how well they ate. from the first calculator, invented in 2400 b.c.e. babylon in the form of an abacus, to the predecessor of the modern computer, created in 1882 by charles babbage, all of our technological innovations are advancements on previous iterations. and indeed, all aspects of our lives today are influenced by technology. in agriculture, the introduction of machines that can till, thresh, plant, and harvest greatly reduced the need for manual labor, which in turn meant there were fewer rural jobs. this led to the urbanization of society, as well as lowered birthrates because there was less need for large families to work the farms. in the criminal justice system, the ability to ascertain innocence through dna testing has saved the lives of people on death row. the examples are endless: technology plays a role in absolutely every aspect of our lives.  158  chapter 8 | media and technology  technological inequality  figure 8.3 some schools sport cutting-edge computer labs, while others sport barbed wire. is your academic technology at the cusp of innovation, relatively disadvantaged, or somewhere in between? (photo courtesy of carlos martinez/flickr)  as with any improvement to human society, not everyone has equal access. technology, in particular, often creates changes that lead to ever greater inequalities. in short, the gap gets wider faster. this technological stratification has led to a new focus on ensuring better access for all. there are two forms of technological stratification. the first is differential class-based access to technology in the form of the digital divide. this digital divide has led to the second form, a knowledge gap, which is, as it sounds, an ongoing and increasing gap in information for those who have less access to technology. simply put, students in well-funded schools receive more exposure to technology than students in poorly funded schools. those students with more exposure gain more proficiency, which makes them far more marketable in an increasingly technology-based job market and leaves our society divided into those with technological knowledge and those without. even as we improve access, we have failed to address an increasingly evident gap in e-readiness—the ability to sort through, interpret, and process knowledge (sciadas 2003). since the beginning of the millennium, social science researchers have tried to bring attention to the digital divide, the uneven access to technology among different races, classes, and geographic areas. the term became part of the common lexicon in 1996, when then vice president al gore used it in a speech. this was the point when personal computer use shifted dramatically, from 300,000 users in 1991 to more than 10 million users by 1996 (rappaport 2009). in part, the issue of the digital divide had to do with communities that received infrastructure upgrades that enabled high-speed internet access, upgrades that largely went to affluent urban and suburban areas, leaving out large swaths of the country. at the end of the twentieth century, technology access was also a big part of the school experience for those whose communities could afford it. early in the millennium, poorer communities had little or no technology access, while welloff families had personal computers at home and wired classrooms in their schools. in the 2000s, however, the prices for low-end computers dropped considerably, and it appeared the digital divide was naturally ending. research demonstrates that technology use and internet access still vary a great deal by race, class, and age in the united states, though most studies agree that there is minimal difference in internet use by adult men and adult women. data from the pew research center (2011) suggests the emergence of yet another divide. as technological devices gets smaller and more mobile, larger percentages of minority groups (such as latinos and african americans) are using their phones to connect to the internet. in fact, about 50 percent of people in these minority groups connect to the web via such devices, whereas only one-third of whites do (washington 2011). and while it might seem that the internet is the internet, regardless of how you get there, there’s a notable difference. tasks like updating a résumé or filling out a job application are much harder on a cell phone than on a wired computer in the home. as a result, the digital divide might mean no access to computers or the internet, but could mean access to the kind of online technology that allows for empowerment, not just entertainment (washington 2011). mossberger, tolbert, and gilbert (2006) demonstrated that the majority of the digital divide for african americans could be explained by demographic and community-level characteristics, such as socioeconomic status and geographic location. for the latino population, ethnicity alone, regardless of economics or geography, seemed to limit technology use. liff and shepard (2004) found that women, who are accessing technology shaped primarily by male users, feel less confident in their internet skills and have less internet access at both work and home. finally, guillen and suarez (2005) found that the global digital divide resulted from both the economic and sociopolitical characteristics of countries.  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  159  use of technology and social media in society by individuals do you own an e-reader or tablet? what about your parents or your friends? how often do you check social media or your cell phone? does all this technology have a positive or negative impact on your life? when it comes to cell phones, 67 percent of users check their phones for messages or calls even when the phone wasn’t ringing. in addition, “44% of cell owners have slept with their phone next to their bed because they wanted to make sure they didn’t miss any calls, text messages, or other updates during the night and 29% of cell owners describe their cell phone as ‘something they can’t imagine living without’” (smith 2012). while people report that cell phones make it easier to stay in touch, simplify planning and scheduling their daily activities, and increase their productivity, that’s not the only impact of increased cell phone ownership in the united states. smith also reports that “roughly one in five cell owners say that their phone has made it at least somewhat harder to forget about work at home or on the weekends; to give people their undivided attention; or to focus on a single task without being distracted” (smith 2012). a new survey from the pew research center reported that 73 percent of adults engage in some sort of social networking online. facebook was the most popular platform, and both facebook users and instagram users check their sites on a daily basis. over a third of users check their sites more than once a day (duggan and smith 2013). with so many people using social media both in the united states and abroad, it is no surprise that social media is a powerful force for social change. you will read more about the fight for democracy in the middle east embodied in the arab spring in chapters 17 and 21, but spreading democracy is just the tip of the iceberg when it comes to using social media to incite change. for example, mckenna pope, a thirteen-year-old girl, used the internet to successfully petition hasbro to fight gender stereotypes by creating a gender-neutral easy-bake oven instead of using only the traditional pink color (kumar 2014). meanwhile in latvia, two twenty-three-year-olds used a u.s. state department grant to create an epetition platform so citizens could submit ideas directly to the latvian government. if at least 20 percent of the latvian population (roughly 407,200 people) supports a petition, the government will look at it (kumar 2014). online privacy and security as we increase our footprints on the web by going online more often to connect socially, share material, conduct business, and store information, we also increase our vulnerability to those with criminal intent. the pew research center recently published a report that indicated the number of internet users who express concern over the extent of personal information about them available online jumped 17 percent between 2009 and 2013. in that same survey, 12 percent of respondents indicated they had been harassed online, and 11 percent indicated that personal information, such as their social security number, had been stolen (rainie, kiesler, kang, and madden 2013). online privacy and security is a key organizational concern as well. recent large-scale data breaches at retailers such as target, financial powerhouses such as jp morgan, the government health insurance site healthcare.gov, and cell phone providers such as verizon, exposed millions of people to the threat of identity theft when hackers got access to personal information by compromising website security. for example, in late august 2014, hackers breached the icloud data storage site and promptly leaked wave after wave of nude photos from the private accounts of actors such as jennifer lawrence and kirsten dunst (lewis 2014). while largescale data breaches that affect corporations and celebrities are more likely to make the news, individuals may put their personal information at risk simply by clicking a suspect link in an official sounding e-mail. how can individuals protect their data? numerous facts sheets available through the government, nonprofits, and the private sector outline common safety measures, including the following: become familiar with privacy rights; read privacy policies when making a purchase (rather than simply clicking “accept”); give out only the minimum information requested by any source; ask why information is being collected, how it is going to be used, and who will have access it; and monitor your credit history for red flags that indicate your identity has been compromised. net neutrality the issue of net neutrality, the principle that all internet data should be treated equally by internet service providers, is part of the national debate about internet access and the digital divide. on one side of this debate is the belief that those who provide internet service, like those who provide electricity and water, should be treated as common carriers, legally prohibited from discriminating based on the customer or nature of the goods. supporters of net neutrality suggest that without such legal protections, the internet could be divided into “fast” and “slow” lanes. a conflict perspective theorist might suggest that this discrimination would allow bigger corporations, such as amazon, to pay internet providers a premium for faster service, which could lead to gaining an advantage that would drive small, local competitors out of business.  160  chapter 8 | media and technology  the other side of the debate holds the belief that designating internet service providers as common carriers would constitute an unreasonable regulatory burden and limit the ability of telecommunication companies to operate profitably. a functional perspective theorist might point out that, without profits, companies would not invest in making improvements to their internet service or expanding those services to underserved areas. the final decision rests with the federal communications commission and the federal government, which must decide how to fairly regulate broadband providers without dividing the internet into haves and have-nots.  8.2 media and technology in society  figure 8.4 in the coming future, there is no doubt that robots are going to play a large role in all aspects of our lives. (photo courtesy of shay sowden/flickr)  technology and the media are interwoven, and neither can be separated from contemporary society in most core and semiperipheral nations. media is a term that refers to all print, digital, and electronic means of communication. from the time the printing press was created (and even before), technology has influenced how and where information is shared. today, it is impossible to discuss media and the ways societies communicate without addressing the fast-moving pace of technology change. twenty years ago, if you wanted to share news of your baby’s birth or a job promotion, you phoned or wrote letters. you might tell a handful of people, but you probably wouldn’t call up several hundred, including your old high school chemistry teacher, to let them know. now, you might join an online community of parents-to-be even before you announce your pregnancy via a staged instagram picture. the circle of communication is wider than ever and when we talk about how societies engage with technology, we must take media into account, and vice versa. technology creates media. the comic book you bought your daughter is a form of media, as is the movie you streamed for family night, the web site you used to order takeout, the billboard you passed on the way to pick up your food, and the newspaper you read while you were waiting for it. without technology, media would not exist, but remember, technology is more than just the media we are exposed to.  categorizing technology there is no one way of dividing technology into categories. whereas once it might have been simple to classify innovations such as machine-based or drug-based or the like, the interconnected strands of technological development mean that advancement in one area might be replicated in dozens of others. for simplicity’s sake, we will look at how the u.s. patent office, which receives patent applications for nearly all major innovations worldwide, addresses patents. this regulatory body will patent three types of innovation. utility patents are the first type. these are granted for the invention or discovery of any new and useful process, product, or machine, or for a significant improvement to existing technologies. the second type of patent is a design patent. commonly conferred in architecture and industrial design, this means someone has invented a new and original design for a manufactured product. plant patents, the final type, recognize the discovery of new plant types that can be asexually reproduced. while genetically modified food is the hotbutton issue within this category, farmers have long been creating new hybrids and patenting them. a more modern example might be food giant monsanto, which patents corn with built-in pesticide (u.s. patent and trademark office 2011).  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  161  anderson and tushman (1990) suggest an evolutionary model of technological change, in which a breakthrough in one form of technology leads to a number of variations. once those are assessed, a prototype emerges, and then a period of slight adjustments to the technology, interrupted by a breakthrough. for example, floppy disks were improved and upgraded, then replaced by zip disks, which were in turn improved to the limits of the technology and were then replaced by flash drives. this is essentially a generational model for categorizing technology, in which first-generation technology is a relatively unsophisticated jumping-off point that leads to an improved second generation, and so on.  making connections:  sociology  in the  real world  violence in media and video games: does it matter?  figure 8.5 one of the most popular video games, grand theft auto, has frequently been at the center of debate about gratuitous violence in the gaming world. (photo courtesy of meddy garnet/flickr) a glance through popular video game and movie titles geared toward children and teens shows the vast spectrum of violence that is displayed, condoned, and acted out. as a way to guide parents in their programming choices, the motion picture industry put a rating system in place in the 1960s. but new media—video games in particular—proved to be uncharted territory. in 1994, the entertainment software rating board (ersb) set a ratings system for games that addressed issues of violence, sexuality, drug use, and the like. california took it a step further by making it illegal to sell video games to underage buyers. the case led to a heated debate about personal freedoms and child protection, and in 2011, the u.s. supreme court ruled against the california law, stating it violated freedom of speech (procon 2012). children’s play has often involved games of aggression—from cowboys and indians, to cops and robbers, to fake sword fights. many articles report on the controversy surrounding the suggested link between violent video games and violent behavior. is the link real? psychologists anderson and bushman (2001) reviewed forty-plus years of research on the subject and, in 2003, determined that there are causal linkages between violent video game use and aggression. they found that children who had just played a violent video game demonstrated an immediate increase in hostile or aggressive thoughts, an increase in aggressive emotions, and physiological arousal that increased the chances of acting out aggressive behavior (anderson 2003). ultimately, repeated exposure to this kind of violence leads to increased expectations that violence is a solution, increased violent behavioral scripts, and an increased cognitive accessibility to violent behavior (anderson 2003). in short, people who play a lot of these games find it easier to imagine and access violent solutions than nonviolent ones, and they are less socialized to see violence as a negative. while these facts do not mean there is no role for video games, it should give players pause. in 2013, the american psychological association began an expansive meta-analysis of peer-reviewed research analyzing the effect of media violence. results are expected in 2014.  162  chapter 8 | media and technology  types of media and technology media and technology have evolved hand in hand, from early print to modern publications, from radio to television to film. new media emerge constantly, such as we see in the online world. print newspaper early forms of print media, found in ancient rome, were hand-copied onto boards and carried around to keep the citizenry informed. with the invention of the printing press, the way that people shared ideas changed, as information could be mass produced and stored. for the first time, there was a way to spread knowledge and information more efficiently; many credit this development as leading to the renaissance and ultimately the age of enlightenment. this is not to say that newspapers of old were more trustworthy than the weekly world news and national enquirer are today. sensationalism abounded, as did censorship that forbade any subjects that would incite the populace. the invention of the telegraph, in the mid-1800s, changed print media almost as much as the printing press. suddenly information could be transmitted in minutes. as the nineteenth century became the twentieth, u.s. publishers such as hearst redefined the world of print media and wielded an enormous amount of power to socially construct national and world events. of course, even as the media empires of william randolph hearst and joseph pulitzer were growing, print media also allowed for the dissemination of countercultural or revolutionary materials. internationally, vladimir lenin’s irksa (the spark) newspaper was published in 1900 and played a role in russia’s growing communist movement (world association of newspapers 2004). with the invention and widespread use of television in the mid-twentieth century, newspaper circulation steadily dropped off, and in the 21st century, circulation has dropped further as more people turn to internet news sites and other forms of new media to stay informed. according to the pew research center, 2009 saw an unprecedented drop in newspaper circulation––down 10.6 percent from the year before (pew 2010). this shift away from newspapers as a source of information has profound effects on societies. when the news is given to a large diverse conglomerate of people, it must maintain some level of broad-based reporting and balance in order to appeal to a broad audience and keep them subscribing. as newspapers decline, news sources become more fractured, so each segment of the audience can choose specifically what it wants to hear and what it wants to avoid. increasingly, newspapers are shifting online in an attempt to remain relevant. it is hard to tell what impact new media platforms will have on the way we receive and process information. increasingly, newspapers are shifting online in an attempt to remain relevant. it is hard to tell what impact new media platforms will have on the way we receive and process information. the pew research center’s project for excellence in journalism (2013) reported that audiences for all the major news magazines declined in 2012, though digital ad revenue increased. the same report suggested that, while newspaper circulation is holding steady at around $10 billion after years of decline, it is digital pay plans that allow newspapers to keep their heads above water, and the digital ad revenue that is increasing for news magazines is not enough to compensate for print revenue loss in newspapers. a 2014 report suggested that u.s. adults read a median of five books per year in 2013, which is about average. but are they reading traditional print or e-books? about 69 percent of people said they had read at least one printed book in the past year, versus 28 percent who said they’d read an e-book (desilver 2014). is print more effective at conveying information? in recent study, mangen, walgermo, and bronnick (2013) found that students who read on paper performed slightly better than those who read an e-book on an open-book reading comprehension exam of multiple-choice and shortanswer questions. while a meta-analysis of research by andrews (1992) seemed to confirm that people read more slowly and comprehend less when reading from screens, a meta-analysis of more recent research on this topic does not show anything definite (noyes and garland 2008). television and radio radio programming obviously preceded television, but both shaped people’s lives in much the same way. in both cases, information (and entertainment) could be enjoyed at home, with a kind of immediacy and community that newspapers could not offer. for instance, many people in the united states might remember when they saw on television or heard on the radio that the twin towers in new york city had been attacked in 2001. even though people were in their own homes, media allowed them to share these moments in real time. this same kind of separate-but-communal approach occurred with entertainment too. school-aged children and office workers gathered to discuss the previous night’s installment of a serial television or radio show. right up through the 1970s, u.s. television was dominated by three major networks (abc, cbs, and nbc) that competed for ratings and advertising dollars. the networks also exerted a lot of control over what people watched. public television, in contrast, offered an educational nonprofit alternative to the sensationalization of news spurred by the network competition for viewers and advertising dollars. those sources—pbs (public broadcasting service), the bbc (british  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  163  broadcasting company), and cbc (canadian broadcasting company)—garnered a worldwide reputation for high-quality programming and a global perspective. al jazeera, the arabic independent news station, has joined this group as a similar media force that broadcasts to people worldwide. the impact of television on u.s. society is hard to overstate. by the late 1990s, 98 percent of u.s. homes had at least one television set, and the average person watched between two and a half and five hours of television daily. all this television has a powerful socializing effect, providing reference groups while reinforcing social norms, values, and beliefs. film the film industry took off in the 1930s, when color and sound were first integrated into feature films. like television, early films were unifying for society: as people gathered in theaters to watch new releases, they would laugh, cry, and be scared together. movies also act as time capsules or cultural touchstones for society. from westerns starring the toughtalking clint eastwood to the biopic of facebook founder and harvard dropout mark zuckerberg, movies illustrate society’s dreams, fears, and experiences. while many consider hollywood the epicenter of moviemaking, india’s bollywood actually produces more films per year, speaking to the cultural aspirations and norms of indian society. increasingly, people are watching films online via netflix, hulu, amazon, and other streaming services. while most streaming video companies keep their user data secret, nielsen estimated that 38 percent of u.s. citizens accessed netflix in 2013. in 2013, google, inc. reported that youtube served 1 billion unique viewers every month—an impressive number, considering that it amounts to one-third of the estimated 3 billion accessing the internet every month (reuters 2013; international telecommunication union 2014). new media  figure 8.6 netflix, one form of new media, exchanges information in the form of dvds to users in the comfort of their own homes. (photo courtesy of marit & toomas hinnosaar/flickr)  new media encompasses all interactive forms of information exchange. these include social networking sites, blogs, podcasts, wikis, and virtual worlds. clearly, the list grows almost daily. however, there is no guarantee that the information offered is accurate. in fact, the immediacy of new media coupled with the lack of oversight means we must be more careful than ever to ensure our news is coming from accurate sources.  164  making connections:  chapter 8 | media and technology  sociology  in the  real world  planned obsolescence: technology that’s built to crash  figure 8.7 people have trouble keeping up with technological innovation. but people may not be to blame, as manufacturers intentionally develop products with short life spans. (photo courtesy of mathias f. svendsen/flickr) chances are your mobile phone company, as well as the makers of your laptop and your household appliances, are all counting on their products to fail. not too quickly, of course, or consumers wouldn't stand for it—but frequently enough that you might find that it costs far more to fix a device than to replace it with a newer model. or you find the phone company e-mails you saying that you’re eligible for a free new phone, because yours is a whopping two years old. and appliance repair people say that while they might be fixing some machines that are twenty years old, they generally aren’t fixing those that are seven years old; newer models are built to be thrown out. this strategy is called planned obsolescence, and it is the business practice of planning for a product to be obsolete or unusable from the time it is created. to some extent, planned obsolescence is a natural extension of new and emerging technologies. after all, who is going to cling to an enormous and slow desktop computer from 2000 when a few hundred dollars can buy one that is significantly faster and better? but the practice is not always so benign. the classic example of planned obsolescence is the nylon stocking. women’s stockings—once an everyday staple of women’s lives––get “runs” or “ladders” after only a few wearings. this requires the stockings to be discarded and new ones purchased. not surprisingly, the garment industry did not invest heavily in finding a rip-proof fabric; it was in manufacturers' best interest that their product be regularly replaced. those who use microsoft windows might feel that like the women who purchased endless pairs of stockings, they are victims of planned obsolescence. every time windows releases a new operating system, there are typically not many innovations in it that consumers feel they must have. however, the software programs are upwardly compatible only. this means that while the new versions can read older files, the old version cannot read the newer ones. in short order, those who have not upgraded right away find themselves unable to open files sent by colleagues or friends, and they usually wind up upgrading as well. ultimately, whether you are getting rid of your old product because you are being offered a shiny new free one (like the latest smartphone model), or because it costs more to fix than to replace (like the ipod model), or because not doing so leaves you out of the loop (like the windows model), the result is the same. it might just make you nostalgic for your old sony discman and simple dvd player.  product advertising companies use advertising to sell to us, but the way they reach us is changing. naomi klein identified the destructive impact of corporate branding her 1999 text, no logo, an antiglobalization treatise that focused on sweatshops, corporate power, and anticonsumerist social movements. in the post-millennial society, synergistic advertising practices ensure you are receiving the same message from a variety of sources and on a variety of platforms. for example, you may see billboards for miller beer on your way to a stadium, sit down to watch a game preceded by a miller commercial on the big  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  165  screen, and watch a halftime ad in which people are shown holding up the trademark bottles. chances are you can guess which brand of beer is for sale at the concession stand. advertising has changed, as technology and media have allowed consumers to bypass traditional advertising venues. from the invention of the remote control, which allows us to skip television advertising without leaving our seats, to recording devices that let us watch programs but skip the ads, conventional television advertising is on the wane. and print media is no different. advertising revenue in newspapers and on television fell significantly in 2009, which shows that companies need new ways of getting their messages to consumers. one model companies are considering to address this advertising downturn uses the same philosophy as celebrity endorsements, just on a different scale. companies are hiring college students to be their on-campus representatives, and they are looking for popular students engaged in high-profile activities like sports, fraternities, and music. the marketing team is betting that if we buy perfume because beyoncé tells us to, we’ll also choose our cell phone or smoothie brand if a popular student encourages that choice. according to an article in the new york times, fall semester 2011 saw an estimated 10,000 u.s. college students working on campus as brand ambassadors for products from red bull energy drinks to hewlett-packard computers (singer 2011). as the companies figure it, college students will trust one source of information above all: other students.  homogenization and fragmentation despite the variety of media at hand, the mainstream news and entertainment you enjoy are increasingly homogenized. research by mcmanus (1995) suggests that different news outlets all tell the same stories, using the same sources, resulting in the same message, presented with only slight variations. so whether you are reading the new york times or the cnn’s web site, the coverage of national events like a major court case or political issue will likely be the same. simultaneously with this homogenization among the major news outlets, the opposite process is occurring in the newer media streams. with so many choices, people increasingly customize their news experience, minimizing their opportunity to encounter information that does not jive with their worldview (prior 2005). for instance, those who are staunchly republican can avoid centrist or liberal-leaning cable news shows and web sites that would show democrats in a favorable light. they know to seek out fox news over msnbc, just as democrats know to do the opposite. further, people who want to avoid politics completely can choose to visit web sites that deal only with entertainment or that will keep them up to date on sports scores. they have an easy way to avoid information they do not wish to hear.  8.3 global implications of media and technology  figure 8.8 these twitter updates—a revolution in real time—show the role social media can play on the political stage. (photo courtesy of cambodia4kidsorg/flickr)  technology, and increasingly media, has always driven globalization. in a landmark book, thomas friedman (2005), identified several ways in which technology “flattened” the globe and contributed to our global economy. the first edition of the world is flat, written in 2005, posits that core economic concepts were changed by personal computing and highspeed internet. access to these two technological shifts has allowed core-nation corporations to recruit workers in call centers located in china or india. using examples like a midwestern u.s. woman who runs a business from her home via the call centers of bangalore, india, friedman warns that this new world order will exist whether core-nation businesses are ready or not, and that in order to keep its key economic role in the world, the united states will need to pay attention to how it prepares workers of the twenty-first century for this dynamic.  166  chapter 8 | media and technology  of course not everyone agrees with friedman’s theory. many economists pointed out that in reality innovation, economic activity, and population still gather in geographically attractive areas, and they continue to create economic peaks and valleys, which are by no means flattened out to mean equality for all. china’s hugely innovative and powerful cities of shanghai and beijing are worlds away from the rural squalor of the country’s poorest denizens. it is worth noting that friedman is an economist, not a sociologist. his work focuses on the economic gains and risks this new world order entails. in this section, we will look more closely at how media globalization and technological globalization play out in a sociological perspective. as the names suggest, media globalization is the worldwide integration of media through the cross-cultural exchange of ideas, while technological globalization refers to the crosscultural development and exchange of technology.  media globalization lyons (2005) suggests that multinational corporations are the primary vehicle of media globalization, and these corporations control global mass-media content and distribution (compaine 2005). it is true, when looking at who controls which media outlets, that there are fewer independent news sources as larger and larger conglomerates develop. the united states offers about 1,500 newspapers, 2,600 book publishers, and an equal number of television stations, plus 6,000 magazines and a whopping 10,000 radio outlets (bagdikian 2004). on the surface, there is endless opportunity to find diverse media outlets. but the numbers are misleading. media consolidation is a process in which fewer and fewer owners control the majority of media outlets. this creates an oligopoly in which a few firms dominate the media marketplace. in 1983, a mere 50 corporations owned the bulk of massmedia outlets. today in the united states (which has no government-owned media) just five companies control 90 percent of media outlets (mcchesney 1999). ranked by 2014 company revenue, comcast is the biggest, followed by the disney corporation, time warner, cbs, and viacom (time.com 2014). what impact does this consolidation have on the type of information to which the u.s. public is exposed? does media consolidation deprive the public of multiple viewpoints and limit its discourse to the information and opinions shared by a few sources? why does it matter? monopolies matter because less competition typically means consumers are less well served since dissenting opinions or diverse viewpoints are less likely to be found. media consolidation results in the following dysfunctions. first, consolidated media owes more to its stockholders than to the public. publicly traded fortune 500 companies must pay more attention to their profitability and to government regulators than to the public's right to know. the few companies that control most of the media, because they are owned by the power elite, represent the political and social interests of only a small minority. in an oligopoly there are fewer incentives to innovate, improve services, or decrease prices. while some social scientists predicted that the increase in media forms would create a global village (mcluhan 1964), current research suggests that the public sphere accessing the global village will tend to be rich, caucasoid, and englishspeaking (jan 2009). as shown by the spring 2011 uprisings throughout the arab world, technology really does offer a window into the news of the world. for example, here in the united states we saw internet updates of egyptian events in real time, with people tweeting, posting, and blogging on the ground in tahrir square. still, there is no question that the exchange of technology from core nations to peripheral and semi-peripheral ones leads to a number of complex issues. for instance, someone using a conflict theorist approach might focus on how much political ideology and cultural colonialism occurs with technological growth. in theory at least, technological innovations are ideology-free; a fiber optic cable is the same in a muslim country as a secular one, a communist country or a capitalist one. but those who bring technology to less-developed nations—whether they are nongovernment organizations, businesses, or governments—usually have an agenda. a functionalist, in contrast, might focus on the ways technology creates new means to share information about successful crop-growing programs, or on the economic benefits of opening a new market for cell phone use. either way, cultural and societal assumptions and norms are being delivered along with those high-speed wires. cultural and ideological bias are not the only risks of media globalization. in addition to the risk of cultural imperialism and the loss of local culture, other problems come with the benefits of a more interconnected globe. one risk is the potential for censoring by national governments that let in only the information and media they feel serve their message, as is occurring in china. in addition, core nations such as the united states risk the use of international media by criminals to circumvent local laws against socially deviant and dangerous behaviors such as gambling, child pornography, and the sex trade. offshore or international web sites allow u.s. citizens (and others) to seek out whatever illegal or illicit information they want, from twenty-four hour online gambling sites that do not require proof of age, to sites that sell child pornography. these examples illustrate the societal risks of unfettered information flow.  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  making connections:  167  the  big picture  china and the internet: an uncomfortable friendship  figure 8.9 what information is accessible to these patrons of an internet café in china? what is censored from their view? (photo courtesy of kai hendry/flickr) in the united states, the internet is used to access illegal gambling and pornography sites, as well as to research stocks, crowd-source what car to buy, or keep in touch with childhood friends. can we allow one or more of those activities, while restricting the rest? and who decides what needs restricting? in a country with democratic principles and an underlying belief in free-market capitalism, the answer is decided in the court system. but globally, the questions––and the government’s responses––are very different. china is in many ways the global poster child for the uncomfortable relationship between internet freedom and government control. china, which is a country with a tight rein on the dissemination of information, has long worked to suppress what it calls “harmful information,” including dissent concerning government politics, dialogue about china’s role in tibet, or criticism of the government’s handling of events. with sites like twitter, facebook, and youtube blocked in china, the nation’s internet users––some 500 million strong in 2011––turn to local media companies for their needs. renren.com is china’s answer to facebook. perhaps more importantly from a social-change perspective, sina weibo is china’s version of twitter. microblogging, or weibo, acts like twitter in that users can post short messages that can be read by their subscribers. and because these services move so quickly and with such wide scope, it is difficult for government overseers to keep up. this tool was used to criticize government response to a deadly rail crash and to protest a chemical plant. it was also credited with the government’s decision to report more accurately on the air pollution in beijing, which occurred after a highprofile campaign by a well-known property developer (pierson 2012). there is no question of china’s authoritarian government ruling over this new form of internet communication. the nation blocks the use of certain terms, such as human rights, and passes new laws that require people to register with their real names and make it more dangerous to criticize government actions. indeed, fifty-six-year-old microblogger wang lihong was recently sentenced to nine months in prison for “stirring up trouble,” as her government described her work helping people with government grievances (bristow 2011). but the government cannot shut down this flow of information completely. foreign companies, seeking to engage with the increasingly important chinese consumer market, have their own accounts: the nba has more than 5 million followers, and tom cruise’s weibo account boasts almost 3 million followers (zhang 2011). the government, too, uses weibo to get its own message across. as the millennium progresses, china’s approach to social media and the freedoms it offers will be watched anxiously––on sina weibo and beyond––by the rest of the world.  technological globalization technological globalization is speeded in large part by technological diffusion, the spread of technology across borders. in the last two decades, there has been rapid improvement in the spread of technology to peripheral and semi-peripheral nations, and a 2008 world bank report discusses both the benefits and ongoing challenges of this diffusion. in general, the  168  chapter 8 | media and technology  report found that technological progress and economic growth rates were linked, and that the rise in technological progress has helped improve the situations of many living in absolute poverty (world bank 2008). the report recognizes that rural and low-tech products such as corn can benefit from new technological innovations, and that, conversely, technologies like mobile banking can aid those whose rural existence consists of low-tech market vending. in addition, technological advances in areas like mobile phones can lead to competition, lowered prices, and concurrent improvements in related areas such as mobile banking and information sharing. however, the same patterns of social inequality that create a digital divide in the united states also create digital divides within peripheral and semi-peripheral nations. while the growth of technology use among countries has increased dramatically over the past several decades, the spread of technology within countries is significantly slower among peripheral and semi-peripheral nations. in these countries, far fewer people have the training and skills to take advantage of new technology, let alone access it. technological access tends to be clustered around urban areas and leaves out vast swaths of peripheral-nation citizens. while the diffusion of information technologies has the potential to resolve many global social problems, it is often the population most in need that is most affected by the digital divide. for example, technology to purify water could save many lives, but the villages in peripheral nations most in need of water purification don’t have access to the technology, the funds to purchase it, or the technological comfort level to introduce it as a solution.  making connections:  sociology  in the  real world  the mighty cell phone: how mobile phones are impacting sub-saharan africa many of africa’s poorest countries suffer from a marked lack of infrastructure including poor roads, limited electricity, and minimal access to education and telephones. but while landline use has not changed appreciably during the past ten years, there’s been a fivefold increase in mobile phone access; more than a third of people in subsaharan africa have the ability to access a mobile phone (katine 2010). even more can use a “village phone”—through a shared-phone program created by the grameen foundation. with access to mobile phone technology, a host of benefits become available that have the potential to change the dynamics in these poorest nations. sometimes that change is as simple as being able to make a phone call to neighboring market towns. by finding out which markets have vendors interested in their goods, fishers and farmers can ensure they travel to the market that will serve them best and avoid a wasted trip. others can use mobile phones and some of the emerging money-sending systems to securely send money to a family member or business partner elsewhere (katine 2010). these shared-phone programs are often funded by businesses like germany’s vodafone or britain’s masbabi, which hope to gain market share in the region. phone giant nokia points out that there are 4 billion mobile phone users worldwide—that’s more than twice as many people as have bank accounts—meaning there is ripe opportunity to connect banking companies with people who need their services (itu telecom 2009). not all access is corporatebased, however. other programs are funded by business organizations that seek to help peripheral nations with tools for innovation and entrepreneurship. but this wave of innovation and potential business comes with costs. there is, certainly, the risk of cultural imperialism, and the assumption that core nations (and core-nation multinationals) know what is best for those struggling in the world’s poorest communities. whether well intentioned or not, the vision of a continent of africans successfully chatting on their iphone may not be ideal. like all aspects of global inequity, access to technology in africa requires more than just foreign investment. there must be a concerted effort to ensure the benefits of technology get to where they are needed most.  8.4 theoretical perspectives on media and technology it is difficult to conceive of any one theory or theoretical perspective that can explain the variety of ways in which people interact with technology and the media. technology runs the gamut from the match you strike to light a candle all the way up to sophisticated nuclear power plants that might power the factory where that candle was made. media could refer to the television you watch, the ads wrapping the bus you take to work or school, or the magazines you flip through in a dentist's waiting room, not to mention all the forms of new media, including instagram, facebook, blogs, youtube, and the like. are media and technology critical to the forward march of humanity? are they pernicious capitalist tools that lead  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  169  to the exploitation of workers worldwide? are they the magic bullet the world has been waiting for to level the playing field and raise the world’s poor out of extreme poverty? choose any opinion and you will find studies and scholars who agree with you––and those who disagree.  functionalism because functionalism focuses on how media and technology contribute to the smooth functioning of society, a good place to begin understanding this perspective is to write a list of functions you perceive media and technology to perform. your list might include the ability to find information on the internet, television’s entertainment value, or how advertising and product placement contribute to social norms. commercial function  figure 8.10 tv commercials can carry significant cultural currency. for some, the ads during the super bowl are more water cooler-worthy than the game itself. (photo courtesy of dennis yang/flickr)  as you might guess, with nearly every u.s. household possessing a television, and the 250 billion hours of television watched annually by people in the united states, companies that wish to connect with consumers find television an irresistible platform to promote their goods and services (nielsen 2012). television advertising is a highly functional way to meet a market demographic where it lives. sponsors can use the sophisticated data gathered by network and cable television companies regarding their viewers and target their advertising accordingly. whether you are watching cartoons on nick jr. or a cooking show on telemundo, chances are advertisers have a plan to reach you. and it certainly doesn’t stop with television. commercial advertising precedes movies in theaters and shows up on and inside public transportation, as well as on the sides of building and roadways. major corporations such as coca-cola bring their advertising into public schools, by sponsoring sports fields or tournaments, as well as filling the halls and cafeterias of those schools with vending machines hawking their goods. with rising concerns about childhood obesity and attendant diseases, the era of soda machines in schools may be numbered. in fact, as part of the united states department of agriculture's healthy, hunger free kids act and michelle obama's let's move! initiative, a ban on junk food in school began in july 2014. entertainment function an obvious manifest function of media is its entertainment value. most people, when asked why they watch television or go to the movies, would answer that they enjoy it. and the numbers certainly illustrate that. while 2012 nielsen research shows a slight reduction of u.s. homes with televisions, the reach of television is still vast. and the amount of time spent watching is equally large. clearly, enjoyment is paramount. on the technology side, as well, there is a clear entertainment  170  chapter 8 | media and technology  factor to the use of new innovations. from online gaming to chatting with friends on facebook, technology offers new and more exciting ways for people to entertain themselves. social norm functions even while the media is selling us goods and entertaining us, it also serves to socialize us, helping us pass along norms, values, and beliefs to the next generation. in fact, we are socialized and resocialized by media throughout our whole lives. all forms of media teach us what is good and desirable, how we should speak, how we should behave, and how we should react to events. media also provide us with cultural touchstones during events of national significance. how many of your older relatives can recall watching the explosion of the space shuttle challenger on television? how many of those reading this textbook followed the events of september 11 or hurricane katrina on television or the internet? just as in anderson and bushman's (2011) evidence in the violence in media and video games: does it matter? feature, debate still exists over the extent and impact of media socialization. one recent study (krahe et al. 2011) demonstrated that violent media content does have a desensitizing affect and is correlated with aggressive thoughts. another group of scholars (gentile, mathieson, and crick 2011) found that among children exposure to media violence led to an increase in both physical and relational aggression. yet, a meta-analysis study covering four decades of research (savage 2003) could not establish a definitive link between viewing violence and committing criminal violence. it is clear from watching people emulate the styles of dress and talk that appear in media that media has a socializing influence. what is not clear, despite nearly fifty years of empirical research, is how much socializing influence the media has when compared to other agents of socialization, which include any social institution that passes along norms, values, and beliefs (such as peers, family, religious institutions, and the like). life-changing functions like media, many forms of technology do indeed entertain us, provide a venue for commercialization, and socialize us. for example, some studies suggest the rising obesity rate is correlated with the decrease in physical activity caused by an increase in use of some forms of technology, a latent function of the prevalence of media in society (kautiainen et al. 2011). without a doubt, a manifest function of technology is to change our lives, sometimes for the better and sometimes for the worse. think of how the digital age has improved the ways we communicate. have you ever used skype or another webcast to talk to a friend or family member far away? or maybe you have organized a fund drive, raising thousands of dollars, all from your desk chair. of course, the downside to this ongoing information flow is the near impossibility of disconnecting from technology that leads to an expectation of constant convenient access to information and people. such a fast-paced dynamic is not always to our benefit. some sociologists assert that this level of media exposure leads to narcotizing dysfunction, a result in which people are too overwhelmed with media input to really care about the issue, so their involvement becomes defined by awareness instead of by action (lazerfeld and merton 1948).  conflict perspective in contrast to theories in the functional perspective, the conflict perspective focuses on the creation and reproduction of inequality—social processes that tend to disrupt society rather than contribute to its smooth operation. when we take a conflict perspective, one major focus is the differential access to media and technology embodied in the digital divide. conflict theorists also look at who controls the media, and how media promotes the norms of upper-middle-class white people in the united states while minimizing the presence of the working class, especially people of color. control of media and technology powerful individuals and social institutions have a great deal of influence over which forms of technology are released, when and where they are released, and what kind of media is available for our consumption, which is a form of gatekeeping. shoemaker and voss (2009) define gatekeeping as the sorting process by which thousands of possible messages are shaped into a mass media-appropriate form and reduced to a manageable amount. in other words, the people in charge of the media decide what the public is exposed to, which, as c. wright mills (1956) famously noted, is the heart of media’s power. take a moment to think of the way “new media” evolve and replace traditional forms of hegemonic media. with hegemonic media, a culturally diverse society can be dominated by one race, gender, or class that manipulates the media to impose its worldview as a societal norm. new media weakens the gatekeeper role in information distribution. popular sites such as youtube and facebook not only allow more people to freely share information but also engage in a form of self-policing. users are encouraged to report inappropriate behavior that moderators will then address. in addition, some conflict theorists suggest that the way u.s. media are generated results in an unbalanced political arena. those with the most money can buy the most media exposure, run smear campaigns against their competitors, and maximize their visual presence. almost a year before the 2012 u.s. presidential election, the candidates––barack obama  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  171  for the democrats and numerous republican contenders––had raised more than $186 million (carmi et al. 2012). some would say that the citizens united vs. federal election committee is a major contributing factor to our unbalanced political arena. in citizens united, the supreme court affirmed the right of outside groups, including super political action committees (superpacs) with undisclosed donor lists, to spend unlimited amounts of money on political ads as long as they don't coordinate with the candidate's campaign or specifically advocate for a candidate. what do you think a conflict perspective theorist would suggest about the potential for the non-rich to be heard in politics, especially when superpacs ensure that the richest groups have the most say? technological social control and digital surveillance social scientists take the idea of the surveillance society so seriously that there is an entire journal devoted to its study, surveillance and society. the panoptic surveillance envisioned by jeremy bentham, depicted in the form of an allpowerful, all-seeing government by george orwell in 1984, and later analyzed by michel foucault (1975) is increasingly realized in the form of technology used to monitor our every move. this surveillance was imagined as a form of constant monitoring in which the observation posts are decentralized and the observed is never communicated with directly. today, digital security cameras capture our movements, observers can track us through our cell phones, and police forces around the world use facial-recognition software. feminist perspective  figure 8.11 what types of women are we exposed to in the media? some would argue that the range of female images is misleadingly narrow. (photo courtesy of cliff1066/flickr)  take a look at popular television shows, advertising campaigns, and online game sites. in most, women are portrayed in a particular set of parameters and tend to have a uniform look that society recognizes as attractive. most are thin, white or light-skinned, beautiful, and young. why does this matter? feminist perspective theorists believe this idealized image is crucial in creating and reinforcing stereotypes. for example, fox and bailenson (2009) found that online female avatars conforming to gender stereotypes enhance negative attitudes toward women, and brasted (2010) found that media (advertising in particular) promotes gender stereotypes. as early as 1990, ms. magazine instituted a policy to publish without any commercial advertising. the gender gap in tech-related fields (science, technology, engineering, and math) is no secret. a 2011 u.s. department of commerce report suggested that gender stereotyping is one reason for this gap which acknowledges the bias toward men as keepers of technological knowledge (us department of commerce 2011). but gender stereotypes go far beyond the use of technology. press coverage in the media reinforces stereotypes that subordinate women; it gives airtime to looks over skills, and coverage disparages women who defy accepted norms. recent research in new media has offered a mixed picture of its potential to equalize the status of men and women in the arenas of technology and public discourse. a european agency, the advisory committee on equal opportunities for men and women (2010), issued an opinion report suggesting that while there is the potential for new media forms to perpetuate  172  chapter 8 | media and technology  gender stereotypes and the gender gap in technology and media access, at the same time new media could offer alternative forums for feminist groups and the exchange of feminist ideas. still, the committee warned against the relatively unregulated environment of new media and the potential for antifeminist activities, from pornography to human trafficking, to flourish there. increasingly prominent in the discussion of new media and feminism is cyberfeminism, the application to, and promotion of, feminism online. research on cyberfeminism runs the gamut from the liberating use of blogs by women living in iraq during the second gulf war (peirce 2011) to an investigation of the suicide girls web site (magnet 2007).  symbolic interactionism technology itself may act as a symbol for many. the kind of computer you own, the kind of car you drive, your ability to afford the latest apple product—these serve as a social indicator of wealth and status. neo-luddites are people who see technology as symbolizing the coldness and alienation of modern life. but for technophiles, technology symbolizes the potential for a brighter future. for those adopting an ideological middle ground, technology might symbolize status (in the form of a massive flat-screen television) or failure (ownership of a basic old mobile phone with no bells or whistles). social construction of reality meanwhile, media create and spread symbols that become the basis for our shared understanding of society. theorists working in the interactionist perspective focus on this social construction of reality, an ongoing process in which people subjectively create and understand reality. media constructs our reality in a number of ways. for some, the people they watch on a screen can become a primary group, meaning the small informal groups of people who are closest to them. for many others, media becomes a reference group: a group that influences an individual and to which an individual compares himself or herself, and by which we judge our successes and failures. we might do very well without the latest smartphone, until we see characters using it on our favorite television show or our classmates whipping it out between classes. while media may indeed be the medium to spread the message of rich white males, gamson, croteau, hoynes, and sasson (1992) point out that some forms of media discourse allow competing constructions of reality to appear. for example, advertisers find new and creative ways to sell us products we don’t need and probably wouldn’t want without their prompting, but some networking sites such as freecycle offer a commercial-free way of requesting and trading items that would otherwise be discarded. the web is also full of blogs chronicling lives lived “off the grid,” or without participation in the commercial economy. social networking and social construction while tumblr and facebook encourage us to check in and provide details of our day through online social networks, corporations can just as easily promote their products on these sites. even supposedly crowd-sourced sites like yelp (which aggregates local reviews) are not immune to corporate shenanigans. that is, we think we are reading objective observations when in reality we may be buying into one more form of advertising. facebook, which started as a free social network for college students, is increasingly a monetized business, selling you goods and services in subtle ways. but chances are you don’t think of facebook as one big online advertisement. what started out as a symbol of coolness and insider status, unavailable to parents and corporate shills, now promotes consumerism in the form of games and fandom. for example, think of all the money spent to upgrade popular facebook games like candy crush. and notice that whenever you become a “fan,” you likely receive product updates and special deals that promote online and real-world consumerism. it is unlikely that millions of people want to be “friends” with pampers. but if it means a weekly coupon, they will, in essence, rent out space on their facebook pages for pampers to appear. thus, we develop both new ways to spend money and brand loyalties that will last even after facebook is considered outdated and obsolete.  chapter review key terms cyberfeminism: the application to and promotion of feminism online design patents: patents that are granted when someone has invented a new and original design for a manufactured product  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  173  digital divide: the uneven access to technology around race, class, and geographic lines e-readiness: the ability to sort through, interpret, and process digital knowledge evolutionary model of technological change: a breakthrough in one form of technology that leads to a number of variations, from which a prototype emerges, followed by a period of slight adjustments to the technology, interrupted by a breakthrough gatekeeping: the sorting process by which thousands of possible messages are shaped into a mass media-appropriate form and reduced to a manageable amount knowledge gap: the gap in information that builds as groups grow up without access to technology media: all print, digital, and electronic means of communication media consolidation: a process by which fewer and fewer owners control the majority of media outlets media globalization: the worldwide integration of media through the cross-cultural exchange of ideas neo-luddites: those who see technology as a symbol of the coldness of modern life net neutrality: the principle that all internet data should be treated equally by internet service providers new media: all interactive forms of information exchange oligopoly: a situation in which a few firms dominate a marketplace panoptic surveillance: a form of constant monitoring in which the observation posts are decentralized and the observed is never communicated with directly planned obsolescence: the act of a technology company planning for a product to be obsolete or unable from the time it’s created plant patents: patents that recognize the discovery of new plant types that can be asexually reproduced technological diffusion: the spread of technology across borders technological globalization: the cross-cultural development and exchange of technology technology: the application of science to solve problems in daily life technophiles: those who see technology as symbolizing the potential for a brighter future utility patents: patents that are granted for the invention or discovery of any new and useful process, product, or machine  section summary 8.1 technology today technology is the application of science to address the problems of daily life. the fast pace of technological advancement means the advancements are continuous, but that not everyone has equal access. the gap created by this unequal access has been termed the digital divide. the knowledge gap refers to an effect of the digital divide: the lack of knowledge or information that keeps those who were not exposed to technology from gaining marketable skills  8.2 media and technology in society media and technology have been interwoven from the earliest days of human communication. the printing press, the telegraph, and the internet are all examples of their intersection. mass media have allowed for more shared social experiences, but new media now create a seemingly endless amount of airtime for any and every voice that wants to be heard. advertising has also changed with technology. new media allow consumers to bypass traditional advertising venues and cause companies to be more innovative and intrusive as they try to gain our attention.  174  chapter 8 | media and technology  8.3 global implications of media and technology technology drives globalization, but what that means can be hard to decipher. while some economists see technological advances leading to a more level playing field where anyone anywhere can be a global contender, the reality is that opportunity still clusters in geographically advantaged areas. still, technological diffusion has led to the spread of more and more technology across borders into peripheral and semi-peripheral nations. however, true technological global equality is a long way off.  8.4 theoretical perspectives on media and technology there are myriad theories about how society, technology, and media will progress. functionalism sees the contribution that technology and media provide to the stability of society, from facilitating leisure time to increasing productivity. conflict theorists are more concerned with how technology reinforces inequalities among communities, both within and among countries. they also look at how media typically give voice to the most powerful, and how new media might offer tools to help those who are disenfranchised. symbolic interactionists see the symbolic uses of technology as signs of everything from a sterile futuristic world to a successful professional life.  section quiz 8.1 technology today 1. jerome is able to use the internet to select reliable sources for his research paper, but charlie just copies large pieces of web pages and pastes them into his paper. jerome has _____________ while charlie does not. a. a functional perspective b. the knowledge gap c. e-readiness d. a digital divide 2. the ________ can be directly attributed to the digital divide, because differential ability to access the internet leads directly to a differential ability to use the knowledge found on the internet. a. digital divide b. knowledge gap c. feminist perspective d. e-gap 3. the fact that your cell phone is using outdated technology within a year or two of purchase is an example of ____________. a. the conflict perspective b. conspicuous consumption c. media d. planned obsolescence 4. the history of technology began _________. a. in the early stages of human societies b. with the invention of the computer c. during the renaissance d. during the nineteenth century  8.2 media and technology in society 5. when it comes to technology, media, and society, which of the following is true? a. media can influence technology, but not society. b. technology created media, but society has nothing to do with these. c. technology, media, and society are bound and cannot be separated. d. society influences media but is not connected to technology. 6. if the u.s. patent office were to issue a patent for a new type of tomato that tastes like a jellybean, it would be issuing a _________ patent? a. utility patent b. plant patent c. design patent d. the u.s. patent office does not issue a patent for plants.  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  175  7. which of the following is the primary component of the evolutionary model of technological change? a. technology should not be subject to patenting. b. technology and the media evolve together. c. technology can be traced back to the early stages of human society. d. a breakthrough in one form of technology leads to a number of variations, and technological developments. 8. which of the following is not a form of new media? a. the cable television program dexter b. wikipedia c. facebook d. a cooking blog written by rachael ray 9. research regarding video game violence suggests that _________. a. boys who play violent video games become more aggressive, but girls do not b. girls who play violent video games become more aggressive, but boys do not c. violent video games have no connection to aggressive behavior d. violent video games lead to an increase in aggressive thought and behavior 10. comic books, wikipedia, mtv, and a commercial for coca-cola are all examples of: a. media b. symbolic interaction perspective c. e-readiness d. the digital divide  8.3 global implications of media and technology 11. when japanese scientists develop a new vaccine for swine flu and offer that technology to u.s. pharmaceutical companies, __________ has taken place. a. media globalization b. technological diffusion c. monetizing d. planned obsolescence 12. in the mid-90s, the u.s. government grew concerned that microsoft was a _______________, exercising disproportionate control over the available choices and prices of computers. a. monopoly b. conglomerate c. oligopoly d. technological globalization 13. the movie babel featured an international cast and was filmed on location in various nations. when it screened in theaters worldwide, it introduced a number of ideas and philosophies about cross-cultural connections. this might be an example of: a. technology b. conglomerating c. symbolic interaction d. media globalization 14. which of the following is not a risk of media globalization? a. the creation of cultural and ideological biases b. the creation of local monopolies c. the risk of cultural imperialism d. the loss of local culture 15. the government of __________ blocks citizens’ access to popular new media sites like facebook, youtube, and twitter. a. china b. india c. afghanistan d. australia  8.4 theoretical perspectives on media and technology 16. a parent secretly monitoring the babysitter through the use of gps, site blocker, and nanny cam is a good example of:  176  chapter 8 | media and technology  a. b. c. d.  the social construction of reality technophilia a neo-luddite panoptic surveillance  17. the use of facebook to create an online persona by only posting images that match your ideal self exemplifies the_____________ that can occur in forms of new media. a. social construction of reality b. cyberfeminism c. market segmentation d. referencing 18. _________ tend to be more pro-technology, while _______ view technology as a symbol of the coldness of modern life. a. luddites; technophiles b. technophiles; luddites c. cyberfeminists; technophiles d. liberal feminists; conflict theorists 19. when it comes to media and technology, a functionalist would focus on: a. the symbols created and reproduced by the media b. the association of technology and technological skill with men c. the way that various forms of media socialize users d. the digital divide between the technological haves and have-nots 20. when all media sources report a simplified version of the environmental impact of hydraulic fracturing, with no effort to convey the hard science and complicated statistical data behind the story, ___________ is probably occurring. a. gatekeeping b. the digital divide c. technophilia d. market segmentation  short answer 8.1 technology today 1. can you think of people in your own life who support or defy the premise that access to technology leads to greater opportunities? how have you noticed technology use and opportunity to be linked, or does your experience contradict this idea? 2. should the u.s. government be responsible for providing all citizens with access to the internet? or is gaining internet access an individual responsibility? 3. how have digital media changed social interactions? do you believe it has deepened or weakened human connections? defend your answer. 4. conduct sociological research. google yourself. how much information about you is available to the public? how many and what types of companies offer private information about you for a fee? compile the data and statistics you find. write a paragraph or two about the social issues and behaviors you notice.  8.2 media and technology in society 5. where and how do you get your news? do you watch network television? read the newspaper? go online? how about your parents or grandparents? do you think it matters where you seek out information? why, or why not? 6. do you believe new media allows for the kind of unifying moments that television and radio programming used to? if so, give an example. 7. where are you most likely to notice advertisements? what causes them to catch your attention?  8.3 global implications of media and technology 8. do you believe that technology has indeed flattened the world in terms of providing opportunity? why, or why not? give examples to support your reason.  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  177  9. where do you get your news? is it owned by a large conglomerate (you can do a web search and find out!)? does it matter to you who owns your local news outlets? why, or why not? 10. who do you think is most likely to bring innovation and technology (like cell phone businesses) to sub-saharan africa: nonprofit organizations, governments, or businesses? why?  8.4 theoretical perspectives on media and technology 11. contrast a functionalist viewpoint of digital surveillance with a conflict perspective viewpoint. 12. in what ways has the internet affected how you view reality? explain using a symbolic interactionist perspective. 13. describe how a cyberfeminist might address the fact that powerful female politicians are often demonized in traditional media. 14. the issue of airplane-pilot exhaustion is an issue of growing media concern. select a theoretical perspective, and describe how it would explain this. 15. would you characterize yourself as a technophile or a luddite? explain, and use examples.  further research 8.1 technology today to learn more about the digital divide and why it matters, check out these web sites: http://openstaxcollege.org/l/ digital_divide (http://openstaxcollege.org/l/digital_divide) and http://openstaxcollege.org/l/digital_divide2 (http://openstaxcollege.org/l/digital_divide2) to find out more about internet privacy and security, check out the web site below: http://openstaxcollege.org/l/2eprivacy (http://openstaxcollege.org/l/2eprivacy)  8.2 media and technology in society to get a sense of the timeline of technology, check out this web site: http://openstaxcollege.org/l/tech_history (http://openstaxcollege.org/l/tech_history) to learn more about new media, click here: http://openstaxcollege.org/l/new_media (http://openstaxcollege.org/l/ new_media) to understand how independent media coverage differs from major corporate affiliated news outlets, review material from the democracy now! website: http://openstaxcollege.org/l/2edemonow (http://openstaxcollege.org/l/2edemonow)  8.3 global implications of media and technology check out more on the global digital divide here: http://openstaxcollege.org/l/global_digital_divide (http://openstaxcollege.org/l/global_digital_divide)  8.4 theoretical perspectives on media and technology to learn more about cyberfeminism, check out the interdisciplinary artist collective, subrosa: http://openstaxcollege.org/l/ cyberfeminism (http://openstaxcollege.org/l/cyberfeminism/) to explore the implications of panoptic surveillance, review some surveillance studies at the free, open source surveillance and society site: http://openstaxcollege.org/l/surveillance (http://openstaxcollege.org/l/surveillance) read an example of socialist media from jacobin magazine here: http://openstaxcollege.org/l/2ejacobin (http://openstaxcollege.org/l/2ejacobin)  references 8.1 technology today guillen, m.f., and s.l. suárez. 2005. “explaining the global digital divide: economic, political and sociological drivers of cross-national internet use.” social forces 84:681–708. lewis, dave. 2014. ""icloud data breach: hacking and celebrity photos."" forbes.com. forbes. retrieved october 6, 2014 (http%3a%2f%2fwww.sans.org%2freading-room%2fwhitepapers%2fcasestudies%2fcase-study-critical-controls-  178  chapter 8 | media and technology  prevented-target-breach-35412 (http://cnx.org/content/m52846/1.7/http%3a%2f%2fwww.sans.org%2freadingroom%2fwhitepapers%2fcasestudies%2fcase-study-critical-controls-prevented-target-breach-35412) ). liff, sondra, and adrian shepard. 2004. “an evolving gender digital divide.” oxford internet institute, internet issue brief no. 2. retrieved january 11, 2012 (educ.ubc.ca/faculty/bryson/565/genderdigdiv.pdf). mcchesney, robert. 1999. rich media, poor democracy: communication politics in dubious times. urbana and chicago: university of illinois press. mossberger, karen, caroline tolbert, and michele gilbert. 2006. “race, place, and information technology.” urban affairs review 41:583–620. pew research center. 2011. “demographics of internet users.” pew internet and american life project, may. retrieved january 12, 2012 (http://www.pewinternet.org/trend-data/whos-online.aspx (http://www.pewinternet.org/trend-data/ whos-online.aspx) ). “planned obsolescence.” 2009. the economist, march 23. retrieved january 12, 2012 (http://www.economist.com/node/ 13354332 (http://www.economist.com/node/13354332) ). rainie, lee, sara kiesler, ruogo kang, and mary madden. 2013. ""anonymity, privacy, and security online."" pew research centers internet american life project rss. pew research center. retrieved october 5, 2014 (http://www.pewinternet.org/2013/09/05/anonymity-privacy-and-security-online/ (http://www.pewinternet.org/2013/09/05/ anonymity-privacy-and-security-online/) ). rappaport, richard. 2009. “a short history of the digital divide.” edutopia, october 27. retrieved january 10, 2012 ( http://www.edutopia.org/digital-generation-divide-connectivity (http://www.edutopia.org/digital-generation-divideconnectivity) ). sciadas, george. 2003. “monitoring the digital divide … and beyond.” world bank group. retrieved january 22, 2012 (http://www.infodev.org/en/publication.20.html (http://www.infodev.org/en/publication.20.html) ). smith, aaron. 2012. ""the best (and worst) of mobile connectivity."" pew research internet project. retrieved december 19, 2014 (http://www.pewinternet.org/2012/11/30/the-best-and-worst-of-mobile-connectivity/ (http://www.pewinternet.org/2012/11/30/the-best-and-worst-of-mobile-connectivity/) ). time.com. 2014. ""rankings."" fortune. time.com. retreived october 1, 2014 (http://fortune.com/rankings/ (http://fortune.com/rankings/) ). washington, jesse. 2011. “for minorities, new ‘digital divide’ seen.” pew internet and american life project, january 10. retrieved january 12, 2012 (http://www.pewinternet.org/media-mentions/2011/for-minorities-new-digital-divideseen.aspx (http://www.pewinternet.org/media-mentions/2011/for-minorities-new-digital-divide-seen.aspx) ).  8.2 media and technology in society anderson, c.a., and b.j. bushman. 2001. “effects of violent video games on aggressive behavior, aggressive cognition, aggressive affect, physiological arousal, and prosocial behavior: a meta-analytic review of the scientific literature.” psychological science 12:353–359. anderson, craig. 2003. “violent video games: myths, facts and unanswered questions.” american psychological association, october. retrieved january 13, 2012 (http://www.apa.org/science/about/psa/2003/10/anderson.aspx (http://www.apa.org/science/about/psa/2003/10/anderson.aspx) ). anderson, philip, and michael tushman. 1990. “technological discontinuities and dominant designs: a cyclical model of technological change.” administrative science quarterly 35:604–633. dillon, andrew. 1992. “reading from paper versus screens: a critical review of the empirical literature.” ergonomics 35(10): 1297–1326. desilver, drew. 2014. “overall book readership stable, but e-books becoming more popular.” pew research center. retrieved december 5, 2014 (http://www.pewresearch.org/fact-tank/2014/01/21/overall-book-readership-stable-but-ebooks-becoming-more-popular/ (http://www.pewresearch.org/fact-tank/2014/01/21/overall-book-readership-stable-but-ebooks-becoming-more-popular/) ). duggan, maeve, and aaron smith. ""social media update 2013."" pew research centers internet american life project rss. pew research center. retrieved october 2, 2014 (http://www.pewinternet.org/2013/12/30/social-mediaupdate-2013/ (http://www.pewinternet.org/2013/12/30/social-media-update-2013/) ).  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  179  international telecommunication unions. 2014. “the world in 2014: ict facts and figures.” united nations. retrieved december 5, 2014 (http://www.itu.int/en/itu-d/statistics/documents/facts/ictfactsfigures2014-e.pdf (http://www.itu.int/en/itu-d/statistics/documents/facts/ictfactsfigures2014-e.pdf) ). jansen, jim. ""use of the internet in higher-income households."" pew research centers internet american life project rss. pew research center. retrieved october 1, 2014 (http://www.pewinternet.org/2010/11/24/use-of-the-internet-inhigher-income-households (http://www.pewinternet.org/2010/11/24/use-of-the-internet-in-higher-income-households) ). kumar, ravi. 2014. ""social media and social change: how young people are tapping into technology."" youthink! n.p. retrieved october 3, 2014 (http://blogs.worldbank.org/youthink/social-media-and-social-change-how-young-people-aretapping-technology (http://blogs.worldbank.org/youthink/social-media-and-social-change-how-young-people-are-tappingtechnology) ). lievrouw, leah a., and sonia livingstone, eds. 2006. handbook of new media: social shaping and social consequences. london : sage publications. mcmanus, john. 1995. “a market-based model of news production.” communication theory 5:301–338. mangen, a., b.r. walgermo, and k. bronnick. 2013. “reading linear texts on paper versus computer screen: effects on reading comprehension.” international journal of educational research 58 :61–68. nielsen. 2013. “'bingeing’ in the new viewing for over-the-top-streamers.” retrieved december 5, 2014 (http://www.nielsen.com/us/en/insights/news/2013/binging-is-the-new-viewing-for-over-the-top-streamers.html (http://www.nielsen.com/us/en/insights/news/2013/binging-is-the-new-viewing-for-over-the-top-streamers.html) ). noyes, jan, and kate j. garland. 2008. “computer- vs. paper-based tasks: are they equivalent?” ergonomics 51(9): 1352–1375. pew research center. 2010. “state of the news media 2010.” pew research center publications, march 15. retrieved january 24, 2012 (http://pewresearch.org/pubs/1523/state-of-the-news-media-2010 (http://pewresearch.org/pubs/1523/ state-of-the-news-media-2010) ). pew research center’s project for excellence in journalism. 2013. “the state of the news media 2013.” pew research center publications. retrieved december 5, 2014 (http://www.stateofthemedia.org/2013/overview-5/key-findings/ (http://www.stateofthemedia.org/2013/overview-5/key-findings/) ). prior, markus. 2005. “news vs. entertainment: how increasing media choice widens gaps in political knowledge and turnout.” american journal of political science 49(3):577–592. procon. 2012. “video games.” january 5. retrieved january 12, 2012 (http://videogames.procon.org/ (http://videogames.procon.org/) ). reuters. 2013. “youtube stats: site has 1 billion active users each month.” huffington post. retrieved december 5, 2014 (http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html (http://www.huffingtonpost.com/2013/ 03/21/youtube-stats_n_2922543.html) ). singer, natasha. 2011. “on campus, it’s one big commercial.” new york times, september 10. retrieved february 10, 2012 (http://www.nytimes.com/2011/09/11/business/at-colleges-the-marketers-areeverywhere.html?pagewanted=1&_r=1&ref=education (http://www.nytimes.com/2011/09/11/business/at-colleges-themarketers-are-everywhere.html?pagewanted=1&_r=1&ref=education) ). smith, aaron. 2012. ""the best (and worst) of mobile connectivity."" pew research centers internet american life project rss. pew research center. retrieved october 3, 2014 (http://www.pewinternet.org/2012/11/30/the-best-andworst-of-mobile-connectivity/ (http://www.pewinternet.org/2012/11/30/the-best-and-worst-of-mobile-connectivity/) ). smith, aaron. 2014a. ""african americans and technology use."" pew research centers internet american life project rss. pew research center. retrieved october 1, 2014 (http://www.pewinternet.org/2014/01/06/african-americans-andtechnology-use/ (http://www.pewinternet.org/2014/01/06/african-americans-and-technology-use/) ). smith, aaron. 2014b. ""older adults and technology use."" pew research centers internet american life project rss. pew reserch center. retrieved october 2, 2014 (http://www.pewinternet.org/2014/04/03/older-adults-and-technology-use/ (http://www.pewinternet.org/2014/04/03/older-adults-and-technology-use/) ). united states patent and trademark office. 2012. “general information concerning patents.” retrieved january 12, 2012 (http://www.uspto.gov/patents/resources/general_info_concerning_patents.jsphttp://www.uspto.gov/patents/resources/ general_info_concerning_patents.jsp (http://www.uspto.gov/patents/resources/ general_info_concerning_patents.jsphttp://www.uspto.gov/patents/resources/general_info_concerning_patents.jsp) ).  180  chapter 8 | media and technology  van de donk, w., b.d. loader, p.g. nixon, and d. rucht, eds. 2004. cyberprotest: new media, citizens, and social movements. new york: routledge. world association of newspapers. 2004. “newspapers: a brief history.” retrieved january 12, 2012 (http://www.wanpress.org/article.php3?id_article=2821 (http://www.wan-press.org/article.php3?id_article=2821) ).  8.3 global implications of media and technology acker, jenny c., and isaac m. mbiti. 2010. “mobile phones and economic development in africa.” journal of economic perspectives 24(3):207–232. retrieved january 12, 2012 (http://pubs.aeaweb.org/doi/pdf/10.1257/jep.24.3.207 (http://pubs.aeaweb.org/doi/pdf/10.1257/jep.24.3.207) pubs.aeaweb.org/doi/pdf/10.1257/jep.24.3.207 (http://pubs.aeaweb.org/doi/pdf/10.1257/jep.24.3.207) ). bagdikian, ben h. 2004. the new media monopoly. boston, ma: beacon press books. bristow, michael. 2011. “can china control social media revolution?” bbc news china, november 2. retrieved january 14, 2012 (http://www.bbc.co.uk/news/world-asia-pacific-15383756 (http://www.bbc.co.uk/news/world-asiapacific-15383756) ). compaine, b. 2005. “global media.” pp. 97-101 in living in the information age: a new media reader belmont: wadsworth thomson learning. friedman, thomas. 2005. the world is flat: a brief history of the twenty-first century. new york: farrar, straus, and giroux. itu news. 2009. “itu telecom world 2009: special report: reflecting new needs and realities.” november. retrieved january 14, 2012 (http://www.itu.int/net/itunews/issues/2009/09/26.aspx (http://www.itu.int/net/itunews/issues/2009/09/ 26.aspx) ). jan, mirza. 2009. “globalization of media: key issues and dimensions.” european journal of scientific research 29:66–75. katine chronicles blog. 2010. “are mobile phones africa’s silver bullet?” the guardian, january 14. retrieved january 12, 2012 (http://www.guardian.co.uk/katine/katine-chronicles-blog?page=6 (http://www.guardian.co.uk/katine/katinechronicles-blog?page=6) ). ma, damien. 2011. “2011: when chinese social media found its legs.” the atlantic, december 18. retrieved january 15, 2012 (http://www.theatlantic.com/international/archive/2011/12/2011-when-chinese-social-media-found-its-legs/ 250083/ (http://www.theatlantic.com/international/archive/2011/12/2011-when-chinese-social-media-found-its-legs/ 250083/) ). mcluhan, marshall. 1964. understanding media: the extensions of man. new york: mcgraw-hill. pierson, david. 2012. “number of web users in china hits 513 million.” los angeles times, january 16. retrieved january 16, 2012 (http://latimesblogs.latimes.com/technology/2012/01/chinese-web-users-grow-to-513-million.html (http://latimesblogs.latimes.com/technology/2012/01/chinese-web-users-grow-to-513-million.html) ). the world bank. 2008. “global economic prospects 2008: technology diffusion in the developing world.” world bank. retrieved january 24, 2012 (http://siteresources.worldbank.org/intgep2008/resources/gep_ove_001-016.pdf (http://siteresources.worldbank.org/intgep2008/resources/gep_ove_001-016.pdf) ).  8.4 theoretical perspectives on media and technology brasted, monica. 2010. “care bears vs. transformers: gender stereotypes in advertisements.” retrieved january 10, 2012 (http://www.sociology.org/media-studies/care-bears-vs-transformers-gender-stereotypes-in-advertisements (http://www.sociology.org/media-studies/care-bears-vs-transformers-gender-stereotypes-in-advertisements) ). carmi, evan, matthew ericson, david nolen, kevin quealy, michael strickland, jeremy white, and derek willis. 2012. “the 2012 money race: compare the candidates.” new york times. retrieved january 15, 2012 (http://elections.nytimes.com/2012/campaign-finance (http://elections.nytimes.com/2012/campaign-finance) ). foucault, michel. 1975. discipline and punish: the birth of the prison. new york: vintage books. fox, jesse, and jeremy bailenson. 2009. “virtual virgins and vamps: the effects of exposure to female characters’ sexualized appearance and gaze in an immersive virtual environment.” sex roles 61:147–157. gamson, william, david croteau, william hoynes, and theodore sasson. 1992. “media images and the social construction of reality.” annual review of sociology 18:373–393.  this openstax book is available for free at http://cnx.org/content/col11762/1.6  chapter 8 | media and technology  181  gentile, douglas, lindsay mathieson, and nikki crick. 2011. “media violence associations with the form and function of aggression among elementary school children.” social development 20:213–232. kautiainen, s., l. koivusilta, t. lintonen, s. m. virtanen, and a. rimpelä. 2005. “use of information and communication technology",t_641ea04cff3e,other,0
c_214f57ed0ca1,"sal checks whether (-1,7) is a solution of the system: x+2y=13 and 3x-y=-11.  is negative 1 comma 7 a solution for the system of linear equations below? and they give us the first equation is x plus 2y is equal to 13. second equation is 3x minus y is equal to negative 11. in order for negative 1 comma 7 to be a solution for the system, it needs to satisfy both equations. or another way of thinking about it, x equals 7, and y-- sorry, x is equal to negative 1. this is the x coordinate. x equals negative 1, and y is equal to 7, need to satisfy both of these equations in order for it to be a solution. so let's try it out. let's try it out with the first equation. so we have x plus 2y is equal to 13. so if we're thinking about that, we're testing to see if when x is equal to negative 1, and y is equal to 7, will x plus 2y equals 13? so we have negative 1 plus 2 times 7-- y should be 7-- this needs to be equal to 13. and i'll put a question mark there because we don't know whether it does. so this is the same thing as negative 1 plus 2 times 7 plus 14. that does, indeed, equal 13. negative 1 plus 14, this is 13. so 13 does definitely equal 13. so this point it does, at least, satisfy this first equation. this point does sit on the graph of this first equation, or on the line of this first equation. now let's look at the second equation. i'll do that one in blue. we have 3 times negative 1 minus y, so minus 7, needs to be equal to negative 11. i'll put a question mark here because we don't know whether it's true or not. so let's see, we have 3 times negative 1 is negative 3. and then we have minus 7 needs to be equal to negative 11-- i put the question mark there. negative 3 minus 7, that's negative 10. so we get negative 10 equaling negative 11. no, negative 10 does not equal a negative 11. so x equaling negative 1, and y equaling 7 does not satisfy the second equation. so it does not sit on its graph. so this over here is not a solution for the system. so the answer is no. it satisfies the first equation, but it doesn't satisfy the second. in order to be a solution for the system, it has to satisfy both equations.",t_3e50bf549f86,other,0
c_a64a41525972,"sal introduces multiplying 2 fractions.  let's think about what it means to multiply 2 over 3, or 2/3, times 4/5. in a previous video, we've already seen how we can actually compute this. this is going to be equal to-- in the numerator, we just multiply the numerators. so it's going to be 2 times 4. and in the denominator, we just multiply the denominator. so it's going to be 3 times 5. and so the numerator is going to be 8, and the denominator is going to be 15. and this is about as simple as we can make it. 8 and 15 don't have any factors common to each other, than 1, so this is what it is. it's 8/15. but how, why does that actually makes sense? and to think about it, we'll think of two ways of visualizing it. so let's draw 2/3. i'll draw it relatively big. so i'm going to draw 2/3, and i'm going to take 4/5 of it. so 2/3, and i'm going to make it pretty big. just like this. so this is 1/3. and then this would be 2/3. which i could do a little bit better job making those equal, or at least closer to looking equal. so there you go. i have thirds. let me do it one more time. so here i have drawn thirds. 2/3 represents 2 of them. it represents 2 of them. one way to think about this is 2/3 times 4/5 is 4/5 of this 2/3. so how do we divide this 2/3 into fifths? well, what if we divided each of these sections into 5. so let's do that. so let's divide each into 5. 1, 2, 3, 4, 5. 1, 2, 3, 4, 5. and i could even divide this into 5 if i want. 1, 2, 3, 4, 5. and we want to take 4/5 of this section here. so how many fifths do we have here? we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. and we've got to be careful. these really aren't fifths. these are actually 15ths, because the whole is this thing over here. so i should really say how many 15ths do we have? and that's where we get this number from. but you see if 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. where did that come from? i had 3, i had thirds. and then i took each of those thirds, and i split them into fifths. so then i have five times as many sections. 3 times 5 is 15. but now we want 4/5 of this right over here. this is 10/15 right over here. notice it's the same thing as 2/3. now if we want to take 4/5 of that, if you have 10 of something, that's going to be 8 of them. so we're going to take 8 of them. so 1, 2, 3, 4, 5, 6, 7, 8. we took 8 of the 15, so that is 8/15. you could have thought about it the other way around. you could have started with fifths. so let me draw it that way. so let me draw a whole. so this is a whole. let me cut it into five equal pieces, or as close as i can draw five equal pieces. 1, 2, 3, 4, 5. 4/5, we're going to shade in 4 of them. 4 of the 5 equal pieces. 3, 4. and now we want to take 2/3 of that. well, how can we do that? well, let's split each of these 5 into 3 pieces. so now we have essentially 15ths again. so 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. we want to take 2/3 of this yellow area. we're not taking 2/3 of the whole section. we're taking 2/3 of the 4/5. so how many 15ths do we have here? we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12. so if you have 12 of something, and you want to take 2/3 of that, you're going to be taking 8 of it. so you're going to be taking 1, 2, 3, 4, 5, 6, 7, 8 or 8 of the fifteenths now. so either way, you get to the same result. one way, you're thinking of taking 4/5 of 2/3. another way you could think of it as you're taking 2/3 of 4/5.",t_bcecc8057493,other,0
c_39834a8d6f76,anmol proves that two angles are congruent in a really interesting triangle like figure.  ,t_5c4d2e0a0e06,other,0
c_537489741969,"glycoproteins have carbohydrate attached to them — a process called glycosylation. the attachment is a covalent linkage to:  the hydroxyl (-oh) group of the r group of serine or threonine - called ""o-linked"" in both cases or to  the amino group (-nh) in the r group of asparagine - called ""n-linked""  2  the carbohydrate consists of short, usually branched, chains of  plain sugars (e.g., glucose, galactose)  amino sugars (sugars with an amino group, e.g., n-acetylglucosamine), and  acidic sugars (sugars with a carboxyl group, e.g., sialic acid)  sugars are very hydrophilic thanks to their many -oh groups. their presence  makes glycoproteins far more hydrophilic than they would be otherwise and  are often essential for the proper folding of the protein into its tertiary structure  most of the proteins exposed to the watery surroundings at the surface of cells are glycoproteins.  this image shows the primary structure of glycophorin a, a glycoprotein that spans the plasma membrane (""lipid bilayer"") of human red blood cells. each rbc has some 500,000 copies of the molecule embedded in its plasma membrane.  fifteen carbohydrate chains are ""o-linked"" to serine (ser) and threonine (thr) residues  one carbohydrate chain is ""n-linked"" to the asparagine (asn) at position 26  two polymorphic versions of glycophorin a, which differ only at residues 1 and 5, occur in humans. these give rise to the mn blood groups  the m allele encodes ser at position 1 (ser-1) and gly at position 5 (gly-5)  the n allele encodes leu-1 and glu-5  genotype to phenotype  individuals who inherit two n alleles (are homozygous) have blood group n.  individuals who are homozygous for the m allele have blood group m.  heterozygous individuals produce both proteins and have blood group mn.  glycophorin a is the most important attachment site by which the parasite plasmodium falciparum invades human red blood cells.  glycosylation versus glycation  the sugars on glycoproteins have been placed there by glycosylation — a precise enzymatic activity that makes a product which would otherwise not function correctly. however, sugars can also spontaneously form covalent links to proteins (and lipids) — a process called glycation. no enzymes are involved so the process is quite random. the products are apt to have reduced, or even no, function. the glycation of proteins and lipids is an inevitable outcome of aging. it is hastened in diabetics with their high blood sugar (glucose) levels. in fact, measuring the amount of glycation of hemoglobin is an important test for determining how well diabetes is being controlled.  contributors  john w. kimball (http://www.biology-pages.info/). this content is distributed under a creative commons attribution 3.0 unported (cc by 3.0) license and made possible by funding from the saylor foundation. (http://www.saylor.org)",t_cd4bcc5a6fc4,other,0
c_81338ba9b971,"when an insulating material is placed in an electric field, it becomes polarized, either by rotation of molecules with pre-existing dipole moments or by induction of dipole moments in the individual molecules.  inside the material, \(d\) is then greater than \(\epsilon_0 e\).  indeed,  \[d=\epsilon_0e+p\label{5.17.1}\]  the excess, \(p\), of \(d\) over \(\epsilon_0 e\) is called the polarization of the medium.  it is dimensionally similar to, and expressed in the same units as, \(d\);  that is to say \(\text{c m}^{-2}\).  another way of looking at the polarization of a medium is that it is the dipole moment per unit volume.  in vector form, the relation is  \[\textbf{d}=\epsilon_0\textbf{e}+\textbf{p}.\label{5.17.2}\]  if the medium is isotropic, all three vectors are parallel.  some media are more susceptible to becoming polarized in a polarizing field than others, and the ratio of \(p\)to \(\epsilon_0 e\) is called the electric susceptibility \(\chi_e\) of the medium:  \[p=\chi_e \epsilon_0e.\label{5.17.3}\]  this implies that \(p\) is linearly proportional to \(e\) but only if \(\chi_e\) is independent of \(e\), which is by no means always the case, but is good for small polarizations.  when we combine equations \ref{5.17.1} and \ref{5.17.3} with \(d = \epsilon e\) and with \(\epsilon_r = \epsilon / \epsilon_0\), the relative permittivity or dielectric constant, we obtain  \[\chi_e = \epsilon_r -1.\label{5.17.4}\]  contributor  jeremy tatum (university of victoria, canada) (http://astrowww.phys.uvic.ca/faculty/tatum/jbt.html)",t_02486f793ea4,other,0
c_fcd18e1f4aee,"learn to multiply and divide decimals by 10 using fraction and place value understanding.  - [instructor] we've already learned that when we multiply by 10, let's say we took the number 53 and we were to multiply it by 10, it has the effect of shifting all the digits once place to the left. so, this should be a review for you. but this was going to be 530. and we could see that what used to be in the tens place has been shifted to the left, to the hundreds place. and what used to be in the ones place has been shifted to the left to the tens place now. and we saw, if you divide by 10, you have the opposite effect. and so, let's say if i had 120, i could say, let's divide by 10, i could also say this is the same thing as 120 times 1/10. what is going to happen there? well, in this situation, all the digits are going to shift one place to the right. so, what used to be in the tens place will now be in the ones place; what used to be in the hundreds place will now be in the tens place. so, this is just going to be equal to 12. so, that was all review. but now were going to extend this a little bit by thinking about things that have place values representing less than a one, i guess you could say, or we're gonna deal with decimals. so, just to get ourselves warmed up, let's see if we could figure out what 3.015 times 10 is. pause this video, and see if you can figure that out. well, the exact same thing is going to happen. all of our digits are going to shift one place to the left. so, right now, we have a three in the ones place, we have a zero in the tenths place, we have a one in the hundredths place, and we have a five in the thousandths, thousandths place. but now, they're all going to shift one place to the left. so, the three is now going to into the tens place, it's going to shift one place to the left. so, we're going to have, in the tens place, we are now going to have our three. and now, this zero, which was in the tenths place, is now going to shift into the ones place. so, the zero is going to go right over, the zero's going to go right over there. that is now in the ones place. and them we'll put our decimal. and now, what's going to go into the tenths place and the hundredths place? and actually, i'll rewrite the thousandths place as well. this one is going to shift one place to the left, into the tenths place, so into the tenths place. and then the five that was in the thousandths place is now going to shift one place to the left, into the hundredths place, so into the hundredths place, just like that. now, we could put a trailing zero over here, but that's not going to change the value of this number, so i'll just leave it like that. and so, there you have it. we see that every digit has shifted one place to the left. so, this is equal to 30.15. i'll just put that zero there for kicks. and so, we could think about the other way around. what if i were to take 67.5, and if i were to divide it by 10, or another way of thinking about it is if i were to multiply this by 1/10. pause the video, and see if you can figure out what that's going to be. well, now, every digit is going to shift one place to the right. so, the six is going to be in the ones place, the seven is going to go into the tenths place, and then the five is going to go into the hundredths place. so, let's write that out. so, i have six is going to go into the ones place, and then we're gonna have our decimal point, our seven is going to go into the tenths place, and then our five is going to go into the hundredths place. so, there you have it, we get 6.75.",t_02543e7a1a73,other,0
c_a64a41525972,"sal introduces multiplying 2 fractions.  let's think about what it means to multiply 2 over 3, or 2/3, times 4/5. in a previous video, we've already seen how we can actually compute this. this is going to be equal to-- in the numerator, we just multiply the numerators. so it's going to be 2 times 4. and in the denominator, we just multiply the denominator. so it's going to be 3 times 5. and so the numerator is going to be 8, and the denominator is going to be 15. and this is about as simple as we can make it. 8 and 15 don't have any factors common to each other, than 1, so this is what it is. it's 8/15. but how, why does that actually makes sense? and to think about it, we'll think of two ways of visualizing it. so let's draw 2/3. i'll draw it relatively big. so i'm going to draw 2/3, and i'm going to take 4/5 of it. so 2/3, and i'm going to make it pretty big. just like this. so this is 1/3. and then this would be 2/3. which i could do a little bit better job making those equal, or at least closer to looking equal. so there you go. i have thirds. let me do it one more time. so here i have drawn thirds. 2/3 represents 2 of them. it represents 2 of them. one way to think about this is 2/3 times 4/5 is 4/5 of this 2/3. so how do we divide this 2/3 into fifths? well, what if we divided each of these sections into 5. so let's do that. so let's divide each into 5. 1, 2, 3, 4, 5. 1, 2, 3, 4, 5. and i could even divide this into 5 if i want. 1, 2, 3, 4, 5. and we want to take 4/5 of this section here. so how many fifths do we have here? we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. and we've got to be careful. these really aren't fifths. these are actually 15ths, because the whole is this thing over here. so i should really say how many 15ths do we have? and that's where we get this number from. but you see if 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. where did that come from? i had 3, i had thirds. and then i took each of those thirds, and i split them into fifths. so then i have five times as many sections. 3 times 5 is 15. but now we want 4/5 of this right over here. this is 10/15 right over here. notice it's the same thing as 2/3. now if we want to take 4/5 of that, if you have 10 of something, that's going to be 8 of them. so we're going to take 8 of them. so 1, 2, 3, 4, 5, 6, 7, 8. we took 8 of the 15, so that is 8/15. you could have thought about it the other way around. you could have started with fifths. so let me draw it that way. so let me draw a whole. so this is a whole. let me cut it into five equal pieces, or as close as i can draw five equal pieces. 1, 2, 3, 4, 5. 4/5, we're going to shade in 4 of them. 4 of the 5 equal pieces. 3, 4. and now we want to take 2/3 of that. well, how can we do that? well, let's split each of these 5 into 3 pieces. so now we have essentially 15ths again. so 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15. we want to take 2/3 of this yellow area. we're not taking 2/3 of the whole section. we're taking 2/3 of the 4/5. so how many 15ths do we have here? we have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12. so if you have 12 of something, and you want to take 2/3 of that, you're going to be taking 8 of it. so you're going to be taking 1, 2, 3, 4, 5, 6, 7, 8 or 8 of the fifteenths now. so either way, you get to the same result. one way, you're thinking of taking 4/5 of 2/3. another way you could think of it as you're taking 2/3 of 4/5.",t_399f481600e1,other,0
c_d26e23e98356,"given incomplete tables of values of b^x and its corresponding inverse function, log_b(y), sal uses the inverse relationship of the functions to fill in the missing values.  voiceover:we've got 2 tables over here. this first table tells us that for any given value of x, what is the value of b to the x? for example, if we look right over here, if x is 1.585, b to the 1.585 is 3. this is telling us that b to the 1.585 is equal to 3. similarly ... i can never say that ... it is telling us that b to the 2.322 is 5. b to the 2.807 is 7. b to the 2.169 is 9. now this table over here is telling us for any given value of y, what is going to be log base b of y? this tells us that log base b of a is 0. log base b of 2 is 1. log base b of 2c is 1.585. log base b of 10d, so this is literally, this is telling us that log base b of 10d is equal to 2.322. that's what this last column tells us. now what i challenge you to do is pause this video, and using just the information here, and you don't need a calculator; in fact, you can't use a calculator. i forbid you; try to figure out what a, b, c, and d are just using your powers of reasoning, no calculator involved. just use your powers of reasoning. can you figure out what a, b, c, and d are? i'm assuming you've given a go at it, so let's see what we can deduce from this. here, we have just a bunch of numbers. we need to figure out what b is. these are all b to the 1.585 power is 3. i don't really know what to make sense of this stuff here. maybe this table will help us. this first ... let me do these in different colors. this first column right over here tells us that log base b of a, so now y is equal to a, that that is equal to 0. now this is an equivalent statement to saying that b to the a power is equal to ... oh sorry, not b to the a power. this is an equivalent statement to saying b to the 0 power is equal to a. this is saying what exponent do i need to raise b to to get a? you raise it to the 0 power. this is saying b to the 0 power is equal to a. now what is anything to the 0 power, assuming that it's not 0? if we're assuming that b is not 0, if we're assuming that b is not 0, so we're going to assume that, and we can assume, and i think that's a safe assumption because where we're raising b to all of these other powers, we're getting a non-0 value. since we know that b is not 0, anything with a 0 power is going to be 1. this tells us that a is equal to 1. we got one figured out. a is equal to 1. now let's look at this next piece of information right over here. what does that tell us? that tells us that log base b of 2 is equal to 1. this is equivalent to saying the power that i needed to raise b to get to to 2 is 1. or if i want to write in exponential form, i could write this as saying that b to the first power is equal to 2. i'm raising something to the first power and i'm getting 2? what is this thing? that means that b must be 2. 2 to the first power is 2. so b is equal to 2. b to the first power is equal to 2. you could say b to the first is equal to 2 to the first. that's also equal to 2. so b must be equal to 2. we've been able to figure that out. this is a 2 right over here. it actually makes sense. 2 to the 1.585 power, yeah, that feels right, that that's about 3. now let's see what else we can do. let's see if we can figure out c. let's look at this column. let's see what this column is telling us. that column we could read as log base b. now our y is 2c. log base b of 2c is equal to 1.585. or we could read this as b, if we write in exponential form, b to the 1.585 is equal to 2c. now what's b to the 1.585? they tell us right over here that b to the 1.585 is 3, is 3, so this right over here is equal to 3. we get 2c is equal to 3, or divide both sides by 2, we would get c is equal to 1.5. this is working out pretty well. now we have this last column, which i will circle in purple, and we can write this as log base b of 10d is equal to 2.322. this is saying the power i need to raise b to to get to 10d is 2.322, or in exponential form, b to the 2.322 is equal to 10d. now what is b to the 2.322? they tell us over here. b to the 2.322 is 5. this is equal to 5. we could write 10d is equal to 5, or divide both sides by 10. d is equal to 0.5, and we're done. we were able to figure out what a, b, c, and d are without the use of a calculator.",t_75c425b9f2b1,other,0
c_625c4f144b69,"sal solves the following age word problem: the sum of 4 consecutive odd integers is 136. what are the 4 integers?  the sum of four consecutive odd integers is 136. what are the four integers? so before even attempting to tackle it, let's think about what it means to be a consecutive odd integer, what four consecutive odd integers could be referring to. so we could start, let's say, we had 3. the next odd integer-- so we want consecutive odd integers. so we want the next odd integer-- would be 5. then the one after that would be 7, and the one after that would be 9. these are consecutive odd integers. another example-- we could start at 11. then the next odd integer is 13. the next one is 15. the next one is 17. the example of non-consecutive odd integers, if someone went from 3 straight to 7, these are not consecutive. the next odd integer after 3 is 5, not 7. so these are examples of consecutive odd integers. these are not consecutive odd integers. so with that out of the way, let's actually try to tackle this question. and i encourage you to pause this video right now and try to tackle this on your own before i take a go at it. well as you can imagine, a little bit of algebra might be handy here. so let's let x be equal to the smallest of the four. so if x is the smallest of the four consecutive odd integers, how can we express the other three in terms of x? we'll just use these examples right over here. if that is x, then how would we express this in terms of x? well, this would be x plus 2. the next odd integer is going to be the previous odd integer plus 2. you're essentially skipping the next number, which is going to be even. so if you added 1, you'd just get to an even number, so you have to add 2 to get to the next odd one. well if you add 2 again, if you add 2 to x plus 2, well now you get to x plus 4. you add 2 to that. you get to x plus 6. and you see that again right over here. if this was x, then this is x plus 2. this is x plus 4, and this is x plus 6. so in general, if x is the smallest of the integers, we can define the other three as x plus 2, x plus 4, and x plus 6. and let's take the sum of them and set that equal to 136 and then solve for x. so the smallest one is x. now the next smallest one is going to be x plus 2. now the one after that's going to be x plus 4, and then the one after that is going to be x plus 6. so this is the sum of the four consecutive odd integers, and they tell us that that is going to be equal to 136. this is equal to 136. and now we can just literally solve for x. we have this one unknown here. so let's add these x terms together. so we have one x, two x's, three x's, four x's. so we can rewrite those literally as 4x. and then we have 2 plus 4, which is 6, plus another 6 is 12. 4x plus 12 is equal to 136. so to solve for x, a good starting point would be to just to isolate the x terms on one side of the equation or try to get rid of this 12. well to get rid of that 12, we'd want to subtract 12 from the left-hand side. but we can't just do it from the left-hand side. then this equality wouldn't hold anymore. if these two things were equal before subtracting the 12, well then if we want to keep them equal, if we want the left and the right to stay equal, we've got to subtract 12 from both sides. so subtracting 12 from both sides gives us, well on the left-hand side, we're just left with 4x. and on the right-hand side, we are left with 136 minus 12 is 124. did i do that right? yeah, 124. so what is x? well, we just divide both sides by 4 to solve for x. and we get-- do that in the same, original color-- x is equal to 124 divided by 4. so let's see. 100 divided by 4 is 25. 24 divided by 4 is 6. 25 plus 6 is 31. and if you don't feel like doing that in your head, you could also, of course, do traditional long division. goes into 124-- 4 doesn't go into 1. 4 goes into 12 three times. 3 times 4 is 12. you subtract, bring down the next 4. 4 goes into 4 one time. you get no remainder. so x is equal to 31. so x is the smallest of the four integers. so this right over here, x is 31. x plus 2 is going to be 33. x plus 4 is going to be 35. and x plus 6 is going to be 37. so our four consecutive odd integers are 31, 33, 35, and 37.",t_b6cb6c18af8b,other,0
c_38469e45c38b,learn how to make a useful bench for camping outdoors with this bushcraft tutorial,t_1c18be69b0b0,other,0
c_c9747df88ab2,"key takeaways  electric current, \(i\), is defined as the rate at which charges cross some plane (for example a plane perpendicular to a wire) per unit time. that is, if an amount of charge, \(\delta q\), enters a wire during an amount of time, \(\delta t\), the current, \(i\), in that wire is defined to be: \[\begin{aligned} i=\frac{\delta q}{\delta t}=\frac{dq}{dt}\end{aligned}\] where a derivative is taken if the rate at which charges are moving is not constant with time.  electric current is a macroscopic quantity that can be measured. conventional current is defined to be positive in the direction in which positive charges flow. in most situations, it is electrons that move inside a conductor, so the current is defined to be positive in the opposite direction of the actual motion of the (negative) electrons.  the current density, \(\vec j\), is defined to be the current per unit area at some point in a conductor, and is a vector in the direction of the electric field, \(\hat e\), at that point: \[\begin{aligned} \vec j = \frac{i}{a}\hat e\end{aligned}\] the current density can be related to the microscopic motion of charges within the conductor. if the current density, \(\vec j\), is known, the corresponding current, \(i\), that crosses a surface with area, \(a\), and normal vector, \(\hat n\), is given by: \[\begin{aligned} i=a \vec j\cdot \hat n=\int \vec j \cdot d\vec a\end{aligned}\] where the integral must be taken if the current density is not constant over the surface.  a conducting material through which current is flowing is called a resistor. when a potential difference is applied across a resistor, the resulting electric field will drive the flow of electrons through the resistor. the electrons will flow with an average “drift velocity”, \(\vec v_d\), which is much lower than the actual (fermi) speed of the electrons in the material. inside the resistor, electrons are constantly accelerated before they collide with atoms in the material losing their kinetic energy, and then accelerating again. thus, the potential energy that is available to the electrons is “used” to heat the resistor, and the electrons, on average, drift quite slowly through the resistor.  the current density in a resistor can be related to the drift velocity of the electrons and the “density of free electrons” in the material, \(n\): \[\begin{aligned} \vec j = -en\vec v_d\end{aligned}\] where, \(e\), is the magnitude of the charge of the electrons and the minus sign indicates that the current density is in the opposite direction of the velocity of the (negative) electrons.  ohm’s law states that the current density, \(\vec j\), at some point in the conductor is proportional to the electric field, \(\vec e\), at that point: \[\begin{aligned} \vec j=\sigma \vec e=\frac{1}{\rho}\vec e\end{aligned}\] where the constant of proportionality, \(\sigma\), is called the “conductivity” of the material (and is a property of the material through which current is flowing). the resistivity, \(\rho\), is a material property that is simply the inverse of the conductivity. both of these properties are a measure of how large a current (or current density) will exist in a material given a certain electric field. for example, the conductivity of an insulating material is close to zero (and its resistivity close to infinity).  for most materials, resistivity usually increases linearly with temperature: \[\begin{aligned} \rho(t)=\rho_0[1+\alpha(t-t_0)]\end{aligned}\] where \(\rho_0\) is the resistivity as measured at some reference temperature, \(t_0\) (usually \(10^{\circ}\text{c}\)), and \(\alpha\), is the “temperature coefficient” for that material. note that this model of resistivity does not hold for extreme temperatures (very cold or very hot), and for some materials, resistivity decreases with temperature (\(\alpha\) is negative).  if we apply ohm’s law to a resistor of length, \(l\), cross-sectional area, \(a\), made of a material with resistivity, \(\rho\), we find that the potential difference applied across the resistor, \(\delta v\), is proportional to the current flowing through the resistor: \[\begin{aligned} \delta v =\rho \frac{l}{a} i\end{aligned}\] the constant of proportionality depends on the material with which the resistor is made (through the resistivity) and on the dimensions of the resistor (through the length and cross-sectional area). the constant of proportionality is called the “resistance” of the resistor, \(r\): \[\begin{aligned} r=\rho \frac{l}{a}\end{aligned}\] ohm’s law is often written for a resistor as the relationship between the current through the resistor, \(i\), and the potential difference across the resistor, \(\delta v\): \[\begin{aligned} \delta v = ri\end{aligned}\] although, technically, ohm’s law is the relation between current density and electric field.  resistors can be combined in series, in which case, the effective resistance of the combination is found by adding the resistances of the individual resistors: \[\begin{aligned} r_{eff}=r_1+r_2+r_2+\dots\quad\text{(series resistors)}\end{aligned}\] when combined in parallel, the inverse of the effective resistance is given by the inverse of the sum of the inverse of the resistances of the individual resistors: \[\begin{aligned} r_{eff}=\frac{1}{\frac{1}{r_1}+\frac{1}{r_2}+\frac{1}{r_3}+\dots}\quad\text{(parallel resistors)}\end{aligned}\]  as charges move through a resistor of resistance, \(r\), under a potential difference, \(\delta v\), and current, \(i\), they transfer their kinetic energy into heating up the resistor. the rate at which they transfer the energy, also called the “power dissipated in the resistor”, is given by: \[\begin{aligned} p=i \delta v=\frac{(\delta v)^2}{r}=i^2r\end{aligned}\] where the various combinations can be obtained by applying the macroscopic version of ohm’s law.  the electrical outlets in our daily lives provide an “alternating” voltage, \(\delta v(t)\), which oscillates sinusoidally: \[\begin{aligned} \delta v(t)=\delta v_0\sin(\omega t)\end{aligned}\] with a maximum amplitude, \(\delta v_0\), and an angular frequency, \(\omega = 2\pi f\). when this potential difference is applied across a resistor, an alternating current is formed, in which the electrons move back and forth, with no net displacement: \[\begin{aligned} i(t)=\frac{\delta v_0}{r}=i_0\sin(\omega t)\end{aligned}\] even though there is not net displacement, the electrons will still transfer energy into the resistor in the form of heat. the average rate at which power is dissipated in the resistor is given by: \[\begin{aligned} \bar p=\frac{1}{2}ri_0^2\end{aligned}\] we introduce the “root mean square” current (voltage), \(i_{rms}\) (\(\delta v_{rms}\)), as an average effective current (voltage): \[\begin{aligned} i_{rms}&amp;=\frac{1}{\sqrt 2}i_0\\ \delta v_{rms}&amp;=\frac{1}{\sqrt 2}\delta v_0\end{aligned}\] such that the power can be expressed using a similar formula as in the direct current case, using the root mean square values: \[\begin{aligned} \bar p = i_{rms}^2r = i_{rms}\delta v_{rms}=\frac{(\delta v_{rms})^2}{r}\end{aligned}\] there are two main types of hazards associated with the use of electricity: fire and electrocution. electrical fires can arise when a large current goes through a wire, since this will dissipate a large amount of heat into the wire (which could set fire to its insulation or other nearby flammable items). electrocution occurs when a current traverses the human body. if a current above \(\sim 80\text{ma}\) crosses the upper body, this can result in ventricular fibrillation, whereby the heart beats very irregularly. of course, one can also be burned by a large current. the amount of current through the body is what will ultimately determine the severity of injuries, and is why one often hears that “it’s current that kills”. a large voltage may not lead to a large current if the resistance of the person is large or if the power supply cannot provide a large current at that large voltage.  important equations  current:  \[\begin{aligned} i = \frac{\delta q}{\delta t}=\frac{dq}{dt} \end{aligned}\]  current density:  \[\begin{aligned} \vec j = \frac{i}{a}\hat e \\ i = \int \vec j \cdot d \vec a\end{aligned}\]  microscopic model of current:  \[\begin{aligned} \vec j = -en \vec v_d\end{aligned}\]  ohm’s law:  \[\begin{aligned} \vec j = \sigma \vec e\end{aligned}\]  resistivity:  \[\begin{aligned} \rho = \frac{1}{\sigma}\\ \rho(t)=\rho_0[1+\alpha(t-t_0)]\end{aligned}\]  resistance:  \[\begin{aligned} r = \rho \frac{l}{a}\end{aligned}\]  ohm’s law (macroscopic):  \[\begin{aligned} \delta v = r i\end{aligned}\]  combining resistors:  \[\begin{aligned} r_{eff}&=r_1+r_2+r_2+\dots\quad\text{(series)}\\ r_{eff}&=\frac{1}{\frac{1}{r_1}+\frac{1}{r_2}+\frac{1}{r_3}+\dots}\quad\text{(parallel)}\end{aligned}\]  power dissipated in a resistor:  \[\begin{aligned} p=i \delta v=\frac{(\delta v)^2}{r}=i^2r\end{aligned}\]  rms voltage and current:  \[\begin{aligned} i_{rms}&=\frac{1}{\sqrt 2}i_0\\ \delta v_{rms}&=\frac{1}{\sqrt 2}\delta v_0\end{aligned}\]  important definitions  definition  current: the rate at which charges flow across a given surface. si units: \([\text{a}]\). common variable(s): \(i\).  definition  current density: a measure of current per unit area, in the direction of the local electric field. si units: \([\text{am}^{-1}]\). common variable(s): \(\vec j\).  definition  resistance: a measure of a specific object’s opposition to the flow of charge. si units: \([\omega]\). common variable(s): \(r\).  definition  resistivity: a measure of a material’s opposition to the flow of charge. si units: \([\omega \text{m}]\). common variable(s): \(\rho\).  definition  conductivity: the inverse of resistivity. si units: \([\omega ^{-1}\text{m}^{-1}]\). common variable(s): \(\sigma\).  definition  drift velocity: the average velocity of an electron drifting in a conductor under the influence of an electric field. si units: \([\text{ms}^{-1}]\). common variable(s): \(\vec v_{d}\).",t_e4e22bdd4a81,other,0
c_8462139841e8,"sal determines the value of coefficient _**c**_ in _**p(x)=x^3+2x^2+cx+10**_ , in order for _**(x-5)**_ to be a factor of _**p**_. the key is using the factor theorem.  - so for what value of c, or values of c, is x minus five? let me write it this way. for what c is x minus five a factor of p of x? i encourage you to pause the video and try to work through it. that p is actually a lower case p. p of x. all right, so i'm assuming you have attempted this. we just have to realize, okay, if x minus five is a factor of p of x, that means you could write p of x, let me do this in that green color, that means you could write p of x as being equal to x minus five times some other business, times some other polynomial. so times some other polynomial. i don't know, let's just call it g of x maybe, g of x, and this would be a 2nd degree polynomial. so what would p of five have to be? well p of five would have to zero. five would have to be a root of this polynomial. you see it right over here. if you replace this with the five, then this is going to be a five, and this is going to be a five. it doesn't matter what g of five is. this is going to be zero. so if x minus five is a factor, if and only if p of five is equal to zero. you could say that five is a root of the polynomial p. p of five is equal to zero. so let's just set p of five equal to zero and then try to solve for c. all right, so we're going to get five to the 3rd power. so this right over here, five to the 3rd, so p of five. p, let me just write it down, p of five is equal to five to the 3rd is 125 plus two times five squared. so that's two times 25, plus 50, plus c times five, plus five c plus 10. that needs to be equal to zero. now let's see, if we were to add 125 to 50 to 10, we are going to get 175, 185. so we get 185 plus five c is equal to zero. subtract 185 from both sides, you get five c is equal to -185, or c is equal to -185 over five, which is going to be, let's see, it's -185 over five, which is equal to, let's see, five goes into 180, let's see, it goes into, well it's five, let's see, it's going to be 30. five times 30 is 150. then we'll have another 35 to go, so it's going to be 37, -37. is that right? five times 30 is 150, five times seven is 35, yep, -37. and we're done. if this was x to the 3rd plus 2 x squared minus 37 x plus 10, then x minus five would be a factor of this polynomial.",t_58b5f45af0be,other,0
c_60f76ffe9ec7,"skills to develop  explain the process of epigenetic regulation  describe how access to dna is controlled by histone modification  eukaryotic gene expression is more complex than prokaryotic gene expression because the processes of transcription and translation are physically separated. unlike prokaryotic cells, eukaryotic cells can regulate gene expression at many different levels. eukaryotic gene expression begins with control of access to the dna. this form of regulation, called epigenetic regulation, occurs even before transcription is initiated.  epigenetic control: regulating access to genes within the chromosome  the human genome encodes over 20,000 genes; each of the 23 pairs of human chromosomes encodes thousands of genes. the dna in the nucleus is precisely wound, folded, and compacted into chromosomes so that it will fit into the nucleus. it is also organized so that specific segments can be accessed as needed by a specific cell type.  the first level of organization, or packing, is the winding of dna strands around histone proteins. histones package and order dna into structural units called nucleosome complexes, which can control the access of proteins to the dna regions (figure \(\pageindex{1}\)a). under the electron microscope, this winding of dna around histone proteins to form nucleosomes looks like small beads on a string (figure \(\pageindex{1}\)b). these beads (histone proteins) can move along the string (dna) and change the structure of the molecule.  figure \(\pageindex{1}\): dna is folded around histone proteins to create (a) nucleosome complexes. these nucleosomes control the access of proteins to the underlying dna. when viewed through an electron microscope (b), the nucleosomes look like beads on a string. (credit “micrograph”: modification of work by chris woodcock)  if dna encoding a specific gene is to be transcribed into rna, the nucleosomes surrounding that region of dna can slide down the dna to open that specific chromosomal region and allow for the transcriptional machinery (rna polymerase) to initiate transcription (figure \(\pageindex{2}\)). nucleosomes can move to open the chromosome structure to expose a segment of dna, but do so in a very controlled manner.  art connection  figure \(\pageindex{2}\): nucleosomes can slide along dna. when nucleosomes are spaced closely together (top), transcription factors cannot bind and gene expression is turned off. when the nucleosomes are spaced far apart (bottom), the dna is exposed. transcription factors can bind, allowing gene expression to occur. modifications to the histones and dna affect nucleosome spacing.  in females, one of the two x chromosomes is inactivated during embryonic development because of epigenetic changes to the chromatin. what impact do you think these changes would have on nucleosome packing?  how the histone proteins move is dependent on signals found on both the histone proteins and on the dna. these signals are tags added to histone proteins and dna that tell the histones if a chromosomal region should be open or closed (figure \(\pageindex{3}\)) depicts modifications to histone proteins and dna). these tags are not permanent, but may be added or removed as needed. they are chemical modifications (phosphate, methyl, or acetyl groups) that are attached to specific amino acids in the protein or to the nucleotides of the dna. the tags do not alter the dna base sequence, but they do alter how tightly wound the dna is around the histone proteins. dna is a negatively charged molecule; therefore, changes in the charge of the histone will change how tightly wound the dna molecule will be. when unmodified, the histone proteins have a large positive charge; by adding chemical modifications like acetyl groups, the charge becomes less positive.  the dna molecule itself can also be modified. this occurs within very specific regions called cpg islands. these are stretches with a high frequency of cytosine and guanine dinucleotide dna pairs (cg) found in the promoter regions of genes. when this configuration exists, the cytosine member of the pair can be methylated (a methyl group is added). this modification changes how the dna interacts with proteins, including the histone proteins that control access to the region. highly methylated (hypermethylated) dna regions with deacetylated histones are tightly coiled and transcriptionally inactive.  figure \(\pageindex{3}\): histone proteins and dna nucleotides can be modified chemically. modifications affect nucleosome spacing and gene expression. (credit: modification of work by nih)  this type of gene regulation is called epigenetic regulation. epigenetic means “around genetics.” the changes that occur to the histone proteins and dna do not alter the nucleotide sequence and are not permanent. instead, these changes are temporary (although they often persist through multiple rounds of cell division) and alter the chromosomal structure (open or closed) as needed. a gene can be turned on or off depending upon the location and modifications to the histone proteins and dna. if a gene is to be transcribed, the histone proteins and dna are modified surrounding the chromosomal region encoding that gene. this opens the chromosomal region to allow access for rna polymerase and other proteins, called transcription factors, to bind to the promoter region, located just upstream of the gene, and initiate transcription. if a gene is to remain turned off, or silenced, the histone proteins and dna have different modifications that signal a closed chromosomal configuration. in this closed configuration, the rna polymerase and transcription factors do not have access to the dna and transcription cannot occur (figure \(\pageindex{3}\)).  link to learning  view this video (http://openstaxcollege.org/l/epigenetic_reg) that describes how epigenetic regulation controls gene expression.  summary  in eukaryotic cells, the first stage of gene expression control occurs at the epigenetic level. epigenetic mechanisms control access to the chromosomal region to allow genes to be turned on or off. these mechanisms control how dna is packed into the nucleus by regulating how tightly the dna is wound around histone proteins. the addition or removal of chemical modifications (or flags) to histone proteins or dna signals to the cell to open or close a chromosomal region. therefore, eukaryotic cells can control whether a gene is expressed by controlling accessibility to transcription factors and the binding of rna polymerase to initiate transcription.  art connections  [link] in females, one of the two x chromosomes is inactivated during embryonic development because of epigenetic changes to the chromatin. what impact do you think these changes would have on nucleosome packing?  [link] the nucleosomes would pack more tightly together.  review questions  what are epigenetic modifications?  the addition of reversible changes to histone proteins and dna  the removal of nucleosomes from the dna  the addition of more nucleosomes to the dna  mutation of the dna sequence  a  which of the following are true of epigenetic changes?  allow dna to be transcribed  move histones to open or close a chromosomal region  are temporary  all of the above  d  free response  in cancer cells, alteration to epigenetic modifications turns off genes that are normally expressed. hypothetically, how could you reverse this process to turn these genes back on?  you can create medications that reverse the epigenetic processes (to add histone acetylation marks or to remove dna methylation) and create an open chromosomal configuration.  glossary  transcription factor  protein that binds to the dna at the promoter or enhancer region and that influences transcription of a gene  contributors  connie rye (east mississippi community college), robert wise (university of wisconsin, oshkosh), vladimir jurukovski (suffolk county community college), jean desaix (university of north carolina at chapel hill), jung choi (georgia institute of technology), yael avissar (rhode island college) among other contributing authors. the openstax college name, openstax college logo, openstax college book covers, openstax cnx name, and openstax cnx logo are not subject to the creative commons license and may not be reproduced without the prior and express written consent of rice university. for questions regarding this license, please contact partners@openstaxcollege.org. download for free at http://cnx.org/contents/185cbf87-c72...f21b5eabd@9.87 (http://cnx.org/contents/185cbf87-c72e-48f5-b51e-f14f21b5eabd@9.87).",t_8adee16ee031,other,0
c_ec8de0363200,"in this video david quickly explains each charge and circuit concept and does a sample question for each one.  - [voiceover] electric charge is a property that some, but not all fundamental particles in nature have. the most commonly talked about fundamentally charged particles are the electrons, which orbit the outside of the atom. these are negatively charged. there's also the protons, which reside inside the nucleus, and these are positively charged. and the neutrons inside the nucleus don't have any net charge. it turns out that all fundamentally charged particles in the universe, have charges that come in integer units of the elementary charge. so if you find a particle in nature, it's gonna have a charge of one times this number, two times this number, three times this number, and it could either be positive or negative. for instance, the electron has a charge of negative 1.6 times 10 to the negative 19th coulombs, and the charge of the proton is positive 1.6 times 10 to the negative 19th coulombs. however, most atoms in the universe are electrically neutral overall, since they'll have just as many negative electrons as they do positive protons. but if an atom had too many electrons, overall that atom would be negatively charged, and if an atom had too few electrons, that atom would be overall positively charged. and something that's really important to remember is that the electric charge is always conserved for every process, in other words, the total charge initially, is gonna equal the total charge finally after any process. so what's an example problem involving electric charge look like? let's say three identically sized metal spheres start off with the charges seen below. positive five q, positive three q, and negative two q. if we touch sphere x to sphere y, and separate them, and then touch sphere y to sphere z, and separate them, what will be the final charge on each sphere? well first, when we touch x to y, the total charge has to be conserved. there's a total charge of eight q amongst them, and since they're identically sized, they'll both share the total charge, which means after they touch, they'll both have positive four q. if one of the spheres were larger, it would gain more of the charge, but the total charge would still be conserved. and now when sphere y is touched to sphere z, the total charge amongst them at that moment would be positive four q plus negative two q, which is positive two q. they would share it equally, so sphere y would have positive q, and sphere z would also have positive q. so the answer here is c. opposite charges attract and like charges repel, and what coulomb's law does is it gives you a way to find the magnitude of the electric force between two charges. the formula for coulomb's law says that the magnitude of the electric force between two charges q1 and q2, is gonna equal the electric constant k, which is nine times 10 to the ninth, times the product of the two charges, measured in coulombs divided by the center to center distance between those two charges, squared. you can't forget to square this distance. and it's gotta be in meters if you want to find si units of newtons for the force. also, don't rely on the negative and positive signs of the charges to tell you which way the force points, just use the fact that opposite charges attract and like charges repel, and use coulomb's law to get the magnitude of the force. so what's an example problem involving coulomb's law look like? let's say two charges exert an electric force of magnitude f on each other. what would be the magnitude of the new electric force if the distance between the charges is tripled and the magnitude of one of the charges is doubled? well we know the formula for coulomb's law says that the force between two charges is the electric constant times one of the charges, times the other charge divided by the distance between them squared, and now once we triple the distance and double a charge, the new electric force is gonna be the electric constant times one of the charges, multiplied by two times one of the charges, divided by three times the distance, which is squared, so i'm gonna get a factor of two on top, and this three will get squared, which gives me a factor of nine on the bottom. if i pull up those extra factors i get that the new force is gonna be two ninths multiplied by k, q1, q2, over d squared, but this entire quantity was just the old force f, so the new force is going to be two ninths of the old force. the electrical current i tells you the amount of coulombs of charge that passes a point in a wire per second. so if you watch some point in a wire, and you count how many coulombs of charge pass by that point per second, that would be the current. or in equation form we can see that the current i is gonna be the amount of charge that flows past a point in a wire per time. this gives the units of i as coulombs per second, which we abbreviate as an ampere. and since charge and time aren't vectors, current is not a vector either. something that's kind of strange is that the so-called conventional direction of current would be the direction that positive charges flow within a wire, however positive charges don't flow within a wire. the only charges that actually flow in a wire are negative charges, but it turns out that negative charges flowing to the left is physically the same as positive charges flowing to the right. so in physics problems we pretend as if it were the positive charges moving, however it's really the electrons, which are negative, that are moving within the wire. so what's an example problem involving electrical current look like? let's say three amps flows within a circuit. how much charge would pass by a point in that wire during a time interval of five minutes? well we know the definition of current is the charge per time, that means the charge is gonna be the amount of current multiplied by the time, so we take our current of three amps, and we multiply by the time, but we can't multiply by five because that's in units of minutes, since amps is coulombs per second, we've got to convert five minutes into seconds, which would be five minutes, multiplied by 60 seconds per minute, which would give us a total amount of charge of 900 coulombs. the resistance of a circuit element measures how much that element will restrict the flow of current. the larger the resistance, the less current there will be allowed to flow. and this definition of resistance is given by ohm's law. ohm's law states that the amount of current that you'll get through a portion of a circuit, it's gonna be proportional to the voltage across that portion, divided by the resistance of that portion of the circuit. so between these two points, the amount of current that will flow, is gonna be equal to the voltage between those two points, divided by the resistance between those two points. so the larger the resistance, the less current will flow, but the greater the voltage supplied, the greater the current will be. and this is what ohm's law says. even though ohm's law gives you a way to define the resistance, you can determine the resistance of a circuit element by knowing the size and shape of that circuit element. in other words, the resistance of a cylindrical resistor, is gonna be equal to the resistivity, which is a measure of an object's natural resistance to current, multiplied by the length of that resistor, the longer the resistor, the greater the resistance and the more it will resist the flow of current, and then divide it by the cross sectional area of that resistor, which would be this area right here, the current is either flowing into or out of. if the resistor is cylindrical, the area of this circle would be pi times r squared, where little r would be the radius of this cross sectional area. the units of resistance is ohms, and it is not a vector. it is always positive or zero. so what's an example problem involving ohm's law, or the resistance of a cylindrical resistor look like? let's say a battery of voltage v is hooked up to a single cylindrical resistor of length l and radius little r, and when that's done, a current i is flowing through the battery. what is the resistivity rho, of that resistor? well we know ohm's law states that the current that flows through a portion of a circuit will be equal to the voltage across that portion, divided by the resistance of that portion. and this means the resistance of this resistor is gonna be the voltage of the battery divided by the current. to factor resistivity into this, we have to use the formula for the resistance of a cylindrical resistor, which is rho times l over a. this gives us the resistance of the resistor, which is gotta equal v over i, and now we can solve for the resistivity rho. we get v times a over i l, but since we're given the radius little r, we gotta write the area in terms of that radius, so this is gonna be v times pi, r squared, divided by i times l, which gives us an answer of c. when dealing with complicated circuits with many resistors, you often have to reduce those resistors into smaller, equivalent amounts of resistors. and the two ways you do this are by finding two resistors that are in series or in parallel. resistors will be in series if the same current that flows through the same resistor, flows through the next resistor. if the current branched off in between them, these resistors would no longer be in series, but if they're in series you can find the equivalent resistance of this section of wire by just adding up the two individual resistances. so the current for resistors in series must be the same, but the voltage might be different, since they could have different resistances. two resistors will be in parallel, if a current comes in, splits into two parts, goes through one resistor each, and then rejoins before hitting anything else in the circuit, and if this is the case, you can find the equivalent resistance of this portion of the circuit, i.e. between these two points, by saying that one over the equivalent resistance is gonna equal one over the resistance of the first resistor, plus one over the resistance of the second resistor. but be careful, one over r1 plus one over r2 just gives you one over r equivalent. if you want r equivalent, you're gonna have to take one over this entire side, in order to get r equivalent. so what's an example problem involving resistors in series and parallel look like? let's say we have this circuit shown below, and we want to know what current flows through the eight ohm resistor. now you might be tempted to say this, since ohm's law says that the current is delta v over r, we can just plug in the voltage of the battery, which is 24 volts, divided by the resistance of the resistor, which is eight ohms, and that would give us three amps. but that's not right at all. when using ohm's law, the current that flows through a resistor r, is gonna be equal to the voltage across that resistor divided by the resistance of that resistor. so if we plug eight ohms into the denominator, we've gotta plug in the voltage across that eight ohm resistor. but the voltage across the eight ohm resistor is not gonna be the full 24 volts of the battery, it's gonna be less than 24 volts. in other words, the battery provides a voltage between this point and this point of 24 volts, but there's gonna be voltage drops across the six and 12 ohm resistors, which make it so that the voltage across the eight ohm resistor is not gonna be the full 24 volts. so we have to reduce these resistors to a single resistance. the six and the 12 are in parallel, so we can say that one over six, plus one over 12, would equal one over the resistance of that portion of the circuit. this is gonna equal three twelves, which is one fourth, so that means that parallel portion of the circuit has an equivalent resistance of four ohms. so between this point and this point, there are four ohms of resistance, and that equivalent resistance is in series with this eight ohm resistor. so we can add four and eight, and get 12 ohms of total resistance. and now i can say that the full 24 volts of the battery is applied across this entire equivalent resistance of 12 ohms, so if i come up here and change this eight ohms to 12 ohms of equivalent resistance for the total circuit, i'll get the correct current that flows through the battery of two amps. and since that's the current that's flowing through the battery, that had to be the current that's flowing through the eight ohm resistor as well. since this eight ohm resistor and the batter are in series. elements in a circuit often use electrical power. that is to say, when current runs through a resistor, the electrons moving through that resistor turn some of their electrical potential energy into energies like heat, light, or sound. and the rate at which these electrons are turning their energy into other forms of energy, is called the electrical power. so the rate at which a resistor is turning electrical potential energy into heat, is the electrical power used by that resistor. in other words, the amount of energy converted into heat, divided by the time it took to convert that energy, is the definition of the power, and there's a way to determine this number of joules per second, in terms of quantities like the current, the voltage, and the resistance. the power used by a resistor can be written as the current through that resistor multiplied by the voltage across that resistor, or if you substituted ohm's law into this formula, you see that this is equivalent to the current through that resistor squared, multiplied by the resistance of the resistor, or we could rearrange these formulas to get that the power used by a resistor would also be the voltage across that resistor squared, divided by the resistance of that resistor. all three of these, if used correctly, will give you the same number for the power used by a resistor, and if you wanted to determine the number of joules of heat energy converted, you could set any one of these equal to the amount of energy per time, and solve for that energy. the units of electrical power are the same as the regular units of power, which is watts, i.e. joules per second, and electrical power is not a vector. so what's an example problem involving electrical power look like? let's say a light bulb of resistance r is hooked up to a source of voltage v, and a second light bulb of resistance 2r, is hooked up to a source of voltage 2v. how does the power used by the second light bulb compare to the power used by the first light bulb? since we have the information about r and v, i'll use the version of the power formula that says that the power used by a resistor is gonna be delta v squared over r. so in terms of quantities given the power used by the first light bulb is gonna be v squared over r. and the power used by the second light bulb is gonna be equal to the voltage across the second light bulb, which is two times the voltage across the first light bulb, and we square that, divided by the resistance of the second light bulb, which is gonna be two times the resistance of the first light bulb. the two squared on top is gonna give me a factor of four, and i'll have another factor of two on the bottom. so if i factor out this four divided by two, i get that the power used by the second light bulb is gonna be two times v squared over r, but v squared over r was the power used by the first light bulb, so the power used by the second light bulb is gonna be two times the power used by the first light bulb, and so if the light bulb of resistance two r has twice the power, and that means it'll be brighter. the quantity that determines the brightness of a light bulb, is the electrical power of that light bulb. it's not necessarily the resistance or the voltage, it's the combination of the two in this formula that will tell you the electrical power, and therefore the brightness of the light bulb. two of the most useful ideas in circuits are referred to as kirchhoff's rules. the first rule is called the junction rule, and it states that all the current entering a junction must equal all the current exiting that junction. in other words, if you add all the current that flows into a junction, that has to equal all the current that flows out of that junction, because current is just flowing charge, and charge is conserved, so charge can't be created or destroyed at any point in the circuit. no more than water can get created or destroyed within a series of pipes. and the second rule is called the loop rule, which states that if you add up all the changes in electric potential, i.e. voltages around any closed loop in a circuit, it'll always add up to zero. so if you add up all the voltages encountered through a closed loop through a circuit, it always adds up to zero. and this is just a result of conservation of energy. the electrons will gain energy when they flow through the battery, and they'll lose energy every time they flow through a resistor, but the total amount of energy they gain from the battery, has to be equal to the total amount of energy they lose due to the resistors. in other words, if we consider a complicated circuit that has a batter and three resistors, the total current flowing into a junction i1, will have to be equal to the total current coming out of that junction, i2 and i3. since no charge gets created or destroyed. and that means when these two currents combine again, the total current flowing out of that section is gonna again be i1. and if we follow a closed loop through this circuit, the sum of all the voltages around that loop have to add up to zero, i.e. the voltage of the battery minus the voltage drop across the first resistor, minus the voltage drop across the second resistor, would have to equal zero. so what's an example problem involving kirchhoff's rules look like? let's say we have the circuit below and we wanted to determine the voltage across the six ohm resistor. to do this, we could use the loop rule, i'll start behind the battery, and i'll go through the resistor, i want to determine the voltage across. i'll add up all the voltages across that loop, and set it equal to zero. so the voltage across the battery is gonna be positive 24 volts, minus the voltage across the six ohm resistor, and then minus the voltage across the eight ohm resistor has to equal zero. but we're given this current, so we know that two amps flows through the eight ohm resistor, and you can always determine the voltage across the resistor using ohm's law, so the voltage across the eight ohm resistor is gonna be two amps, which is flowing through the eight ohm resistor, multiplied by eight ohms, and we get 16 volts. which i can plug into here, and this gives me 24 volts minus the voltage across the six ohm resistor, minus 16, has to equal zero. and if i solve this for the voltage across the six ohm resistor, i get 24 volts minus 16 volts, which is eight volts. so the voltage across the six ohm resistor would be eight volts. note, because the 12 ohm resistor and the six ohm resistor are in parallel, the voltage across the 12 ohm resistor would also be eight volts, because the voltage across any two elements in parallel, have to be the same. voltmeters are the device that you use to measure the voltage between two points in a circuit. when hooking up a voltmeter you've gotta hook it up in parallel between the two points you wanna find the voltage across. in other words, to determine the voltage between this point and this point, which would be the voltage across r3, you would hook up the voltmeter in parallel with r3. ammeters are the devices we use to measure the electrical current that pass through a point in a circuit, and ammeters have to be hooked up in series with the circuit element you want to determine the current through. in other words, if we wanted to determine the current through r1, we would hook up the ammeter in series with r1. note that for these electrical devices to work well, the ammeter should have almost zero internal resistance, thereby not affecting the current that flows through the circuit, and voltmeters should have near infinite resistance, so that it doesn't draw any of the current from the resistor. in reality, ammeters have a very small, but non-zero internal resistance, and voltmeters have a very high, but not infinite internal resistance. so what would an example problem involving voltmeters and ammeters look like? let's say we have the circuit shown below, and these numbered circles represent possible places we could stick a voltmeter to measure the voltage across the eight ohm resistor. which two of these voltmeters would correctly give the voltage across the eight ohm resistor? and you have to be careful, some ap problems are gonna require you to select two correct answers for the multiple choice, so be sure to read the instructions carefully. voltmeter number four is a terrible choice, you never hook up your voltmeter in series, but the circuit element you're trying to find the voltage across, and voltmeter number one is doing nothing really, because its' measuring the voltage between two points in a wire with nothing in between that wire. so the voltage measured by voltmeter one should just be zero, since the voltage across a wire of zero resistance should just give you zero volts. so the correct choices would be voltmeter number two, which gives you the voltage across the eight ohm resistor, and voltmeter number three, which also gives you an equivalent measurement of the voltage across the resistor eight ohms.",t_bcee5771c94c,other,0
c_468e14cc6ff5,lomer lock in fcc  a lomer lock is a type of sessile dislocation which acts as a pinning point in forest hardening. below is a video which explains the formation of lomer lock.,t_c3c21cf0d7a3,other,0
c_2a15cf4a51b4,"learn to fill holes and cracks with sawdust and wood filler. filling holes and cracks - part 2 in this video you will learn to fill holes and cracks with sawdust and wood filler. watch the video how to fill holes and cracks part 1. step 1 - fill with sawdust. to make a filling with sawdust, pour a small quantity of adhesive on scrap wood. add some sawdust and mix it well with a putty. the sawdust should be fine. it is advisable to use the sawdust from the same wood you are fixing. mix until the colour is consistent and the mixture is almost the colour of the wood. push in the mixture in the knothole, crack or hole and wipe off the excess immediately before it dries. leave the piece to dry for 3 to 4 hours. you can now flatten it out with a paring chisel. you may also use a shaving blade. the adhesive has some plastic and it can be difficult to sand off. therefore it is better to avoid using excess adhesive. polish the area lightly with sandpaper. step 2 - fill with a wood filler. you can also use a wood filler to fill holes in a workpiece that you will eventually paint. choose a wood filler that matches the colour of the wood. mix the wood filler as per instructions. in this case we will mix an equal quantity of resin and hardener. add some sawdust and mix well with the putty. apply the filler over the hole or the crack.  wipe off any excess with the putty. let it dry for a few hours. add some sawdust over the filler so that it dries quickly. let it dry for a few hours. brush off the sawdust on the top. scrape the excess wood filler off with a plane blade iron. plane the workpiece to level it. if there is a spot where the wood filler is protruding too much, you might need to chisel it off. finish by planing the workpiece. you have successfully learnt to fill holes and cracks.",t_2b545619478a,other,0
c_44c461a67ad3,"analyzing concentrations when ph lower than half-equivalence point. from 2015 ap chemistry free response 3f.  - the ph of the soft drink is 3.37 after the addition of the potassium sorbate. which species, the sorbic acid or the sorbate ion, has a higher concentration in the soft drink. justify your answer. so, this is related to the question we've been doing because the sorbate ion, this is what happens when you put potassium sorbate and it dis-associates in a solution. so the concentration of the sorbate ion is the same thing as the concentration. one way to think about it, is going to be the same as the concentration of your potassium sorbate. so if we're thinking about titrating potassium sorbate, which we've been doing in the last several parts of the problem. at what point do you have an equal concentration of potassium sorbate and sorbic acid. well you have equal concentrations at the half-equivalence point. we marked that out when we figured it out in the last few parts of this problem. and the half-equivalence point happened at a ph of, we actually figured it out before, 4.77. so we could say... ""half-equivalence point ""of titration ""of potassium sorbate ""with hydrochloric acid ""happens at a ph of,"" let me write that ph of, ""4.77."" and that's the point at which you have equal concentrations of, so we can put this in parentheses, ""can be viewed as point ""where we have equal ""concentrations, ""of c6h7o2 minus,"" and ascorbic acid, ""hc6h7o2."" ""ph of 3.37 is lower and will thus,"" or we could say, ""will happen beyond ""half-equivalence point."" beyond half-equivalence point. so, concentration of the sorbic acid is higher. ""so concentration ""of sorbic acid, ""hc6h7o2, is higher."" when you're starting off, if you're doing a titration. your concentration of potassium sorbate, it'll be higher then you keep titrating and it keeps reacting with the hydrochloric acid. you get to the half-equivalence point where these two things are going to have equal concentrations. then if you keep titrating it, well then you're going to become more acidic and your going to have a higher concentration of the sorbic acid. so one way to think about, actually let me underline that whole part, ""so concentration of sorbic acid is higher."" that's the main thing that they're asking for. but the way to think about this soft drink is something it might not have, and obviously people are sitting there and titrating every soft drink. but you can kinda view this soft drink as well it got that point after a theoretical titration that got us past the... half-equivalence point. and so therefore, most of our things that we care about is in the form, is in the acid form versus the conjugate base. most of the sorbic acid is in its acid form. or i guess you could say it the other way. most of the sorbate has become the conjugate acid.",t_9140a93528df,other,0
c_263b2af8c510," how to stitch a churidar: 2/4 the hem in this video you will learn how to stitch the hem of a churidar. don’t forget to watch the previous video to learn how to stitch the casing. the hem needs to be stitched before the inseam. to make a hem, first straighten the leg out and tuck the end of the bottom layer out of the way. hold the upper layer and make a fold at the notch marking the hemline. finger-press along the fold to set a crease. now, tuck the raw end of the fabric inward to make a double fold, as shown. secure the fold with a series of three to four pins. set one end of the hem under the needle and start sewing. reverse stitch and remove the pins one by one as they approach the needle. ensure that the fold is secured by the stitches from end to end. cut the thread and repeat the steps on the second layer of fabric. you have now learnt how to stitch the hem of a churidar. to learn how to stitch the inseams and close your garment, watch the next video.",t_b0c27c7fdc07,other,0
c_5daf280a4786,"[see learning resources here.](https://smarthistory.org/shimomura/)      roger shimomura, _diary: december 12, 1941_ , 1980, acrylic on canvas, 127.6 x 152.4 cm (smithsonian american art museum, gift of the artist, (c) roger shimomura). a conversation with dr. sarah newman, james dicke curator of contemporary art, smithsonian american art museum, and dr. beth harris. this seeing america video was (upbeat piano music) - [woman] we're in the smithsonian american art museum looking at a painting by roger shimomura, diary, december 12, 1941. this painting actually refers very specifically to an experience of his grandmother's. that date might resonate, at least a date close to that as the date that pearl harbor was bombed, december 7th in 1941. - [woman] immediately after pearl harbor was bombed, the american government froze the bank accounts of all japanese citizens and all japanese americans living in the us. but then a few days later on december 12th, which is when this diary takes place, president roosevelt gave the order that these japanese americans could withdraw up to a $100 a month from their bank accounts. and so even though they were citizens, and they had lived here, they were effectively treated as a national security threat. - [woman] shimomura was born in '39, so in 1941, 1942, he's a toddler and like so many people of japanese decent on the west coast he was relocated, he was imprisoned, in what we refer to as an internment camp in idaho. - [woman] this was in the months before the internment camps were established in early 1942. - [woman] the artist's grandmother, on december 12th, five days after the bombing of pearl harbor, wrote this in her diary. - [woman] i spent all day at home, starting from today, we were permitted to withdraw $100 from the bank. this was for our sustenance of life, we who are enemy to them. i deeply felt america's large heartedness in dealing with us. - [woman] what an interesting statement, referring to the government of the united states as large-hearted, in allowing them to withdraw $100 from their bank account. - [woman] it reads very strange to us now. there is a large part of her that did feel gratitude to the untied states, dealing with a difficult circumstance and she's trying to understand their point of view as well. - [woman] we notice a few things immediately. one is that she's not in an american home. we see her rather in this very traditional japanese environment. - [woman] she is pictured as a young woman, she's wearing a kimono, there are tatami mats on the floor, translucent rice-paper screens around her. she's writing her diary but she's looking off into the distance, and behind her, you can see the silhouette in this shoji screen, of superman and he's standing there, and he's this large heroic looming figure. his cape rustling in the wind. - [woman] but he has a menacing presence. - [woman] the presence of superman can be read in two separate ways. you can take him in a very straight way, looking at her diary and equating superman to the large-hearted american, and obviously superman is a heroic figure, he's a protective figure, he might be standing outside of her house to protect her, but at the same time, i think you're also getting part of the artist's own perspective. roger shimomura, read his grandmother's diary in translation and came across that notion of the large-hearted american and puzzled over it, and said is this really as she intended it, although she kept 56 diaries over her lifetime, only 37 of them remain, and she actually burned a number of diaries that she kept during and after the war. so, there's the sense that she may have destroyed the diaries that were not so sympathetic to the americans, so here, we can see superman looking over her shoulder and watching what she's writing. we are surveilling her. - [woman] we do see him in the comic books, defending the united states, and going after the axis powers, going after hitler, going after the japanese, who are depicted often in the comic books, in a very offensive stereotypical way. - [woman] superman was used in american war propaganda and he was often wrestling with these stereotypical japanese figures. - [woman] and actively looking for imagined japanese conspirators, who are looking to undermine the united states government war efforts. - [woman] this looks like a very japanese image, it looks like a ukiyo-e print, but when you think about his grandmother, she had come to the united states in 1912, she was an american at this point, she would not have been wearing japanese clothes, she did not live in a japanese house, so by putting her in this very traditional japanese environment, shimomura is actively stereotyping her, so she was always a japanese person in the eyes of the american government. - [woman] and this was something that shimomura himself experiences, kind of discrimination. - [woman] he would often encounter people who said, how do you speak english so well, since you're japanese? - [woman] and he couldn't even speak or read japanese. - [woman] he grew up on comic books, and when he was a young artist, he was a pop artist, and you can see a lot of the same formal qualities of pop art and comic books and traditional japanese ukiyo-e prints, they're very similar. they have these black outlined figures, these large planes of flat vibrant color, so he saw his own identity as a pop artist, and someone interested in comic books, mixed in interestingly with traditional japanese culture. - [woman] she's got this beautiful kimono on, these lovely yellows and purples and oranges and greens and then the space outside is also rendered in those colors, but on either side of her, these silhouettes, the grays, the cream color, it feels almost like a more threatening environment around her. and even the grid becomes here, like the bars of a prison, and reminiscent of the internment camps, the prisons that were set up for people of japanese descent. his family was in idaho in a place called minidoka, that actually had eight guard towers and a barbed wire around it. - [woman] there's definitely the sense that she's living in this beautiful environment, but that there are shadows looming around her, while this depicts a scene that, was before the interment camps, roger shimomura knows the history, knows what's going to happen so these shadows looming are real shadows and this is a history that profoundly affected his family, it profoundly affected all japanese people living in the united states at this time, and it's one that they struggled to recover from. (upbeat piano music)",t_8391da63f41d,other,0
c_f7100d18dea0,"chapter 64 of the book on powershell.chapter 64: sharepoint module section 64.1: loading sharepoint snap-in loading the sharepoint snapin can be done using the following: add-pssnapin ""microsoft.sharepoint.powershell""  this only works in the 64bit version of powershell. if the window says ""windows powershell (x86)"" in the title you are using the incorrect version. if the snap-in is already loaded, the code above will cause an error. using the following will load only if necessary, which can be used in cmdlets/functions: if ((get-pssnapin ""microsoft.sharepoint.powershell"" -erroraction silentlycontinue) -eq $null) { add-pssnapin ""microsoft.sharepoint.powershell"" }  alternatively, if you start the sharepoint management shell, it will automatically include the snap-in. to get a list of all the available sharepoint cmdlets, run the following: get-command -module microsoft.sharepoint.powershell  section 64.2: iterating over all lists of a site collection print out all list names and the item count. $site = get-spsite -identity https://mysharepointsite/sites/test foreach ($web in $site.allwebs) { foreach ($list in $web.lists) { # prints list title and item count write-output ""$($list.title), items: $($list.itemcount)"" } } $site.dispose()  section 64.3: get all installed features on a site collection get-spfeature -site https://mysharepointsite/sites/test  get-spfeature can also be run on web scope (-web <weburl>), farm scope (-farm) and web application scope (webapplication <webappurl>).  get all orphaned features on a site collection another usage of get-spfeature can be to ﬁnd all features that have no scope: get-spfeature -site https://mysharepointsite/sites/test |? { $_.scope -eq $null )  goalkicker.com – powershell® notes for professionals  160",t_dbac6386ca37,other,0
c_bdb5d96db68e,"coulomb was the first to provide a detailed quantitative description of the force between charged objects. nowadays, we use the (derived) si unit of “coulomb” (c) to represent charge. the “charge” of an object corresponds to the net excess (or lack) of electrons on the object. an electron has a charge of \(-e=-1.6\times 10^{-19}\text{c}\). thus, an object with a charge of \(-1\text{c}\) has an excess of about \(-1.6\times 10^{19}\) electrons on it, which is a very large charge. if an object has an excess of electrons, it is negatively charged and we indicate this with a negative sign on the charge of the object. an object with a (positive) charge of \(1\text{c}\) thus has a deficit of \(-1.6\times 10^{19}\) electrons.  through careful studies of the force between two charged spheres, coulomb observed1 that:  the force is attractive if the objects have opposite charges and repulsive if the objects have the same charge.  the force is inversely proportional to the squared distance between spheres.  the force is larger if the charges involved are larger.  this leads to coulomb’s law for the electric force (or simply “coulomb’s law”), \(\vec f_{12}\), exerted on a point charge \(q_1\) by another point charge \(q_2\):  \[\vec f_{12}=k\frac{q_{1}q_{2}}{r^{2}}\hat r_{21}\]  where \(\hat r_{21}\) is the unit vector from \(q_2\) to \(q_1\) and \(r\) is the distance between the two charges, as illustrated in figure 16.2.1. \(k=8.99\times 10^{9}\text{n}\cdot\text{m}^{2}\text{/c}^{2}\) is simply a proportionality constant (“coulomb’s constant”) to ensure that the quantity on the right will have units of newtons when all other quantities are in s.i. units. in some instances, it is more convenient to use the “permittivity of free space”, \(\epsilon_0\), rather than coulomb’s constant, in which case coulomb’s law has the form: \[\begin{aligned} \vec f_{12}=\frac{1}{4\pi\epsilon_0}\frac{q_1q_2}{r^2}\hat r_{21}\end{aligned}\] where \(\epsilon_{0}=\frac{1}{4\pi k}=8.85\times 10^{-12}\text{c}^{2}\cdot\text{n}^{-1}\cdot\text{m}^{-2}\) is a more fundamental constant, as we will see in later chapters.  figure 16.2.1: vectors involved in applying coulomb's law.  if the two charges have positions \(\vec r_1\) and \(\vec r_2\), respectively, then the vector \(\hat r_{21}\) is given by: \[\begin{aligned} \hat r_{21} = \frac{\vec r_2 - \vec r_1}{||\vec r_2 - \vec r_1||}\end{aligned}\] coulomb’s law is mathematically identical to the gravitational force in newton’s universal theory of gravity. rather than quantity of mass determining the strength of the gravitational force, it is the quantity of charge that determines the strength of the electric force. the only major difference is that gravity is always attractive, whereas the coulomb force can be repulsive.  exercise \(\pageindex{1}\)  the coulomb force is conservative.  true.  false.  answer  the product \(q_1q_2\) in the numerator of coulomb’s force is positive if the two charges have the same sign (both positive or both negative) and negative if the charges have opposite signs. again, referring to figure 16.2.1, if the two charges are positive, the force on \(q_1\) will point in the same direction as \(\hat r_{21}\) (since all of the scalars are positive in coulomb’s law) and thus be repulsive. if, instead, the two charges have opposite signs, the product \(q_1q_2\) will be negative and the force vector on \(q_1\) will point in the opposite direction from \(\hat r_{21}\) and the force is attractive.  example \(\pageindex{1}\)  calculate the magnitude of the electric force between the electron and the proton in a hydrogen atom and compare this to the gravitational force between them.  solution:  we model this by assuming that the electron and proton are point charges a distance of \(1 \unicode{xc5}=1\times 10^{-10}\text{m}\) apart (\(1\) angstrom is about the size of the hydrogen atom). the proton and electron have the same charge with magnitude \(e=1.6\times 10^{-19}\text{c}\), so the (attractive) electric force between them has a magnitude of:  \[\begin{aligned} f^{e}=k\frac{q_{1}q_{2}}{r^{2}}=(9\times 10^{9}\text{n}\cdot \text{m}^{2}\text{/c}^{2})\frac{(1.6\times 10^{-19}\text{c})(1.6\times 10^{-19}\text{c})}{(1\times 10^{-10}\text{m})^{2}}=2.3\times 10^{-8}\text{n} \end{aligned}\]  which is a small number, but acting on a very small mass. in comparison, the force of gravity between an electron (\(m_e=9.1\times 10^{-31}\text{kg}\)) and a proton (\(m_p=1.7\times 10^{-27}\text{kg}\)) is given by:  \[\begin{aligned} f^{g}=g\frac{m_{2}m_{p}}{r^{2}}=(6.7\times 10^{-11}\text{nm}^{2}\text{/kg}^{2}\frac{(9.1\times 10^{-31}\text{kg})(1.7\times 10^{-27}\text{kg})}{(1\times 10^{-10}\text{m})^{2}}=1.04\times 10^{-47}\text{n} \end{aligned}\]  discussion:  as we can see, the electric force between an electron and a proton is \(39\) orders of magnitude larger than the gravitational force! this shows that the gravitational force is extremely weak on the scale of particles and has essentially no effect in particle physics. indeed, the best current theory of particle physics, and the most precisely tested theory in physics, the “standard model”, does not need to include gravity in order to provide a spectacularly precise description of particles. one of the big challenges in theoretical physics is nonetheless to develop a theory that integrates the gravitational force with the other forces.  example \(\pageindex{2}\)  three charges, \(q_1=1\text{nc}\), \(q_2=-2\text{nc}\), and \(q=-1\text{nc}\), are held fixed at the three corners of an equilateral triangle with sides of length \(a=1\text{cm}\), with a coordinate system as shown in figure 16.2.2. what is the electric force vector on charge \(q\)? (note that \(1\text{nc}=1\times 10^{-9}\text{c}\)).  figure 16.2.2: three charges arranged in an equilateral triangle of side \(a\).  solution:  the net electric force on charge \(q\) will be the vector sum of the forces from charges \(q_1\) and \(q_2\). we thus need to determine the force vectors on \(q\) from each charge using coulomb’s law, and then add those two vectors to obtain the net force on \(q\). the force vectors exerted on \(q\) from each charge are illustrated in figure 16.2.3.  figure 16.2.3: force vectors on charge \(q\).  the force from charge \(q_1\) has magnitude:  \[\begin{aligned} f_{q1}= \left|k\frac{q_{1}q}{a^{2}} \right|=(9\times 10^{9}\text{n}\cdot\text{m}^{2}\text{/c}^{2})\frac{(1\times 10^{-9}\text{c})(1\times 10^{-9}\text{c})}{(0.01\text{m})^{2}}=9\times 10^{-5}\text{n} \end{aligned}\]  and components:  \[\begin{aligned} \vec f_{q1}&=-f_{q1}\cos(60^{\circ})\hat x-f_{q1}\sin(60^{\circ})\hat y\\ &=-(4.5\times 10^{-5}\text{n})\hat x-(7.8\times 10^{-5}\text{n})\hat y\end{aligned}\]  similarly, the force on \(q\) from \(q_2\) has magnitude:  \[\begin{aligned} f_{q2}=\left |k\frac{q_2q}{a^2}\right |=(9\times 10^{9}\text{n}\cdot \text{m}^2\text{/c}^{2})\frac{(2\times 10^{-9}\text{c})(1\times 10^{-9}\text{c})}{(0.01\text{m})^2}=1.8\times 10^{-4}\text{n}\end{aligned}\]  and components:  \[\begin{aligned} \vec f_{q2}&=-f_{q2}\cos(60^{\circ})\hat x+f_{q2}\sin(60^{\circ})\hat y\\ &=-(9.0\times 10^{-5}\text{n})\hat x+(1.6\times 10^{-4}\text{n})\hat y\end{aligned}\]  finally, we can add the two force vectors together to obtain the net force on \(q\):  \[\begin{aligned} \vec f^{net}&=\vec f_{q1}+\vec f_{q2}\\ &=-(4.5\times 10^{-5}\text{n})\hat x-(7.8\times 10^{-5}\text{n})\hat y-(9.0\times 10^{-5}\text{n})\hat x+(1.6\times 10^{-4}\text{n})\hat y\\ &=-(13.5\times 10^{-5}\text{n})\hat x+(8.2\times 10^{-5}\text{n})\hat y\end{aligned}\]  which has a magnitude of \(15.8\times 10^{-5}\text{n}\).  discussion:  in this example, we determined the net force on a charge by making use of the superposition principle; namely, that we can treat the forces exerted on \(q\) by \(q_1\) and \(q_2\) independently, without needing to consider the fact that \(q_1\) and \(q_2\) exert forces on each other.  footnotes  1. others had initially observed the inverse square law for the electric force, but coulomb was the first to formalize the theory.",t_7f7e2ea1c574,other,0
c_e45895b39b27,"chapter 1 of the book on algorithms.chapter 1: getting started with algorithms section 1.1: a sample algorithmic problem an algorithmic problem is speciﬁed by describing the complete set of instances it must work on and of its output after running on one of these instances. this distinction, between a problem and an instance of a problem, is fundamental. the algorithmic problem known as sorting is deﬁned as follows: [skiena:2008:adm:1410219] problem: sorting input: a sequence of n keys, a_1, a_2, ..., a_n. output: the reordering of the input sequence such that a'_1 <= a'_2 <= ... <= a'_{n-1} <= a'_n an instance of sorting might be an array of strings, such as { haskell, emacs } or a sequence of numbers such as { 154, 245, 1337 }.  section 1.2: getting started with simple fizz buzz algorithm in swift for those of you that are new to programming in swift and those of you coming from diﬀerent programming bases, such as python or java, this article should be quite helpful. in this post, we will discuss a simple solution for implementing swift algorithms. fizz buzz you may have seen fizz buzz written as fizz buzz, fizzbuzz, or fizz-buzz; they're all referring to the same thing. that ""thing"" is the main topic of discussion today. first, what is fizzbuzz? this is a common question that comes up in job interviews. imagine a series of a number from 1 to 10. 1 2 3 4 5 6 7 8 9 10  fizz and buzz refer to any number that's a multiple of 3 and 5 respectively. in other words, if a number is divisible by 3, it is substituted with ﬁzz; if a number is divisible by 5, it is substituted with buzz. if a number is simultaneously a multiple of 3 and 5, the number is replaced with ""ﬁzz buzz."" in essence, it emulates the famous children game ""ﬁzz buzz"". to work on this problem, open up xcode to create a new playground and initialize an array like below: // for example let number = [1,2,3,4,5] // here 3 is fizz and 5 is buzz  to ﬁnd all the ﬁzz and buzz, we must iterate through the array and check which numbers are ﬁzz and which are buzz. to do this, create a for loop to iterate through the array we have initialised: for num in number { // body and calculation goes here }  after this, we can simply use the ""if else"" condition and module operator in swift ie - % to locate the ﬁzz and buzz goalkicker.com – algorithms notes for professionals  2  for num in number { if num % 3 == 0 { print(""\(num) fizz"") } else { print(num) } }  great! you can go to the debug console in xcode playground to see the output. you will ﬁnd that the ""ﬁzzes"" have been sorted out in your array. for the buzz part, we will use the same technique. let's give it a try before scrolling through the article — you can check your results against this article once you've ﬁnished doing this. for num in number if num % 3 == 0 print(""\(num) } else if num % print(""\(num) } else { print(num) } }  { { fizz"") 5 == 0 { buzz"")  check the output! it's rather straight forward — you divided the number by 3, ﬁzz and divided the number by 5, buzz. now, increase the numbers in the array let number = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]  we increased the range of numbers from 1-10 to 1-15 in order to demonstrate the concept of a ""ﬁzz buzz."" since 15 is a multiple of both 3 and 5, the number should be replaced with ""ﬁzz buzz."" try for yourself and check the answer! here is the solution: for num in number if num % 3 == 0 print(""\(num) } else if num % print(""\(num) } else if num % print(""\(num) } else { print(num) } }  { && num % 5 == 0 { fizz buzz"") 3 == 0 { fizz"") 5 == 0 { buzz"")  wait...it's not over though! the whole purpose of the algorithm is to customize the runtime correctly. imagine if the range increases from 1-15 to 1-100. the compiler will check each number to determine whether it is divisible by 3 or 5. it would then run through the numbers again to check if the numbers are divisible by 3 and 5. the code would essentially have to run through each number in the array twice — it would have to runs the numbers by 3 ﬁrst and then run it by 5. to speed up the process, we can simply tell our code to divide the numbers by 15 directly. here is the ﬁnal code: for num in number {  goalkicker.com – algorithms notes for professionals  3  if num % 15 == 0 { print(""\(num) fizz buzz"") } else if num % 3 == 0 { print(""\(num) fizz"") } else if num % 5 == 0 { print(""\(num) buzz"") } else { print(num) } }  as simple as that, you can use any language of your choice and get started enjoy coding  goalkicker.com – algorithms notes for professionals  4",t_e697dec24728,other,0
c_c7451da1b936,"rheumatic fever is an inflammatory disease that can develop as a complication of inadequately treated strep throat.  learning objectives  outline the effect of infection by steptococcus pyogenes on the immune system  key takeaways  key points  rheumatic fever is a condition that is a complication of untreated strep throat. strep throat is caused by a group a streptococcal infection found in the throat.  when the body senses the strep infection, it sends antibodies to fight it and sometimes these antibodies attack the tissues of your joints or heart instead. this is known as anitbody cross-reactivity which leads to rheumatic fever.  symptoms of rheumatic fever occur several weeks after initial throat problems have disappeared; and include chest pain, fever, heart problems, joint pain, nosebleeds, and skin rash.  rheumatic fever is treated using a combination of antibiotics and anti-inflammatory medications.  key terms  rheumatism: any disorder of the muscles, tendons, joints, bones, nerves, characterized by pain, discomfort and disability.  streptococcus: a spherical, gram-positive bacterium of the genus streptococcus. although commonly found benignly in the human mouth and gut, and though many species are non-pathogenic, other species can cause diseases including strep throat and more serious conditions.  rheumatic fever is an inflammatory disease that occurs following a streptococcus pyogenes infection, such as streptococcal pharyngitis (strep throat) or scarlet fever, that affects the peri-arteriolar connective tissue. believed to be caused by antibody cross-reactivity that can involve the heart, joints, skin, and brain; the illness typically develops two to three weeks after a streptococcal infection.  streptococcus pyogenes bacteria: photomicrograph of streptococcus pyogenes bacteria, 900x mag. a pus specimen, viewed using pappenheim’s stain. last century, infections by s. pyogenes claimed many lives especially since the organism was the most important cause of puerperal fever and scarlet fever.  acute rheumatic fever commonly appears in children between the ages of six and 15, with only 20% of first-time attacks occurring in adults. the illness is so named because of its similarity in presentation to rheumatism.  this cross-reactivity is a type ii hypersensitivity reaction and is termed molecular mimicry. during a streptococcus infection, mature antigen -presenting cells, such as b cells, present the bacterial antigen to cd4-t cells which differentiate into helper t2cells. in turn, helper t2 cells activate the b cells to become plasma cells and induce the production of antibodies against the cell wall of streptococcus. however the antibodies may also react against the myocardium and joints, producing the symptoms of rheumatic fever.  diagnosis of rheumatic fever can be made when two of the major criteria, or one major plus two minor criteria, are present along with evidence of streptococcal infection.  the major criteria for diagnosis include:  arthritis in several large joints (polyarthritis)  heart inflammation (carditis)  nodules under the skin (subcutaneous skin nodules)  rapid, jerky movements (chorea, sydenham chorea)  skin rash (erythema marginatum)  minor criteria:  fever of 38.2–38.9 °c (101–102 f)  arthralgia: joint pain without swelling (cannot be included if polyarthritis is present as a major symptom)  raised erythrocyte sedimentation rate or c reactive protein  leukocytosis  ecg showing features of heart block, such as a prolonged pr interval (cannot be included if carditis is present as a major symptom)  previous episode of rheumatic fever or inactive heart disease.  acute rheumatic fever is treated with antibiotics and anti-inflammatory medications such as aspirin and corticosteroids.",t_820d83224b89,other,0
c_84407f804a58,"cathedral church of the blessed virgin mary of lincoln, begun 1088, lincoln, england. speakers: dr. beth harris and dr. steven zucker  (cheerful piano music) - [dr. steven zucker] we're standing on the top of a steep hill next to a castle, in front of lincoln cathedral. - [dr. beth harris] what's so fun about lincoln cathedral is that it shows us the development of architecture, beginning with the anglo-norman romanesque, through the early english gothic, through to the decorated period of gothic. and it shows us this in a way that makes it very easy to see, and is incredibly beautiful. we're standing in front of the west facade which is overwhelming in it's size. - [dr. steven zucker] you assume that this incredible width represents the width of the cathedral within, but typical of english gothic churches, this is really a screen, and what is interesting is that there's still a fragment of the original church in this west front. - [dr. beth harris] the original church was built in the anglo-romanesque style, brought over by william the conqueror from normandy, from the north of france, and we see that, especially in the lowest levels of the facade, where we see these big, round arches, that are highly decorated with a chevron and other patterning. this is typically anglo-norman romanesque. - [dr. steven zucker] we've walked up to the central portal and i'm struck by just how uniquely english the decoration is. - [dr. beth harris] well it reminds me of anglo-saxon manuscripts, we see interlacing patterns and animals and figurative compositions including adam and eve. but most interesting are the faces and tongues that wrap around the column closest to the doorway. - [dr. steven zucker] and then arches over the central doorway and down the other side. look at the double-headed serpent or dragon at the very top of the arch. it reminds you of the vikings who had such an impact. - [dr. beth harris] and this interest in the decorative is something that carries through in so much gothic art and architecture in england. - [dr. steven zucker] but the west front is enormous and towers above this ancient stonework. - [dr. beth harris] the remainder of the west front dates to the early english gothic period, we've backed up as much as we can, so we can try to take in the enormity of the west facade. so if we move above those rounded, romanesque arches that form the oldest part of the facade, we see motifs that carry through the interior of it, including overlapping arcades, and an explosion of lancet shapes, this is a very gothic shape. - [dr. steven zucker] and then rising above that are two towers that are so massive, and so tall, that they dwarf even the huge scale of the screen. - [dr. beth harris] for all it's height, we're looking at a church facade that emphasizes it's width and not it's height. some art historians have seen the influence of ancient roman architecture in the three massive round arches that take up so much of this facade. but there's also so much else to see here, colonnettes separated by crockets, i see ball flowers, i see tiny heads, there's so much to see on the outside and so much to see of these decorative elements when we go inside the cathedral. - [dr. steven zucker] let's go in. - [dr. beth harris] like so many medieval cathedrals, lincoln cathedral was built over several building campaigns. we've walked through the nave to an area at the east end of the church called saint hugh's choir. named after saint hugh, who was the bishop during the rebuilding in the 13th century, and whose relics, whose remains are buried here. - [dr. steven zucker] when the church was rebuilt what is now known as saint hugh's choir was the most sacred part of the church, and the eastern most part of the church, the church has since expanded in both directions. but because, with the exception of parts of the west front, this is now the oldest part of lincoln cathedral, it's a great place for us to start. - [dr. beth harris] well this looks so early english gothic. particularly in it's use of purbeck marble, that is a kind of brownish-gray stone that came from the island of purbeck, often used in gothic architecture here in england, and makes for these lovely contrasts in tone. - [dr. steven zucker] with the limestone that's used throughout the rest of the cathedral. this is a typical gothic elevation, it's made up of three parts. the lowest part is an arcade, above that a gallery, which has a walkway within it, then the clerestory, with quite large windows, made possible by these flying buttresses on the exterior of the church. which brings the enormous weight of the stone vaulting above outside, and helps to brace the buildings lateral thrust. - [dr. beth harris] and typically for english gothic architecture we notice that the clerestory is set back, so there's a passageway in front of it, though that passageway is much narrower than the gallery below. also typically for english gothic architecture we have a sense of the width of the wall. we see that especially in the gallery, where we have these rolls of molding that create the pointed arches, and these bundles of colonnettes that carry the sub arches within. - [dr. steven zucker] also distinctly early english gothic is the fact that the rib vaults don't begin at the floor level. instead they spring from corbels midway up the facade. - [dr. beth harris] but what saint hugh's choir is known for is the vaulting. this vault has the nickname of a crazy vault, and it does indeed feel crazy, it feels irrational. normally we have a groin vault, where we can clearly see the intersecting barrel vaults, picked out by ribs that form clear diagonals, that give us a sense of the structure of the vault. but here, the ribs seem mismatched. - [dr. steven zucker] when we walk into a medieval cathedral, we expect a great degree of symmetry, but here there's an alternation that is unnerving, but it's also elegant, and to my eye, a quintessentially gothic experimentation. - [dr. beth harris] normally in a gothic church you can read the segments of space, but here, because of the craziness of the ribs, one can't read space, space becomes much more illegible, much more irrational. - [dr. steven zucker] this is the introduction of a tierceron, that is of a secondary rib. this will have an enormous impact, not only in the rest of the cathedral here in lincoln, but in cathedrals throughout the british isles. - [dr. beth harris] we begin to have linear decoration of the vaulting that is separate from the structure of the vaulting. - [dr. steven zucker] there's a sense of rhythm, a kind of musicality here. - [dr. beth harris] and we should also mention the ridge rib, that goes down the very center. and this is one of the earliest uses of the ridge rib, which will also be very common in english gothic architecture. - [dr. steven zucker] lets take a look at the part of the building that was constructed next. - [dr. beth harris] so here in the nave we see the same three part elevation of the nave arcade, the gallery and the clerestory, but here the clerestory is even taller, we see three lancet windows in each bay, and even more light floods into the church. and there's so much decoration. we see quatrefoils, ball flowers at the capitals, we see floral motifs, even little faces. - [dr. steven zucker] we see piers that are made visually lighter because they're surrounded by free-standing colonettes. - [dr. beth harris] if we look up at the vault, we see the ridge rib running down the center we see that for each bay, the ribs of the vaulting originate in the corbel and fan out, creating this lovely decorative, fan-like pattern of tiercerons, these secondary ribs. - [dr. steven zucker] but here, we also see an additional, shorter rib which is known as a lierne. - [dr. beth harris] all of these things, the tierceron, the ridge rib, the lierne, this is the vocabulary of english gothic vaulting. - [dr. steven zucker] and just note how the intersections of each of those ribs is decorated by these wonderfully elaborate bosses. we're walking from the nave, back to the eastern most end of the church, and we're surrounded by blind arcades. - [dr. beth harris] lovely slender colonettes, decorated with chevrons and other patterns. but on the far side, these deep interlocking arcades. - [dr. steven zucker] they create a wonderful complex rhythm and they're decorated with ball flowers in the capitals, chevrons, and at least the outer of the arches is made up of a trefoil. and then, as if that's not enough, there're also figural busts of angels and other saintly figures. - [dr. beth harris] we're standing in what's known as the angel choir. now it has this name because of all of the beautifully carved angels that we see in the spandrels. - [dr. steven zucker] this part of the church was added after st hugh's choir was completed, after the nave was completed, and in fact, saint hugh's remains, which are quite sacred, were translated from what is now known as his choir, to the angel choir. - [dr. beth harris] that ceremony was attended by king edward the first, and 230 knights. - [dr. steven zucker] and here we see an entirely new style in the development of english gothic. the west front had remains of the original church in a romanesque style, saint hugh's choir and the nave reflecting early english gothic, and here the second phase of the english gothic, known as the decorated. - [dr. beth harris] everywhere we look, are decorative surfaces, floral motifs, crockets. - [dr. steven zucker] starting at the bottom, you have this beautiful alternation of limestone and purbeck, but you also have piers that are made entirely of purbeck marble. - [dr. beth harris] and we have folic capitals, arches that are decorated with a zigzag pattern that resembles chevron, and the corbels are themselves, dense with foliage. - [dr. steven zucker] even the ridge rib is decorated. - [dr. beth harris] i think all of the heavy handedness of the decoration here, is an indication of the spiritual value that was placed on this part of the church where saint hugh's relics resided. we have to also remember that much of this was likely painted, so even more highly decorative. - [dr. steven zucker] lets go back to the west transept, because there are two large rose windows, very unusual in english cathedrals. at the end of the north transept, is a large rose window, known as the dean's eye. this is the older of the two. - [dr. beth harris] and here we see scenes from the last judgment. - [dr. steven zucker] and this is known as plate tracery. that is, it seems as if the stone has been cut open to fit the glass. - [dr. beth harris] if we turn around, in the south transept we see a stained glass window known as the bishop's eye. this is from a later period, and you can see the development of stained glass windows. here we see a kind of tracery known as bar tracery. so instead of a sense of puncturing the stone to allow for light to come through, we have a sense of stained glass being held up by thin ribs, in this case this beautiful, fluid, circular patterns, that form two leaf-like shapes. - [dr. steven zucker] now unfortunately the original glass that was held in place is gone. old glass was collected and put back, but we don't know if there were originally figural scenes, and if there were, what they would have represented. - [dr. beth harris] so here at lincoln, we can see the development from the anglo-norman, through the early english gothic, through the decorated. - [dr. steven zucker] this staged development allows us to read the cathedral as a kind of textbook of the development of architectural styles, but more than that, this is simply a magnificent cathedral. (cheerful piano music)",t_2f4831fade76,other,0
c_5faae28dc4a7,"there are multiple requests for including a temporal dimension in owl. some of those requirements are described in the ontology’s annotation fields (see the owl files of bfo and dolce), or the labels of the object properties in the bfo v2.1 draft, where they mention temporality that cannot be represented formally in owl: e.g., dolce has a temporally indexed parthood in the paper-based version but this could not be transferred into the owl file. this is, perhaps, even more an issue for domain ontologies. for instance, snomed ct [sno12] has concepts like “biopsy, planned”, i.e., an event is expected to happen in the future, and “concussion with loss of consciousness for less than one hour”, i.e., a specific interval and where the loss of consciousness can be before or after the concussion, the symptom hairloss during the treatment chemotherapy, and butterfly is a transformation of caterpillar. other examples are a business rule alike ‘rentalcar must be returned before deposit is reimbursed’. adding an object property before in one’s owl ontology is not going to ensure that in all possible models, some return event happened before a reimbursement event, however, because it does not know when what happened.  there is no single computational solution to solve these examples all at once in another way beyond owl. thus far, it is a bit of a patchwork of various theories and some technologies, with, among many aspects, the allen’s interval algebra [all83] with the core qualitative temporal relations (such as before and during), linear temporal logics (ltl) and computational tree logics (ctl, with branching time). there is also a time ontology6 that was recently standardized by the w3c (more explanation in [hp04]), but it is an ontology for annotations only—i.e., no temporal reasoning intended—and suffers from the class-as-instance modeling confusion7.  in the remainder of this section, we will look at some motivations for temporal ontologies first, proceed to a very expressive temporal dl, \(\mathcal{dlr_{us}}\), and finally look at several modeling issues it helps solving. although computationally, things do not look rosy at all, it is possible to squeeze out a bit here and there, which we shall touch upon at the end.  why temporal ontologies?  there are two principal parts to answering this question: because of what we want to represent and what inferencing we want to do with it.  the things to represent  quite common time aspects in conceptual data modelling for information systems are the requirements to record actual dates and intervals and calendar calculations. this is not particularly relevant for a domain ontology, but it would be useful to have an ontology about such things so that the applications use the same notions and, hence, will be interoperable in that regard.  in chapter 6 we have seen bfo and the ro, where it was the intention by its developers to add a precedes and an immediately precedes relation to the obo foundry ontologies, which could not be done other than for annotation purposes. there are more such established qualitative temporal relations, also known as the ‘allen relations’ or ‘allen’s interval algebra’, after the author who gave a first systematic and formal account of them [all83], which comprise relations such as before, after, during, while, and meet. some might say they are all the temporal relations one will ever need, but one may wish to be more specific in specialized subject domains, such as a transformation_of a caterpillar into a butterfly, not just that a butterfly was a caterpillar ‘before’, and one thing developed_from another thing in developmental biology. also, the latter two are persistent changes cf. permitting to go back to what it was before.  modelers want to do even more than that: temporalizing classes and relations. the former is well-known in databases as ‘object migration’; e.g., an active project evolves to a completed project, and each divorcee in the census database must have been married before. relation migration follows the idea of temporal classes, but applies to \(n\)-ary tuples (with \(n\geq 2\)); e.g. ‘during \(x\)’s lifetime, it always has \(y\) as part’ and ‘every passenger that boards the plane must have checked in before departure of that flight’.  more comprehensive and real examples, can be found in, among others, [agk08, kee09, ka10, ssbs09]. this is not to say that all ontologies have, or ought have, a temporal component to represent the subject domain as accurately as possible. it depends on the use case scenarios and cqs devised for the ontology.  temporal reasoning services  as with a-temporal ontologies, one would want to have the same ones for temporal ontologies, such as satisfiable checking, subsumption reasoning, and classification. logical implications are a bit more involved; e.g., given \(b\sqsubseteq a\), then it must be the case that objects ‘active’ (alive) in \(b\) must be active in \(a\) and, e.g., to come up for promotion to become a company’s manager (b), one must first exist as an employee (a) of that company. also, an ontology should permit either a statement that ‘x must happen before y’ or that ‘y must happen before x’, but not both. that is, there are temporal constraints that are not permitted to be contradicted, and algorithms are needed to check for that.  one also would want to be able to query temporal information. for instance, to retrieve the answer to “who was the south african president after nelson mandela?” and “which library books have not been borrowed in the past five years?”. this also suggests that the ‘plain’ obda may be extended to a temporal obda system; see [akk+17] for a recent survey. there is a range of other examples that involve time in some way in information systems, and which have been solved and implemented already, such as querying with a calendar hierarchy and across calendars and finding a solution satisfying a set of constraints for scheduling the lecture hours of a study program; there uses are outside the scope.  open issues  there are many problems that are being investigated in temporal information and knowledge processing. on the one hand, there are the modeling issues in ontology development and figuring out what temporal features modelers actually require in a temporal logic cf. the logicians deciding which temporal features a modeler gets (typically only the computational well-behaved ones), the interaction between temporal logic and temporal databases (temporal obda), and further investigation into the interaction between temporal dls with temporal conceptual data modeling. this, in turn, requires one to look into the computational properties of various fragments of expressive temporal logics. more fundamental issues have to do with making choices regarding linear time vs. branching time (ltl vs ctl), endurantism vs. perdurantism (‘4d-fluents’) as was noted in chapter 6 as a choice for foundational ontologies, and dense time vs points in time.  temporal dls  if one assumes that recent advances in temporal dls may have the highest chance of making it into a temporal owl, then the following is ‘on offer’.  a very expressive (undecidable) dl language is \(\mathcal{dlr_{us}}\) (with the \(\mathcal{u}\)ntil and since operators), which already has been used for temporal conceptual data modeling [aps07] and for representing essential and immutable parts and wholes [agk08], which also solves the boxer example of section 6.2: part-whole relations. it uses linear time and mostly qualitative temporal constraints.  an inexpressive language is tdl-lite [akl+07], which is a member of the dl-lite family of dl languages (of which one is the basis for owl 2 ql). it also uses linear time and mostly qualitative temporal constraints, but fewer of them (e.g., one can’t have temporal relations).  metric temporal logic, which zooms in on quantitative temporal constraints; e.g. [bbk+17].  4-d fluents/n-ary approach in owl with swrl rules [bpta17], rather than a new language.  it is already known that \(\mathcal{el}++\) (the basis for owl 2 el) does not keep the nice computational properties when extended with ltl, and results with \(\mathcal{el}++\) with ctl are not out yet. if you are really interested in the topic, you may want to have a look at a survey [lwz08] or take a broader scope with any of the four chapters from the kr handbook [vhlp08] that cover temporal knowledge representation and reasoning, situation calculus, event calculus, and temporal action logics, or the handbook of temporal reasoning in artificial intelligence [em05]. to give a flavor of how temporal logics may look like and what one can do with it, we shall focus on \(\mathcal{dlr_{us}}\), which has been extended with temporal relations and attributes and is also used for temporal conceptual modeling (including a graphical notation in the new trend notation [kb17]).  the \(\mathcal{dlr_{us}}\) temporal dl  \(\mathcal{dlr_{us}}\) [afwz02] combines the propositional temporal logic with \(\mathcal{s}\)ince and \(\mathcal{u}\)ntil operators with the a-temporal dl \(\mathcal{dlr}\) [cdg03] and can be regarded as an expressive fragment of the first-order temporal logic \(l^{ \{since, until\}}\) [ct98, hwz99, gkwz03].  as with other \(\mathcal{dlr}\)s, the basic syntactical types of \(\mathcal{dlr_{us}}\) are classes and \(n\)-ary relations \((n\geq 2)\). starting from a set of atomic classes (denoted by \(cn\)), a set of atomic relations (denoted by \(rn\)), and a set of role symbols (denoted by \(u\)), we can define complex class and relationship expressions (see upper part of figure 10.2.1), where the restriction that binary constructors (\(\sqcap,\sqcup,\mathcal{u},\mathcal{s}\)) are applied to relations of the same arity, \(i, j, k, n\) are natural numbers, \(i\leq ≤ n, j\) does not exceed the arity of \(r\). all the boolean constructors are available for both class and relation expressions. the selection expression \(u_{i} /n : c\) denotes an \(n\)-ary relation whose \(i\)-th argument \((i\leq n)\), named \(u_{i}\) , is of type \(c\). (if it is clear from the context, we omit \(n\) and write \((u_{i} : c)\).) the projection expression \(\exists ≶^{k} [u_{j} ]r\) is a generalization with cardinalities of the projection operator over argument \(u_{j}\) of relation \(r\); the classical projection is \(\exists\geq^{1} [u_{j} ]r\).  the model-theoretic semantics of \(\mathcal{dlr_{us}}\) assumes a flow of time \(\mathcal{t} =\langle\mathcal{t}_{p} &lt;1\rangle\), where \(\mathcal{t}_{p}\) is a set of time points and \(&lt;\) a binary precedence relation on \(\mathcal{t}_{p}\), assumed to be isomorphic to \(\langle\mathbb{z}, &lt;\rangle\). the language of \(\mathcal{dlr_{us}}\) is interpreted in temporal models over \(\mathcal{t}\) , which are triples of the form \(\mathcal{i}\doteq\langle\mathcal{t},\delta^{\mathcal{i}},\cdot^{\mathcal{i}(t)}\rangle\), where \(\delta^{\mathcal{i}}\) is nonempty set of objects (the domain of \(\mathcal{i}\)) and \(\cdot^{\mathcal{i}(t)}\) an interpretation function. since the domain, \(\delta^{\mathcal{i}}\) , is time independent, we assume here the so called constant domain assumption with rigid designator—i.e., an instance is always present in the interpretation domain and it identifies the same instance at different points in time. the interpretation function is such that, for every \(t\in\mathcal{t}\) (a shortcut for \(t\in\mathcal{t}_{p}\)), every class \(c\), and every \(n\)-ary relation \(r\), we have \(c^{\mathcal{i}(t)}\subseteq\delta^{\mathcal{i}}\) and \(r^{\mathcal{i}(t)}\subseteq (\delta^{\mathcal{i}})^{n} \). the semantics of class and relation expressions is defined in the lower part of fig. 10.2.3, where \((u, v) = \{w\in\mathcal{t} | u &lt; w &lt; v\}\). for classes, the temporal operators \(\diamondsuit^{+}\) (some time in the future), \(\oplus\) (at the next moment), and their past counterparts can be defined via \(\:\mathcal{u}\) and \(\mathcal{s}\): \(\diamondsuit^{+} c\equiv \top\mathcal{u} c, \oplus c\equiv\bot\mathcal{u} c\), etc. the operators \(\box^{+}\) (always in the future) and \(\box^{−}\) (always in the past) are the duals of \(\diamondsuit^{+}\) (some time in the future) and \(\diamondsuit^{−}\) (some time in the past), respectively, i.e., \(\box^{+} c\equiv\neg\diamondsuit^{+}\neg c\)  figure 10.2.1: syntax and semantics of \(\mathcal{dlr_{us}}\).  and \(\box^{−} c\equiv\neg\diamondsuit^{−}\neg c\), for both classes and relations. the operators \(\diamondsuit^{*}\) (at some moment) and its dual \(\box^{*}\) (at all moments) can be defined for both classes and relations as \(\diamondsuit^{*} c\equiv c\sqcup\diamondsuit^{+}c\sqcup\diamondsuit^{−} c\) and \(\box^{*} c\equiv c\sqcap\box^{+} c\sqcap\box^{−} c\), respectively.  a \(\mathcal{dlr_{us}}\) knowledge base is a finite set \(\sigma\) of \(\mathcal{dlr_{us}}\) axioms of the form \(c_{1}\sqsubseteq c_{2}\) and \(r_{1}\sqsubseteq r_{2}\), with \(r_{1}\) and \(r_{2}\) being relations of the same arity. an interpretation \(\mathcal{i}\) satisfies \(c_{1}\sqsubseteq c_{2} (r_{1}\sqsubseteq r_{2})\) if and only if the interpretation of \(c_{1} (r_{1})\) is included in the interpretation of \(c_{2} (r_{2})\) at all time, i.e., \(c^{\mathcal{i}(t)}_{1}\subseteq c^{\mathcal{i}(t)}_{2} (r^{\mathcal{i}(t)}_{1}\subseteq r^{\mathcal{i}(t)}_{2} )\), for all \(t\in\mathcal{t}\) . thus, \(\mathcal{dlr_{us}}\) axioms have a global reading. to see examples on how a \(\mathcal{dlr_{us}}\) knowledge base looks like we refer to the following sections where examples are provided.  modeling  let us look at some examples, both in shorthand \(\mathcal{dlr_{us}}\) notation and in their semantics. the second line provides a verbalization of the axiom, using the cnl approach described in section 9.2: ontology verbalization, but then tailored to verbalizing the temporal features.  – \(\texttt{mscstudent}\sqsubseteq\diamondsuit^{*}\neg\:\texttt{mscstudent}\)  each msc student is not a(n) msc student for some time.  – \(\texttt{marriedto}\sqsubseteq\diamondsuit^{*}\neg\:\texttt{marriedto}\)  the objects participating in a fact in person married to person do not relate through married-to at some time; or: people who are married now aren’t married at another time.  – \(o\in\ academic ^{\mathcal{i}(t)} ∧ o\notin phdstudent^{\mathcal{i}(t)} ∧ o\in phdstudent^{\mathcal{i}(t−1)} ∧ o\notin academic^{\mathcal{i}(t−1)}\)  a(n) academic may have been a(n) phd student before, but is not a(n) phd student now.  – \(o\in frog^{\mathcal{i}(t)} →\exists t^{'} < t.o\in dev^{\mathcal{i}(t^{'})}_{tadpole,frog}\)  each frog was a(n) tadpole before, but is not a(n) tadpole now.  the aforementioned ‘planned’ biopsy can now also be represented as something that will hold in the future \(\diamondsuit^{+}\texttt{biopsy}\) and the returning (of the car) before the reimbursement (of the deposit) as, e.g., \(\texttt{reimbursement}\sqsubseteq\diamondsuit^{−}\texttt{return}\), i.e., “if reimbursement, then sometime in the past there was a return”.  with this machinery, one can also solve the “assuming boxers must have their own hands and boxers are humans, is hand part of boxer in the same way as brain is part of human?” that we have encountered in section 6.2: part-whole relations. recasting this problem into the temporal dimension, we can encode it in \(\mathcal{dlr_{us}}\) and prove the correctness of the intended behaviour [agk08]. the hand being part of the boxer is an immutable parthood, whereas the brain being part of the human is an essential parthood. that is: the ‘essential’ parthood relation means, informally, that ‘that specific object must be part of the whole for entire lifetime of the whole object’, whereas ‘immutable’ means, informally, ‘for the time the objects are instance of that specific class (which is typically a role they play for some duration that is less that the lifetime of the object), it is essential’. the formal apparatus is quite lengthy, including recasting ontoclean’s rigidity (recall section 5.2: methods to improve an ontology’s quality ""philosophy-based methods: ontoclean to correct a taxonomy"") into the temporal modality, and is described in detail in [agk08]. the short version showing the main axioms that represent that difference is as follows. first, for illustrative purpose, let’s introduce a part-whole relation to relate brain to human:  \(\texttt{humanbrainpw}\sqsubseteq\texttt{partwhole}\)  \(\texttt{humanbrainpw}\sqsubseteq\texttt{part : brain}\sqcap\texttt{whole : human}\)  subsequently, we add the ‘essential’ to it, which means it holds at all times, i.e., \(\box^{*}\) , for both human (once a human always a human for the whole lifetime of the object—it is a rigid property) and the essential parthood (once a part, always a part):  \(\texttt{human}\sqsubseteq\box^{*}\texttt{human}\)  \(\texttt{human}\sqsubseteq\exists\texttt{[whole]}\box^{*}\texttt{humanbrainpw}\)  then, the boxer’s hands. also here, for illustrative purpose, we introduce the part-whole relation humanhandpw to relate the hand to human:  \(\texttt{humanhandpw}\sqsubseteq\texttt{partwhole}\)  \(\texttt{humanhandpw}\sqsubseteq\texttt{part : hand}\sqcap\texttt{whole : human}\)  to state that a boxer is at some time not \((\diamondsuit^{*}\neg)\) a boxer (an anti-rigid property), and is a human, the following axioms suffice:  \(\texttt{boxer}\sqsubseteq\diamondsuit^{*}\neg\texttt{boxer}\)  \(\texttt{boxer}\sqsubseteq\texttt{human}\)  the next step is the cardinality constraint that a boxer must have exactly two hands, if temporarily something is wrong with the boxer (e.g., the boxer has an injured hand for some time) he isn’t a boxer either (‘suspended’), and finally, that if that part-whole relation does not hold anymore (‘disabled’), then the boxer ceases to be a boxer:  \(\texttt{boxer}\sqsubseteq\exists^{=2}\texttt{ [whole]humanhandpw}\)  \(\texttt{suspended-humanhandpw}\sqsubseteq\texttt{whole : suspended-boxer}\)  \(\texttt{disabled-humanhandpw}\sqsubseteq\texttt{whole : disabled-boxer}\)  note that ‘suspended’ and ‘disabled’ are names for so-called status relations that are defined formally in [agk08] and do not exactly have their colloquial meaning. if the boxer has to be continuously active by some rule from, say, the boxing association, then the ‘suspended’ axiom has to replaced by the following one, i.e., the relation is not allowed to be ‘suspended’:  \(\texttt{suspended-humanhandpw}\sqsubseteq\bot\)  obviously, this can be defined for any essential or immutable relation, regardless whether it is a part-whole relation or not. the upside is that now we know how to represent it; the downside is that it uses both dl role hierarchies and temporal relations, which are computationally costly. what to do with this insight is something that a modeler has to decide.  footnotes  6http://www.w3.org/tr/owl-time/ (http://www.w3.org/tr/owl-time/)  7e.g., dayofweek(friday) and, in the one for the gregorian calendar, monthofyear(january): friday does have instances, such as friday 6 july 2018 and friday 13 july 2018, etc., and likewise for the other days and for the month instances.",t_471b68343444,other,0
c_13e3c1933c24,"in the last decennia extensive research has been carried out into the cutting of water saturated sand. in the cutting of water-saturated sand, the phenomenon of dilatation plays an important role. in fact the effects of gravity, inertia, cohesion and adhesion can be neglected at cutting speeds in the range of 0.5 – 10 m/s. in the cutting equations, as published by miedema (1987 september), there is a division by the sine of the sum of the blade angle, the shear angle, the angle of internal friction and the soil/interface friction angle. when the sum of these angle approaches 180o, a division by zero is the result, resulting in infinite cutting forces. this may occur for example for α=80o, α=30o, α=40o and α=30o. when this sum is greater than 180 degrees, the cutting forces become negative. it is obvious that this cannot be the case in reality and that nature will look for another cutting mechanism.  hettiaratchi and reece (1975) found a mechanism, which they called boundary wedges for dry soil. at large cutting angles a triangular wedge will exist in front of the blade, not moving relative to the blade. this wedge acts as a blade with a smaller blade angle. in fact, this reduces the sum of the 4 angles mentioned before to a value much smaller than 180o. the existence of a dead zone (wedge) in front of the blade when cutting at large cutting angles will affect the value and distribution of vacuum water pressure on the interface. he et al. (1998) proved experimentally that also in water saturated sand at large cutting angles a wedge will occur. a series of tests with rake angles 90, 105 and 120 degrees under fully saturated and densely compacted sand condition was performed by he et al. (1998) at the dredging technology laboratory of delft university of technology. the experimental results showed that the failure pattern with large rake angles is quite different from that with small rake angles. for large rake angles a dead zone is formed in front of the blade, but not for small rake angles. in the tests he carried out, both a video camera and film camera were used to capture the failure pattern. the video camera was fixed on the frame which is mounted on the main carriage, translates with the same velocity as the testing cutting blade. shown in the static slide of the video record, as in figure 12-1, the boundary wedges exist during the cutting test. the assumption of an alternative failure mechanism is based on a small quantity of picture material, see figure 12-1. it is described as a static wedge in front of the blade, which serves as a new virtual blade over which the sand flows away.  figure 12-1: failure pattern with rake angle of 120o.  although the number of experiments published is limited, the research is valuable as a starting point to predict the shape of the wedge. at small cutting angles the cutting forces are determined by the horizontal and vertical force equilibrium equations of the sand cut in front of the blade. these equations contain 3 unknowns, so a third equation/condition had to be found. the principle of minimum energy is used as a third condition to solve the 3 unknowns. this has proved to give very satisfactory results finding the shear angle and the horizontal and vertical cutting forces at small cutting angles. at large cutting angles, a 4th unknown exists, the wedge angle or virtual blade angle. this means that a 4th equation/condition must be found in order to determine the wedge angle. there are 3 possible conditions that can be used: the principle of minimum energy, the circle of mohr, the equilibrium of moments of the wedge. in fact, there is also a 5th unknown, the mobilized friction on the blade. new research carried out in the dredging engineering laboratory shows that a wedge exists, but not always a static wedge. the sand inside the wedge is still moving, but with a much lower velocity then the sand outside the wedge. this results in fully mobilized friction on the blade. the bottom boundary of the wedge, which is horizontal for a static wedge, may have a small angle with respect to the horizontal in the new case considered.  figure 12-2: sand cutting with a wedge, definitions.  definitions:  a: the wedge tip.  b: end of the shear plane.  c: the blade top.  d: the blade tip.  a-b: the shear plane.  a-c: the wedge surface.  a-d: the wedge bottom.  d-c: the blade surface.  hb: the height of the blade.  hi: the thickness of the layer cut.  vc: the cutting velocity.  α: the blade angle.  β: the shear angle.  fh: the horizontal force, the arrow gives the positive direction.  fv: the vertical force, the arrow gives the positive direction.  figure 12-3: the cutting mechanism.  figure 12-2 shows the definitions of the cutting process with a static wedge. a-b is the shear plane where dilatation occurs. a-c is the front of the static wedge and forms a pseudo cutting blade. a-c-d is the static wedge, where c- d is the blade, a-d the bottom of the wedge and a-c the pseudo blade or the front of the wedge. the sand wedge theory is based on publications of hettiaratchi and reece (1975), miedema (1987 september), he et al. (1998), yi (2000), miedema et al. (2001), yi et al. (2001), ma (2001), miedema et al. (2002a), miedema et al. (2002b), yi et al. (2002), miedema (2003), miedema et al. (2003), miedema (2004), miedema et al. (2004), he et al. (2005), ma et al. (2006a), ma et al. (2006b), miedema (2005), miedema (2006a), miedema (2006b).",t_1e1817897607,other,0
c_3be9dcdd38c6,"sal solves 9.087+15.31 using the ""standard algorithm"".  let's see if we can add 9.087 to 15.31. and i encourage you to pause the video and try to do it on your own. so i'm assuming you have tried to do it on your own. and now let's see how we could actually tackle this. now, one thing i want to point out, some of you all might have seen these numbers all lined up and immediately want to say, hey, 7 plus 1 is 8, and 8 plus 3 is 11, carry the 1, et cetera, et cetera. and if you did that, you would be making a mistake. because, you see, right over here, these decimals aren't lined up. here, if you did that, you would be adding the 7 thousandths to 1 hundredths. you would be adding 0 tenths to 5 ones. you would be adding 9 to 1 tens, or essentially, this is a 10 right over here. so the places would be all mixed up. so what you need to do is to actually align the decimals so that your place values are aligned. so what you want to do is you want to align things up. so we could write 9.087. and then we want to align the decimal. so let's align the decimal. this is what has to match up. and this is going to be 15.31. and this should hopefully make sense to you as well. this is 9 point something plus 15 point something so it's going to be-- if you add 9 to 15, it will be 24 point something, give or take a little bit. and you see that here. here you have a 9 plus the 15. so you have lined up the appropriate place values. and now we are ready to add. it's a good idea to start with the smallest place value, so if you have any extra at a certain place, you can bring something into the next place value. so here you say 7 plus-- well, this is 7 thousandths. it's in the thousandths place. and you might want to-- you say, well, what do i add it to? there are no thousandths right over here. and you're right. there are no thousandths. so we could literally write 0 thousandths. so 7 thousandths plus 0 thousandths is 7 thousandths. 8 hundredths plus 1 hundredth is 9 hundredths. 0 plus 0 tenths plus 3 tenths is 3 tenths. we got our decimal. then you have 9 ones plus 5 ones is 14 ones. well, 14 ones is the same thing as 4 ones and 1 ten. so we'll carry that 1 right over there. this is just 1 ten plus 4 ones, which is 14. and so then finally, you have 1 ten plus another ten is 2. so we get 24.397.",t_e0a678db7a14,other,0
c_06989acf533c,"environmental justice  environmental justice is defined as the fair treatment and meaningful involvement of all people regardless of race, color, national origin, or income with respect to the development, implementation, and enforcement of environmental laws, regulations, and policies. it will be achieved when everyone enjoys the same degree of protection from environmental and health hazards and equal access to the decision-making process to have a healthy environment in which to live, learn, and work.  during the 1980’s minority groups protested that hazardous waste sites were preferentially sited in minority neighborhoods. in 1987, benjamin chavis of the united church of christ commission for racism and justice coined the term environmental racism to describe such a practice. the charges generally failed to consider whether the facility or the demography of the area came first. most hazardous waste sites are located on property that was used as disposal sites long before modern facilities and disposal methods were available. areas around such sites are typically depressed economically, often as a result of past disposal activities. persons with low incomes are often constrained to live in such undesirable, but affordable, areas. the problem more likely resulted from one of insensitivity rather than racism. indeed, the ethnic makeup of potential disposal facilities was most likely not considered when the sites were chosen.  decisions in citing hazardous waste facilities are generally made on the basis of economics, geological suitability and the political climate. for example, a site must have a soil type and geological profile that prevents hazardous materials from moving into local aquifers. the cost of land is also an important consideration. the high cost of buying land would make it economically unfeasible to build a hazardous waste site in beverly hills. some communities have seen a hazardous waste facility as a way of improving their local economy and quality of life. emelle county, alabama had illiteracy and infant mortality rates that were among the highest in the nation. a landfill constructed there provided jobs and revenue that ultimately helped to reduce both figures.  in an ideal world, there would be no hazardous waste facilities, but we do not live in an ideal world. unfortunately, we live in a world plagued by rampant pollution and dumping of hazardous waste. our industrialized society has necessarily produced wastes during the manufacture of products for our basic needs. until technology can find a way to manage (or eliminate) hazardous waste, disposal facilities will be necessary to protect both humans and the environment. by the same token, this problem must be addressed. industry and society must become more socially sensitive in the selection of future hazardous waste sites. all humans who help produce hazardous wastes must share the burden of dealing with those wastes, not just the poor and minorities.  figure \(\pageindex{1}\). an inupiaq woman, nome, alaska, c. 1907. credit: this work (https://en.wikipedia.org/wiki/history_of_alaska#/media/file:inuit_woman_1907_crisco_edit_2.jpg) is in the public domain, cc0 (http://creativecommons.org/publicdomain/zero/1.0/)  indigenous people  since the end of the 15th century, most of the world’s frontiers have been claimed and colonized by established nations. invariably, these conquered frontiers were home to people indigenous to those regions. some were wiped out or assimilated by the invaders, while others survived while trying to maintain their unique cultures and way of life. the united nations officially classifies indigenous people as those “having an historical continuity with pre-invasion and pre-colonial societies,” and “consider themselves distinct from other sectors of the societies now prevailing in those territories or parts of them.” furthermore, indigenous people are “determined to preserve, develop and transmit to future generations, their ancestral territories, and their ethnic identity, as the basis of their continued existence as peoples in accordance with their own cultural patterns, social institutions and legal systems.” a few of the many groups of indigenous people around the world are: the many tribes of native americans (i.e., navajo, sioux) in the contiguous 48 states, the inuit of the arctic region from siberia to canada, the rainforest tribes in brazil, and the ainu of northern japan.  many problems face indigenous people including the lack of human rights, exploitation of their traditional lands and themselves, and degradation of their culture. in response to the problems faced by these people, the united nations proclaimed an “international decade of the world’s indigenous people” beginning in 1994. the main objective of this proclamation, according to the united nations, is “the strengthening of international cooperation for the solution of problems faced by indigenous people in such areas as human rights, the environment, development, health, culture and education.” its major goal is to protect the rights of indigenous people. such protection would enable them to retain their cultural identity, such as their language and social customs, while participating in the political, economic and social activities of the region in which they reside.  despite the lofty u.n. goals, the rights and feelings of indigenous people are often ignored or minimized, even by supposedly culturally sensitive developed countries. in the united states many of those in the federal government are pushing to exploit oil resources in the arctic national wildlife refuge on the northern coast of alaska. the “gwich’in,” an indigenous people who rely culturally and spiritually on the herds of caribou that live in the region, claim that drilling in the region would devastate their way of life. thousands of years of culture would be destroyed for a few months’ supply of oil. drilling efforts have been stymied in the past, but mostly out of concern for environmental factors and not necessarily the needs of the indigenous people. curiously, another group of indigenous people, the “inupiat eskimo,” favor oil drilling in the arctic national wildlife refuge. because they own considerable amounts of land adjacent to the refuge, they would potentially reap economic benefits from the development of the region.  the heart of most environmental conflicts faced by governments usually involves what constitutes proper and sustainable levels of development. for many indigenous peoples, sustainable development constitutes an integrated wholeness, where no single action is separate from others. they believe that sustainable development requires the maintenance and continuity of life, from generation to generation and that humans are not isolated entities, but are part of larger communities, which include the seas, rivers, mountains, trees, fish, animals and ancestral spirits. these, along with the sun, moon and cosmos, constitute a whole. from the point of view of indigenous people, sustainable development is a process that must integrate spiritual, cultural, economic, social, political, territorial and philosophical ideals.  attribution  essentials of environmental science (http://www.ck12.org/user%3azg9yc25lckbnbwfpbc5jb20./book/essentials-of-environmental-science/section/2.1/)  by kamala doršner is licensed under cc by 4.0. modified from original by matthew r. fisher.",t_9be51db476a6,other,0
c_940c020b6ea4,"chapter 5 of the book on powershell.chapter 5: basic set operations a set is a collection of items which can be anything. whatever operator we need to work on these sets are in short the set operators and the operation is also known as set operation. basic set operation includes union, intersection as well as addition, subtraction, etc.  section 5.1: filtering: where-object / where / ? filter an enumeration by using a conditional expression synonyms: where-object where ?  example: $names = @( ""aaron"", ""albert"", ""alphonse"",""bernie"", ""charlie"", ""danny"", ""ernie"", ""frank"") $names | where-object { $_ -like ""a*"" } $names | where { $_ -like ""a*"" } $names | ? { $_ -like ""a*"" }  returns: aaron albert alphonse  section 5.2: ordering: sort-object / sort sort an enumeration in either ascending or descending order synonyms: sort-object sort  assuming: $names = @( ""aaron"", ""aaron"", ""bernie"", ""charlie"", ""danny"" )  ascending sort is the default: $names | sort-object $names | sort  aaron aaron bernie goalkicker.com – powershell® notes for professionals  14  charlie danny to request descending order: $names | sort-object -descending $names | sort -descending  danny charlie bernie aaron aaron you can sort using an expression. $names | sort-object { $_.length }  aaron aaron danny bernie charlie  section 5.3: grouping: group-object / group you can group an enumeration based on an expression. synonyms: group-object group  examples: $names = @( ""aaron"", ""albert"", ""alphonse"",""bernie"", ""charlie"", ""danny"", ""ernie"", ""frank"") $names | group-object -property length $names | group -property length  response: count name group 4 5 {aaron, danny, ernie, frank} 2  6  {albert, bernie}  1  8  {alphonse}  1  7  {charlie}  goalkicker.com – powershell® notes for professionals  15  section 5.4: projecting: select-object / select projecting an enumeration allows you to extract speciﬁc members of each object, to extract all the details, or to compute values for each object synonyms: select-object select  selecting a subset of the properties: $dir = dir ""c:\myfolder"" $dir | select-object name, fullname, attributes $dir | select name, fullname, attributes  name fullname attributes images c:\myfolder\images directory data.txt c:\myfolder\data.txt archive source.c c:\myfolder\source.c archive selecting the ﬁrst element, and show all its properties: $d | select -first 1 *  pspath psparentpath pschildname psdrive psprovider psiscontainer basename mode name parent exists root fullname extension creationtime creationtimeutc lastaccesstime lastaccesstimeutc lastwritetime lastwritetimeutc attributes  goalkicker.com – powershell® notes for professionals  16",t_dbac6386ca37,other,0
c_f62d97ee8f66,"what is 'innate behaviour'? where does it feature in the environment? and how does it compare to 'learned behaviour?   innate behaviour is instinctive; it is determined by our nervous system and does not involve conscious decision. it is often inflexible, such as a reflex response to a stimulus. we do not acquire innate behaviour through learning and practice, but are born with the behaviour pattern 'hard-wired' into our nervous system. we have inherited the response in our genes from our parents. there is little variation in response between individuals. you do not need to learn how to sneeze, or a spider does not learn how to spin a web; this things come 'naturally'. learned behaviour however does involve learning, and we modify our learned behaviour responses as a result of experience. this means that learned behaviour does vary between individuals.  ",t_20e07b6d7c83,other,0
c_0480dca4469e,"mysterious negative numbers! what are they? they are numbers less than zero. if you understand the nature of below zero temperatures, you can understand negative numbers. we'll help.  in this video, i want to familiarize ourselves with negative numbers, and also learn a bit of how do we add and subtract them. and when you first encounter them, they look like this deep and mysterious thing. when we first count things, we're counting positive numbers. what does a negative number even mean? but when we think about it, you probably have encountered negative numbers in your everyday life. and let me just give you a few examples. so before i actually give the example, the general idea is a negative number is any number less than the 0. and if that sounds strange and abstract to you, let's just think about it in a couple of different contexts. if we're measuring the temperature-- and it could be in celsius or fahrenheit. let's just assume we're measuring it in celsius. and so, let me draw a little scale that we can measure the temperature on. and so, let's say this is 0 degrees celsius. that is 1 degree celsius, 2 degrees celsius, 3 degrees celsius. now let's say that it's a pretty chilly day, and it's currently 3 degrees celsius. and someone who predicts the future tells you that it is going to get 4 degrees colder the next day. so how cold will it be? how can you represent that coldness? well, if it only got 1 degree colder, we would be at 2 degrees. but we know we have to go 4 degrees colder. if we got 2 degrees colder, we would be at 1 degree. if we got 3 degrees colder, we would be at 0. but 3 isn't enough. we have to get 4 degrees colder. so we have to actually go one more below the 0. and that one below 0, we call that negative 1. and so, you can kind of see that the number line, as you go to the right of 0 on the number line, it increases in positive values. as you go to the left of the number line, you're going to have negative 1. then you're going to have negative 2. and you're going to have negative 3. and you're going to have-- depending on how you think about it-- you're going to have larger negative numbers. but i want to make it very clear-- negative 3 is less than negative 1. there is less heat in the air then negative 1. it is colder. there's less temperature there. so let me just make it very clear. negative 100 is much smaller than negative 1. you might look at 100, and you might look at 1, and your gut reaction is to say, wow, 100 is a much larger number than 1. but when you think about it, negative 100 means there's a lack of something. if it's negative 100 degrees, there's a lack of heat. so there's much less heat here then if we had negative 1. let me give you another example. let's say in my bank account today, i have $10. let me do this in a new color. so let's say today i have $10. now let's say i go out there-- because i feel good about my $10-- and let's say i go and spend $30. and for the sake of argument, let's say i have a very flexible bank, one that lets me spend more money than i have-- and these actually exist. so i spend $30. so what's my bank account going to look like? so let me draw a number line here. and you might already have an intuitive response. i will owe the bank some money. so let me write this over here. so tomorrow, what is my bank account? so you might immediately say, look, if i have $10, and i spend $30, there's $20 that had to come from someplace, and that $20 is coming from the bank. so i'm going to owe the bank $20. and so, in my bank account, to sure how much i have, i could say $10 minus $30 is actually negative $20. so in my bank account tomorrow, i'm going to have negative $20. so if i say i have negative $20, that means that i owe the bank. i don't even have it. not only do i have nothing, i owe something. it's going in reverse. here, i have something to spend. if my $10 is in my bank, that means the bank owes me $10. i have $10 that i can use to go spend. now all of a sudden, i owe the bank. i've gone in the other direction. and if we use a number line here, it should hopefully make a little bit of sense. so that is 0. i'm starting off with $10. and spending $30 means i'm moving 30 spaces to the left. so if i move 10 spaces to the left-- if i only spend $10, i'll be back at 0. if i spend another $10, i'll be at negative $10. if i spend another $10 after that, i will be at negative $20. so each of these distances-- i spent $10, i'd be at 0. another $10, i'd be at negative $10. another $10, i would be at negative $20. and this whole distance right here is how much i spent. i spent $30. so the general idea, when you spend or if you subtract or if we're getting colder, you would move to the left of the number line. the numbers would get smaller. and we now know they can get smaller than 0. they can go to negative 1, negative 2, they can even go to negative 1.5, negative 1.6. you're getting more and more negative the more you lose. if you're adding-- if i go and get my paycheck, i will move to the right of the number line. now with that out of the way, let's just do a couple of more pure math problems. and just think about what it means if we were to say 3 minus 4. so once again, this is exactly the situation that we did here with the temperature. we're starting at 3, and we're subtracting 4. so we're going to move 4 to the left. we go 1, 2, 3, 4. so that gets us to negative 1. and when you're starting to do this, you really understand what a negative number means. i really encourage you to visualize the number line, and really move along it depending on whether you're adding and subtracting. now let's do a couple more. let's say i have 2 minus 8. and we'll think about more ways to do this in future videos. but once again, you just want to do the number line. you have a 0 here. let me draw the spacing a little bit. so we have 0 here. we're at 1, 2. if we're subtracting 8, that means we're going to move 8 to the left. so we're going to go 1 to the left, 2 the left. so we've gone 2 to the left to get to 0. we have to move how many more to the left? well, we've already moved 2 the left. to get to 8, we have to move 6 more to the left. so we're going to have to move 1, 2, 3, 4, 5, 6 more to the left. well, where is that going to put us? well, we were at 0. this is a negative 1, negative 2, negative 3, negative 4, negative 5, negative 6. so 2 minus 8 is negative 6. 2 minus 2 would be 0. when you're subtracting 8, you're subtracting another 6. so we'd go up to negative 6. we go 6 below 0. let me do one more example. and this one will be a little less conventional for you, but hopefully it will make sense. and i'll do this in a new color. let me take negative 4 minus 2. so we're starting at a negative number, and then we're subtracting from that. and if this seems confusing, just remember the number line. so this is 0 right here. this is negative 1, negative 2, negative 3, negative 4. so that's where we're starting. now we're going to subtract 2 from negative 4. so we're going to move 2 to the left. so if we subtract 1, we will be at negative 5. if we subtract another 1, we are going to be at negative 6. we are going to be at negative 6. so this is negative 6. let's do another interesting thing. let's start at negative 3. let's say we have negative 3. instead of subtracting something from that, let's add 2 to it. so where would this put us on the number line? so we're starting at negative 3, and we're adding 2, so we're going to move to the right. so you add 1, you become negative 2. but if you add another 1, which we have to do, you become negative 1. you move 2 to the right. so negative 3 plus negative 2 is negative 1. and you can see for yourself but this all fits our traditional notion of adding and subtracting. if we start at negative 1, and we subtract 2, we should get negative 3-- kind of reverse of this thing up here. negative 3 plus 2 gets us there. then if we start then, we subtract 2, we should get back to negative 3, and we see that happens. if you start at negative 1 right over here, and you subtract 2-- you move 2 to the left-- you get back to negative 3. so hopefully, this starts to give you a sense of what it means to deal with, or add and subtract, negative numbers. but we're going to give a lot more examples in the next video. and we're actually going to see what it means to subtract a negative number.",t_7ab6740c1f76,other,0
c_d66d0bc7cfc3,"what is photosynthesis? | biology | fuseschool  we wouldn’t have life without photosynthesis; life processes depend upon it. not only are photosynthetic organisms the main producers of food, but without photosynthesis earth’s atmosphere would lose its oxygen.   in photosynthesis is that green plants and algae trap light from the sun to fix carbon dioxide with hydrogen and water. this makes organic compounds which then provide food for not only the plant itself but also all animals.   find out more in this video!   ",t_8b1628016e6b,other,0
c_70bd1f11980f,"in this video david gives some problem solving strategies for centripetal force problems and explains many common misconceptions people have about centripetal forces.  - [instructor] there are unfortunately quite a few common misconceptions that many people have when they deal with centripetal force problems, so in this video, we're gonna go over some examples to give you some problem solving strategies that you can use as well as going over a lot of the common misconceptions that people have when they deal with these centripetal motion problems. so, to start with, imagine this example, let's say a string is causing a ball to rotate in a circle. and to make it simple, let's say this ball is tracing out a perfect circle, and let's say it's sitting on a perfectly frictionless table so this would be the bird's eye view. this is the view from above. what it would look like from the side would be something like this. you'd have the ball tied to the rope and then you nail some sort of stake in the middle of the table. you tie the rope to the stake, and then you give the ball a push. and the ball's gonna take this circular path on the table when we view it from the side. but when we view it from above, you see this path traced out. so this is a bird's eye view that you would see if you were looking down from above the table, and this would be the side view. so let me ask you this question. what force is causing this ball to go in a circle? now, a lot of people want to answer that question with the centripetal force. they'd say that it's the centripetal force that points inward that causes this ball to go in a circle, and that's not wrong. it's the truth, but it's not the whole truth. and the reason is that when we say centripetal force, all we really mean is a force that's directed toward the center of the circle. so saying the force that causes this ball to go in a circle is the centripetal force is a little unsatisfying. it'd be like answering the question, what force balances the force of gravity while the ball's on the table with the answer, the upward force. i mean, yeah, we knew it had to be an upward force, but that really doesn't tell us what force it is. similarly, just saying the centripetal force just tells us what direction the force points. it doesn't really tell us what type of force this is, so to answer this question over here in a better way, if someone asked you what force counteracts gravity that keeps the ball from falling through the table, instead of saying upward force, it'd be better to just say that's the normal force. and we can do better over here as well. instead of just saying the centripetal force, we could say what kind of force this is. it's gotta be one of the forces that we already know about. i mean, it's gotta be either the force of friction or normal force or tension or the force of gravity. the centripetal force isn't a new type of force. it's just one of the forces we already know that happens to be pointing toward the center of the circle. and that's important because this is our first, big common misconception. people think the centripetal force is a new kind of force, but it's not. it's just one of the forces we already know that happen to be pointing toward the center of the circle and that happen to be causing an object to move in a circle. so in this case over here, what force is it? well, there's a rope tied to this mass, and that rope's gonna pull on it. and when a rope pulls, we call that the force of tension, so i'm gonna call this the tension. so that's a little better. now we know what kind of force is acting as the centripetal force. now, be careful out there. sometimes, people want to do this, they're like, oh yeah, there's a force of tension, and there's also a centripetal force. but that's just crazy because this tension is the centripetal force. i wouldn't draw it twice anymore than i'd come over here and say, yeah, there's a normal force, there's also upward force. the upward force is the normal force. i wouldn't draw it again. similarly, over here, i'm not gonna draw the centripetal force twice. the tension was the centripetal force. i mean, it's possible you could have two forces inward. maybe there's two ropes and you had a second tension over here pulling inward, but you'd better be able to identify what force it is before you draw it. don't just call it f centripetal, so you might be like, yeah, yeah, i get it. the centripetal force is just an extra title we give to a force that happens to point toward the center of the circle, but how would i ever solve a problem like this? what strategy do i use? i've got forces that are up, that are down, that are in. so let me show you how to solve some problems and some things to keep in mind. so let me add some numbers in here. so let's say i told you this. let's say the mass of the ball was two kilograms, the rope's length was 0.5 meters, and the ball is traveling around the circle at a constant speed of five meters per second. so what kind of question might you be asked if given a problem like this? a possible question would be, well, what's the force of tension in the rope? and so, now's a good time for me to let you in on a little secret. the secret to solving centripetal force problems is that you solve them the same way you solve any force problem. in other words, first, you draw a quality force diagram. and then you use newton's second law for one of the directions at a time. and if the direction you chose to analyze newton's second law for didn't get you to where you needed to be, just do it again. use newton's second law again for another direction, and that'll get you to where you need to be. so in other words, let's draw a quality force diagram. we've got forces, but they're kind of all over here. this side view's gonna better illustrate all the forces involved. so we've already got the normal force upward and the force of gravity downward. now, i'm gonna draw this tension pointing inward, that's the force that's acting as the centripetal force. now, we're gonna use newton's second law for one of the directions. which direction should we pick? well, which force do we want to find? we want to find this force of tension, so even though i could if i wanted to use newton's second law for this vertical direction, the tension doesn't even point that way, so i'm not gonna bother with that direction first. i'm gonna see if i can get by doing this in one step, so i'm gonna use this horizontal direction and that's gonna be the centripetal direction, i.e., into the circle. and when we're dealing with the centripetal force, we're gonna be dealing with the centripetal acceleration, so over here, when i use a and set that equal to the net force over mass, if i'm gonna use the centripetal force, i'm gonna have to use the centripetal acceleration. in other words, i'm gonna only plug forces that go into, radially into the circle here, and i'm gonna have the radial centripetal acceleration right here. and we know the formula for centripetal acceleration, that's v squared over r, so i'm gonna plug v squared over r into the left hand side. that's the thing that's new. when we used newton's second law for just regular forces, we just left it as a over here, but now, when you're using this law for the particular direction that is the centripetal direction, you're gonna replace a with v squared over r and then i set it equal to the net force in the centripetal direction over the mass. so what am i gonna plug in up here? what forces do i put up here? i mean, i've got normal force, tension, gravity. a common misconception is that people try to put them all into here. people put the gravitational force, the normal force, the tension, why not? but remember, if we've selected the centripetal direction, centripetal just means pointing toward the center of the circle, so i'm only going to plug in forces that are directed in toward the center of the circle, and that's not the normal force or the gravitational force. these forces do not point inward toward the center of the circle. the only force in this case that points toward the center of the circle is the tension force, and like we already said, that is the centripetal force. so over here, i'd have v squared over r, and that would equal the only force acting as the centripetal force is the tension. now, should that be positive or negative? well, we're gonna treat inward as positive, so any forces that point inward are gonna be positive. is it possible for a centripetal force to be negative? it is. if there was some force that pointed outward, if for some reason there was another string pulling on the ball outward, we would include that force in this calculation, and we would include it with a negative sign, so forces that are directed out of the circle, we're gonna count as negative and forces that are directed into the circle, we're gonna count as positive in here. and if they're not directed into or out, we're not gonna include them in this calculation at all. now, you might object. you might say, wait a minute. there is a force out of the circle. this ball wants to go out of the circle. there should be a force this way. this is often referred to as the centrifugal force, and that doesn't really exist. so when people say that there's an outward force trying to direct this ball out of the circle, they're usually referring to this centrifugal force, but this doesn't exist. it turns out this is not a real thing if you're using a good reference frame. there is no natural outward force for something going in a circle. you might object. you might be like, wait a minute. if i let go of this ball, it flies out of the circle. won't it go flying off this way? and no, it won't. if you let go of the string right now, for some reason the string broke, at this moment this ball would not veer off that way. there's no force pushing it to the right. the ball, if the string broke, would just follow newton's first law. it says it would just travel in a straight line with constant velocity, and it would roll off the table. so the reason you have to pull on the rope to get the ball to go in a circle is not because there's an outward force but because this ball wants to maintain its velocity. it has inertia, it wants to keep moving in a straight line, but you have to keep pulling on it to keep changing the direction of this velocity. so even though many people think there's an outward centrifugal force that's just naturally occurring on an object going in a circle, there is not. so finally, we can come back over to here. i can put my mass here. i can finally solve for my force of tension. if i do this, i'll multiply both sides by mass, and i just get that the force of tension is mass times the speed squared over the radius of the circle, and if i plug in my values, the mass was two, the speed was five, and you can't forget to square it. you divide by the radius which was 0.5, and you get that the force of tension had to be 100 newtons. so in this case, the force of tension, which is the centripetal force, is equal to 100 newtons. now, some of you might be thinking, hey, this was way too much work for what ended up being a really simple problem. why did we have to go through all the trouble of stating all of this problem solving strategy? and i agree. this one was easy, but other problems won't be easy. and if you don't have some sort of problem solving framework to fall back on, you'll be shooting blind and that's a lonely, lonely place to be. so let's use this same procedure, but let's look at a new problem. let's say, you have this. let's say you were riding your bike over a circular hill. so this gray line represents the pavement, and it starts off flat. but then the pavement veers upward and it creates this concrete hill that you ride over and then down and you ride over to this side. and all this purple circle is representing is the fact that if you were to continue this crest of the hill around into a circle, it would form this shape, so that gives us a way to define what the radius is of this top part of the hill. so, let's put some numbers in here. let's say the radius of this hill was eight meters. let's say the mass of you and your bike together are about 100 kilograms. and let's say you're riding over this hill at six meters per second. and let's say i asked you, what's the size of the normal force exerted on you and your bike as you ride over the crest of this hill at six meters per second? now, let me show you what you can't do because most people would try to do this. they really want to say that the normal force is just gonna be equal to the force of gravity. therefore, since the force of gravity is mg, the normal force should just be mg, but that can't be right. if the forces on an object are balanced and they cancel, the object is just gonna maintain its velocity, size, and direction, so this object, since it's going to the right, this bike would just continue going to the right and it would just hover straight off this hill. that'd be awesome, but that doesn't happen. this bike moves downward. it accelerates downward after this moment since it rides down the hill, so the downward force has got to be bigger. the force of gravity's gonna be bigger than the normal force 'cause if it wasn't, this bike would just hover off into space. so how do you solve this problem? we use the same strategy we used before. we're gonna draw a force diagram, but we already did that. we're gonna use newton's second law for one of the directions, and the direction we're gonna pick is the vertical direction. now, is that vertical direction the centripetal direction? yeah, it is because look at into the circle is downward. because this bike is at the crest of the hill, down corresponds to pointing toward the center of the circle and upward corresponds to pointing away, radially away from the center of the circle. so, since i'm dealing with the centripetal direction, we plug in the formula for the centripetal acceleration, and the part where you have to be most careful is what you plug into the centripetal forces. remember that into the circle counts as positive and out of the circle counts as negative. so both of these forces, normal and gravity, are gonna be included, but only one of them are gonna be included with a positive sign. think about which one. can you figure out which force would be included in here with a positive sign? if you said the force of gravity, you're right, which is weird. usually, we treat the force of gravity as negative because it points down, but for centripetal forces, what we care about is into or out of the circle. so, i'm gonna treat gravity as a positive centripetal force. gravity is the force pointing toward the center of the circle, and the normal force in this case is gonna be a negative centripetal force since it's directed out of the center of the circle. and then, we divide by our mass. and so, if we solve this for the normal force, if you do some algebra, we'll multiply both sides by m, we move over the f n and then move the m v squared to the other side and what we end up getting is that mg minus m times v squared over r is equal to the normal force, which if we plug in numbers, gives us 100 kilograms times 9.8 minus 100 kilograms times the speed squared, that's gonna be six meters per second squared, divided by the radius of the circle we're traveling in which is eight meters, and you end up getting 530 newtons. so the normal force on you and your bike as you ride over this hill is 530 newtons. that is not equal to your weight. this is less than your weight. the force of gravity on you is gonna be m times g, that would be about 980 newtons. so you experience less normal force, and this is natural. this is what happens when you ride over a hill fast. you feel slightly weightless as you go over that hill. if you've ever gone with a car a little too fast over a hill, you feel that whoa in your stomach, and you're like, hey, that was cool. that was the weightlessness you felt for a moment. if you go too fast, if you go too fast, this normal force will become zero. you'll subtract so much m v squared over r here, the normal force becomes zero. when that happens, you do become airborne, so be careful driving over those hills. if you drive too fast, you'll become airborne since your normal force is gonna become zero. so, recapping, when you solve centripetal force problems, be sure to draw a quality force diagram. then use newton's second law for one of the directions at a time. if you use the centripetal direction, the direction pointed radially into the circle, you can say that the acceleration in that direction is v squared over r, but be sure to only plug in forces that are directed radially, that is to say, forces that are pointed into or out of the circle. if they point into the circle, they're gonna be positive forces, and if they point out of the circle, they're gonna be negative forces.",t_8ec8cdc6271e,other,0
c_bfcf4f0213bb,"learn how mortgages work, how to use a mortgage calculator, and how to use a spreadsheet to show the payoff of a mortgage over time and the interest paid each year. [click here to download the spreadsheet from the video.](http://cdn.kastatic.org/downloads/mortgagecalculator.xlsx.)  - [voiceover] what i want to do in this video is explain what a mortgage is. i think most of us have at least a general sense of it, but even better than that, actually go into the numbers and understand a little bit of what you are actually doing when you're paying a mortgage, what it's made up of and how much of it is interest versus how much of it is actually paying down the loan. let's just start with a little example. let's say that there is a house that i like. let's say that that is the house that i would like to purchase. it has a price tag of, let's say that i need to pay $500,000 to buy that house. this is the seller of the house right here. and they have a mustache. that's the seller of the house. i would like to buy it. i would like to buy the house. this is me right here. and i've been able to save up $125,000 dollars. i've been able to save up $125,000 but i would really like to live in that house so i go to a bank. i go to a bank, let me get a good color for a bank. that is the bank right there. and i say, ""mr. bank, can you lend me ""the rest of the amount i need for that house?"" which is essentially $375,000. i'm putting 25% down. this number right here, that is 25% of $500,000. so i ask the bank, ""can i have a loan for the balance? can i have $375,000 loan?"" and the bank says, ""sure. you seem like a nice guy ""with a good job who has good credit rating. ""i will give you the loan but while you're paying off the loan you can't have the title of that house. ""we have to have that title of the house ""and once you pay off the loan, ""we're going to give you the title of the house."" what's gonna happen here is the loan is gonna go to me, so it's $375,000. $375,000 loan. then i can go and buy the house. i'm gonna give the total $500,000, $500,000 to the seller of the house, and i'll actually move into the house myself, assuming i'm using it for my own residence. but the title of the house, the document that says who actually owns the house. this is the home title. this is the title of the house. home title. it will not go to me. it will go to the bank. the home title will go from the seller, or maybe even the seller's bank, because maybe they haven't paid off their mortgage. it will go to the bank that i'm borrowing from. this transferring of the title to secure a loan. when i say ""secure a loan,"" i'm saying i need to give something to the lender in case i don't pay back the loan or if i just disappear. this is the security right here. that is technically what a mortgage is. this pledging of the title as the security for the loan, that's what a mortgage is. it actually comes from old french. mort means dead, and the gage means pledge. i'm 100% sure i'm mispronouncing it, but it comes from dead pledge because i'm pledging it now but that pledge will eventually die once i pay off the loan. once i pay off the loan this pledge of the title to the bank will die and it will come back to me. that's why it's called a dead pledge, or a mortgage. and probably because it comes from old french is the reason we don't say mort-gage, we say mortgage. but anyway, this is a little bit technical, but normally when people refer to a mortgage they're really referring to the loan itself. they're really referring to the mortgage loan. what i want to do in the rest of this video is use a screenshot from a spreadsheet i made to actually show you the math, or actually show you what your mortgage payment is going to. you can download this spreadsheet at khanacademy, khanacademy.org/downloads/mortgagecalculator or actually, even better, just go to the downloads folder and on your web browser you'll see a bunch of files, and it will be the file called mortgagecalculator, mortgagecalculator.xlsx. it's a microsoft 2007 format. just go to this url, then you'll see all the files there and you can just download this file if you want to play with it. what it does here, in this kind of dark brown color, these are the assumptions that you can input and then you can change these cells in your spreadsheet without breaking the whole spreadsheet. here i've assumed a 5.5% interest rate. i'm buying a $500,000 home. it's a 25% down payment, that's the $125,000 that i had saved up, that i talked about right over there. and then the loan amount. well, i have 125, i'm gonna have to borrow 375, it calculates it for us. and then i'm gonna get a pretty plain vanilla loan. this is gonna be a 30 year. when i say term in years, this is how long the loan is for. so 30 years. it's gonna be a 30 year fixed-rate mortgage. fixed rate, which means the interest rate won't change. we'll talk about that a little bit. this 5.5% that i'm paying on the money that i borrowed will not change over the course of the 30 years. we will see that the amount i've borrowed changes as i pay down some of the loan. this little tax rate that i have here, this is to actually figure out what is the tax savings of the interest deduction on my loan. we'll talk about that in a second, you can ignore it for now. then these other things that aren't in brown, you shouldn't mess with these if you actually do open up the spreadsheet yourself. these are automatically calculated. this right here is a monthly interest rate. so it's literally the annual interest rate, 5.5%, divided by 12. and most mortgage loans are compounded on a monthly basis so at the end of every month they see how much money you owe and they will charge you this much interest on that for the month. now given all of these assumptions, there's a little bit of behind-the-scenes math, and in a future video i might actually show you how to calculate what the actual mortgage payment is. it's actually a pretty interesting problem. but for a $500,000 loan-- well, a $500,000 house, a $375,000 loan over 30 years at a 5.5% interest rate, my mortgage payment is going to be roughly $2,100. right when i bought the house, i want to introduce a little bit of vocabulary, and we've talked about this in some of the other videos. there's a asset in question right here, it's called a house. and we're assuming it's worth $500,000. we're assuming it's worth $500,000. that is an asset. it's an asset because it gives you future benefit; the future benefit of being able to live in it. now there's a liability against that asset, that's the mortgage loan. that's a $375,000 liability. $375,000 loan or debt. if this was your balance sheet, if this was all of your assets and this is all of your debt, and you were essentially to sell the assets and pay off the debt, if you sell the house you get the title, you can get the money, then you pay it back to the bank. well actually, it doesn't necessarily go into that order but i won't get too technical. but if you were to unwind this transaction immediately after doing it, then you would have a $500,000 house, you'd pay off your $375,000 in debt, and you would get, in your pocket, $125,000, which is exactly what your original down payment was. but this is your equity. the reason why i'm pointing it out now is, in this video i'm not gonna assume anything about the house price, whether it goes up or down, we're assuming it's constant. but you could not assume it's constant and play with the spreadsheet a little bit. but i'm introducing this because as we pay down the debt this number's going to get smaller. so this number is getting smaller. let's say at some point this is only 300,000. then my equity is going to get bigger. so you could do equity is how much value you have after you pay off the debt for your house. if you were to sell the house, pay off the debt, what do you have left over for yourself. this is the real wealth in the house, this is what you own. wealth in house, or the actual what the owner has. what i've done here is-- actually before i get to the chart let me actually show you how i calculate the chart. i do this over the course of 30 years, and it goes by month. so you can imagine that there's actually 360 rows here in the actual spreadsheet, and you'll see that if you go and open it up. but i just want to show you what i did. on month 0, which i don't show here, you borrow $375,000. now, over the course of that month they're going to charge you .46% interest. remember, that was 5.5% divided by 12. .46% interest on $375,000 is $1,718.75. so i haven't made any mortgage payments yet. i've borrowed 375,000. this much interest essentially got built up on top of that, it got accrued. so now before i've paid any of my payments, instead of owing 375,000 at the end of the first month, i owe $376,718. now, i'm a good guy, i'm not gonna default on my mortgage so i make that first mortgage payment that we calculated right over here. after i make that payment then i'm essentially, what's my loan balance after making that payment? well, this was before making the payment, so you subtract the payment from it. this is my loan balance after the payment. now this right here, the little asterisk here, this is my equity now. so remember, i started with $125,000 of equity. after paying one loan balance, after my first payment, i now have $125,410 in equity, so my equity has gone up by exactly $410. now you're probably saying, ""gee. i made a $2,000 payment, ""roughly a $2,000 payment, ""and my equity only went up by $410 ""shouldn't this debt have gone down by $2,000 ""and my equity have gone up by $2,000?"" and the answer is no because you had to pay all of this interest. so at the very beginning, your payment, your $2,000 payment, is mostly interest. only $410 of it is principal. so as your loan balance goes down you're going to pay less interest here, so each of your payments are going to be more weighted towards principal, and less weighted towards interest. and then to figure out the next line, this interest accrued right here, i took your loan balance exiting the last month, multiplied that times .46%. you get this new interest accrued. this is your new pre-payment balance. i pay my mortgage again. this is my new loan balance. and notice, already by month two, $2 more went to principal. and $2 less went to interest. and over the course of 360 months you're going to see that it's an actual, sizable difference, and that's what this chart shows us right here. this is the interest and principal portions of our mortgage payment. so this entire height right here, this is-- let me scroll down a little bit. this is by month. so this entire height, you notice, this is exactly our mortgage payment, this $2,129. now, on that very first month you saw that of my $2,100, only $400 of it, this is the $400. only $400 of it went to actually pay down the principal, the actual loan amount. the rest of it went to pay down interest, the interest for that month. most of it went for the interest of the month. but as i start paying down the loan, as the loan balance gets smaller and smaller, each of my payments, there's less interest to pay. let me do a better color than that. there's less interest. we go out here, this is month 198, over there that last month there was less interest, so more of my $2,100 actually goes to pay off the loan until we get all the way to month 360. you can see this in the actual spreadsheet. at month 360 my final payment is all going to pay off the principal. very little, if anything, of that is interest. now, the last thing i want to talk about in this video, without making it too long, is this idea of a interest tax deduction. a lot of times you'll hear financial planners or realtors tell you the benefit of buying your house is it has tax advantages, and it does. your interest is tax deductible. your interest, not your whole payment. your interest is tax deductible. i want to be very clear what deductible means. first let's talk about what the interest means. this whole time over 30 years i am paying $2,100 a month, or $2129.21 a month. now the beginning, a lot of that is interest. so on month one, 1,700 of that was interest. that $1,700 is tax deductible. as we go further and further, each month i get smaller and smaller tax deductible portion of my actual mortgage payment. out here the tax deduction is actually very small, as i'm getting ready to pay off my entire mortgage and get the title of my house. i want to be very clear on this notion of what tax deductible even means, because i think it is misunderstood very often. let's say in one year i paid, i don't know, i'm gonna make up a number, i didn't calculate it on the spreadsheet. let's say in year one i pay $10,000 in interest. 10,000 in interest. remember, my actual payments will be higher than that because some of my payments went to actually paying down the loan. but let's say 10,000 went to interest. and let's say before this, let's say before this i was making 100,000, let's put the loan aside. let's say i was making $100,000 a year, and let's say i was paying roughly 35% on that 100,000. i won't go into the whole tax structure and the different brackets and all of that. let's say if i didn't have this mortgage i would pay 35% taxes, which would be about $35,000 in taxes for that year. this is just a rough estimate. when you say that $10,000 is tax deductible, the interest is tax deductible, that does not mean that i can just take it from the $35,000 that i would have normally owed and only pay 25,000. what it means is i can deduct this amount from my income. when i tell the irs how much did i make this year, instead of saying i made $100,000, i say that i made $90,000 because i was able to deduct this, not directly from my taxes, i was able to deduct it from my income. so now if i only made $90,000 -- and this is, i'm doing a gross oversimplification of how taxes actually get calculated -- and i pay 35% of that, let's get the calculator out. let's get the calculator. so 90 times .35 is equal to 31,500. so this will be equal to $31,500. $31,500. off of a 10,000 deduction, $10,000 of deductible interest, i essentially saved $3,500. i did not save $10,000. another way to think about it, if i paid 10,000 interest and my tax rate is 35%, i'm gonna save 35% of this in actual taxes. this is what people mean when they say deductible. you're deducting it from the income that you report to the irs. if there's something that you could take straight from your taxes, that's called a tax credit. if there was some special thing that you could actually deduct it straight from your taxes, that's a tax credit. but a deduction just takes it from your income. on this spreadsheet i just want to show you that i actually calculated, in that month, how much of a tax deduction do you get. so for example, just off of the first month you paid $1,700 in interest of your $2,100 mortgage payment, so 35% of that, and i got 35% as one of your assumptions, 35% of $1,700, i will save $600 in taxes on that month. so roughly over the course of the first year i'm gonna save about $7,000 in taxes, so that's nothing to sneeze at. anyway, hopefully you found this helpful and i encourage you to go to that spreadsheet, and play with the assumptions, only the assumptions in this brown color unless you really know what you're doing with a spreadsheet, and you can see how this actually changes based on different interest rates, different loan amounts, different down payments, different terms. different tax rates, that will actually change the tax savings, and you can play around with the different types of fixed mortgages on this spreadsheet.",t_2c5e532fd534,other,0
c_18e574256c4a,"chapter 39 of the book on .net framework.chapter 39: threading section 39.1: accessing form controls from other threads if you want to change an attribute of a control such as a textbox or label from another thread than the gui thread that created the control, you will have to invoke it or else you might get an error message stating: ""cross-thread operation not valid: control 'control_name' accessed from a thread other than the thread it was created on."" using this example code on a system.windows.forms form will cast an exception with that message: private void button4_click(object sender, eventargs e) { thread thread = new thread(updatetextbox); thread.start(); } private void updatetextbox() { textbox1.text = ""updated""; // throws exception }  instead when you want to change a textbox's text from within a thread that doesn't own it use control.invoke or control.begininvoke. you can also use control.invokerequired to check if invoking the control is necessary. private void updatetextbox() { if (textbox1.invokerequired) textbox1.begininvoke((action)(() => textbox1.text = ""updated"")); else textbox1.text = ""updated""; }  if you need to do this often, you can write an extension for invokeable objects to reduce the amount of code necessary to make this check: public static class extensions { public static void begininvokeifrequired(this isynchronizeinvoke obj, action action) { if (obj.invokerequired) obj.begininvoke(action, new object[0]); else action(); } }  and updating the textbox from any thread becomes a bit simpler: private void updatetextbox() { textbox1.begininvokeifrequired(() => textbox1.text = ""updated""); }  goalkicker.com – .net framework notes for professionals  125  be aware that control.begininvoke as used in this example is asynchronous, meaning that code coming after a call to control.begininvoke can be run immedeately after, whether or not the passed delegate has been executed yet. if you need to be sure that textbox1 is updated before continuing, use control.invoke instead, which will block the calling thread until your delegate has been executed. do note that this approach can slow your code down signiﬁcantly if you make many invoke calls and note that it will deadlock your application if your gui thread is waiting for the calling thread to complete or release a held resource.  goalkicker.com – .net framework notes for professionals  126",t_37500189976b,other,0
c_ae6d8ac930e9,"sequences are ordered lists of numbers (called ""terms""), like 2,5,8. some sequences follow a specific pattern that can be used to extend them indefinitely. for example, 2,5,8 follows the pattern ""add 3,"" and now we can continue the sequence. sequences can have formulas that tell us how to find any term in the sequence. for example, 2,5,8,... can be represented by the formula 2+3(n-1).  what i want to do in this video is familiarize ourselves with the notion of a sequence. and all a sequence is is an ordered list of numbers. so for example, i could have a finite sequence-- that means i don't have an infinite number of numbers in it-- where, let's say, i start at 1 and i keep adding 3. so 1 plus 3 is 4. 4 plus 3 is 7. 7 plus 3 is 10. and let's say i only have these four terms right over here. so this one we would call a finite sequence. i could also have an infinite sequence. so an example of an infinite sequence-- let's say we start at 3, and we keep adding 4. so we go to 3, to 7, to 11, 15. and you don't always have to add the same thing. we'll explore fancier sequences. the sequences where you keep adding the same amount, we call these arithmetic sequences, which we will also explore in more detail. but to show that this is infinite, to show that we keep this pattern going on and on and on, i'll put three dots. this just means we're going to keep going on and on and on. so we could call this an infinite sequence. now, there's a bunch of different notations that seem fancy for denoting sequences. but this is all they refer to. but i want to make us comfortable with how we can denote sequences and also how we can define them. we could say that this right over here is the sequence a sub k for k is going from 1 to 4, is equal to this right over here. so when we look at it this way, we can look at each of these as the terms in the sequence. and this right over here would be the first term. we would call that a sub 1. this right over here would be the second term. we'd call it a sub 2. i think you get the picture-- a sub 3. this right over here is a sub 4. so this just says, all of the a sub k's from k equals 1, from our first term, all the way to the fourth term. now, i could also define it by not explicitly writing the sequence like this. i could essentially do it defining our sequence as explicitly using kind of a function notation or something close to function notation. so the same exact sequence, i could define it as a sub k from k equals 1 to 4, with-- instead of explicitly writing the numbers here, i could say a sub k is equal to some function of k. so let's see what happens. when k is 1, we get 1. when k is 2, we get 4. when k is 3, we get 7. so let's see. when k is 3, we added 3 twice. let me make it clear. so this was a plus 3. this right over here was a plus 3. this right over here is a plus 3. so whatever k is, we started at 1. and we added 3 one less than the k term times. so we could say that this is going to be equal to 1 plus k minus 1 times 3, or maybe i should write 3 times k minus 1-- same thing. and you can verify that this works. if k is equal to 1, you're going to get 1 minus 1 is 0. and so a sub 1 is going to be 1. if k is equal to 2, you're going to have 1 plus 3, which is 4. if k is equal to 3, you get 3 times 2 plus 1 is 7. so it works out. so this is one way to explicitly define our sequence with kind of this function notation. i want to make it clear-- i have essentially defined a function here. if i wanted a more traditional function notation, i could have written a of k, where k is the term that i care about. a of k is equal to 1 plus 3 times k minus 1. this is essentially a function, where an allowable input, the domain, is restricted to positive integers. now, how would i denote this business right over here? well, i could say that this is equal to-- and people tend to use a. but i could use the notation b sub k or anything else. but i'll do a again-- a sub k. and here, we're going from our first term-- so this is a sub 1, this is a sub 2-- all the way to infinity. or we could define it-- if we wanted to define it explicitly as a function-- we could write this sequence as a sub k, where k starts at the first term and goes to infinity, with a sub k is equaling-- so we're starting at 3. and we are adding 4 one less time. for the second term, we added 4 once. for the third term, we add 4 twice. for the fourth term, we add 4 three times. so we're adding 4 one less than the term that we're at. so it's going to be plus 4 times k minus 1. so this is another way of defining this infinite sequence. now, in both of these cases, i defined it as an explicit function. so this right over here is explicit. that's not an attractive color. let me write this in. this is an explicit function. and so you might say, well, what's another way of defining these functions? well, we can also define it, especially something like an arithmetic sequence, we can also define it recursively. and i want to be clear-- not every sequence can be defined as either an explicit function like this, or as a recursive function. but many can, including this, which is an arithmetic sequence, where we keep adding the same quantity over and over again. so how would we do that? well, we could also-- another way of defining this first sequence, we could say a sub k, starting at k equals 1 and going to 4 with. and when you define a sequence recursively, you want to define what your first term is, with a sub 1 equaling 1. you can define every other term in terms of the term before it. and so then we could write a sub k is equal to the previous term. so this is a sub k minus 1. so a given term is equal to the previous term. let me make it clear-- this is the previous term, plus-- in this case, we're adding 3 every time. now, how does this make sense? well, we're defining what a sub 1 is. and if someone says, well, what happens when k equals 2? well, they're saying, well, it's going to be a sub 2 minus 1. so it's going to be a sub 1 plus 3. well, we know a sub 1 is 1. so it's going to be 1 plus 3, which is 4. well, what about a sub 3? well, it's going to be a sub 2 plus 3. a sub 2, we just calculated as 4. you add 3. it's going to be 7. this is essentially what we mentally did when i first wrote out the sequence, when i said, hey, i'm just going to start with 1. and i'm just going to add 3 for every successive term. so how would we do this one? well, once again, we could write this as a sub k. starting at k, the first term, going to infinity with-- our first term, a sub 1, is going to be 3, now. and every successive term, a sub k, is going to be the previous term, a sub k minus 1, plus 4. and once again, you start at 3. and then if you want the second term, it's going to be the first term plus 4. it's going to be 3 plus 4. you get to 7. and you keep adding 4. so both of these, this right over here is a recursive definition. we started with kind of a base case. and then every term is defined in terms of the term before it or in terms of the function itself, but the function for a different term.",t_b69f140661cb,other,0
c_e7c0bcbab53f,"defining solute, solvent, hydration, dissolution, precipitation, net ionic equation, and spectator ions. looking at the molecular level interactions between water and ions in nacl.  - [voiceover] let's say we have some solid sodium chloride, so some salt. and that right there is supposed to be our pile of salt. we're going to put our salt into some water. we have a beaker containing h2o. the sodium chloride is going to dissolve in the water. so the sodium chloride is our solute and the water will be our solvent. this is the process of dissolution. if you look more closely at sodium chloride, solid sodium chloride is an ionic crystal. it's held together by the ionic bonds, right? so the sodium cation, or the positive charge, is attracted to the chloride anion with a negative charge. that's holding together our ionic crystal. when you put the solid sodium chloride into water, remember, water is a polar molecule. the oxygen is more electronegative than the hydrogens here. so the oxygen gets a partial negative charge and these hydrogens get a partial positive charge. so we have a polar molecule here. the negative charge on the oxygen is going to interact with the positive charge on the sodium. right? opposite charges attract. we have one water molecule here attracted to this sodium cation, and this water molecule would do the same, right? so partial negative charge attracted to the positive charge on the sodium. so the water molecules are going to pull off the sodium cations and eventually give you this situation over here. we have the partial negative oxygens, right? partial negative oxygens are going to interact with the sodium cation, right? so the water is a dipole and the sodium cation is an ion. so we could call this an ion-dipole interaction. the water molecules break the ionic bonds, pull off the sodium cations, surround the sodium cation. we call this process hydration. this is the process of hydration, where the ion is surrounded and stabilized by a shell of our solvent molecules. the same thing would happen with the chloride anions. right up here, the chloride anion is negatively charged. but this time, the negative charge would be attracted to the positive part of our polar molecule, right? the oxygen is partially negative and this hydrogen here would be partially positive. opposite charges attract, the positive charge is going to interact with the negative charge. same for this molecule of water, partially positive hydrogen. once again, this interaction is going to pull off that chloride anion and move it into solution. so we have our partial positive hydrogens interacting with our negatively-charged chloride anions here. once again, we get ion-dipole interactions. the chloride anion is surrounded by our water molecules, so once again, the process of hydration. the end result is, each sodium cation is surrounded by water molecules and each chloride anion is surrounded by water molecules. the sodium chloride has dissolved in water. we formed a solution, an aqueous solution, of sodium chloride. the way that you see that written, you would write, here we have solid sodium chloride, which we put into water, our solvent, and the water molecules surrounded our ions. now we have sodium ions in solution, so we write an aq here for aqueous sodium ions, and we have chloride anions also in solution, so we write an aq here. so we have an aqueous solution of sodium chloride. the sodium chloride has dissolved in water. now let's say we have one beaker that contains a solution of nacl, so an aqueous solution of nacl has sodium cations in solution and chloride anions in solution. let's say we have another beaker that contains a solution of silver nitrate, which is agno3. so an aqueous solution of silver nitrate means we have silver cations in solution, ag+, and nitrate anions, no3-. now let's say we add the contents of one beaker to the other beaker. let's pour the contents of, let's say, this beaker into this beaker. we're combining our two solutions. we would notice a few things. we would notice the volume to increase, obviously, since we're pouring the contents of one into the other. we would also notice a white solid form. a white solid is going to form down here. that white solid forms when the silver cations interact with the cloride anions. we get a solid forming that is silver chloride, agcl. we would write agcl here. we put a subscript s, indicating that a solid formed. this solid is called a precipitate. this solid spontaneously falls out of solution. this is the process of precipitation, which is the opposite of dissolution. in dissolution, we put a solid into water and we formed ions, right? in precipitation, the ions come together to form a solid, and that solid spontaneously falls out of solution. silver chloride is our precipitate. we would still have some ions in solution. we would still have sodium cations and nitrate anions. in here, we would have sodium cations in solution and nitrate anions in solution. we could add them into here. we could say, nano3, aqueous, meaning those ions are present in solution. let's look in more detail about what's happening with the formation of our precipitate. we know that we had silver cations in solution. here's our silver cation over here. we know that this ion is being surrounded by water molecules in the process of hydration, right? so these oxygens are partially negative right here. since opposites attract, there's a force that's holding that ion in our solution, the forces of hydration. same thing for the chloride anion, right? the partial positive charge on the hydrogen, opposite charges attract, right? so those water molecules are stabilizing the chloride anion in solution. but when we pour those two solutions together, we form our precipitate. we form silver chloride. we form this ionic crystal down here. once again, opposite charges attract. so the positively-charged silver cation is attracted to the negatively-charged chloride anion here. since we notice this solid to form, the electrostatic attractions of our ionic crystal must be stronger than the forces of hydration. this chloride anion would move into here, and then this silver cation would move into here. so the ions come out of solution and a precipitate spontaneously forms. we form our solid, silver chloride. this is one way to represent what's going on here. we could have also drawn out all of the ions, right? instead of writing that, another way to represent what's happening would be to say, a solution of sodium chloride would be sodium cations in solution, so we write our sodium cations here, chloride anions, so cl-. we added to that our solution of silver nitrate, which had silver ions in solution, so ag+, and nitrate anions, so no3-. and we saw a precipitate form. we formed agcl, which is our solid. we write agcl here, which is our precipitate. then we also had sodium cations and nitrate anions. we had sodium cations, na+, and we had nitrate anions, no3-. that's a lot of writing. either one tells you the same amount of information. this one down here just shows you all of the ions. really, only some of the ions are reacting. the silver cation and the chloride anion are coming together to form silver chloride. we could write a net ionic equation showing what's happening to form our precipitate. we could show the silver cations here, ag+. we could show our silver cations and our chloride anions combining to form our precipitate, agcl. this is the net ionic equation. this is the net ionic equation because some of our ions aren't taking part in this reaction. they're just observing what's happening. this sodium cation is on the left side. it's also on the right side. it's an ion in solution. same thing with the nitrate anion. it's over here on the left side as a ion in solution. it's over here on the right side as a ion in solution. the sodium cation and the nitrate anion are called spectator ions. these are called spectator ions because they're not taking part in what's happening. they're just watching. they're watching as the silver chloride precipitates out of solution. that's why we call them spectator ions. so this is the idea of precipitation.",t_d4ab441eef7f,other,0
c_50cdf39ba5a8,"acute angles measure less than 90 degrees.  right angles measure 90 degrees. obtuse angles measure more than 90 degrees.  learn about angles types and see examples of each.  in this video, i really just want to introduce you to some terminology for some basic angle types. and the terminology i want to introduce you to are acute angles, right angles, and obtuse angles. and i think when we just go through these, they'll be pretty self-explanatory. an acute angle is an angle-- well, let me just draw them first. then it might start to make sense. so an acute angle will look something like that. i draw two rays that are coming from a common point. so the acute angle will be this angle right over here. i could also draw an acute angle, maybe an angle that's formed from the intersection of two lines. this angle will be acute, and so will this angle. they're both acute angles. and we're going to see is acute angles are ones that are-- since i haven't defined right angles yet-- they're narrower. and what we're going to see is that they're smaller than right angles. right angles are when the rays or the lines are going, i guess, in the-- i don't want to use the word, right, in my definition-- but if one is going horizontal, the other one will be going vertical. so let me draw it with the rays first. so the right angle, this one's going from the left to the right. then the other ray is going from the bottom to the top. this angle right over here is a right angle. and i could label it like that, as a traditional angle. but the general convention for labeling right angles is to put a little, kind of a half of a box right over there. and that means that is a right angle. or that if this is going left to right, this is going perfectly top to bottom, that this is in no way kind of-- i guess the best way to think about it and why it's called right is that this ray is completely upright, compared to this ray over here. and let me draw it with some lines. so if i have one line like this and then i have another line like that, a right angle over here-- actually all of these would have to be right angles-- it would mean that this line is completely-- if this was the ground, this line is completely upright, relative to this line over here. so either of these, that's what a right angle means. and now that we've defined right angle, i can give you another definition for an acute angle. an acute angle has a measure, or it's smaller, than a right angle. when you learn about radians and degrees, which are different ways to measure angles, you'll see that a right angle can be measured as 90 degrees. this over here is less than 90 degrees. so this is less than 90 degrees. and one way to conceptualize this is that this angle, its opening is smaller, it's more narrow, the lines are-- you would have to rotate one line less to get to the other line than you would over here. here, you'd have to move it all the way over there. here, you'd only have to move it a little bit. so the acute angle is less than a right angle. and so you might imagine already what an obtuse angle is. it is greater than a right angle. so let me draw a couple of examples of obtuse angles. so an obtuse angle might look like-- let me make it a little bit clearer. it might look like that. if this was a right angle, this line over here would look something like that. it would be completely upright relative to this if this were the ground. but we don't see that. this orange ray over here is actually opened out wider. it's opened up wider. so it is obtuse. and this kind of comes from the actual everyday meaning. acute means very sharp or very sensitive. obtuse means not very sharp or not very sensitive. so you could imagine this looks like a sharp point or it's not opening up much, so maybe it's more sensitive relative to other things, or i don't know. i'm just trying to make connections. this is less sensitive. it's all big and open. it won't be able to notice things that are small because i don't know. maybe that's not an appropriate analogy. but one way to think about it, it's kind of open up wider, or it's bigger than a right angle. it's larger than 90 degrees if you measure it. you would have to rotate this ray more to get to this other ray than you would if they were right angles, and definitely a lot more than if they were acute angles. if i were to draw this with lines, which of the angles are obtuse and which are acute? well, the way i've drawn them right over here, these two over here are acute, and then these over here are going to be obtuse. this one and this one, these are both obtuse angles. and i actually drew it up here, as well. this one and this one are going to be obtuse. so very simple idea. if one line or one ray relative to the other one is straight up and down, versus to left and right, or is completely upright, then we're talking about a right angle. if they're closer to each other, if you have to rotate them less, you're talking about an acute angle. if you have to rotate them more, you're talking about an obtuse angle. and i think when you just look at them visually, it's pretty easy to pick out.",t_a071fdc9e189,other,0
c_4db652346fdf,"gibbs free energy and equilibrium constant of dehydration reaction. from 2015 ap chemistry free response 2c.  because the dehydration reaction is not observed to occur at 298 kelvin, the student claims that the reaction has an equilibrium constant less that one point zero zero at 298 kelvin. do the thermodynamic data for the reaction support the students claim? justify your answer, including a calculation of standard or change in standard gibbs free energy at 298 kelvin for the reaction. so lets first of all, let's review what the students claim is. the student claims that since the reaction is not observed at 298 kelvin that at that temperature the reaction... the student claims that the reaction has an equilibrium constant less than one point o at 298 kelvin. that's their claim. and if the idea of equilibrium constant or gibbs free energy are completely foreign to you i encourage you to review the videos on khan academy on gibbs free energy and equilibrium constants. if they are familiar to you but you're like, ok i don't know all the formulas that might connect the information that's given in the problem and how to calculate delta g. and maybe how do we go from delta g to equilibrium constants and figuring out whether the equilibrium constant is going to be greater than or less than one or even equal to one. the good thing is that they give you all of the formulas that you need. it's on the first page of the free response section. you just have to understand which ones are applicable and what's actually going on with those equations. so let's first of all think about whether we can calculate delta g with the information that they've given. and if you go to the first page on one of the formulas they give you and you might even remember how to figure out whether a reaction is spontaneous or not and how you can calculate delta g based on the temperature, the change in entropy, and the change in enthalpy. you have this formula right over here. and i literally just copied and pasted it from what they give you when you take the test. and so they give us the change in enthalpy for the reaction. they give us the temperature, 298 kelvin. they give us the change in entropy for the reaction. this is the change in standard entropy, change in standard enthalpy for the reaction. and so using those we can figure out what delta g is going to be. and then we can say, ""ok, is it consistent? is it greater than zero? which is conssistant with the reaction not being spontaneous which seems to be what's observed. and then how can we go from that delta g to the equilibrium constant?"" well they also tell us that delta g is equal to this second thing. and this connects delta g in the equilibrium constant. and we know some things about r and t. in fact we know exactly what r and t are if we need them. so let's go ahead and apply these equations right over here. so you have... actually let me just write all of the information we have first. so what is our change in standard enthalpy? we're going to have to figure that out. we're going to have to figure out what our change in standard entropy is going to be. we know what the temperature is. we know that that is 298 kelvin. and we can worry about r in a second if we need to. so up here when they gave us the reaction they gave us our change in standard enthalpy and our change in standard entropy at 298 kelvin. this is very convenient. so our change in enthalpy is 45.5 kilojoules per mole. our change in standard entropy is 126 joules per kelvin-mole so this is very interesting. this is given in kilojoules, this is given in joules. and so we wanna make sure that we're being consistent. so let's just make sure that everything is in joules. so i'm going to write this, this thing is the same as 45,500 joules per mole for this reaction. so let me write this down, this is 45,500, this is 126 joules per kelvin-mole. so this is, this right over here, is 45,500 joules per mole. this is 126 joules per kelvin-mole. and now we can figure out what the delta g is going to be. delta g is going to be equal to... well our change in enthalpy is 45,500 joules per mole minus our temperature, 298 kelvin. times our change in entropy. times 126 joules per kelvin-mole. and notice the kelvin and then the kelvin, those should both be capital ks, capital k, cancel out. and the units here are going to be joules per mole. the units here are going to be joules per mole. and then we just figure out the difference. so let's do this. let me get my calculator out. and so this is going to be... well let me multiply these two first. we're going to have 298 times 126 is equal to that. and let's see, i'm going to subtract this from 45,500 so let me just make it a negative. and add it to 45,500 is going to be equal to... is going to be equal to 7,952. and if we want to stay... i mean we want to stay consistant with how many significant digits or significant figures we have. and it looks like it's pretty consistently three significant figures. so we want three significant figures here. so we could write 7,900, roughly 7,950. so our delta g is approximately 7,950 joules per mole. and the fact that this is greater than zero tells us that this is not going to be spontaneous at that temperature. so it's already consistent with our observations. and that's always a good reality check. because, are the things that you're seeing consistent with what the question is describing? so delta g greater than zero consistent. consistent with reaction. reaction being, or not being spontaneous. not being spontaneous. spontaneous at 298 kelvin. in the videos on khan academy on gibbs free energy we go into a lot more detail on what this is. but one way to think about it is, this is the energy, the change in energy that's available to do work. and so if you have more, if your gibbs free energy increases over the course of the reaction, that means the products have more energy to do work. and so that means you have to put work into it in order for the reaction to actually proceed. if your delta g is negative that means your products have less energy to do work than your reactants. which means that it can release that energy. it can do work, and it can be spontaneous. so this one, it's greater than zero. so it's not going to be spontaneous. but that doesn't answer the question for us. we want to validate the claim that the reaction has an equilibrium less than one at 298 kelvin. and lucky for us they also give us the formula that ties our delta g to our equilibrium constant. and we know the other things. we know r and we know t. and we might not actually have to think about them. because they're not telling us to calculate the equilibrium constant. they're just saying we'll validate that it's going to be less than one. and so, if we took 7,950 joules per mole is equal to negative rt times the natural log of our equilibrium constant we'll solve for the equilibrium constant. let's see, if i divide both sides by negative rt. negative rt. i'm going to get the natural log. i'll just write it this way, the natural log of my equilibrium constant is going to be equal to 7,950 joules per mole over negative rt. or you could say e, this is just... what power do i raise e to to get k. or so, you could say e to the negative 7,950 joules per mole over rt is going t to be equal to k. and we could actually calculate what this is. we know which r to use. we're dealing with joules and moles. so it would be this first gas constant right over here eight point three one four joules per mole-kelvin. but we actually don't even have to do that because we just have to validate that k is going to be less than one. what happens if you raise e to a negative exponent? and this is going to be a negative exponent. this is positive, that is positive, this is positive. we know it's 298 kelvin positive, positive. so my entire exponent is going to be negative. so negative, so negative. so you could say that k equals e to negative number. i'll get this right. it's kind of weird to write the negative and then the negative number. e to a negative number. which must be less than one. remember if the exponent is zero, e to the zero power is one, e to anything positive is going to be greater than one. and e to anything negative is going to be less than one. you wanna be careful, not less than zero. you actually can't get to less than zero. it's going to be less than one. and so this by itself already validates the students claim. if you wanna go further you could just calculate that. you could just say k is equal to e to the negative 7,950 joules per mole over r. which is what? eight point three one four joules per mole kelvin. eight point three one four. eight point three one four joules per mole kelvin times 298 kelvin. those cancel out and joules per mole divided by joules per mole. those cancel out. and so, you would get your number. and actually let's just calculate it. just for kicks, just to really feel good about it. and you can see this is going to be dimensionless. and equilibrium constants are dimensionless. so we are going to get, this is kind of fun. so let's see. let's do this denominator first. if you have eight point three one four times 298 times 298. that's going to be equal to that. now we're dividing by that. so let me take the reciprocal of that and multiply it by 7,950. 7,950 is equal to that. now we want to raise e to the negative of that. so lets make that negative and now let's raise e to that power. so lets see, we can raise e to that power. so we just press that and there you have it. this is approximately zero point four four zero. i guess you could say, well let's just say four zero four. so this is approximately zero point four zero four. approximately, and i already forgot the number, i have a bad memory, zero point zero four zero four. zero point zero four zero four. and the whole rules of significant figures get a little bit trickier when you're starting to deal with exponents like this. so we're not going to, and they don't ask us to calculate the exact value but hopefully this makes you at least appreciate that the equilibrium concept is for sure is less than one.",t_2681ec14d41f,other,0
c_bafa96bcd456,"sal graphs y=(x^2)/(x^2-16).  in this video, we're going to see if we can graph a rational function. a rational function is just a function that has an expression on the numerator and the denominator. it has a polynomial in the numerator-- let's see, we have x squared over-- and another polynomial in the denominator --x squared minus 16. we could obviously graph this by just trying out a bunch of points and then connecting the dots. that's what a calculator would do for us, a graphing calculator. but what we want to do is, before we try out some points to kind of fill in the gaps, i want to understand the basic structure of this graph first. and to understand that, i want to see what happens as x gets really big, so x gets really big, or x gets really, really small, as x goes in the negative direction. or another way we could think about it, i want to understand what happens as the magnitude of x, or the absolute value of x, becomes really big as it approaches really, really bigness, or as it approaches infinity. so when the size of x approaches infinity. which essentially is saying, as x goes really far in the positive direction, or x goes really far in the negative direction, what is going to happen to the value of this function? so let's get out a calculator. won't use the graphing part of it just yet, but let's just try out some values. what happens when x is equal to 10? it's going to be the same thing as when x is equal to negative 10, because when you put a negative 10 here, you square it, you get 100, just like 10. same here, negative 10, you square it, you get the same thing as a positive 10. so whether you go in the super high positive direction or the super low negative direction, as you approach positive or negative infinity, you're going to approach the same thing because you're squaring the values. but let's try out some values. if i get 10 squared divided by 10 squared minus 16, i get 1.19. now what happens if x gets a little bit bigger? this is x is equal to 10. what happens when x is equal to 100? we have 100 squared divided by 100 squared minus 16. i'm getting even closer to 1. when x was 10, around here, we're getting y is 1.19. when x is 100, 100 squared over 100 squared minus 16, y is 1.0016. just for fun, let's try 1,000. so it's 1,000 squared divided by 1,000 squared minus 16. and we're even closer to 1. so as the size of x gets larger and larger and larger, our y gets closer and closer to 1. and that would also be true if this was a negative 10, because negative 10 squared over negative 10 squared minus 16 is going to be the exact same thing. because the negative, when you square it, is going to be a positive. it's going to be the same thing as 10 squared, same thing over here. so whether x gets really big or x gets really small, we're going to be approaching y is equal to 1. you could try it with a million if you want, and you're going to get a number even closer to 1. so as the size of x approaches infinity, the absolute value of x, or the distance from the origin, approaches infinity, y is approaching 1. or another way to think about it is, the graph of this function is going to approach the line y is equal to 1. so let me graph the line y is equal to 1. so i'll do it in a dotted line because this isn't the graph of our function, but this is a line that our function is approaching. so that is the graph of y is equal to 1. now, this idea of a function, or the graph of a function, approaching a line but never quite touching it. so this is going to get closer and closer and closer to this line, y equal to one, in that direction, but never quite getting close enough to it. it'll approach 0, its distance from this y equals 1, but it'll never quite get there. this line that the graph is approaching is called an asymptote. and it'll be even more clear once i actually graph the function. we're going to work up there. and since it's a horizontal line, we call this a horizontal asymptote. this is what our graph approaches as we go in the positive direction, or really far in the negative direction. let's think about some of the other interesting things about this, about this function right here. well one thing that might pop out at you is this is a difference of squares. this is x squared minus 4 squared. so we can rewrite this as x squared over x plus 4 times x minus 4. so what's going to happen here, as x approaches either positive 4, or x approaches negative 4? well, first of all, try those values out. if x is equal to 4, what is going to happen? this expression right here, this term right here, is going to be equal to 0. and we're going to be dividing by 0. we cannot do that. similarly, if x is equal to negative 4, we'd be dividing by 0. this expression, right here, is going to be equal to 0. we can't do that. we could say that this function is undefined at x is equal to plus or minus 4. it can't equal those values because we'd be dividing by 0 in either one of those circumstances. now, what happens as we approach those values? what happens as x approaches negative 4? let's just do that one for fun. what happens as x approaches negative 4? let's say we're approaching it from the negative direction. so let's try it out in our calculator. so let's say we want to go from the negative direction. so let's start with negative 4.1. so if we have negative 4.1 squared divided by negative 4.1 squared minus 16, what do we get? we get 20.75. so we get this number, whatever. let's see if we get even closer to negative 4. so let me just get that entry there. so let's get a little bit closer to negative 4. so instead of negative 4.1, let's do negative 4.01. so let me insert a negative 4.01. and then over here, this is negative 4.01, and see what it is. now we went to 200, so we're getting to larger and larger values. let's try negative 4.001. let's try that out. whoops, that's not what i wanted to do. i wanted to do that. so let's try. no that's not what i want to do. let's see. so we want to go to, instead of 4.01, i want to do 4.001, and over there, negative 4.001. and what do we get? we get 2,000. so as we get closer and closer to negative 4 from the negative direction, we're approaching larger and larger, super larger numbers. and you can try it, if it's 4.0000001, it's going to get to smaller and smaller numbers-- or sorry, larger and larger numbers here. if you do 4.001, it's probably going to be 20,000. and then if you add another 0 here. so as we get closer and closer, it's getting to larger and larger numbers. so we could say, as x approaches negative 4, we could say y is approaching infinity. it's getting to a larger and larger and larger value. but we can't ever quite get to x is equal to 4. it's undefined there. that will make the denominator here equal to 0. so what we want to do here is, we can never quite equal x equal negative 4. so let me see, x is equal to 1, 2, 3, 4. we can never quite get to x is equal to negative 4. let me draw x is equal to negative 4 as a dotted line, right there. that is x is equal to negative 4. we can never quite get there, but as we approached it from the negative side, as we had 4.1, then 4.01, we went to larger and larger values. and we also know that as we went on the left-hand side, as we go to larger and larger x values, that y will get closer and closer to 1. so you have a general sense of what this part of the graph will look like. this part of the graph is going to look something like that. as x gets to super negative numbers, it gets closer and closer to 1, as x gets closer and closer to negative 4 from the negative direction, it's going to go closer and closer to infinity. you're going to get closer and closer to a very-- it's going to get larger and larger, i guess, is an easy way to say it. now, just like x equal negative 4, x equals 4 will also be a point where the graph is undefined. so let me graph that here. 1, 2, 3, 4. right here. right over here. x is equal to 4. and, once again, what happens as we approach x equals 4, let's say from the positive direction? so as x approaches 4 from the positive direction, what's going to happen? so this is like trying out x is equal to 4.01, or x is equal to 4.001, or x is equal to 4.0001. so we're just getting closer and closer and closer to x is equal to 4. well, these values are the exact same values that we just tried on our calculator, except they are the negative version of them, right? and we already saw that, just the way that this function is set up, the negative numbers, they get squared, so whether you take the negative or the positive x values, it's going to be the same thing. this graph is symmetric. when x is equal to negative 5, it's the same thing as x is equal 5. when x is equal to negative 10, it's the same thing as x equals 10. so the same thing is going to happen. you could try it out with your calculator, if you like. if you try out these values, you're going to see, as we get closer and closer to 4, we're going to approach larger and larger numbers. these same numbers over here. so the graph over here, as we get closer and closer to 4, we're going to approach larger and larger numbers. and then here, as x gets larger and larger and larger, we saw over here, we had these horizontal asymptotes, y gets closer and closer to 1. so just like we called this a horizontal asymptote, these values-- or you can even view these vertical lines: x is equal to negative 4 and x is equal to 4 --we call these vertical asymptotes. these are lines, asymptotes, once again, they are lines that the graph approaches, but never quite touches. so that's what's going on here. and then we can think about what's happening to the graph inside of here. so you could think of it in a couple of ways. you could say, well, what happens as x approaches 4 from the negative direction? so let's try that out, from the negative direction. so what happens if you do 3.9 squared divided by 3.9 squared minus 16? you get negative 19.25. now what happens if we do 3.99? so let me put another 9 here. so we're going to get closer and closer to 4, and we're going to do it from the left-hand side as we approach 4. so insert another 9 here. so even more negative. so let's just do one more. so we're going to be even more negative. so let me make it 3.999. get even closer to 4. you're getting even more negative. and this is also going to be true if we did negative 3.9, or negative 3.99, or negative 3.999, because when we square it, the negatives and the positives are the same thing. you square negative 1, you get a positive 1. so as we approach 4 from-- you go 3.9, 3.99, we get closer and closer to 4 --we're getting more and more negative numbers. we approach negative infinity. so as we approach-- let me just graph it here. as we approach from this direction, we're going to get smaller-- want to not touch our asymptote --it's going to look something like that. as we approach it from the left-hand side, we're getting smaller and smaller numbers. and that's also going to be true as we approach negative 4 from the right-hand side, right? as we get negative 3.9, 3.99, 3.999, we're going to drop down. it's going to look something like that. and now that we have a general sense of what the graph is, now is a good time where we could maybe plot a few points here. and the easiest one is, what happens when x is equal to 0? you have 0 squared over 0 squared minus 16. so the point when x is equal to 0, we're going to have 0 over, well, negative 16, which is just 0. so the point 0, 0 is on this curve. and then we could try some other points if you like, but the general shape here is going to look something like this. you could plot more points if you really want to nail down exactly what the curve is doing in between, but here is the general structure. and we tried out a lot of values with the calculator. and i did that because i really wanted to show you why it's dropping down like this. and if you think about it, it makes complete sense. as you get closer and closer, let's say you get closer and closer to 4. either way, as you get closer and closer to 4, this is going to become a smaller and smaller and smaller number, because this is the difference between x and 4. so this is becoming a smaller and smaller and smaller number. then, when you take 1 over that, right? you can essentially view this as x squared over x plus 4, or times 1 over x minus 4. if this is becoming smaller and smaller, this whole thing, 1 over a super small number, is a super large number. so as you can imagine, you're going to get larger and larger, and depending on whether you are approaching from the positive or negative, so whether this is a super small negative number or super small positive number, that's going to flip the sign. but either way, the magnitude-- so we're getting to a very large magnitude in the negative direction because the difference between x and 4 on this side is negative, right? 3.9 minus 4 is 0.1. take the inverse of that, it's 10. so we're getting negative numbers here. you take the inverse, you're going to get super large negative numbers. so i really want to give you that intuition. but the general way of being able to graph these type of things, your first thing you want to do is identify the horizontal asymptotes. what happens as we get very-- the magnitude of our x is very large, so super positive values or super negative values. you could try it out on a calculator, if you like. you literally, if you try out the value of a million or a billion, it will kind of give you the answer. but the way you could also think about it is, as x gets really large, you could view that this thing, these terms right here grow so much faster-- i mean this is just a constant term. this term doesn't matter anymore. if this is a million and a million, who cares about the 16? so as x gets really large, you could say that y is approximately x squared over x squared. these two terms dominate. you don't need to worry about the 16 anymore. and of course, this is equal to 1, which is exactly what we got when we plugged in really large numbers. so, in a problem like this, where you have the same coefficient, or where you have the same degree on the numerator and the denominator, you look at the coefficient of those terms. so in this case, the coefficient is 1 and 1. so our horizontal asymptote is going to be 1 divided by 1, or y is equal to 1. if this was 2x squared over x squared minus 16, our horizontal asymptote would be y is equal to 2. we would approach that line, up there. if it was a negative 2, our horizontal asymptote would be y is equal to negative 2. so that's how you identify the horizontal asymptotes where you have the same degree in the numerator and the denominator. if the denominator has a larger degree, then the denominator is going to get larger much faster than the numerator, and your asymptote is going to be 0. i'll show an example of that in the future. and obviously, if your numerator has a higher degree than your denominator, it's going to grow way faster than your denominator, and you won't have any asymptote. you'll just keep growing, or keep going in the negative direction. and that's actually the case with all of the polynomials we've seen. you can do them all as being over 1. in which case, there was no horizontal asymptote. now the vertical asymptotes you identify by essentially just factoring the denominator and figuring out where does it equal 0. those are the points where the function is not defined. and i'll show you in the future, there are some special cases where they won't be vertical asymptotes, and i guess that special case is, for example, if you had-- well, i won't show you the special case right now. i'll show you that in a future video. but in general, if you factor the bottom terms and they don't cancel out with anything on the numerator, then you're going to be dealing with a vertical asymptote. if i had another x minus 4 up here, if my numerator was x squared times x minus 4, and then these canceled out, and my expression simplified to this, the equation would still be undefined at x is equal to 4, because you would give the 0 in the denominator. but since that x minus 4 cancels out with the x minus 4 in the numerator, it would not have been a vertical asymptote. we'll look at that in the future. but this equation wasn't that. so the general rule of thumb for identifying the vertical asymptotes, factor the denominator, figure out where the denominator equals 0, and if those terms don't cancel out with any terms of the numerator, then those are vertical asymptotes. and then to figure out the behavior, i guess, within the asymptotes, you can plot some points. you can try out some points. you can actually substitute values for x and figure out what y is. now just to validate that we hopefully got the right answer, let's actually graph our rational function. so let me turn it on. let me graph it. and we say y is equal to x squared divided by x squared minus 16. and let's see what we get. nope, i just want to graph it. my range is off. let me do my range. let me see, x minimum value i want for x, let's say it's negative 10. my maximum value i want for x is 10. x scale is 1. y minimum value, i want negative 10. y maximum value, i want 10. then y scale, i want 1. now let me graph it. there we go. look at that. just like what we drew. we have an asymptote, as x gets really large, or x gets really, really small, that asymptote is y is equal to 1. we have our vertical asymptote. it graphed it because it tried to connect the dots, but it essentially graphed our asymptotes for us, but that wouldn't actually be part of the graph. but as we approach 4 from 0, i guess we can say, we go super negative. as we approach negative 4 from 0, we get super negative. because in either of those situations, as you approach 4 from this side, this term is going to be negative. as you approach negative 4 from thid side, this term, right here, is going to be-- well, this term right here is going to be positive, but then this term right here is going to be negative. negative times a positive, you could play with it as you like. but we approach negative infinity in either case. and then as x approaches infinity, this thing asymptotes away. so hopefully you found that fun.",t_686dec2dab6f,other,0
c_ea21baa4d1b5,"mutations  errors occurring during dna replication are not the only way by which mutations can arise in dna. mutations, variations in the nucleotide sequence of a genome, can also occur because of physical damage to dna. such mutations may be of two types: induced or spontaneous. induced mutations are those that result from an exposure to chemicals, uv rays, x-rays, or some other environmental agent. spontaneous mutations occur without any exposure to any environmental agent; they are a result of spontaneous biochemical reactions taking place within the cell.  mutations may have a wide range of effects. some mutations are not expressed; these are known as silent mutations. point mutations are those mutations that affect a single base pair. the most common nucleotide mutations are substitutions, in which one base is replaced by another. these can be of two types, either transitions or transversions. transition substitution refers to a purine or pyrimidine being replaced by a base of the same kind; for example, a purine such as adenine may be replaced by the purine guanine. transversion substitution refers to a purine being replaced by a pyrimidine, or vice versa; for example, cytosine, a pyrimidine, is replaced by adenine, a purine. mutations can also be the result of the addition of a nucleotide, known as an insertion, or the removal of a base, also known as deletion. sometimes a piece of dna from one chromosome may get translocated to another chromosome or to another region of the same chromosome; this is known as translocation.  as we will visit later, when a mutation occurs in a protein coding region it may have several effects. transition or transversion mutants may lead to no change in the protein sequence (known as silent mutations), change the amino acid sequence (known as missense mutations), or create what is known as a stop codon (known as a nonsense mutation). insertions and deletions in protein coding sequences lead to what are known as frameshift mutations. missense mutations that lead to conservative changes results in the substitution of similar but not identical amino acids. for example, the acidic amino acid glutamate being substituted for the acidic amino acid aspartate would be considered conservative. in general we do not expect these types of missense mutations to be as severe as a non-conservative amino acid change; such as a glutamate substituted for a valine. drawing from our understanding of functional group chemistry we can correctly infer that this type of substitution may lead to severe functional consequences, depending upon location of the mutation.  note: vocabulary watch  note that the preceding paragraph had a lot of potentially new vocabulary - it would be a good idea to learn these terms.  (https://bio.libretexts.org/@api/deki/files/10076/figure_14_06_05-1.png?revision=1)  figure 1. mutations can lead to changes in the protein sequence encoded by the dna.  suggested discussion  based on your understanding of protein structure, which regions of a protein would you think are more sensitive to substitutions, even conserved amino acid substitutions? why?  suggested discussion  a insertion mutation that results in the insertion of three nucleotides is often less deleterious than a mutation that results in the insertion of one nucleotide. why?  mutations: some nomenclature and considerations  mutation  etymologically (http://dictionary.reference.com/browse/etymology) speaking, the term mutation simply means a change or alteration. in genetics, a mutation is a change in the genetic material - dna sequence - of an organism. by extension, a mutant is the organism in which a mutation has occurred. but what is the change compared to? the answer to this question, is that it depends. the comparison can be made with the direct progenitor (cell or organism) or to patterns seen in a population of the organism in question. it mostly depends on the specific context of the discussion. since genetic studies often look at a population (or key subpopulations) of individuals we begin by describing the term ""wild-type"".  wild type vs mutant  what do we mean by ""wild type""? since the definition can depend on context, this concept is not entirely straightforward. here are a few examples of definitions you may run into:  possible meanings of ""wild-type""  an organism having an appearance that is characteristic of the species in a natural breeding population (i.e. a cheetah's spots and tear-like dark streaks that extend from the eyes to the mouth).  the form or forms of a gene  in nature in a given species.  most commonly occurring  a phenotype, genotype, or gene  in a natural population of organisms or strain of organisms in contrast to that of natural or laboratory mutant forms.  that predominates  the normal, as opposed to the mutant, gene or allele.  the common thread to all of the definitions listed above is based on the ""norm"" for a set of characteristics with respect to a specific trait compared to the overall population. in the ""pre-dna sequencing age"" species were classified based on common phenotypes (what they looked like, where they lived, how they behaved, etc.). a ""norm"" was established for the species in question. for example, crows display a common set of characteristics, they are large, black birds that live in specific regions, eat certain types of food and behave in a certain characteristic way. if we see one, we know its a crow based on these characteristics. if we saw one with a white head, we would think that either it is a different bird (not a crow) or a mutant, a crow that has some alteration from the norm or wild type.  in this class we take what is common about those varying definitions and adopt the idea that ""wild type"" is simply a reference standard against which we can compare members of a population.  suggested discussion  if you were assigning wild type traits to describe a dog, what would they be? what is the difference between a mutant trait and variation of a trait in a population of dogs? is there a wild type for a dog that we could use as a standard? how would we begin to think about this concept with respect to dogs?  (https://bio.libretexts.org/@api/deki/files/10077/flies.jpg?revision=1)  figure 2. mutations can lead to changes in the protein sequence encoded by the dna that then impact the outward appearance of the organism.      (source (http://blogs.brandeis.edu/flyonthewall/tag/day-in-the-life/))  mutations are simply changes from the ""wild type"", reference or parental sequence for an organism. while the term ""mutation"" has colloquially negative connotations we must remember that change is neither inherently ""bad"". indeed, mutations (changes in sequences) should not primarily be thought of as ""bad"" or ""good"", but rather simply as changes and a source of genetic and phenotypic diversity on which evolution by natural selection can occur. natural selection ultimately determines the long-term fate of mutations. if the mutation confers a selective advantage to the organism, the mutation will be selected and may eventually become very common in the population. conversely, if the mutation is deleterious, natural selection will ensure that the mutation will be lost from the population. if the mutation is neutral, that is it neither provides a selective advantage or disadvantage, then it may persist in the population. different forms of a gene, including those associated with ""wild type"" and respective mutants, in a population are termed alleles.  consequences of mutations  for an individual, the consequence of mutations may mean little or it may mean life or death. some deleterious mutations are null or knock-out mutations which result in a loss of function of the gene product. these mutations can arise by a deletion of the either the entire gene, a portion of the gene, or by a point mutation in a critical region of the gene that renders the gene product non-functional. these types of mutations are also referred to as loss-of-function mutations. alternatively, mutations may lead to a modification of an existing function (i.e. the mutation may change the catalytic efficiency of an enzyme, a change in substrate specificity, or a change in structure). in rare cases a mutation may create a new or enhanced function for a gene product; this is often referred to as a gain-of-function mutation. lastly, mutations may occur in non-coding regions of dna. these mutations can have a variety of outcomes including altered regulation of gene expression, changes in replication rates or structural properties of dna and other non-protein associated factors.  suggested discussion  in the discussion above what types of scenarios would allow such a gain-of-function mutant the ability to out compete a wild type individual within the population? how do you think mutations relate to evolution?  mutations and cancer  mutations can affect either somatic cells or germ cells. sometimes mutations occur in dna repair genes, in effect compromising the cell's ability to fix other mutations that may arise. if, as a result of mutations in dna repair genes, many mutations accumulate in a somatic cell, they may lead to problems such as the uncontrolled cell division observed in cancer. cancers, including forms of pancreatic cancer, colon cancer, and colorectal cancer have been associated with mutations like these in dna repair genes. if, by contrast, a mutation in dna repair occurs in germ cells (sex cells), the mutation will be passed on to the next generation, as in the case of diseases like hemophilia and xeroderma pigmentosa. in the case of xeroderma pigmentoas individuals with compromised dna repair processes become very sensitive to uv radiation. in severe cases these individuals may get severe sun burns with just minutes of exposure to the sun. nearly half of all children with this condition develop their first skin cancers by age 10.  consequences of errors in replication, transcription and translation  something key to think about:  cells have evolved a variety of ways to make sure dna errors are both detected and corrected, rom proof reading by the various dna-dependent dna polymerases, to more complex repair systems. why did so many different mechanisms evolve to repair errors in dna? by contrast, similar proof-reading mechanisms did not evolve for errors in transcription or translation. why might this be? what would be the consequences of an error in ? would such an error effect the offspring? would it be lethal to the cell? what about ? ask the same questions about the process of translation. what would happen if the wrong amino acid was accidentally put into the growing polypeptide during the translation of a protein? contrast this with dna replication.  transcription  translation  mutations as instruments of change  mutations are how populations can adapt to changing environmental pressures  mutations are randomly created in the genome of every organism, and this in turn creates genetic diversity and a plethora of different alleles per gene per organism in every population on the planet. if mutations did not occur, and chromosomes were replicated and transmitted with 100% fidelity, how would cells and organisms adapt? whether mutations are retained by evolution in a population depends largely on whether the mutation provides selective advantage, poses some selective cost or is at the very least, not harmful. indeed, mutations that appear neutral may persist in the population for many generations and only be meaningful when a population is challenged with a new environmental challenge. at this point the apparently previously neutral mutations may provide a selective advantage.  example: antibiotic resistance  the bacterium e. coli is sensitive to an antibiotic called streptomycin, which inhibits protein synthesis by binding to the ribosome. the ribosomal protein l12 can be mutated such that streptomycin no longer binds to the ribosome and inhibits protein synthesis. wild type and l12 mutants grow equally well and the mutation appears to be neutral in the absence of the antibiotic. in the presence of the antibiotic wild type cells die and l12 mutants survive. this example shows how genetic diversity is important for the population to survive. if mutations did not randomly occur, when the population is challenged by an environmental event, such as the exposure to streptomycin, the entire population would die. for most populations this becomes a numbers game. if the mutation rate is 10-6 then a population of 107 cells would have 10 mutants; a population of 108 would have 100 mutants, etc.  (https://bio.libretexts.org/@api/deki/files/10078/mutation.jpg?revision=1)  uncorrected errors in dna replication lead to mutation. in this example, an uncorrected error was passed onto a bacterial daughter cell. this error is in a gene that encodes for part of the ribosome. the mutation results in a different final 3d structure of the ribosome protein. while the wildtype ribosome can bind to streptomycin (an antibiotic that will kill the bacterial cell by inhibiting the ribosome function) the mutant ribosome cannot bind to streptomycin. this bacteria is now resistant to streptomycin.  source: bis2a team original image  suggested discussion  based on our example, if you were to grow up a culture of e. coli to population density of 109 cells/ml; would you expect the entire population to be identical? how many mutants would you expect to see in 1 ml of culture?  an example: lactate dehydrogenase  lactate dehydrogenase (ldh), the enzyme that catalyzes the reduction of pyruvate into lactic acid in fermentation, while virtually every organism has this activity, the corresponding enzyme and therefore gene differs immensely between humans and bacteria. the proteins are clearly related, they perform the same basic function but have a variety of differences, from substrate binding affinities and reaction rates to optimal salt and ph requirements. each of these attributes have been evolutionarily tuned for each specific organism through multiple rounds of mutation and selection.  suggested discussion  we can use comparative dna sequence analysis to generate hypotheses about the evolutionary relationships between three or more organisms. one way to accomplish this is to compare the dna or protein sequences of proteins found in each of the organisms we wish to compare. let us, for example, imagine that we were to compare the sequences of ldh from three different organisms, organism a, organism b and organism c. if we compare the ldh protein sequence from organism a to that from organism b we find a single amino acid difference. if we now look at organism c, we find 2 amino acid differences between its ldh protein and the one in organism a and one amino acid difference when the enzyme from organism c is compared to the one in organism b. both organisms b and c share a common change compared to organism a.  schematic depicting the primary structures of ldh proteins from organism a, organism b, and organism c. the letters in the center of the proteins line diagram represent amino acids at a unique position and the proposed differences in each sequence. the n and c termini are also noted h2n and cooh, respectively. attribution: marc t. facciotti (original work)  question: is organism c more closely related to organism a or b? the simplest explanation is that organism a is the earliest form, a mutation occurred giving rise to organism b. over time a second mutation arose in the b lineage to give rise to the enzyme found in organism c. this is the simplest explanation, however we can not rule out other possibilities. can you think of other ways the different forms of the ldh enzyme arose these three organisms?  glossary  induced mutation:  mutation that results from exposure to chemicals or environmental agents  mutation:  variation in the nucleotide sequence of a genome  mismatch repair:  type of repair mechanism in which mismatched bases are removed after replication  nucleotide excision repair:  type of dna repair mechanism in which the wrong base, along with a few nucleotides upstream or downstream, are removed  proofreading:  function of dna pol in which it reads the newly added base before adding the next one  point mutation:  mutation that affects a single base  silent mutation:  mutation that is not expressed  spontaneous mutation:  mutation that takes place in the cells as a result of chemical reactions taking place naturally without exposure to any external agent  transition substitution:  when a purine is replaced with a purine or a pyrimidine is replaced with another pyrimidine  transversion substitution:  when a purine is replaced by a pyrimidine or a pyrimidine is replaced by a purine  evolution and natural selection  brief overview  evolution and natural selection are core concepts in biology that are typically invoked to help explain the diversity of and relationships between life on earth, both extant and extinct. fortunately, in bis2a, you need to understand and use only a few core ideas related to evolution and natural selection. we describe these below. you will expand your understanding and add details to these core concepts in bis2b and bis2c.  the first idea you need to grasp is that evolution can be simply defined as the development/change of something over time. in the automotive industry, the shapes and features of cars can be said to evolve (change in time). in fashion, it can be said that style evolves. in biology, life and, in particular, reproducing populations of organisms with different traits evolve.  the second thing to understand is that natural selection is a process by which nature filters organisms in a population. what is the filter? here it becomes a little more complicated (but only a little). the simplest explanation is that the selective filter is just a combination of all living and nonliving factors in an environment, which influence how successfully an organism can reproduce. the factors that influence the ability of an organism to reproduce are known as selective pressures. a small but important complication is that these factors are not the same everywhere; they change in time and by location. thus, the selective pressures that create the filter are constantly changing (sometimes rapidly, sometimes slowly), and organisms in the same reproducing population could experience different pressures at different times and in different locations.   the theory of evolution by natural selection puts these two ideas together; it stipulates that change in biology happens over time and that the variation in a population is constantly subjected to selection based on how differences in traits influence reproduction. but what are these characteristics or traits? what traits/features/functions can be subject to selection? the short answer is: just about anything associated with an organism for which variation exists in a population and for which this variation leads to a differential likelihood of generating offspring will probably be subject to filtering by natural selection. we also call these traits heritable phenotypes. organisms in a population that have phenotypes, which enable them to pass the selective filter more efficiently than others, are said to have a selective advantage and/or greater fitness.  it is important to reiterate that while the phenotypes carried by individual organisms may be subject to selection, the process of evolution by natural selection both requires and acts on phenotypic variation within populations. if neither variation nor populations in which that variation can reside exist, there is no opportunity or need for selection. everything is and stays the same.  common misconceptions and a course specific note  finally, we draw your attention to a critical point and common misconception among beginning students in biology. this misconception can arise when, for the sake of discussion, we decide to anthropomorphize nature by giving it an intellect. for example, we may try to build an example for evolution by natural selection by proposing that a surplus of a particular food exists in an environment and there is an organism close by that is starving. it would be correct to reason that if the organism could eat that food that this might give it a selective advantage over other organisms that cannot. if later we find an example of organisms that have the capability to eat that surplus food, it might be tempting to say that nature evolved to solve the problem the surplus food. the process of evolution by natural selection, however, happens randomly and without direction. that is, nature does not identify “problems” that are limiting fitness. nature does not identify features that would make an organism more successful and then start creating diverse solutions that meet this need. the generation of variation is not guided. variation happens and natural selection filters what works best. the observation that an organism exists that can eat the surplus food is not a reflection of nature actively solving a problem, but rather, a reflection of whatever processes that led to phenotypic variation in an ancestral population that created—among many other variants—a phenotype that increased fitness (possibly because the ancestral organisms were able to eat the surplus food).  this point of the preceding paragraph is particularly important to understand in the context of bis2a because of the way we will be utilizing the design challenge to understand biology. while the design challenge is intended to help focus our attention on functions under selection and their relationship to determining fitness, it can be easy—if we aren’t attentive—to lapse into language that would suggest that nature purposefully designs solutions to solve specific problems. always remember that we are looking retrospectively at what nature has selected and that we are attempting to understand why a specific phenotype may have been selected over many other possibilities. in doing so, we will be inferring or hypothesizing to the best of our ability (which is sometimes wrong) a sensible reason to explain why a phenotype might have provided a selective advantage. we are not saying that the phenotype evolved to provide a specific selective advantage. the distinction between these two ideas may be subtle, but it is critical!  note: possible discussion  what physical traits can you think of that give a selective advantage to certain species? under what conditions would this trait grant those advantages? under what conditions might that trait be a selective disadvantage?  note: possible discussion  the great varieties of domesticated dog breeds from which we can choose for companionship are also the result of a process of evolution by selection. likewise, the development of many very different looking crops—cabbage, brussel sprouts, kohlrabi, kale, broccoli and cauliflower—is also the result of evolution by selection. however, in these two cases the selection or filtering process is referred to artificial selection rather than natural selection. discuss how artificial and natural selection are similar and different?  note: possible discussion  how do environmental and political factors influence manufacturing processes such as automobile design? fashion? etc. what aspects are similar to the evolution of an organism, and what aspects are different?  note: possible discussion  a related but slightly different misconception about evolution by natural selection is that this process leads to the creation of the most efficient solutions to problems. what is the problem with this notion?  sickle cell anemia: the impact of environmental factors on the persistent of a disease  genes are translated into proteins; mutations often (but not always) result in changes in the sequence of amino acids in those proteins. changes in the amino acid sequence can modify (in various ways) or even completely destroy protein function. proteins have many functions within cells, and a change in those functions results in a change in the phenotype of that cell or organism. so a mutation as simple as a single base change in a dna sequence can have dramatic effects on phenotype. one of the best examples of this phenomenon can be observed when mutations occur in the gene for one of the protein components of the red blood cell protein we call hemoglobin.  a major component of the erythrocytes (red blood cells) found in ver­tebrates is hemoglobin. a molecule of hemoglobin from a normal adult human contains four proteins (two identical alpha polypeptides and two identical beta polypeptides) surrounding a core of heme (complex molecule containing an atom of iron which can combine reversibly with oxygen). thus, hemoglobin functions as the major oxygen-carrying constituent of blood. because of hemoglobin, a given volume of blood can carry far more oxygen than could be dissolved in an equal volume of water.  in many human populations, particularly those with origins in central africa or the mediterranean, there are individuals who suffer from severe anemia and whose blood contains numerous distorted, sickle-shaped erythrocytes. hence, the disease was given the name sickle cell anemia.  (https://bio.libretexts.org/@api/deki/files/10033/sickle_cells.jpg?revision=1)  figure 1. notice the sickle shaped cells in the image by dr graham beards via wikimedia commons  biochemical studies established that the gene affected in sickle-cell ane­mia has the code for an abnormal beta polypeptide, which is one of the components of the hemoglobin molecule. therefore, there are two different forms of the hemoglobin gene that codes for the beta chain:  form 1: hba has the code for a normal beta chain  form 2: hbs has the code for an abnormal beta chain  humans are diploid organisms; they have two copies of most genes. however, the two copies they possess do not have to be identical. when there are two possible alleles for a gene (such as in the gene for the beta chain of hemoglobin), a diploid individual will have one of three possible combinations of the two alleles. they can be hba hba , hba hbs, or hbshbs.  the set of alleles present in an individual for a given gene is known as the individual’s genotype. the three combinations of two alleles above are therefore the three different genotypes. individuals that have two copies of the same allele are called homozygous; individuals with two different alleles are called heterozygous. so an individual that is hba hba is homozygous normal beta chain; an individual that is hba hbs is heterozygous; and an individual that is hbs hbs is homozygous abnormal beta chain. it is the homozygous hbs individuals that contain sickle-shaped blood cells.  mechanism of the disease  in the capillaries (microscopic blood vessels that directly exchange oxygen with the tissues), erythrocytes can be subjected to low oxygen tension after they lose their oxygen to the surrounding tissues. in this low oxygen situation, the abnormal hemoglobin molecules of hbs hbs individuals tend to polymerize (join together), forming stiff, tubular fibers which ultimately distort the shape of the entire erythrocyte, giving it the characteristic “sickle” shape. these sickled cells have a number of effects on the body via two processes.  sickled cells are less able to enter and move through the capillaries: once in the capillaries, they clog capillary flow and cause small blood clots. reduced blood flow results in reduced oxygen availability to the tissues. reduced oxygen supply results in tissue death and damage to vital organs (e.g., the heart, liver and spleen).  sickled blood cells have a shorter lifespan than normal red blood cells: reduced lifespan of erythrocytes places a greater demand on the bone marrow to make new red blood cells and on the spleen to break down dead erythrocytes. increased demand on the bone marrow results in severe pain in the long bones and joints. individuals suffering from sickle cell anemia are frequently ill and generally have a considerably reduced lifespan. these individuals are said to have sickle cell disease.  heterozygous individuals (hba hbs) are said to be carriers for sickle cell anemia. note that this is a specific term and is not the same thing as sickle cell anemia—heterozygotes do not have the disease themselves but their children may inherit the condition. carriers have no anemia, have good health (as do hba hba individuals), and their erythrocytes maintain normal shape in the blood. in other words, they are phenotypically normal under most conditions, and probably do not know that they “carry” the hbs allele. however, if heterozygotes are exposed to condi­tions of low oxygen levels (such as strenuous activity at high altitudes), some of their erythrocytes do sickle. red blood cells in blood samples of heterozygotes subjected to greatly reduced oxygen tension in the laboratory also sickle.  why is sickle cell anemia most prevalent in people with origins in central africa and the mediterranean? if you look at figure 2 (https://legacy.cnx.org/groupworkspaces/wg3733/module.2016-11-12.5670439228/module_view#sickle_cell_and_malaria), you will see the occurrence of sickle cell anemia overlaps with the pervasiveness of malaria. this seems odd, but those individuals who are heterozygous (hba hbs) for the sickle cell allele are less likely to contract and die from malaria then those who are homozygous (hba hba). the hbs polypeptide that is produced by the heterozygous individual stops the organism (plasmodium) that causes malaria from invading the red blood cells. so, in areas where malaria is common there is selection pressure for the hbs allele, and the hbs allele occurs in a higher frequency because the those who have one copy of the hbs allele will live longer and have more children. in areas where malaria is not common, there is selection pressure against the hbs allele, and the hbs allele occurs in a lower frequency. as you will learn in a later chapter, there is an 25% chance that two carriers will have a child who is homozygous hbs hbs), and this child will pay the evolutionary price for the protection from malaria that the parents were afforded. it seems to be in this way that evolution by natural selection retains such a potentially detrimental allele in a population. the sickle cell example is only one of what is called heterozygous advantage; we have provided a number of other examples in table 1 (https://legacy.cnx.org/groupworkspaces/wg3733/module.2016-11-12.5670439228/module_view#eip-101).  ------------------------------------------------------------------- | distribution of malaria and the frequency of sickle cell allele |  -------------------------------------------------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |                      recessive illness |                                   heterozygote advantage |                                                                   possible explanation |  |                        cystic fibrosis |    protection against diarrheal diseases such as cholera | carriers have too few functional chloride channels in intestinal cells, blocking toxin |  |                        g6pd deficiency |                               protection against malaria |                                                red blood cells inhospitable to malaria |  |                  phenylketonuria (pku) | protection against miscarriage induced by a fungal toxin |                        excess amino acid (phenylalanine) in carriers inactivates toxin |  |                      tay-sachs disease |                          protection against tuberculosis |                                                                                unknown |  | noninsulin-dependent diabetes mellitus |                            protection against starvation |                      tendency to gain weight protects against starvation during famine |  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",t_cc8700c2d799,other,0
c_ee775318909f,"in this video you video you will learn how to hit a backhand volley. how to hit a backhand volley in this video, you will learn how to hit a backhand volley. it is an attacking net shot that is struck before the ball bounces the three key steps are the preparation, the shot and the follow through step1 the preparation use a continental grip the racket frame should be perpendicular to the ground and the base of the 'v' formed with the thumb and the index along the first bevel hold the throat of the racket firmly with the non racket hand stand in the ready position two metres from the net, with legs shoulder width apart and knees bent the racket handle should be waist-high and the head should point diagonally upward, forming an 'l' shape with the arm step 2 the shot do a split step when your opponent contacts the ball this will allow you to turn to the forehand or the backhand the racket should be above the ball in the set up position swing your arm downward and forward as you strike the ball and step forward with your racket leg simultaneously keep the side of the frame up and push the ball forward with a firm and locked wrist the contact should take place at the equator and the back of the ball the underspin is generated by using the shoulder as a hinge, starting with the racket above the ball and contacting it below the swing should be minimal and compact, as if you were blocking the ball step 3  the follow through in a backhand volley you could extend the racket hand a little more than in the forehand volley lead with the bottom edge and step forward into the shot it's important to put some bodyweight into the volley remember to extend the non racket hand behind to help you balance practice volleying against the wall or with a partner enjoy your game",t_62e210e7ff49,other,0
c_884656a3cd6c,"even though we have formally defined \(\mathbb{c}\) as the set of all ordered pairs of real numbers, we can nonetheless extend the usual arithmetic operations on \(\mathbb{r}\) so that they also make sense on \(\mathbb{c}\). we discuss such extensions in this section, along with several other important operations on complex numbers.  2.2.1 addition and subtraction of complex numbers  addition of complex numbers is performed component-wise, meaning that the real and imaginary parts are simply combined.  definition 2.2.1.  given two complex numbers \((x_{1}, y_{1}), (x_{2}, y_{2}) \in \mathbb{c}\), we define their complex sum to be  \[ (x_{1}, y_{1}) + (x_{2}, y_{2}) = (x_{1} + x_{2}, y_{1} + y_{2}). \]  example 2.2.2. \( (3, 2) + (17, -4.5) = (3 + 17, 2 - 4.5) = (20, -2.5).\)  as with the real numbers, subtraction is defined as addition with the so-called additive inverse, where the additive inverse of \(z=(x,y)\) is defined a \(-z=(-x,-y)\).  example 2.2.3.  \( (\pi, \sqrt{2}) - (\pi/2, \sqrt{19}) = (\pi, \sqrt{2}) + (-\pi/2, -\sqrt{19}), \)  where  \[ (\pi, \sqrt{2}) + (-\pi/2, -\sqrt{19}) = (\pi - \pi/2, \sqrt{2} - \sqrt{19}) = (\pi/2, \sqrt{2} - \sqrt{19}). \]  the addition of complex numbers shares many of the same properties as the addition of real numbers, including associativity, commutativity, the existence and uniqueness of an additive identity, and the existence and uniqueness of additive inverses. we summarize these properties in the following theorem, which you should prove for your own practice.  theorem 2.2.4. let \(z_{1}, z_{2}, z_{3} \in \mathbb{c}\) be any three complex numbers. then the following statements are true.  (associativity) \((z_{1} + z_{2}) + z_{3} = z_{1} + (z_{2} + z_{3})\).  (commutativity) \(z_{1} + z_{2} = z_{2} + z_{1}\).  (additive identity) there is a unique complex number, denoted \(0\), such that, given any complex number \(z \in \mathbb{c}\), \(0 + z = z\). moreover, \(0 = (0, 0)\).  (additive inverses) given any complex number \(z \in \mathbb{c}\), there is a unique complex number, denoted \(-z\), such that \(z + (-z) = 0\). moreover, if \(z = (x, y)\) with \(x, y \in \mathbb{r}\), then \(-z = (-x, -y)\).  the proof of this theorem is straightforward and relies solely on the definition of complex addition along with the familiar properties of addition for real numbers. for example, to check commutativity, let \(z_{1} = (x_{1}, y_{1})\) and \(z_{2} = (x_{2}, y_{2})\) be complex numbers with \(x_{1}, x_{2}, y_{1}, y_{2} \in \mathbb{r}\). then \[ z_{1} + z_{2} = (x_{1} + x_{2}, y_{1} + y_{2}) = (x_{2} + x_{1}, y_{2} + y_{1}) = z_{2} + z_{1}. \]  2.2.2 multiplication and division of complex numbers  the definition of multiplication for two complex numbers is at first glance somewhat less straightforward than that of addition.  definition 2.2.5. given two complex numbers \((x_{1}, y_{1}), (x_{2}, y_{2}) \in \mathbb{c}\), we define their complex product to be  \[ (x_{1}, y_{1})(x_{2}, y_{2}) = (x_{1}x_{2} - y_{1}y_{2} , x_{1}y_{2} + x_{2}y_{1}). \]  according to this definition, \(i^2=-1\). in other words, \(i\) is a solution of the polynomial equation \(z^2+1=0\), which does not have solutions in \(\mathbb{r}\).  solving such otherwise unsolvable equations was largely the main motivation behind the introduction of complex numbers. note that the relation \(i^2=-1\) and the assumption that complex numbers can be multiplied like real numbers is sufficient to arrive at the general rule for multiplication of complex numbers:  \begin{align*} (x_{1} + y_{1}i)(x_{2} + y_{2}i) &amp; = x_{1}x_{2} + x_{1}y_{2}i + x_{2}y_{1}i +  y_{1}y_{2}i^{2} \\ &amp; = x_{1}x_{2} + x_{1}y_{2}i + x_{2}y_{1}i -  y_{1}y_{2} \\ &amp; = x_{1}x_{2} -  y_{1}y_{2} + (x_{1}y_{2} + x_{2}y_{1})i. \end{align*}  as with addition, the basic properties of complex multiplication are easy enough to prove using the definition.  we summarize these properties in the following theorem, which you should also prove for your own practice.  theorem 2.2.6. let \(z_{1}, z_{2}, z_{3} \in \mathbb{c}\) be any three complex numbers.  then the following statements are true.  (associativity) \((z_{1}z_{2})z_{3} = z_{1}(z_{2}z_{3})\).  (commutativity) \(z_{1}z_{2} = z_{2}z_{1}\).  (multiplicative identity) there is a unique complex number, denoted \(1\), such that, given any \(z \in \mathbb{c}\), \(1 z = z\).  moreover, \(1 = (1, 0)\).  (distributivity of multiplication over addition) \(z_{1}(z_{2} + z_{3}) = z_{1}z_{2} + z_{1}z_{3}\).  just as is the case for real numbers, any non-zero complex number \(z\) has a unique multiplicative inverse, which we may denote by either \(z^{-1}\) or \(1/z\).  theorem 2.2.6. (continued).  (multiplicative inverses) given \(z \in \mathbb{c}\) with \(z \neq 0\), there is a unique complex number, denoted \(z^{-1}\), such that \(z z^{-1} = 1\).  moreover, if \(z = (x, y)\) with \(x, y \in \mathbb{r}\), then  \[ z^{-1} = \left(\frac{x}{x^{2} + y^{2}}, \frac{-y}{x^{2} + y^{2}}\right). \]  proof.  uniqueness: a complex number \(w\) is an inverse of \(z\) if \(z w=1\) (by the commutativity of complex multiplication this is equivalent to \(w z=1\). we will first prove that if \(w\) and \(v\) are two complex numbers such that \(z w=1\) and \(z v=1\), then we necessarily have \(w=v\).  this will then imply that any \(z\in\mathbb{c}\) can have at most one inverse.  to see this, we start from \(z v=1\).  multiplying both sides by \(w\), we obtain \(w z v=w 1\).  using the fact that \(1\) is the multiplicative unit, that the product is commutative, and the assumption that \(w\) is an inverse, we get \(z w v=v=w\).  existence: now assume \(z\in\mathbb{c}\) with \(z\neq 0\), and write \(z=x+y i\) for \(x,y\in\mathbb{r}\). since \(z\neq 0\), at least one of \(x\) or \(y\) is not zero, and so \(x^2 + y^2 &gt;0\). therefore, we can define  \[ w=\left(\frac{x}{x^{2} + y^{2}}, \frac{-y}{x^{2} + y^{2}}\right), \]  and one can check that \(z w=1\).  now, we can define the division of a complex number \(z_1\) by a non-zero complex number \(z_2\) as the product of \(z_1\) and \(z_2^{-1}\).  explicitly, for two complex numbers \(z_1= x_{1} + i y_{1}\) and \(z_2 =x_{2} +i y_{2}\), we have that their complex quotient is  \[ \frac{z_1}{z_2} = \frac{x_{1}x_{2} + y_{1}y_{2}+ \left(x_{2}y_{1} - x_{1}y_{2}\right)i}{x_{2}^{2} + y_{2}^{2}}. \]  example 2.2.7.  we illustrate the above definition with the following example: \[ \frac{(1, 2)}{(3, 4)} = \left( \frac{1\cdot 3 + 2\cdot 4}{3^{2} + 4^{2}} , \frac{3\cdot 2 - 1\cdot 4}{3^{2} + 4^{2}} \right) = \left( \frac{3 + 8}{9 + 16} , \frac{6 - 4}{9 + 16} \right) = \left( \frac{11}{25} , \frac{2}{25} \right). \]  2.2.3 complex conjugation  complex conjugation is an operation on \(\mathbb{c}\) that will turn out to be very useful because it allows us to manipulate only the imaginary part of a complex number. in particular, when combined with the notion of modulus (as defined in the next section), it is one of the most fundamental operations on \(\mathbb{c}\). the definition and most basic properties of complex conjugation are as follows. (as in the previous sections, you should provide a proof of the theorem below for your own practice.)  definition 2.2.8.  given a complex number \(z = (x, y) \in \mathbb{c}\) with \(x, y \in \mathbb{r}\), we define the (complex) conjugate of \(z\) to be the complex number  \[ \bar{z} = (x, -y). \]  theorem 2.2.9. given two complex numbers \(z_{1}, z_{2} \in \mathbb{c}\),  \(\overline{z_{1} + z_{2}} = \overline{z_{1}} + \overline{z_{2}}\).  \(\overline{z_{1}z_{2}} = \overline{z_{1}}\, \overline{z_{2}}\).  \(   \overline{1/z_1} = 1/\overline{z_1}\), for all  \(z_1\neq 0\).  \(\overline{z_{1}} = z_{1}\) if and only if \(\imaginarypart(z_{1}) = 0\).  \(\overline{\overline{z_{1}}} = z_{1}\).  the real and imaginary parts of \(z_{1}\) can be expressed as  \[ \mathrm{re}(z_{1}) = \frac{1}{2}(z_{1} + \overline{z_{1}}) {\rm \quad and \quad} \mathrm{im}(z_{1}) = \frac{1}{2 i}(z_1 - \overline{z_1}). \]  2.2.4 the modulus (a.k.a. norm, length, or magnitude)  in this section, we introduce yet another operation on complex numbers, this time based upon a generalization of the notion of absolute value of a real number. to motivate the definition, it is useful to view the set of complex numbers as the two-dimensional euclidean plane, i.e., to think of \(\mathbb{c}=\mathbb{r}^2\) being equal as sets. the modulus, or length, of \(z\in\mathbb{c}\) is then defined as the euclidean distance between \(z\), as a point in the plane, and the origin \(0 = (0,0)\).  this is the content of the following definition.  definition 2.2.10. given a complex number \(z = (x, y) \in \mathbb{c}\) with \(x, y \in \mathbb{r}\), the modulus of \(z\) is defined to be  \[ |z| = \sqrt{x^{2} + y^{2}}. \]  in particular, given \(x \in \mathbb{r}\), note that  \[ | (x, 0) | = \sqrt{x^{2} + 0} = | x | \]  under the convention that the square root function takes on its principal positive value.  example 2.2.11. using the above definition, we see that the modulus of the complex number \((3, 4)\) is  \[ | (3, 4) | = \sqrt{3^{2} + 4^{2}} = \sqrt{9 + 16} = \sqrt{25} = 5. \]  to see this geometrically, construct a figure in the euclidean plane, such as  (https://math.libretexts.org/@api/deki/files/699/screen_shot_2014-01-03_at_12.16.20_pm.png?revision=1)  and apply the pythagorean theorem to the resulting right triangle in order to find the distance from the origin to the point \((3, 4)\).  the following theorem lists the fundamental properties of the modulus, and especially as it relates to complex conjugation. you should provide a proof for your own practice.  theorem 2.2.12. given two complex numbers \(z_{1}, z_{2} \in \mathbb{c}\),  \(|z_{1}z_{2}| = |z_{1}|\cdot|z_{2}|\).  \({\displaystyle \left|\frac{z_{1}}{z_{2}}\right| = \frac{|z_{1}|}{|z_{2}|}}\), assuming that \(z_{2} \neq 0\).  \(|\overline{z_{1}}| = |z_{1}|\).  \(|\mathrm{re}(z_{1})| \leq |z_{1}|\) and \(|\mathrm{im}(z_{1})| \leq |z_{1}|\).  (triangle inequality) \(|z_{1} + z_{2}| \leq |z_{1}| + |z_{2}|\).  (another triangle inequality) \(|z_{1} - z_{2}| \geq |\,|z_{1}| - |z_{2}|\,|\).  (formula for multiplicative inverse) \(z_{1}\overline{z_{1}} = |z_{1}|^{2}\), from which  \[ z_{1}^{-1} = \frac{\overline{z_{1}}}{|z_{1}|^{2}} \]  when we assume that \(z_{1} \neq 0\).  2.2.5 complex numbers as vectors in \(\mathbb{r}^{2}\)  when complex numbers are viewed as points in the euclidean plane \(\mathbb{r}^{2}\), several of the operations defined in section 2.2 can be directly visualized as if they were operations on vectors.  for the purposes of this chapter, we think of vectors as directed line segments that start at the origin and end at a specified point in the euclidean plane. these line segments may also be moved around in space as long as the direction (which we will call the argument in section 2.3.1 below) and the length (a.k.a.~the modulus) are preserved. as such, the distinction between points in the plane and vectors is merely a matter of convention as long as we at least implicitly think of each vector as having been translated so that it starts at the origin.  as we saw in example 2.2.11 above, the modulus of a complex number can be viewed as the length of the hypotenuse of a certain right triangle. the sum and difference of two vectors can also each be represented geometrically as the lengths of specific diagonals within a particular parallelogram that is formed by copying and appropriately translating the two vectors being combined.  example 2.2.13. we illustrate the sum \((3, 2) + (1, 3) = (4, 5)\) as the main, dashed diagonal of the parallelogram in the left-most figure below.  the difference \((3, 2) - (1, 3) = (2, -1)\) can also be viewed as the shorter diagonal of the same parallelogram, though we would properly need to insist that this shorter diagonal be translated so that it starts at the origin. the latter is illustrated in the right-most figure below.  (https://math.libretexts.org/@api/deki/files/700/screen_shot_2014-01-03_at_12.18.50_pm.png?revision=1)  contributors  isaiah lankham,  (http://www.math.ucdavis.edu/%7eissy/contact_info.html)mathematics department at uc davis (http://www.math.ucdavis.edu/)  bruno nachtergaele,  (http://www.math.ucdavis.edu/%7ebxn/)mathematics department at uc davis (http://www.math.ucdavis.edu/)  anne schilling,  (http://www.math.ucdavis.edu/%7eanne/)mathematics department at uc davis (http://www.math.ucdavis.edu/)  both hardbound and softbound versions of this textbook are available online at worldscientific.com. (http://www.worldscientific.com/worldscibooks/10.1142/9808)",t_6a03b3cc5702,other,0
c_b24afa6d544b,"the last sentence in the previous section may strike you as rather odd, because one sometimes has the impression that quantum mechanics is replete with ad hoc assumptions, peppered as it is with various quantum numbers which can assume only integral values for some mysterious reason that no one can understand. therefore, before moving on to wave mechanics as applied to atomic spectra, it will be useful to remind ourselves of some aspects of the behaviour of waves in a taut, stretched string. by doing this, we may be able to take some of the ""mystery"" out of quantum mechanics, and to see that many of its assumptions are my no means ad hoc, and arise rather naturally from the elementary theory of waves.  we'll start by imagining a long, taut string, which is constrained so that it can vibrate only in a single plane. let us suppose that it suffers a brief disturbance, such as by being struck or plucked. in that case a wave (not necessarily periodic) of the form  \[\psi_1 = f_1 ( x - ct) \label{7.5.1} \]  will travel down the string to the right (positive \(x\)-direction) with speed \(c\) (this is not intended to mean the speed of light - just the speed at which waves are propagated in the string, which depends on its mass per unit length and its tension), and another wave  \[\psi_2 = f_2 (x + ct) \label{7.5.2}\]  will move to the left. the symbol \(\psi\) is just the transverse displacement of the string. it can easily be verified by direct substitution that either of these satisfies a differential equation of the form  \[c^2 \frac{\partial^2 \psi}{\partial x^2} = \frac{\partial^2 \psi}{\partial t^2}. \label{7.5.3}\]  indeed it is also easy to verify that any linear combination such as  \[\psi = a \ f_1 (x-ct) + b \ f_2 ( x +ct) \label{7.5.4}\]  also satisfies the differential equation. since equation \(\ref{7.5.3}\) is a second-order differential equation, there are just two arbitrary constants of integration, and, since there are two arbitrary constants in equation \(\ref{7.5.4}\)., the latter is the most general solution of the different equation. the differential equation is the general differential equation for a wave in one dimension. two points are worth noting. one, there is no minus sign in it. two, if your memory fails you, you can easily determine which side of the equation the \(c^2\) is on by considering the dimensions.  if the function is periodic, it can be represented as the sum of a number (perhaps an infinite number) of sine and cosine terms with frequencies related to each other by rational fractions. even if the function is not periodic, it can still be represented by sine and cosine functions, except that in this case there is a continuous distribution of component frequencies. the distribution of component frequencies is then the fourier transform of the wave profile. (if you are shaky with fourier transforms, do not worry - i promise not to mention them again in this chapter.) because of this, i shall assume all waves to be sinusoidal functions.  let us now assume that the string is fixed at both ends. (until this point i had not mentioned whether the ends of the string were fixed or not, although i had said that the string was taut. i suppose it would be possible for those of mathematical bent to imagine a taut string of infinite length, though my imagination begins to falter after the first few parsecs.) if a sine wave travels down the string, when it reaches the end it reverses its direction, and it does so again at the other end. what happens is that you end up with two waves travelling in opposite directions:  \begin{array}{c c c} \psi &amp; = &amp; a \sin k(x-ct) + a \sin k (x+ct) \\ &amp; = &amp; a \sin (kx-\omega t ) + a \sin (k x + \omega t ). \\ \label{7.5.5} \end{array}  here \(k\) is the propagation constant \(2\pi/\lambda\) and \(\omega\) is the angular frequency \(2\pi \nu\).  by a trigonometric identity this can be written:  \[\psi = 2 a \cos \omega t \sin k x. \label{7.5.6} \]  this is a stationary sin wave (\(\sin kx\)) whose amplitude (\(2a \cos \omega t\)) varies periodically with time. in other words, it is a stationary or standing wave system. notice particularly that a stationary or standing wave system is represented by the product of a function of space and a function of time:  \[ \psi (x,t) = \psi (x) . \chi (t). \label{7.5.7}\]  (these are fixed boundary conditions) the only possible wavelengths are such that there is a node at each fixed end, and consequently there can only be an integral number of antinodes or half wavelengths along the length of the string. if the length of the string is \(l\), the fundamental mode of vibration has a wavelength \(2l\) and a fundamental frequency of \(c/(2l)\). other modes (the higher harmonics) are equal to an integral number of times this fundamental frequency; that is \(nc/(2l)\), where \(n\) is an integer. note that the introduction of this number \(n\), which is restricted to integral values (a ""quantum number"", if you will) is a consequence of the fixed boundary conditions.  because the string is fixed at both ends  which modes are excited and with what relative amplitudes depends upon the initial conditions − that is, on whether the string is plucked (initially \(\psi \neq 0\), \(\dot \psi = 0\)) or struck (initially \(\psi = 0\), \(\dot \psi \neq 0\)), and where it was plucked or struck. it would require some skill and practice (ask any musician) to excite only one vibrational mode, unless you managed to get the initial conditions exactly right, and the general motion is a linear superposition of the normal modes.  i'll mention just one more thing here, which you should recall if you have studied waves at all, namely that the energy of a wave of a given frequency is proportional to the square of its amplitude.  volumes could be written about the vibrations of a stretched string. i would ask the reader to take notice especially of these four points.  a stationary solution is the product of a function of space and a function of time.  restriction to a discrete set of frequencies involving an integral number is a consequence of fixed boundary conditions.  the general motion is a linear combination of the normal modes.  the energy of a wave is proportional to the square of its amplitude.  contributors  jeremy tatum (university of victoria, canada) (http://astrowww.phys.uvic.ca/faculty/tatum/jbt.html)",t_58da7e2b2fb8,other,0
c_66fd067ab892,"sal discusses the exact order of steps in the process of solving the equation 3(x+6)^2=75.  use the cards below to create a list of steps in order that will solve the following equation. 3 times x plus 6 squared is equal to 75. and i encourage you to pause this video now and try to figure it out on your own. figure out which of these steps and in what order you would do to solve for x here. so i'm assuming you've given it a go. so let's try to work through it together. and first, let me just rewrite the equation. so we have 3 times the quantity x plus 6 squared is equal to 75. so what i want to do is i want to isolate the x plus 6 squared on the left-hand side. or another way of thinking about it-- i don't want this 3 here anymore. so how would i get rid of that 3? well, i could divide the left-hand side by 3. but if i do that to only one side of the equation, it won't be equal anymore. these two things in yellow were equal to each other. if i want the equalities to hold, anything that i do to the left-hand side, i have to do the right-hand side. so let me divide that by 3 as well. and so on the left-hand side, i am left with x plus 6 squared is equal to 75 divided by 3. so 75 divided by 3 is 25. so actually, let me just pick out the first one i did. i divided both sides by 3. so that was my first step then. let me write that in a darker color. so that was my first step right over there. now let's think about what we're doing. we're saying that something squared is equal to 25. so this something could be the positive or negative square root of 25. so we could write this as x plus 6 is equal to the plus or minus square root of 25. so i'm essentially taking the positive and negative square root of both sides. so, let's see. this looks like this step. i took the square root of both sides. that's step number two. and so, let me just rewrite this. this is the same thing as x plus 6 is equal to plus or minus 5. and now i want to just have an x on the left-hand side. i want to solve for x. that's the goal from the beginning. so i would like to get rid of this 6. well, the easiest way to do that is to subtract 6 from the left-hand side. but just like before, i can't just do it from one side of an equation. then the equality wouldn't be true. we're literally saying that x plus 6 is equal to plus or minus 5. so x plus 6 minus 6 is going to be equal to plus or minus 5 minus 6. or actually, let me write it this way. so let me subtract 6 from both sides. on the left-hand side, i'm left with an x. and on the right-hand side, i could write it this way. let me do it in that green color. i have negative 6 plus or minus 5. so what are the possible values of x? or actually, i keep forgetting. we don't have to actually give the value for x. we just have to say what steps we did. so then, let's see. after we took the square root of both sides, we then subtracted 6 from both sides. so that was step three right over there. then that got us to essentially the two possible x's that would satisfy this equation right over here. and just for fun, let's actually solve it all the way. so if we solve it all the way, so x is equal to negative 6 plus 5 is negative 1, or x is equal to negative 6 minus 5 is negative 11. and you could verify that both of these work. if you put either of them in here-- if you put negative 1 here, you get negative 1 plus 6 squared is 5 squared. if you put negative 11 here, it's negative 11 plus 6 is negative 5 squared. obviously either plus or minus 5 squared is going to be 25. 25 times 3 is 75. so these are our three steps. we divided both sides by 3. then we took the square root of both sides. then we subtracted 6 from both sides. and then we were essentially done. so let's input those steps. so the first thing we did, we divide both sides by 3. that's the first thing we did. and then we took the square root of both sides. and then we subtracted 6 from both sides. we got it right.",t_3fae22a1000e,other,0
c_fd2e1cca7a1b,"chapter 13 | linear regression and correlation  559  13 | linear regression and correlation  figure 13.1 linear regression and correlation can help you determine if an auto mechanic’s salary is related to his work experience. (credit: joshua rothhaas)  introduction professionals often want to know how two or more numeric variables are related. for example, is there a relationship between the grade on the second math exam a student takes and the grade on the final exam? if there is a relationship, what is the relationship and how strong is it? in another example, your income may be determined by your education, your profession, your years of experience, and your ability, or your gender or color. the amount you pay a repair person for labor is often determined by an initial amount plus an hourly fee. these examples may or may not be tied to a model, meaning that some theory suggested that a relationship exists. this link between a cause and an effect, often referred to as a model, is the foundation of the scientific method and is the core of how we determine what we believe about how the world works. beginning with a theory and developing a model of the theoretical relationship should result in a prediction, what we have called a hypothesis earlier. now the hypothesis concerns a full set of relationships. as an example, in economics the model of consumer choice is based upon assumptions concerning human behavior: a desire to maximize something called utility, knowledge about the benefits of  560  chapter 13 | linear regression and correlation  one product over another, likes and dislikes, referred to generally as preferences, and so on. these combined to give us the demand curve. from that we have the prediction that as prices rise the quantity demanded will fall. economics has models concerning the relationship between what prices are charged for goods and the market structure in which the firm operates, monopoly verse competition, for example. models for who would be most likely to be chosen for an on-the-job training position, the impacts of federal reserve policy changes and the growth of the economy and on and on. models are not unique to economics, even within the social sciences. in political science, for example, there are models that predict behavior of bureaucrats to various changes in circumstances based upon assumptions of the goals of the bureaucrats. there are models of political behavior dealing with strategic decision making both for international relations and domestic politics. the so-called hard sciences are, of course, the source of the scientific method as they tried through the centuries to explain the confusing world around us. some early models today make us laugh; spontaneous generation of life for example. these early models are seen today as not much more than the foundational myths we developed to help us bring some sense of order to what seemed chaos. the foundation of all model building is the perhaps the arrogant statement that we know what caused the result we see. this is embodied in the simple mathematical statement of the functional form that y = f(x). the response, y, is caused by the stimulus, x. every model will eventually come to this final place and it will be here that the theory will live or die. will the data support this hypothesis? if so then fine, we shall believe this version of the world until a better theory comes to replace it. this is the process by which we moved from flat earth to round earth, from earth-center solar system to sun-center solar system, and on and on. the scientific method does not confirm a theory for all time: it does not prove “truth”. all theories are subject to review and may be overturned. these are lessons we learned as we first developed the concept of the hypothesis test earlier in this book. here, as we begin this section, these concepts deserve review because the tool we will develop here is the cornerstone of the scientific method and the stakes are higher. full theories will rise or fall because of this statistical tool; regression and the more advanced versions call econometrics. in this chapter we will begin with correlation, the investigation of relationships among variables that may or may not be founded on a cause and effect model. the variables simply move in the same, or opposite, direction. that is to say, they do not move randomly. correlation provides a measure of the degree to which this is true. from there we develop a tool to measure cause and effect relationships; regression analysis. we will be able to formulate models and tests to determine if they are statistically sound. if they are found to be so, then we can use them to make predictions: if as a matter of policy we changed the value of this variable what would happen to this other variable? if we imposed a gasoline tax of 50 cents per gallon how would that effect the carbon emissions, sales of hummers/hybrids, use of mass transit, etc.? the ability to provide answers to these types of questions is the value of regression as both a tool to help us understand our world and to make thoughtful policy decisions.  13.1 | the correlation coefficient r as we begin this section we note that the type of data we will be working with has changed. perhaps unnoticed, all the data we have been using is for a single variable. it may be from two samples, but it is still a univariate variable. the type of data described in the examples above and for any model of cause and effect is bivariate data — ""bi"" for two variables. in reality, statisticians use multivariate data, meaning many variables. for our work we can classify data into three broad categories, time series data, cross-section data, and panel data. we met the first two very early on. time series data measures a single unit of observation; say a person, or a company or a country, as time passes. what are measured will be at least two characteristics, say the person’s income, the quantity of a particular good they buy and the price they paid. this would be three pieces of information in one time period, say 1985. if we followed that person across time we would have those same pieces of information for 1985,1986, 1987, etc. this would constitute a times series data set. if we did this for 10 years we would have 30 pieces of information concerning this person’s consumption habits of this good for the past decade and we would know their income and the price they paid. a second type of data set is for cross-section data. here the variation is not across time for a single unit of observation, but across units of observation during one point in time. for a particular period of time we would gather the price paid, amount purchased, and income of many individual people. a third type of data set is panel data. here a panel of units of observation is followed across time. if we take our example from above we might follow 500 people, the unit of observation, through time, ten years, and observe their income, price paid and quantity of the good purchased. if we had 500 people and data for ten years for price, income and quantity purchased we would have 15,000 pieces of information. these types of data sets are very expensive to construct and maintain. they do, however, provide a tremendous amount of information that can be used to answer very important  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  561  questions. as an example, what is the effect on the labor force participation rate of women as their family of origin, mother and father, age? or are there differential effects on health outcomes depending upon the age at which a person started smoking? only panel data can give answers to these and related questions because we must follow multiple people across time. the work we do here however will not be fully appropriate for data sets such as these. beginning with a set of data with two independent variables we ask the question: are these related? one way to visually answer this question is to create a scatter plot of the data. we could not do that before when we were doing descriptive statistics because those data were univariate. now we have bivariate data so we can plot in two dimensions. three dimensions are possible on a flat piece of paper, but become very hard to fully conceptualize. of course, more than three dimensions cannot be graphed although the relationships can be measured mathematically. to provide mathematical precision to the measurement of what we see we use the correlation coefficient. the correlation tells us something about the co-movement of two variables, but nothing about why this movement occurred. formally, correlation analysis assumes that both variables being analyzed are independent variables. this means that neither one causes the movement in the other. further, it means that neither variable is dependent on the other, or for that matter, on any other variable. even with these limitations, correlation analysis can yield some interesting results. the correlation coefficient, ρ (pronounced rho), is the mathematical statistic for a population that provides us with a measurement of the strength of a linear relationship between the two variables. for a sample of data, the statistic, r, developed by karl pearson in the early 1900s, is an estimate of the population correlation and is defined mathematically as:  r=  1 n−1  σ ⎛⎝x 1i − x 1⎞⎠⎛⎝x 2i − x 2⎞⎠ s x1 s x2 –  –  or –  r=  –  σ x 1i x 2i − n x 1 − x 2  – 2⎞⎛ – 2⎞ ⎛ σ x 12 i − n x 1 σ x 22 i − n x 2 ⎝ ⎠⎝ ⎠ –  –  where sx1 and sx2 are the standard deviations of the two independent variables x1 and x2, x 1 and x 2 are the sample means of the two variables, and x1i and x2i are the individual observations of x1 and x2. the correlation coefficient r ranges in value from -1 to 1. the second equivalent formula is often used because it may be computationally easier. as scary as these formulas look they are really just the ratio of the covariance between the two variables and the product of their two standard deviations. that is to say, it is a measure of relative variances. in practice all correlation and regression analysis will be provided through computer software designed for these purposes. anything more than perhaps one-half a dozen observations creates immense computational problems. it was because of this fact that correlation, and even more so, regression, were not widely used research tools until after the advent of “computing machines”. now the computing power required to analyze data using regression packages is deemed almost trivial by comparison to just a decade ago. to visualize any linear relationship that may exist review the plot of a scatter diagrams of the standardized data. figure 13.2 presents several scatter diagrams and the calculated value of r. in panels (a) and (b) notice that the data generally trend together, (a) upward and (b) downward. panel (a) is an example of a positive correlation and panel (b) is an example of a negative correlation, or relationship. the sign of the correlation coefficient tells us if the relationship is a positive or negative (inverse) one. if all the values of x1 and x2 are on a straight line the correlation coefficient will be either 1 or -1 depending on whether the line has a positive or negative slope and the closer to one or negative one the stronger the relationship between the two variables. but always remember that the correlation coefficient does not tell us the slope.  562  chapter 13 | linear regression and correlation  figure 13.2  remember, all the correlation coefficient tells us is whether or not the data are linearly related. in panel (d) the variables obviously have some type of very specific relationship to each other, but the correlation coefficient is zero, indicating no linear relationship exists. if you suspect a linear relationship between x1 and x2 then r can measure how strong the linear relationship is. what the value of r tells us: • the value of r is always between –1 and +1: –1 ≤ r ≤ 1. • the size of the correlation r indicates the strength of the linear relationship between x1 and x2. values of r close to –1 or to +1 indicate a stronger linear relationship between x1 and x2. • if r = 0 there is absolutely no linear relationship between x1 and x2 (no linear correlation). • if r = 1, there is perfect positive correlation. if r = –1, there is perfect negative correlation. in both these cases, all of the original data points lie on a straight line: any straight line no matter what the slope. of course, in the real world, this will not generally happen. what the sign of r tells us • a positive value of r means that when x1 increases, x2 tends to increase and when x1 decreases, x2 tends to decrease (positive correlation). • a negative value of r means that when x1 increases, x2 tends to decrease and when x1 decreases, x2 tends to increase (negative correlation).  note strong correlation does not suggest that x1 causes x2 or x2 causes x1. we say ""correlation does not imply causation.""  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  563  13.2 | testing the significance of the correlation coefficient the correlation coefficient, r, tells us about the strength and direction of the linear relationship between x1 and x2. the sample data are used to compute r, the correlation coefficient for the sample. if we had data for the entire population, we could find the population correlation coefficient. but because we have only sample data, we cannot calculate the population correlation coefficient. the sample correlation coefficient, r, is our estimate of the unknown population correlation coefficient. ρ = population correlation coefficient (unknown) r = sample correlation coefficient (known; calculated from sample data) the hypothesis test lets us decide whether the value of the population correlation coefficient ρ is ""close to zero"" or ""significantly different from zero"". we decide this based on the sample correlation coefficient r and the sample size n. if the test concludes that the correlation coefficient is significantly different from zero, we say that the correlation coefficient is ""significant."" • conclusion: there is sufficient evidence to conclude that there is a significant linear relationship between x1 and x2 because the correlation coefficient is significantly different from zero. • what the conclusion means: there is a significant linear relationship x1 and x2. if the test concludes that the correlation coefficient is not significantly different from zero (it is close to zero), we say that correlation coefficient is ""not significant"".  performing the hypothesis test • null hypothesis: h0: ρ = 0 • alternate hypothesis: ha: ρ ≠ 0 what the hypotheses mean in words • null hypothesis h0: the population correlation coefficient is not significantly different from zero. there is not a significant linear relationship (correlation) between x1 and x2 in the population. • alternate hypothesis ha: the population correlation coefficient is significantly different from zero. there is a significant linear relationship (correlation) between x1 and x2 in the population. drawing a conclusion there are two methods of making the decision concerning the hypothesis. the test statistic to test this hypothesis is:  tc =  r  ⎛ 2⎞ ⎝1 − r ⎠  (n − 2)  or tc = r n − 2 1 − r2 where the second formula is an equivalent form of the test statistic, n is the sample size and the degrees of freedom are n-2. this is a t-statistic and operates in the same way as other t tests. calculate the t-value and compare that with the critical value from the t-table at the appropriate degrees of freedom and the level of confidence you wish to maintain. if the calculated value is in the tail then cannot accept the null hypothesis that there is no linear relationship between these two independent random variables. if the calculated t-value is not in the tailed then cannot reject the null hypothesis that there is no linear relationship between the two variables. a quick shorthand way to test correlations is the relationship between the sample size and the correlation. if:  |r| ≥ 2 n then this implies that the correlation between the two variables demonstrates that a linear relationship exists and is statistically significant at approximately the 0.05 level of significance. as the formula indicates, there is an inverse relationship between the sample size and the required correlation for significance of a linear relationship. with only 10 observations, the required correlation for significance is 0.6325, for 30 observations the required correlation for significance  564  chapter 13 | linear regression and correlation  decreases to 0.3651 and at 100 observations the required level is only 0.2000. correlations may be helpful in visualizing the data, but are not appropriately used to ""explain"" a relationship between two variables. perhaps no single statistic is more misused than the correlation coefficient. citing correlations between health conditions and everything from place of residence to eye color have the effect of implying a cause and effect relationship. this simply cannot be accomplished with a correlation coefficient. the correlation coefficient is, of course, innocent of this misinterpretation. it is the duty of the analyst to use a statistic that is designed to test for cause and effect relationships and report only those results if they are intending to make such a claim. the problem is that passing this more rigorous test is difficult so lazy and/or unscrupulous ""researchers"" fall back on correlations when they cannot make their case legitimately.  13.3 | linear equations linear regression for two variables is based on a linear equation with one independent variable. the equation has the form:  y = a + bx where a and b are constant numbers. the variable x is the independent variable, and y is the dependent variable. another way to think about this equation is a statement of cause and effect. the x variable is the cause and the y variable is the hypothesized effect. typically, you choose a value to substitute for the independent variable and then solve for the dependent variable.  example 13.1 the following examples are linear equations.  y = 3 + 2x y = –0.01 + 1.2x the graph of a linear equation of the form y = a + bx is a straight line. any line that is not vertical can be described by this equation.  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  example 13.2 graph the equation y = –1 + 2x.  figure 13.3  13.2 is the following an example of a linear equation? why or why not?  figure 13.4  example 13.3 aaron's word processing service (awps) does word processing. the rate for services is $32 per hour plus a $31.50 one-time charge. the total cost to a customer depends on the number of hours it takes to complete the job. find the equation that expresses the total cost in terms of the number of hours required to complete the job. solution 13.3 let x = the number of hours it takes to get the job done. let y = the total cost to the customer.  565  566  chapter 13 | linear regression and correlation  the $31.50 is a fixed cost. if it takes x hours to complete the job, then (32)(x) is the cost of the word processing only. the total cost is: y = 31.50 + 32x  slope and y-intercept of a linear equation for the linear equation y = a + bx, b = slope and a = y-intercept. from algebra recall that the slope is a number that describes the steepness of a line, and the y-intercept is the y coordinate of the point (0, a) where the line crosses the y-axis. from calculus the slope is the first derivative of the function. for a linear function the slope is dy / dx = b where we can read the mathematical expression as ""the change in y (dy) that results from a change in x (dx) = b * dx"".  figure 13.5 three possible graphs of y = a + bx. (a) if b > 0, the line slopes upward to the right. (b) if b = 0, the line is horizontal. (c) if b < 0, the line slopes downward to the right.  example 13.4 svetlana tutors to make extra money for college. for each tutoring session, she charges a one-time fee of $25 plus $15 per hour of tutoring. a linear equation that expresses the total amount of money svetlana earns for each session she tutors is y = 25 + 15x. what are the independent and dependent variables? what is the y-intercept and what is the slope? interpret them using complete sentences. solution 13.4 the independent variable (x) is the number of hours svetlana tutors each session. the dependent variable (y) is the amount, in dollars, svetlana earns for each session. the y-intercept is 25 (a = 25). at the start of the tutoring session, svetlana charges a one-time fee of $25 (this is when x = 0). the slope is 15 (b = 15). for each session, svetlana earns $15 for each hour she tutors.  13.4 | the regression equation regression analysis is a statistical technique that can test the hypothesis that a variable is dependent upon one or more other variables. further, regression analysis can provide an estimate of the magnitude of the impact of a change in one variable on another. this last feature, of course, is all important in predicting future values. regression analysis is based upon a functional relationship among variables and further, assumes that the relationship is linear. this linearity assumption is required because, for the most part, the theoretical statistical properties of non-linear estimation are not well worked out yet by the mathematicians and econometricians. this presents us with some difficulties in economic analysis because many of our theoretical models are nonlinear. the marginal cost curve, for example, is decidedly nonlinear as is the total cost function, if we are to believe in the effect of specialization of labor and the law of diminishing marginal product. there are techniques for overcoming some of these difficulties, exponential and logarithmic transformation of the data for example, but at the outset we must recognize that standard ordinary least squares (ols) regression analysis will always use a linear function to estimate what might be a nonlinear relationship. the general linear regression model can be stated by the equation:  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  567  y i = β 0 + β 1 x 1i + β 2 x 2i + ⋯ + β k x ki + ε i where β0 is the intercept, βi's are the slope between y and the appropriate xi, and ε (pronounced epsilon), is the error term that captures errors in measurement of y and the effect on y of any variables missing from the equation that would contribute to explaining variations in y. this equation is the theoretical population equation and therefore uses greek letters. the equation we will estimate will have the roman equivalent symbols. this is parallel to how we kept track of the population parameters and sample parameters before. the symbol for the population mean was µ and for the sample mean – x and for the population standard deviation was σ and for the sample standard deviation was s. the equation that will be estimated with a sample of data for two independent variables will thus be:  y i = b 0 + b 1 x 1i + b 2 x 2i + e i as with our earlier work with probability distributions, this model works only if certain assumptions hold. these are that the y is normally distributed, the errors are also normally distributed with a mean of zero and a constant standard deviation, and that the error terms are independent of the size of x and independent of each other.  assumptions of the ordinary least squares regression model each of these assumptions needs a bit more explanation. if one of these assumptions fails to be true, then it will have an effect on the quality of the estimates. some of the failures of these assumptions can be fixed while others result in estimates that quite simply provide no insight into the questions the model is trying to answer or worse, give biased estimates. 1. the independent variables, x i , are all measured without error, and are fixed numbers that are independent of the error term. this assumption is saying in effect that y is deterministic, the result of a fixed component “x” and a random error component “ϵ.” 2. the error term is a random variable with a mean of zero and a constant variance. the meaning of this is that the variances of the independent variables are independent of the value of the variable. consider the relationship between personal income and the quantity of a good purchased as an example of a case where the variance is dependent upon the value of the independent variable, income. it is plausible that as income increases the variation around the amount purchased will also increase simply because of the flexibility provided with higher levels of income. the assumption is for constant variance with respect to the magnitude of the independent variable called homoscedasticity. if the assumption fails, then it is called heteroscedasticity. figure 13.6 shows the case of homoscedasticity where all three distributions have the same variance around the predicted value of y regardless of the magnitude of x. 3. while the independent variables are all fixed values they are from a probability distribution that is normally distributed. this can be seen in figure 13.6 by the shape of the distributions placed on the predicted line at the expected value of the relevant value of y. 4. the independent variables are independent of y, but are also assumed to be independent of the other x variables. the model is designed to estimate the effects of independent variables on some dependent variable in accordance with a proposed theory. the case where some or more of the independent variables are correlated is not unusual. there may be no cause and effect relationship among the independent variables, but nevertheless they move together. take the case of a simple supply curve where quantity supplied is theoretically related to the price of the product and the prices of inputs. there may be multiple inputs that may over time move together from general inflationary pressure. the input prices will therefore violate this assumption of regression analysis. this condition is called multicollinearity, which will be taken up in detail later. 5. the error terms are uncorrelated with each other. this situation arises from an effect on one error term from another error term. while not exclusively a time series problem, it is here that we most often see this case. an x variable in time period one has an effect on the y variable, but this effect then has an effect in the next time period. this effect gives rise to a relationship among the error terms. this case is called autocorrelation, “self-correlated.” the error terms are now not independent of each other, but rather have their own effect on subsequent error terms. figure 13.6 shows the case where the assumptions of the regression model are being satisfied. the estimated line is ^  y = a + bx. three values of x are shown. a normal distribution is placed at each point where x equals the estimated line and the associated error at each value of y. notice that the three distributions are normally distributed around the point on the line, and further, the variation, variance, around the predicted value is constant indicating homoscedasticity from assumption 2. figure 13.6 does not show all the assumptions of the regression model, but it helps visualize these important ones.  568  chapter 13 | linear regression and correlation  figure 13.6  figure 13.7  this is the general form that is most often called the multiple regression model. so-called ""simple"" regression analysis has only one independent (right-hand) variable rather than many independent variables. simple regression is just a special case of multiple regression. there is some value in beginning with simple regression: it is easy to graph in two dimensions, difficult to graph in three dimensions, and impossible to graph in more than three dimensions. consequently, our graphs will be for the simple regression case. figure 13.7 presents the regression problem in the form of a scatter plot graph of the data set where it is hypothesized that y is dependent upon the single independent variable x. a basic relationship from macroeconomic principles is the consumption function. this theoretical relationship states that as a person's income rises, their consumption rises, but by a smaller amount than the rise in income. if y is consumption and x is income in the equation below figure 13.7, the regression problem is, first, to establish that this relationship exists,  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  569  and second, to determine the impact of a change in income on a person's consumption. the parameter β1 was called the marginal propensity to consume in macroeconomics principles. each ""dot"" in figure 13.7 represents the consumption and income of different individuals at some point in time. this was called cross-section data earlier; observations on variables at one point in time across different people or other units of measurement. this analysis is often done with time series data, which would be the consumption and income of one individual or country at different points in time. for macroeconomic problems it is common to use times series aggregated data for a whole country. for this particular theoretical concept these data are readily available in the annual report of the president’s council of economic advisors. the regression problem comes down to determining which straight line would best represent the data in figure 13.8. regression analysis is sometimes called ""least squares"" analysis because the method of determining which line best ""fits"" the data is to minimize the sum of the squared residuals of a line put through the data.  figure 13.8 population equation: c = β0 + β1 income + ε estimated equation: c = b0 + b1 income + e  this figure shows the assumed relationship between consumption and income from macroeconomic theory. here the data are plotted as a scatter plot and an estimated straight line has been drawn. from this graph we can see an error term, e1. each data point also has an error term. again, the error term is put into the equation to capture effects on consumption that are not caused by income changes. such other effects might be a person’s savings or wealth, or periods of unemployment. we will see how by minimizing the sum of these errors we can get an estimate for the slope and intercept of this line. consider the graph below. the notation has returned to that for the more general model rather than the specific case of the macroeconomic consumption function in our example.  570  chapter 13 | linear regression and correlation  figure 13.9 ^  the ŷ is read ""y hat"" and is the estimated value of y. (in figure 13.8 c represents the estimated value of consumption because it is on the estimated line.) it is the value of y obtained using the regression line. ŷ is not generally equal to y from the data. the term y 0 - ŷ 0 = e 0 is called the ""error"" or residual. it is not an error in the sense of a mistake. the error term was put into the estimating equation to capture missing variables and errors in measurement that may have occurred in the dependent variables. the absolute value of a residual measures the vertical distance between the actual value of y and the estimated value of y. in other words, it measures the vertical distance between the actual data point and the predicted point on the line as can be seen on the graph at point x0. if the observed data point lies above the line, the residual is positive, and the line underestimates the actual data value for y. if the observed data point lies below the line, the residual is negative, and the line overestimates that actual data value for y. in the graph, y 0 - ŷ 0 = e 0 is the residual for the point shown. here the point lies above the line and the residual is positive. for each data point the residuals, or errors, are calculated yi – ŷi = ei for i = 1, 2, 3, ..., n where n is the sample size. each |e| is a vertical distance. the sum of the errors squared is the term obviously called sum of squared errors (sse). using calculus, you can determine the straight line that has the parameter values of b0 and b1 that minimizes the sse. when you make the sse a minimum, you have determined the points that are on the line of best fit. it turns out that the line of best fit has the equation:  ŷ = b0 + b1 x –  –  where b 0 = y − b 1 x and b 1 =  –  –  σ ⎛⎝x − x ⎞⎠⎛⎝y − y ⎞⎠ cov(x, y) = – σ (x − x ) 2 sx2 –  –  the sample means of the x values and the y values are x and y , respectively. the best fit line always passes through the –  –  point ( x , y ) called the points of means.  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  571  the slope b can also be written as:  ⎛s y ⎞ b 1 = r y,x ⎝s ⎠ x  where sy = the standard deviation of the y values and sx = the standard deviation of the x values and r is the correlation coefficient between x and y. these equations are called the normal equations and come from another very important mathematical finding called the gauss-markov theorem without which we could not do regression analysis. the gauss-markov theorem tells us that the estimates we get from using the ordinary least squares (ols) regression method will result in estimates that have some very important properties. in the gauss-markov theorem it was proved that a least squares line is blue, which is, best, linear, unbiased, estimator. best is the statistical property that an estimator is the one with the minimum variance. linear refers to the property of the type of line being estimated. an unbiased estimator is one whose estimating function has an expected mean equal to the mean of the population. (you will remember that the expected value of µ –x was equal to the population mean µ in accordance with the central limit theorem. this is exactly the same concept here). both gauss and markov were giants in the field of mathematics, and gauss in physics too, in the 18th century and early 19th century. they barely overlapped chronologically and never in geography, but markov’s work on this theorem was based extensively on the earlier work of carl gauss. the extensive applied value of this theorem had to wait until the middle of this last century. using the ols method we can now find the estimate of the error variance which is the variance of the squared errors, e2. this is sometimes called the standard error of the estimate. (grammatically this is probably best said as the estimate of the error’s variance) the formula for the estimate of the error variance is:  s 2e =  σ (y i − ŷ i ) 2 σ ei2 = n−k n−k  where ŷ is the predicted value of y and y is the observed value, and thus the term ⎛⎝y i − ŷ i⎞⎠ 2 is the squared errors that are to be minimized to find the estimates of the regression line parameters. this is really just the variance of the error terms and follows our regular variance formula. one important note is that here we are dividing by (n - k) , which is the degrees of freedom. the degrees of freedom of a regression equation will be the number of observations, n, reduced by the number of estimated parameters, which includes the intercept as a parameter. the variance of the errors is fundamental in testing hypotheses for a regression. it tells us just how “tight” the dispersion is about the line. as we will see shortly, the greater the dispersion about the line, meaning the larger the variance of the errors, the less probable that the hypothesized independent variable will be found to have a significant effect on the dependent variable. in short, the theory being tested will more likely fail if the variance of the error term is high. upon reflection this should not be a surprise. as we tested hypotheses about a mean we observed that large variances reduced the calculated test statistic and thus it failed to reach the tail of the distribution. in those cases, the null hypotheses could not be rejected. if we cannot reject the null hypothesis in a regression problem, we must conclude that the hypothesized independent variable has no effect on the dependent variable. a way to visualize this concept is to draw two scatter plots of x and y data along a predetermined line. the first will have little variance of the errors, meaning that all the data points will move close to the line. now do the same except the data points will have a large estimate of the error variance, meaning that the data points are scattered widely along the line. clearly the confidence about a relationship between x and y is effected by this difference between the estimate of the error variance.  testing the parameters of the line the whole goal of the regression analysis was to test the hypothesis that the dependent variable, y, was in fact dependent upon the values of the independent variables as asserted by some foundation theory, such as the consumption function example. looking at the estimated equation under figure 13.8, we see that this amounts to determining the values of b0 and b1. notice that again we are using the convention of greek letters for the population parameters and roman letters for their estimates. the regression analysis output provided by the computer software will produce an estimate of b0 and b1, and any other b's for other independent variables that were included in the estimated equation. the issue is how good are these estimates? in order to test a hypothesis concerning any estimate, we have found that we need to know the underlying sampling distribution. it should come as no surprise at his stage in the course that the answer is going to be the normal distribution. this can be seen by remembering the assumption that the error term in the population, ε, is normally distributed. if the error  572  chapter 13 | linear regression and correlation  term is normally distributed and the variance of the estimates of the equation parameters, b0 and b1, are determined by the variance of the error term, it follows that the variances of the parameter estimates are also normally distributed. and indeed this is just the case. we can see this by the creation of the test statistic for the test of hypothesis for the slope parameter, β1 in our consumption function equation. to test whether or not y does indeed depend upon x, or in our example, that consumption depends upon income, we need only test the hypothesis that β1 equals zero. this hypothesis would be stated formally as:  h0 : β1 = 0 ha : β1 ≠ 0 if we cannot reject the null hypothesis, we must conclude that our theory has no validity. if we cannot reject the null hypothesis that β1 = 0 then b1, the coefficient of income, is zero and zero times anything is zero. therefore the effect of income on consumption is zero. there is no relationship as our theory had suggested. notice that we have set up the presumption, the null hypothesis, as ""no relationship"". this puts the burden of proof on the alternative hypothesis. in other words, if we are to validate our claim of finding a relationship, we must do so with a level of significance greater than 90, 95, or 99 percent. the status quo is ignorance, no relationship exists, and to be able to make the claim that we have actually added to our body of knowledge we must do so with significant probability of being correct. john maynard keynes got it right and thus was born keynesian economics starting with this basic concept in 1936. the test statistic for this test comes directly from our old friend the standardizing formula:  tc =  b1 − β1 sb 1  where b1 is the estimated value of the slope of the regression line, β1 is the hypothesized value of beta, in this case zero, and s b is the standard deviation of the estimate of b1. in this case we are asking how many standard deviations is the estimated 1  slope away from the hypothesized slope. this is exactly the same question we asked before with respect to a hypothesis about a mean: how many standard deviations is the estimated mean, the sample mean, from the hypothesized mean? the test statistic is written as a student's t distribution, but if the sample size is larger enough so that the degrees of freedom are greater than 30 we may again use the normal distribution. to see why we can use the student's t or normal distribution we have only to look at s b ,the formula for the standard deviation of the estimate of b1: 1  sb = 1  ⎛ ⎝  s e2  –  x i − x⎞⎠ 2  or  sb = 1  s e2 ⎛ ⎞ 2 ⎝n − 1⎠s x  where se is the estimate of the error variance and s2x is the variance of x values of the coefficient of the independent variable being tested. we see that se, the estimate of the error variance, is part of the computation. because the estimate of the error variance is based on the assumption of normality of the error terms, we can conclude that the sampling distribution of the b's, the coefficients of our hypothesized regression line, are also normally distributed. one last note concerns the degrees of freedom of the test statistic, ν=n-k. previously we subtracted 1 from the sample size to determine the degrees of freedom in a student's t problem. here we must subtract one degree of freedom for each parameter estimated in the equation. for the example of the consumption function we lose 2 degrees of freedom, one for b 0 , the intercept, and one for b1, the slope of the consumption function. the degrees of freedom would be n - k - 1, where k is the number of independent variables and the extra one is lost because of the intercept. if we were estimating an equation with three independent variables, we would lose 4 degrees of freedom: three for the independent variables, k, and one more for the intercept. the decision rule for acceptance or rejection of the null hypothesis follows exactly the same form as in all our previous test of hypothesis. namely, if the calculated value of t (or z) falls into the tails of the distribution, where the tails are defined by α ,the required significance level in the test, we cannot accept the null hypothesis. if on the other hand, the calculated value of the test statistic is within the critical region, we cannot reject the null hypothesis.  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  573  if we conclude that we cannot accept the null hypothesis, we are able to state with (1 - α) level of confidence that the slope of the line is given by b1. this is an extremely important conclusion. regression analysis not only allows us to test if a cause and effect relationship exists, we can also determine the magnitude of that relationship, if one is found to exist. it is this feature of regression analysis that makes it so valuable. if models can be developed that have statistical validity, we are then able to simulate the effects of changes in variables that may be under our control with some degree of probability , of course. for example, if advertising is demonstrated to effect sales, we can determine the effects of changing the advertising budget and decide if the increased sales are worth the added expense.  multicollinearity our discussion earlier indicated that like all statistical models, the ols regression model has important assumptions attached. each assumption, if violated, has an effect on the ability of the model to provide useful and meaningful estimates. the gauss-markov theorem has assured us that the ols estimates are unbiased and minimum variance, but this is true only under the assumptions of the model. here we will look at the effects on ols estimates if the independent variables are correlated. the other assumptions and the methods to mitigate the difficulties they pose if they are found to be violated are examined in econometrics courses. we take up multicollinearity because it is so often prevalent in economic models and it often leads to frustrating results. the ols model assumes that all the independent variables are independent of each other. this assumption is easy to test for a particular sample of data with simple correlation coefficients. correlation, like much in statistics, is a matter of degree: a little is not good, and a lot is terrible. the goal of the regression technique is to tease out the independent impacts of each of a set of independent variables on some hypothesized dependent variable. if two 2 independent variables are interrelated, that is, correlated, then we cannot isolate the effects on y of one from the other. in an extreme case where x 1 is a linear combination of x 2 , correlation equal to one, both variables move in identical ways with y. in this case it is impossible to determine the variable that is the true cause of the effect on y. (if the two variables were actually perfectly correlated, then mathematically no regression results could actually be calculated.) the normal equations for the coefficients show the effects of multicollinearity on the coefficients.  b1 =  b2 =  s y⎛⎝r x 1 y - r x 1 x 2 r x 2 y⎞⎠ s x 1⎛⎝1 - r 2x 1 x 2⎞⎠  s y⎛⎝r x 2 y - r x 1 x 2 r x 1 y⎞⎠ -  s x 2⎛⎝1 - r 2x 1 x 2⎞⎠ -  -  b0 = y - b1 x 1 - b2 x 2 the correlation between x 1 and x 2 , r x2 x , appears in the denominator of both the estimating formula for b 1 and b 2 1 2 . if the assumption of independence holds, then this term is zero. this indicates that there is no effect of the correlation on the coefficient. on the other hand, as the correlation between the two independent variables increases the denominator decreases, and thus the estimate of the coefficient increases. the correlation has the same effect on both of the coefficients of these two variables. in essence, each variable is “taking” part of the effect on y that should be attributed to the collinear variable. this results in biased estimates. multicollinearity has a further deleterious impact on the ols estimates. the correlation between the two independent variables also shows up in the formulas for the estimate of the variance for the coefficients.  s 2b =  s 2e ⎛ ⎞ 2 ⎛ ⎞ 2 ⎝n - 1⎠s x 1⎝1 - r x 1 x 2⎠  s 2b =  s 2e ⎛ ⎞ 2 ⎛ ⎞ 2 ⎝n - 1⎠s x 2⎝1 - r x 1 x 2⎠  1  2  here again we see the correlation between x 1 and x 2 in the denominator of the estimates of the variance for the coefficients for both variables. if the correlation is zero as assumed in the regression model, then the formula collapses to the familiar ratio of the variance of the errors to the variance of the relevant independent variable. if however the two independent variables are correlated, then the variance of the estimate of the coefficient increases. this results in a smaller t-value for the test of hypothesis of the coefficient. in short, multicollinearity results in failing to reject the null hypothesis  574  chapter 13 | linear regression and correlation  that the x variable has no impact on y when in fact x does have a statistically significant impact on y. said another way, the large standard errors of the estimated coefficient created by multicollinearity suggest statistical insignificance even when the hypothesized relationship is strong.  how good is the equation? in the last section we concerned ourselves with testing the hypothesis that the dependent variable did indeed depend upon the hypothesized independent variable or variables. it may be that we find an independent variable that has some effect on the dependent variable, but it may not be the only one, and it may not even be the most important one. remember that the error term was placed in the model to capture the effects of any missing independent variables. it follows that the error term may be used to give a measure of the ""goodness of fit"" of the equation taken as a whole in explaining the variation of the dependent variable, y. the multiple correlation coefficient, also called the coefficient of multiple determination or the coefficient of determination, is given by the formula:  r 2 = ssr sst where ssr is the regression sum of squares, the squared deviation of the predicted value of y from the mean value of y –⎞ ⎛ ⎝ŷ − y ⎠ , and sst is the total sum of squares which is the total squared deviation of the dependent variable, y, from its mean value, including the error term, sse, the sum of squared errors. figure 13.10 shows how the total deviation of the dependent variable, y, is partitioned into these two pieces.  figure 13.10  figure 13.10 shows the estimated regression line and a single observation, x1. regression analysis tries to explain the variation of the data about the mean value of the dependent variable, y. the question is, why do the observations of y vary – from the average level of y? the value of y at observation x1 varies from the mean of y by the difference ( y i − y ). the sum of these differences squared is sst, the sum of squares total. the actual value of y at x1 deviates from the estimated value, ŷ, by the difference between the estimated value and the actual value, ( y i − ŷ ). we recall that this is the error term, e, and the sum of these errors is sse, sum of squared errors. the deviation of the predicted value of y, ŷ, from the mean value – of y is ( ŷ − y ) and is the ssr, sum of squares regression. it is called “regression” because it is the deviation explained  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  575  by the regression. (sometimes the ssr is called ssm for sum of squares mean because it measures the deviation from the mean value of the dependent variable, y, as shown on the graph.). because the sst = ssr + sse we see that the multiple correlation coefficient is the percent of the variance, or deviation in y from its mean value, that is explained by the equation when taken as a whole. r2 will vary between zero and 1, with zero indicating that none of the variation in y was explained by the equation and a value of 1 indicating that 100% of the variation in y was explained by the equation. for time series studies expect a high r2 and for cross-section data expect low r2. while a high r2 is desirable, remember that it is the tests of the hypothesis concerning the existence of a relationship between a set of independent variables and a particular dependent variable that was the motivating factor in using the regression model. it is validating a cause and effect relationship developed by some theory that is the true reason that we chose the regression analysis. increasing the number of independent variables will have the effect of increasing r2. to – account for this effect the proper measure of the coefficient of determination is the r 2 , adjusted for degrees of freedom, to keep down mindless addition of independent variables. there is no statistical test for the r2 and thus little can be said about the model using r2 with our characteristic confidence level. two models that have the same size of sse, that is sum of squared errors, may have very different r2 if the competing models have different sst, total sum of squared deviations. the goodness of fit of the two models is the same; they both have the same sum of squares unexplained, errors squared, but because of the larger total sum of squares on one of the models the r2 differs. again, the real value of regression as a tool is to examine hypotheses developed from a model that predicts certain relationships among the variables. these are tests of hypotheses on the coefficients of the model and not a game of maximizing r2. another way to test the general quality of the overall model is to test the coefficients as a group rather than independently. because this is multiple regression (more than one x), we use the f-test to determine if our coefficients collectively affect y. the hypothesis is:  ho : β1 = β2 = … = βi = 0 h a : ""at least one of the βi is not equal to 0"" if the null hypothesis cannot be rejected, then we conclude that none of the independent variables contribute to explaining the variation in y. reviewing figure 13.10 we see that ssr, the explained sum of squares, is a measure of just how much of the variation in y is explained by all the variables in the model. sse, the sum of the errors squared, measures just how much is unexplained. it follows that the ratio of these two can provide us with a statistical test of the model as a whole. remembering that the f distribution is a ratio of chi squared distributions and that variances are distributed according to chi squared, and the sum of squared errors and the sum of squares are both variances, we have the test statistic for this hypothesis as:  fc =  ⎛ ssr ⎞ ⎝ k ⎠  ⎛ sse ⎞ ⎝n − k − 1 ⎠  where n is the number of observations and k is the number of independent variables. it can be shown that this is equivalent to: 2 fc = n − k − 1 * r 2 k 1−r  building from figure 13.10 where r2 is the coefficient of determination which is also a measure of the “goodness” of the model. as with all our tests of hypothesis, we reach a conclusion by comparing the calculated f statistic with the critical value given our desired level of confidence. if the calculated test statistic, an f statistic in this case, is in the tail of the distribution, then we cannot accept the null hypothesis. by not being able to accept the null hypotheses we conclude that this specification of this model has validity, because at least one of the estimated coefficients is significantly different from zero. an alternative way to reach this conclusion is to use the p-value comparison rule. the p-value is the area in the tail, given the calculated f statistic. in essence, the computer is finding the f value in the table for us. the computer regression output for the calculated f statistic is typically found in the anova table section labeled “significance f"". how to read the output of an excel regression is presented below. this is the probability of not accepting a false null hypothesis. if this probability  576  chapter 13 | linear regression and correlation  is less than our pre-determined alpha error, then the conclusion is that we cannot accept the null hypothesis.  dummy variables thus far the analysis of the ols regression technique assumed that the independent variables in the models tested were continuous random variables. there are, however, no restrictions in the regression model against independent variables that are binary. this opens the regression model for testing hypotheses concerning categorical variables such as gender, race, region of the country, before a certain data, after a certain date and innumerable others. these categorical variables take on only two values, 1 and 0, success or failure, from the binomial probability distribution. the form of the equation becomes:  ŷ = b0 + b2 x2 + b1 x1  figure 13.11  where x 2 = 0, 1 . x2 is the dummy variable and x1 is some continuous random variable. the constant, b0, is the yintercept, the value where the line crosses the y-axis. when the value of x2 = 0, the estimated line crosses at b0. when the value of x2 = 1 then the estimated line crosses at b0 + b2. in effect the dummy variable causes the estimated line to shift either up or down by the size of the effect of the characteristic captured by the dummy variable. note that this is a simple parallel shift and does not affect the impact of the other independent variable; x1.this variable is a continuous random variable and predicts different values of y at different values of x1 holding constant the condition of the dummy variable. an example of the use of a dummy variable is the work estimating the impact of gender on salaries. there is a full body of literature on this topic and dummy variables are used extensively. for this example the salaries of elementary and secondary school teachers for a particular state is examined. using a homogeneous job category, school teachers, and for a single state reduces many of the variations that naturally effect salaries such as differential physical risk, cost of living in a particular state, and other working conditions. the estimating equation in its simplest form specifies salary as a function of various teacher characteristic that economic theory would suggest could affect salary. these would include education level as a measure of potential productivity, age and/or experience to capture on-the-job training, again as a measure of productivity. because the data are for school teachers employed in a public school districts rather than workers in a for-profit company, the school district’s average revenue per average daily student attendance is included as a measure of ability to pay. the results of the regression analysis using data on 24,916 school teachers are presented below.  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  577  standard errors of the estimates for teacher's earnings function (sb)  variable  regression coefficients (b)  intercept  4269.9  gender (male = 1)  632.38  13.39  total years of experience  52.32  1.10  years of experience in current district  29.97  1.52  education  629.33  13.16  total revenue per ada  90.24  3.76  –2  r n  .725 24,916  table 13.1 earnings estimate for elementary and secondary school teachers  the coefficients for all the independent variables are significantly different from zero as indicated by the standard errors. dividing the standard errors of each coefficient results in a t-value greater than 1.96 which is the required level for 95% significance. the binary variable, our dummy variable of interest in this analysis, is gender where male is given a value of 1 and female given a value of 0. the coefficient is significantly different from zero with a dramatic t-statistic of 47 standard deviations. we thus cannot accept the null hypothesis that the coefficient is equal to zero. therefore we conclude that there is a premium paid male teachers of $632 after holding constant experience, education and the wealth of the school district in which the teacher is employed. it is important to note that these data are from some time ago and the $632 represents a six percent salary premium at that time. a graph of this example of dummy variables is presented below.  figure 13.12  578  chapter 13 | linear regression and correlation  in two dimensions, salary is the dependent variable on the vertical axis and total years of experience was chosen for the continuous independent variable on horizontal axis. any of the other independent variables could have been chosen to illustrate the effect of the dummy variable. the relationship between total years of experience has a slope of $52.32 per year of experience and the estimated line has an intercept of $4,269 if the gender variable is equal to zero, for female. if the gender variable is equal to 1, for male, the coefficient for the gender variable is added to the intercept and thus the relationship between total years of experience and salary is shifted upward parallel as indicated on the graph. also marked on the graph are various points for reference. a female school teacher with 10 years of experience receives a salary of $4,792 on the basis of her experience only, but this is still $109 less than a male teacher with zero years of experience. a more complex interaction between a dummy variable and the dependent variable can also be estimated. it may be that the dummy variable has more than a simple shift effect on the dependent variable, but also interacts with one or more of the other continuous independent variables. while not tested in the example above, it could be hypothesized that the impact of gender on salary was not a one-time shift, but impacted the value of additional years of experience on salary also. that is, female school teacher’s salaries were discounted at the start, and further did not grow at the same rate from the effect of experience as for male school teachers. this would show up as a different slope for the relationship between total years of experience for males than for females. if this is so then females school teachers would not just start behind their male colleagues (as measured by the shift in the estimated regression line), but would fall further and further behind as time and experienced increased. the graph below shows how this hypothesis can be tested with the use of dummy variables and an interaction variable.  figure 13.13  the estimating equation shows how the slope of x1, the continuous random variable experience, contains two parts, b1 and b3. this occurs because of the new variable x2 x1, called the interaction variable, was created to allow for an effect on the slope of x1 from changes in x2, the binary dummy variable. note that when the dummy variable, x2 = 0 the interaction variable has a value of 0, but when x2 = 1 the interaction variable has a value of x1. the coefficient b3 is an estimate of the difference in the coefficient of x1 when x2 = 1 compared to when x2 = 0. in the example of teacher’s salaries, if there is a premium paid to male teachers that affects the rate of increase in salaries from experience, then the rate at which male teachers’ salaries rises would be b1 + b3 and the rate at which female teachers’ salaries rise would be simply b1. this hypothesis can be tested with the hypothesis:  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  579  h 0 : β 3 = 0| β 1 = 0, β 2 = 0 h a : β 3 ≠ 0| β 1 ≠ 0, β 2 ≠ 0 this is a t-test using the test statistic for the parameter β3. if we cannot accept the null hypothesis that β3=0 we conclude there is a difference between the rate of increase for the group for whom the value of the binary variable is set to 1, males in this example. this estimating equation can be combined with our earlier one that tested only a parallel shift in the estimated line. the earnings/experience functions in figure 13.13 are drawn for this case with a shift in the earnings function and a difference in the slope of the function with respect to total years of experience.  example 13.5 a random sample of 11 statistics students produced the following data, where x is the third exam score out of 80, and y is the final exam score out of 200. can you predict the final exam score of a randomly selected student if you know the third exam score?  x (third exam score)  y (final exam score)  65  175  67  133  71  185  71  163  66  126  75  198  67  153  70  163  71  159  69  151  69  159  table 13.2  (b) scatter plot showing the scores on the final exam based on scores from the third exam.  (a) table showing the scores on the final exam based on scores from the third exam. figure 13.14  13.5 | interpretation of regression coefficients: elasticity and logarithmic transformation as we have seen, the coefficient of an equation estimated using ols regression analysis provides an estimate of the slope of a straight line that is assumed be the relationship between the dependent variable and at least one independent variable. from the calculus, the slope of the line is the first derivative and tells us the magnitude of the impact of a one unit change in the x variable upon the value of the y variable measured in the units of the y variable. as we saw in the case of dummy variables, this can show up as a parallel shift in the estimated line or even a change in the slope of the line through an interactive variable. here we wish to explore the concept of elasticity and how we can use a regression analysis to estimate the various elasticities in which economists have an interest. the concept of elasticity is borrowed from engineering and physics where it is used to measure a material’s responsiveness  580  chapter 13 | linear regression and correlation  to a force, typically a physical force such as a stretching/pulling force. it is from here that we get the term an “elastic” band. in economics, the force in question is some market force such as a change in price or income. elasticity is measured as a percentage change/response in both engineering applications and in economics. the value of measuring in percentage terms is that the units of measurement do not play a role in the value of the measurement and thus allows direct comparison between elasticities. as an example, if the price of gasoline increased say 50 cents from an initial price of $3.00 and generated a decline in monthly consumption for a consumer from 50 gallons to 48 gallons we calculate the elasticity to be 0.25. the price elasticity is the percentage change in quantity resulting from some percentage change in price. a 16 percent increase in price has generated only a 4 percent decrease in demand: 16% price change → 4% quantity change or .04/.16 = .25. this is called an inelastic demand meaning a small response to the price change. this comes about because there are few if any real substitutes for gasoline; perhaps public transportation, a bicycle or walking. technically, of course, the percentage change in demand from a price increase is a decline in demand thus price elasticity is a negative number. the common convention, however, is to talk about elasticity as the absolute value of the number. some goods have many substitutes: pears for apples for plums, for grapes, etc. etc. the elasticity for such goods is larger than one and are called elastic in demand. here a small percentage change in price will induce a large percentage change in quantity demanded. the consumer will easily shift the demand to the close substitute. while this discussion has been about price changes, any of the independent variables in a demand equation will have an associated elasticity. thus, there is an income elasticity that measures the sensitivity of demand to changes in income: not much for the demand for food, but very sensitive for yachts. if the demand equation contains a term for substitute goods, say candy bars in a demand equation for cookies, then the responsiveness of demand for cookies from changes in prices of candy bars can be measured. this is called the cross-price elasticity of demand and to an extent can be thought of as brand loyalty from a marketing view. how responsive is the demand for coca-cola to changes in the price of pepsi? now imagine the demand for a product that is very expensive. again, the measure of elasticity is in percentage terms thus the elasticity can be directly compared to that for gasoline: an elasticity of 0.25 for gasoline conveys the same information as an elasticity of 0.25 for $25,000 car. both goods are considered by the consumer to have few substitutes and thus have inelastic demand curves, elasticities less than one. the mathematical formulae for various elasticities are:  price elasticity:η p =  ⎛ ⎝  %∆q⎞⎠ (%∆p)  where η is the greek small case letter eta used to designate elasticity. ∆ is read as “change”.  income elasticity: η y =  ⎛ ⎝  %∆q⎞⎠ (%∆y)  where y is used as the symbol for income.  cross-price elasticity:η p1 =  ⎛ ⎝ ⎛ ⎝  %∆q 1⎞⎠ %∆p 2⎞⎠  where p2 is the price of the substitute good. examining closer the price elasticity we can write the formula as:  ηp =  ⎛ ⎞ %∆q⎞⎠ dq ⎛ p ⎞ = = b⎝ p ⎠ q (%∆p) dp ⎝q ⎠ ⎛ ⎝  where b is the estimated coefficient for price in the ols regression. the first form of the equation demonstrates the principle that elasticities are measured in percentage terms. of course, the ordinary least squares coefficients provide an estimate of the impact of a unit change in the independent variable, x, on the dependent variable measured in units of y. these coefficients are not elasticities, however, and are shown in the second way ⎛dq ⎞ of writing the formula for elasticity as ⎝ ⎠ , the derivative of the estimated demand function which is simply the slope of dp the regression line. multiplying the slope times p provides an elasticity measured in percentage terms.  q  along a straight-line demand curve the percentage change, thus elasticity, changes continuously as the scale changes, while the slope, the estimated regression coefficient, remains constant. going back to the demand for gasoline. a change in price from $3.00 to $3.50 was a 16 percent increase in price. if the beginning price were $5.00 then the same 50¢ increase would be only a 10 percent increase generating a different elasticity. every straight-line demand curve has a range of elasticities starting at the top left, high prices, with large elasticity numbers, elastic demand, and decreasing as one goes down the  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  581  demand curve, inelastic demand. in order to provide a meaningful estimate of the elasticity of demand the convention is to estimate the elasticity at the point of means. remember that all ols regression lines will go through the point of means. at this point is the greatest weight of the data used to estimate the coefficient. the formula to estimate an elasticity when an ols demand curve has been estimated becomes: ⎛−⎞  η p = b⎜ p −⎟ ⎝q ⎠ −  −  where p and q are the mean values of these data used to estimate b , the price coefficient. the same method can be used to estimate the other elasticities for the demand function by using the appropriate mean values of the other variables; income and price of substitute goods for example.  logarithmic transformation of the data ordinary least squares estimates typically assume that the population relationship among the variables is linear thus of the form presented in the regression equation. in this form the interpretation of the coefficients is as discussed above; quite simply the coefficient provides an estimate of the impact of a one unit change in x on y measured in units of y. it does not matter just where along the line one wishes to make the measurement because it is a straight line with a constant slope thus constant estimated level of impact per unit change. it may be, however, that the analyst wishes to estimate not the simple unit measured impact on the y variable, but the magnitude of the percentage impact on y of a one unit change in the x variable. such a case might be how a unit change in experience, say one year, effects not the absolute amount of a worker’s wage, but the percentage impact on the worker’s wage. alternatively, it may be that the question asked is the unit measured impact on y of a specific percentage increase in x. an example may be “by how many dollars will sales increase if the firm spends x percent more on advertising?” the third possibility is the case of elasticity discussed above. here we are interested in the percentage impact on quantity demanded for a given percentage change in price, or income or perhaps the price of a substitute good. all three of these cases can be estimated by transforming the data to logarithms before running the regression. the resulting coefficients will then provide a percentage change measurement of the relevant variable. to summarize, there are four cases: 1. unit ∆x → unit ∆y (standard ols case) 2. unit ∆x → %∆y 3. %∆x → unit ∆y 4. %∆x → %∆y (elasticity case) case 1: the ordinary least squares case begins with the linear model developed above:  y = a + bx where the coefficient of the independent variable b = dy is the slope of a straight line and thus measures the impact of a  dx  unit change in x on y measured in units of y. case 2: the underlying estimated equation is:  log⎛⎝y⎞⎠ = a + bx the equation is estimated by converting the y values to logarithms and using ols techniques to estimate the coefficient of the x variable, b. this is called a semi-log estimation. again, differentiating both sides of the equation allows us to develop the interpretation of the x coefficient b:  d⎛⎝log y⎞⎠ = bdx dy = bdx y  multiply by 100 to covert to percentages and rearranging terms gives:  100b = %∆y unit ∆x 100b is thus the percentage change in y resulting from a unit change in x.  582  chapter 13 | linear regression and correlation  case 3: in this case the question is “what is the unit change in y resulting from a percentage change in x?” what is the dollar loss in revenues of a five percent increase in price or what is the total dollar cost impact of a five percent increase in labor costs? the estimated equation for this case would be:  y = a + blog⎛⎝x ⎞⎠ here the calculus differential of the estimated equation is:  dy = bd⎛⎝logx ⎞⎠ dy = b dx x divide by 100 to get percentage and rearranging terms gives:  b = dy = unit ∆y 100 100 dx %∆x x therefore,  b is the increase in y measured in units from a one percent increase in x. 100  case 4: this is the elasticity case where both the dependent and independent variables are converted to logs before the ols estimation. this is known as the log-log case or double log case, and provides us with direct estimates of the elasticities of the independent variables. the estimated equation is:  logy = a + blogx differentiating we have:  d⎛⎝logy ⎞⎠ = bd⎛⎝logx ⎞⎠ d⎛⎝logx ⎞⎠ = b 1 dx x thus:  1 dy = b 1 dx y x  or  dy = b dx y x  ⎛ ⎞ or b = dy ⎝ x ⎠ dx y  and b = %∆y our definition of elasticity. we conclude that we can directly estimate the elasticity of a variable through  %∆x  double log transformation of the data. the estimated coefficient is the elasticity. it is common to use double log transformation of all variables in the estimation of demand functions to get estimates of all the various elasticities of the demand curve.  13.6 | predicting with a regression equation one important value of an estimated regression equation is its ability to predict the effects on y of a change in one or more values of the independent variables. the value of this is obvious. careful policy cannot be made without estimates of the effects that may result. indeed, it is the desire for particular results that drive the formation of most policy. regression models can be, and have been, invaluable aids in forming such policies. the gauss-markov theorem assures us that the point estimate of the impact on the dependent variable derived by putting in the equation the hypothetical values of the independent variables one wishes to simulate will result in an estimate of the dependent variable which is minimum variance and unbiased. that is to say that from this equation comes the best unbiased point estimate of y given the values of x.  ŷ = b 0 + b, x 1i + ⋯ + b k x ki remember that point estimates do not carry a particular level of probability, or level of confidence, because points have no “width” above which there is an area to measure. this was why we developed confidence intervals for the mean and proportion earlier. the same concern arises here also. there are actually two different approaches to the issue of developing estimates of changes in the independent variable, or variables, on the dependent variable. the first approach wishes to measure the expected mean value of y from a specific change in the value of x: this specific value implies the expected value. here the question is: what is the mean impact on y that would result from multiple hypothetical experiments on y at this specific value of x. remember that there is a variance around the estimated parameter of x and thus each experiment will result in a bit of a different estimate of the predicted value of y.  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  583  the second approach to estimate the effect of a specific value of x on y treats the event as a single experiment: you choose x and multiply it times the coefficient and that provides a single estimate of y. because this approach acts as if there were a single experiment the variance that exists in the parameter estimate is larger than the variance associated with the expected value approach. the conclusion is that we have two different ways to predict the effect of values of the independent variable(s) on the dependent variable and thus we have two different intervals. both are correct answers to the question being asked, but there are two different questions. to avoid confusion, the first case where we are asking for the expected value of the mean of the estimated y, is called a confidence interval as we have named this concept before. the second case, where we are asking for the estimate of the impact on the dependent variable y of a single experiment using a value of x, is called the prediction interval. the test statistics for these two interval measures within which the estimated value of y will fall are: confidence interval for expected value of mean value of y for x=xp ⎛ ⎞2 ⎞ ⎛ ⎝x p - x ⎠ ŷ = ± t α s e⎜ 1n + sx ⎟ 2  –  ⎝  ⎠  prediction interval for an individual y for x = xp  ⎛  ŷ = ± t α s e⎜ 1 + 1n + 2  ⎝  x p - x ⎞⎠ 2 ⎞ sx ⎟  ⎛ ⎝  –  ⎠  where se is the standard deviation of the error term and sx is the standard deviation of the x variable. the mathematical computations of these two test statistics are complex. various computer regression software packages provide programs within the regression functions to provide answers to inquires of estimated predicted values of y given various values chosen for the x variable(s). it is important to know just which interval is being tested in the computer package because the difference in the size of the standard deviations will change the size of the interval estimated. this is shown in figure 13.15.  figure 13.15 prediction and confidence intervals for regression equation; 95% confidence level.  figure 13.15 shows visually the difference the standard deviation makes in the size of the estimated intervals. the confidence interval, measuring the expected value of the dependent variable, is smaller than the prediction interval for the same level of confidence. the expected value method assumes that the experiment is conducted multiple times rather than just once as in the other method. the logic here is similar, although not identical, to that discussed when developing the relationship between the sample size and the confidence interval using the central limit theorem. there, as the number of experiments increased, the distribution narrowed and the confidence interval became tighter around the expected value of the mean. it is also important to note that the intervals around a point estimate are highly dependent upon the range of data used to  584  chapter 13 | linear regression and correlation  estimate the equation regardless of which approach is being used for prediction. remember that all regression equations go through the point of means, that is, the mean value of y and the mean values of all independent variables in the equation. as the value of x chosen to estimate the associated value of y is further from the point of means the width of the estimated interval around the point estimate increases. choosing values of x beyond the range of the data used to estimate the equation possess even greater danger of creating estimates with little use; very large intervals, and risk of error. figure 13.16 shows this relationship.  figure 13.16 confidence interval for an individual value of x, xp, at 95% level of confidence  figure 13.16 demonstrates the concern for the quality of the estimated interval whether it is a prediction interval or a – confidence interval. as the value chosen to predict y, xp in the graph, is further from the central weight of the data, x , we see the interval expand in width even while holding constant the level of confidence. this shows that the precision of any estimate will diminish as one tries to predict beyond the largest weight of the data and most certainly will degrade rapidly for predictions beyond the range of the data. unfortunately, this is just where most predictions are desired. they can be made, but the width of the confidence interval may be so large as to render the prediction useless. only actual calculation and the particular application can determine this, however.  example 13.6 recall the third exam/final exam example . we found the equation of the best-fit line for the final exam grade as a function of the grade on the third-exam. we can now use the least-squares regression line for prediction. assume the coefficient for x was determined to be significantly different from zero. suppose you want to estimate, or predict, the mean final exam score of statistics students who received 73 on the third exam. the exam scores (x-values) range from 65 to 75. since 73 is between the x-values 65 and 75, we feel comfortable to substitute x = 73 into the equation. then:  ^y = − 173.51 + 4.83(73) = 179.08 we predict that statistics students who earn a grade of 73 on the third exam will earn a grade of 179.08 on the final exam, on average. a. what would you predict the final exam score to be for a student who scored a 66 on the third exam? solution 13.6  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  585  a. 145.27 b. what would you predict the final exam score to be for a student who scored a 90 on the third exam? solution 13.6 b. the x values in the data are between 65 and 75. ninety is outside of the domain of the observed x values in the data (independent variable), so you cannot reliably predict the final exam score for this student. (even though it is possible to enter 90 into the equation for x and calculate a corresponding y value, the y value that you get will have a confidence interval that may not be meaningful.) to understand really how unreliable the prediction can be outside of the observed x values observed in the data, make the substitution x = 90 into the equation. ^  ⎛  ⎞  y = –173.51 + 4.83⎝90⎠ = 261.19 the final-exam score is predicted to be 261.19. the largest the final-exam score can be is 200.  13.7 | how to use microsoft excel® for regression analysis this section of this chapter is here in recognition that what we are now asking requires much more than a quick calculation of a ratio or a square root. indeed, the use of regression analysis was almost non- existent before the middle of the last century and did not really become a widely used tool until perhaps the late 1960’s and early 1970’s. even then the computational ability of even the largest ibm machines is laughable by today’s standards. in the early days programs were developed by the researchers and shared. there was no market for something called “software” and certainly nothing called “apps”, an entrant into the market only a few years old. with the advent of the personal computer and the explosion of a vital software market we have a number of regression and statistical analysis packages to choose from. each has their merits. we have chosen microsoft excel because of the wide-spread availability both on college campuses and in the post-college market place. stata is an alternative and has features that will be important for more advanced econometrics study if you choose to follow this path. even more advanced packages exist, but typically require the analyst to do some significant amount of programing to conduct their analysis. the goal of this section is to demonstrate how to use excel to run a regression and then to do so with an example of a simple version of a demand curve. the first step to doing a regression using excel is to load the program into your computer. if you have excel you have the analysis toolpak although you may not have it activated. the program calls upon a significant amount of space so is not loaded automatically. to activate the analysis toolpak follow these steps: click “file” > “options” > “add-ins” to bring up a menu of the add-in “toolpaks”. select “analysis toolpak” and click “go” next to “manage: excel add-ins” near the bottom of the window. this will open a new window where you click “analysis toolpak” (make sure there is a green check mark in the box) and then click “ok”. now there should be an analysis tab under the data menu. these steps are presented in the following screen shots.  586  figure 13.17  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  chapter 13 | linear regression and correlation  figure 13.18  587  588  chapter 13 | linear regression and correlation  figure 13.19  figure 13.20  click “data” then “data analysis” and then click “regression” and “ok”. congratulations, you have made it to the regression window. the window asks for your inputs. clicking the box next to the y and x ranges will allow you to use the click and drag feature of excel to select your input ranges. excel has one odd quirk and that is the click and drop feature requires that the independent variables, the x variables, are all together, meaning that they form a single matrix. if your data are set up with the y variable between two columns of x variables excel will not allow you to use click and drag. as an example, say column a and column c are independent variables and column b is the y variable, the dependent variable.  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  589  excel will not allow you to click and drop the data ranges. the solution is to move the column with the y variable to column a and then you can click and drag. the same problem arises again if you want to run the regression with only some of the x variables. you will need to set up the matrix so all the x variables you wish to regress are in a tightly formed matrix. these steps are presented in the following scene shots.  figure 13.21  figure 13.22  once you have selected the data for your regression analysis and told excel which one is the dependent variable (y) and which ones are the independent valuables (x‘s), you have several choices as to the parameters and how the output will be  590  chapter 13 | linear regression and correlation  displayed. refer to screen shot figure 13.22 under “input” section. if you check the “labels” box the program will place the entry in the first column of each variable as its name in the output. you can enter an actual name, such as price or income in a demand analysis, in row one of the excel spreadsheet for each variable and it will be displayed in the output. the level of significance can also be set by the analyst. this will not change the calculated t statistic, called t stat, but will alter the p value for the calculated t statistic. it will also alter the boundaries of the confidence intervals for the coefficients. a 95 percent confidence interval is always presented, but with a change in this you will also get other levels of confidence for the intervals. excel also will allow you to suppress the intercept. this forces the regression program to minimize the residual sum of squares under the condition that the estimated line must go through the origin. this is done in cases where there is no meaning in the model at some value other than zero, zero for the start of the line. an example is an economic production function that is a relationship between the number of units of an input, say hours of labor, and output. there is no meaning of positive output with zero workers. once the data are entered and the choices are made click ok and the results will be sent to a separate new worksheet by default. the output from excel is presented in a way typical of other regression package programs. the first block of information gives the overall statistics of the regression: multiple r, r squared, and the r squared adjusted for degrees of freedom, which is the one you want to report. you also get the standard error (of the estimate) and the number of observations in the regression. the second block of information is titled anova which stands for analysis of variance. our interest in this section is the column marked f. this is the calculated f statistics for the null hypothesis that all of the coefficients are equal to zero verse the alternative that at least one of the coefficients are not equal to zero. this hypothesis test was presented in 13.4 under “how good is the equation?” the next column gives the p value for this test under the title “significance f”. if the p value is less than say 0.05 (the calculated f statistic is in the tail) we can say with 90 % confidence that we cannot accept the null hypotheses that all the coefficients are equal to zero. this is a good thing: it means that at least one of the coefficients is significantly different from zero thus do have an effect on the value of y. the last block of information contains the hypothesis tests for the individual coefficient. the estimated coefficients, the intercept and the slopes, are first listed and then each standard error (of the estimated coefficient) followed by the t stat (calculated student’s t statistic for the null hypothesis that the coefficient is equal to zero). we compare the t stat and the critical value of the student’s t, dependent on the degrees of freedom, and determine if we have enough evidence to reject the null that the variable has no effect on y. remember that we have set up the null hypothesis as the status quo and our claim that we know what caused the y to change is in the alternative hypothesis. we want to reject the status quo and substitute our version of the world, the alternative hypothesis. the next column contains the p values for this hypothesis test followed by the estimated upper and lower bound of the confidence interval of the estimated slope parameter for various levels of confidence set by us at the beginning.  estimating the demand for roses here is an example of using the excel program to run a regression for a particular specific case: estimating the demand for roses. we are trying to estimate a demand curve, which from economic theory we expect certain variables affect how much of a good we buy. the relationship between the price of a good and the quantity demanded is the demand curve. beyond that we have the demand function that includes other relevant variables: a person’s income, the price of substitute goods, and perhaps other variables such as season of the year or the price of complimentary goods. quantity demanded will be our y variable, and price of roses, price of carnations and income will be our independent variables, the x variables. for all of these variables theory tells us the expected relationship. for the price of the good in question, roses, theory predicts an inverse relationship, the negatively sloped demand curve. theory also predicts the relationship between the quantity demanded of one good, here roses, and the price of a substitute, carnations in this example. theory predicts that this should be a positive or direct relationship; as the price of the substitute falls we substitute away from roses to the cheaper substitute, carnations. a reduction in the price of the substitute generates a reduction in demand for the good being analyzed, roses here. reduction generates reduction is a positive relationship. for normal goods, theory also predicts a positive relationship; as our incomes rise we buy more of the good, roses. we expect these results because that is what is predicted by a hundred years of economic theory and research. essentially we are testing these century-old hypotheses. the data gathered was determined by the model that is being tested. this should always be the case. one is not doing inferential statistics by throwing a mountain of data into a computer and asking the machine for a theory. theory first, test follows. these data here are national average prices and income is the nation’s per capita personal income. quantity demanded is total national annual sales of roses. these are annual time series data; we are tracking the rose market for the united states from 1984-2017, 33 observations. because of the quirky way excel requires how the data are entered into the regression package it is best to have the  this openstax book is available for free at http://cnx.org/content/col11776/1.33  chapter 13 | linear regression and correlation  591  independent variables, price of roses, price of carnations and income next to each other on the spreadsheet. once your data are entered into the spreadsheet it is always good to look at the data. examine the range, the means and the standard deviations. use your understanding of descriptive statistics from the very first part of this course. in large data sets you will not be able to “scan” the data. the analysis toolpac makes it easy to get the range, mean, standard deviations and other parameters of the distributions. you can also quickly get the correlations among the variables. examine for outliers. review the history. did something happen? was here a labor strike, change in import fees, something that makes these observations unusual? do not take the data without question. there may have been a typo somewhere, who knows without review. go to the regression window, enter the data and select 95% confidence level and click “ok”. you can include the labels in the input range if you have put a title at the top of each column, but be sure to click the “labels” box on the main regression page if you do. the regression output should show up automatically on a new worksheet.  figure 13.23  the first results presented is the r-square, a measure of the strength of the correlation between y and x1, x2, and x3 taken as a group. our r-square here of 0.699, adjusted for degrees of freedom, means that 70% of the variation in y, demand for roses, can be explained by variations in x1, x2, and x3, price of roses, price of carnations and income. there is no statistical test to determine the “significance” of an r2. of course a higher r2 is preferred, but it is really the significance of the coefficients that will determine the value of the theory being tested and which will become part of any policy discussion if they are demonstrated to be significantly different form zero. looking at the third panel of output we can write the equation as:  y = b0 + b1 x1 + b2 x2 + b3 x3 + e where b0 is the intercept, b1 is the estimated coefficient on price of roses, and b2 is the estimated coefficient on price of carnations, b3 is the estimated effect of income and e is the error term. the equation is written in roman letters indicating that these are the estimated values and not the population parameters, β’s. our estimated equation is:  quantity of roses sold = 183,475 − 1.76 price of roses + 1.33 price of carnations + 3.03 income we first observe that the signs of the coefficients are as expected from theory. the demand curve is downward sloping with the negative sign for the price of roses. further the signs of both the price of carnations and income coefficients are positive as would be expected from economic theory. interpreting the coefficients can tell us the magnitude of the impact of a change in each variable on the demand for roses. it is the ability to do this which makes regression analysis such a valuable tool. the estimated coefficients tell us that an increase the price of roses by one dollar will lead to a 1.76 reduction in the number roses purchased. the price of carnations seems to play an important role in the demand for roses as we see that increasing the price of carnations by one dollar would  592  chapter 13 | linear regression and correlation  increase the demand for roses by 1.33 units as consumers would substitute away from the now more expensive carnations. similarly, increasing per capita income by one dollar will lead to a 3.03 unit increase in roses purchased. these results are in line with the predictions of economics theory with respect to all three variables included in this estimate of the demand for roses. it is important to have a theory first that predicts the significance or at least the direction of the coefficients. without a theory to test, this research tool is not much more helpful than the correlation coefficients we learned about earlier. we cannot stop there, however. we need to first check whether our coefficients are statistically significant from zero. we set up a hypothesis of:  h0 : β1 = 0 ha : β1 ≠ 0  for all three coefficients in the regression. recall from earlier that we will not be able to definitively say that our estimated b1 is the actual real population of β1, but rather only that with (1-α)% level of confidence that we cannot reject the null hypothesis that our estimated β1 is significantly different from zero. the analyst is making a claim that the price of roses causes an impact on quantity demanded. indeed, that each of the included variables has an impact on the quantity of roses demanded. the claim is therefore in the alternative hypotheses. it will take a very large probability, 0.95 in this case, to overthrow the null hypothesis, the status quo, that β = 0. in all regression hypothesis tests the claim is in the alternative and the claim is that the theory has found a variable that has a significant impact on the y variable. the test statistic for this hypothesis follows the familiar standardizing formula which counts the number of standard deviations, t, that the estimated value of the parameter, b1, is away from the hypothesized value, β0, which is zero in this case:  tc =  b1 − β0 sb 1  the computer calculates this test statistic and presents it as “t stat”. you can find this value to the right of the standard error of the coefficient estimate. the standard error of the coefficient for b1 is sb1 in the formula. to reach a conclusion we compare this test statistic with the critical value of the student’s t at degrees of freedom n-3-1 =29, and alpha = 0.025 (5% significance level for a two-tailed test). our t stat for b1 is approximately 5.90 which is greater than 1.96 (the critical value we looked up in the t-table), so we cannot accept our null hypotheses of no effect. we conclude that price has a significant effect because the calculated t value is in the tail. we conduct the same test for b2 and b3. for each variable, we find that we cannot accept the null hypothesis of no relationship because the calculated t-statistics are in the tail for each case, that is, greater than the critical value. all variables in this regression have been determined to have a significant effect on the demand for roses. these tests tell us whether or not an individual coefficient is significantly different from zero, but does not address the overall quality of the model. we have seen that the r squared adjusted for degrees of freedom indicates this model with these three variables explains 70% of the variation in quantity of roses demanded. we can also conduct a second test of the model taken as a whole. this is the f test presented in section 13.4 of this chapter. because this is a multiple regression (more than one x), we use the f-test to determine if our coefficients collectively affect y. the hypothesis is:  h 0 : β 1 = β 2 = ... = βi = 0  h a : ""at least one of the β i is not equal to 0"" under the anova section of the output we find the calculated f statistic for this hypotheses. for this example the f statis",t_4ec8068f449a,other,0
c_9f02b43dad38,"in this video, you will learn all about the abdominal breathing technique to maintain control over your breathing when running.",t_90b662d4cdb3,other,0
c_36e2f094f9a2,"some of accuracy issues to enhance the quality and improvements of the integral method were suggested in the analysis of the emptying tank. there are problems that the integral methods even with these enhancements simply cannot tackle. the improvements to the integral methods are the corrections to the estimates of the energy or other quantities in the conservation equations. in the calculations of the exit velocity of a tank, two such corrections were presented. the first type is the prediction of the velocities profile (or the concentration profile). the second type of corrections is the understanding that averaged of the total field is different from the averaged of different zooms. in the case of the tank, the averaged velocity in \(x\) direction is zero yet the averaged velocity in the two zooms (two halves) is not zero. in fact, the averaged energy in the \(x\) direction contributes or effects the energy equation. the accuracy issues that integral methods intrinsically suffers from no ability to exact flow field and thus lost the accuracy as was discussed in the example. the integral method does not handle the problems such as the free surface with reasonable accuracy. furthermore, the knowledge of whether the flow is laminar or turbulent (later on this issue) has to come from different techniques. hence the prediction can skew the actual predictions.  fig. 7.5 flow in an oscillating manometer.  in the analysis of the tank it was assumed that the dissipation can be ignored. in cases that dissipation play major role, the integral does not provide a sufficient tool to analyze the issue at hand. for example, the analysis of the oscillating manometer cannot be carried by the integral methods. a liquid in manometer is disturbed from a rest by a distance of \(h_0\). the description \(h(t)\) as a function of time requires exact knowledge of the velocity field. additionally, the integral methods is too crude to handle issues of free interface. these problem were minor for the emptying the tank but for the oscillating manometer it is the core of the problem. hence different techniques are required. the discussion on the limitations was not provided to discard usage of this method but rather to provide a guidance of use with caution. the integral method is a powerful and yet simple method but has has to be used with the limitations of the method in mind.  contributors and attributions  dr. genick bar-meir (http://www.potto.org/genick.php). permission is granted to copy, distribute and/or modify this document under the terms of the gnu free documentation license, version 1.2 or later or potto license.",t_7087ba281413,other,0
c_e739b04655c6,"sal solves the following age word problem: in 40 years, imran will be 11 times as old as he is right now. how old is he right now?  we're told that in 40 years, imran will be 11 times as old as he is right now. and then we're asked, how old is he right now? and so i encourage you to try this on your own. well, let's see if we can set this up as an equation. so let's figure out what our unknown is first. well, our unknown is how old he is right now. i'm just arbitrarily using x. we always like to use x. but i could've really set it to be anything. but let's say x is equal to how old he is right now. how old-- not how hold. how old he is now. now, what do we know about how old he will be in 40 years? well, he's going to be how old he is now plus 40. so let me write that down. so in 40 years imran is going to be x plus 40, plus this 40 right over here. but they give us another piece of information. this by itself isn't enough to figure out how old he is right now. but they tell us in 40 years, imran will be 11 times as old as he is right now. so that's saying that this quantity right over here, x plus 40, is going to be 11 times x. in 40 years, he's going to be 11 times as old as he is right now. so this is going to be times 11. you take x, multiply it times 11, you're going to get how old he's going to be in 40 years. so let's write that down as an equation. you take x, multiply it by 11, so 11 times as old as he is right now is how old he is going to be in 40 years. and we have set up a nice little, tidy linear equation now. so we just have to solve for x. so let's get all the x's on the left-hand side. we have more x's here than on the right-hand side. so we avoid negative numbers, let's stick all the x's here. so if i want to get rid of this x on the right hand side, i'd want to subtract an x. but obviously, i can't just do it to the right. otherwise, the equality won't be true anymore. i need to do it on the left as well. and so i am left with-- if i have 11 of something and i take away 1 of them, i'm left with 10 of that something. so i'm left with 10 times x is equal to-- well, these x's, x minus x is just 0. that was the whole point. it's going to be equal to 40. and you could do this in your head at this point, but let's just solve it formally. so if we want a 1 coefficient here, we'd want to divide by 10, but we've got to do that to both sides. and so we are left with-- and we could have our drum roll now. we are left with x is equal to 4 years old. x is equal to 4. so our answer to the question, how old is imran right now? he is 4 years old. and let's verify this. if he's 4 years old right now, in 40 years he's going to be 44 years old. and 44 years old is indeed 11 times older than 4 years old. this is a factor of 11 years, so it all worked out.",t_686010077852,other,0
c_4dbac2a61ffa,"figure 1  case study conclusion: to give a shot or not  new mother samantha left her pediatrician’s office still unsure whether to vaccinate baby james. dr. rodriguez gave her a list of reputable sources where she could look up information about the safety of vaccines for herself, such as the centers for disease control and prevention (cdc). samantha reads that the consensus within the scientific community is that there is no link between vaccines and autism. she finds a long list of studies published in peer-reviewed scientific journals that disprove any link. additionally, some of the studies are “meta-analyses” that analyzed the findings from many individual studies. samantha is reassured by the fact that many different researchers, using a large number of subjects in numerous well-controlled and well-reviewed studies, all came to the same conclusion.  samantha also went back to the author’s website that originally scared her about the safety of vaccines. she found that the author was not a medical doctor or scientific researcher, but rather was a self-proclaimed “child wellness expert.” also, he sold books and advertising on his site, some of which were related to claims of vaccine injury. she realized that he was both an unqualified and potentially biased source of information.  also, samantha realized that some of his arguments were based on correlations between autism and vaccines, but, as the saying goes, “correlation does not imply causation.” for instance, the recent rise in autism rates may have occurred during the same time period as an increase in the number of vaccines given in childhood, but samantha could think of many other environmental and social factors that have also changed during this time period. there are just too many variables to come to the conclusion that vaccines, or anything else, are the cause of the rise in autism rates based on that type of argument alone. also, she learned that the age of onset of autism symptoms happens to typically be around the time that the mmr vaccine is first given, so the apparent association in the timing may just be a coincidence.  finally, samantha came across news about a measles outbreak that originated in california in 2014 and 2015. measles wasn’t just a disease of the past as she had thought! she learned that measles and whooping cough, which had previously been rare thanks to widespread vaccinations, are now on the rise, and that people choosing not to vaccinate their children seems to be one of the contributing factors. she realized that it is important to vaccinate her baby against these diseases, not only to protect him from their potential deadly effects, but to also protect others in the population.  in her reading, samantha learns that scientists do not yet know the causes of autism, but she feels reassured by the abundance of data that disproves any link with vaccines. she thinks that the potential benefit of protecting her baby’s health against deadly diseases outweighs any unsubstantiated claims about vaccines. she will be making an appointment to get baby james his shots soon.  chapter summary  in this chapter, you learned about some of the same concepts that helped samantha make an informed decision. specifically:  science is a distinctive way of gaining knowledge about the natural world that is based on the use of evidence to logically test ideas. as such, science is more of a process than a body of knowledge.  a scientific theory, such as the germ theory of disease, is the highest level of explanation in science. a theory is a broad explanation for many phenomena that is widely accepted because it is supported by a great deal of evidence.  the scientific investigation is the cornerstone of science as a process. an investigation is a procedure for gathering evidence to test a hypothesis.  a scientific experiment is a type of scientific investigation in which the researcher manipulates variables under controlled conditions to test expected outcomes. experiments are the gold standard for scientific investigations and can establish causation between variables.  nonexperimental scientific investigations such as observational studies and modeling may be undertaken when experiments are impractical, unethical, or impossible. observational studies generally can establish correlation but not causation between variables.  now that you know about the nature and process of science, you can apply these concepts in the next chapter to the study of human biology.  chapter summary review  1. which of the following is the best example of “doing science?”  a. memorizing the processes of the water cycle  b. learning how to identify trees from their leaves  c. learning the names of all the bones in the human body  d. making observations of wildlife while hiking in the woods  2. a scientist develops a new idea based on her observations of nature. what should she do next?  a. think of a way to test the idea  b. claim that she has discovered a new theory  c. reject any evidence that conflicts with the idea  d. look only for evidence that supports the idea  3. which of the following is defined as a possible answer to a scientific question?  a. an observation  b. data  c. a hypothesis  d. statistics  4. do scientists usually come up with a hypothesis in the absence of any observations? explain your answer.  5. why does a good hypothesis have to be falsifiable?  6. name one scientific law.  7. name one scientific theory.  8. give an example a scientific idea that was later discredited.  9. would the idea that the earth revolves around the sun be considered consensus science or frontier science?  10. true or false. a scientific investigation always follows the same sequence of steps in a linear fashion.  11. true or false. data that does not support a hypothesis is not useful.  12. true or false. experimentation is the only valid type of scientific investigation.  13. true or false. correlation does not imply causation.  14. explain why science is considered an iterative process.  15. a statistical measurement called a p-value is often used in science to determine whether or not a difference between two groups is actually significant or simply due to chance. a p-value of 0.03 means that there is a 3% chance that the difference is due to chance alone. do you think a p-value of 0.03 would indicate that the difference is likely to be significant? why or why not?  16. a. why is it important that scientists communicate their findings to others?  b. how do they usually do this?  17. what is a “control group” in science?  18. in a scientific experiment, why is it important to only change one variable at a time?  19. which is the dependent variable – the variable that is manipulated or the variable that is being affected by the change?  20. rank the following types of scientific studies in order of their typical strength, from those that are generally the least conclusive to those that are generally the most conclusive:  cohort; case-control; double-blind; cross-sectional; blind  21. which is most likely to show or disprove causation between two variables?  a. a controlled experiment  b. an observational study  c. the development of a hypothesis  d. an observation  22. you see an ad for a “miracle supplement” called nqp3 that claims the supplement will reduce belly fat. they say it works by reducing the hormone cortisol and by providing your body with missing unspecified “nutrients”, but they do not cite any peer-reviewed clinical studies. they show photographs of three people who appear slimmer after taking the product. a board-certified plastic surgeon endorses the product on television. answer the following questions about this product.  a. do you think that because a doctor endorsed the product, it really works? explain your answer.  b. what are two signs that these claims could actually be pseudoscience instead of true science?  c. do you think the photographs are good evidence that the product works? why or why not?  d. if you wanted to do a strong scientific study of whether this supplement does what it claims, what would you do? be specific about the subjects, data collected, how you would control variables, and how you would analyze the data.  e. what are some ways that you would ensure that the subjects in your experiment in part d are treated ethically and according to human subjects protections regulations?  image attributions  [figure 1]  credit: dirvish;  source: https://flic.kr/p/9aghcr  (https://flic.kr/p/9aghcr) license: cc by-nc 3.0 (https://creativecommons.org/licenses/by-nc/3.0/)",t_5085053a76d7,other,0
c_b9986c364a7d,source_url=http://www.prathamopenschool.org/coursecontent/videos/en_water_bell.mp4,t_ae74949b7b30,other,0
c_88ef8fc9bf0f,"in both developed and developing nations, indoor air pollution poses a greater health risk than outdoor air pollution. according to the world health organization (who) and other agencies such as the environmental protection agency (epa), indoor air generally contains higher concentrations of toxic pollutants than outdoor air. additionally, people generally spend more time indoors than outdoors, hence, the health effects from indoor air pollution in workplaces, schools, and homes are far greater than outdoor. indoor pollution sources that release gases or particles into the air are the primary cause of indoor air quality problems in homes. inadequate ventilation can increase indoor pollutant levels by not bringing in enough outdoor air to dilute emissions from indoor sources and by not carrying indoor air pollutants out of the home.  outdoor air enters and leaves a building by infiltration, natural ventilation, and mechanical ventilation. in infiltration, outdoor air flows into the house through openings, joints, and cracks in walls, floors, and ceilings, and around windows and doors. in natural ventilation, air moves through opened windows and doors. air movement associated with infiltration and natural ventilation is caused by air temperature differences between indoors and outdoors and by wind. finally, there are a number of mechanical ventilation devices, from outdoor-vented fans that intermittently remove air from a single room, such as bathrooms and kitchen, to air handling systems that use fans and duct work to continuously remove indoor air and distribute filtered and conditioned outdoor air to strategic points throughout the house. the rate at which outdoor air replaces indoor air is described as the air exchange rate. when there is little infiltration, natural ventilation, or mechanical ventilation, the air exchange rate is low and pollutant levels can increase. high temperature and humidity levels can also increase concentrations of some pollutants.  there are many sources of indoor air pollution in any home (figure \(\pageindex{1}\)). these include combustion sources such as oil, gas, kerosene, coal, wood, and tobacco products; building materials and furnishings as diverse as deteriorated, asbestos-containing insulation, wet or damp carpet, and cabinetry or furniture made of certain pressed wood products; products for household cleaning and maintenance, personal care, or hobbies; central heating and cooling systems and humidification devices. pollutants causing indoor air pollution can also originate from outside sources such as radon, pesticides, and outdoor air pollution. radon is a naturally occurring radioactive gas produced from the decay of uranium in rock. if a building/home is constructed in an area with uranium containing rock, the gas can seep through the foundations and accumulate in basements. exposure to radon can cause lung cancer.  the relative importance of any single source depends on how much of a given pollutant it emits and how hazardous those emissions are. in some cases, factors such as how old the source is and whether it is properly maintained are significant. for example, an improperly adjusted gas stove can emit significantly more carbon monoxide than one that is properly adjusted. some sources, such as building materials, furnishings, and household products like air fresheners, release pollutants more or less continuously. other sources, related to activities carried out in the home, release pollutants intermittently. these include smoking, the use of unvented or malfunctioning stoves, furnaces, or space heaters, the use of solvents in cleaning and hobby activities, the use of paint strippers in redecorating activities, and the use of cleaning products and pesticides in house-keeping. high pollutant concentrations can remain in the air for long periods after some of these activities.  risks from indoor air pollution differ between less industrialized and industrialized nations. indoor pollution has a greater impact in less industrialized nations where many people use cheaper sources of fuel such as wood, charcoal, and crop waste among others for cooking and heating, often with little or no ventilation. the most significant indoor pollutant, therefore, is soot and carbon monoxide. in industrialized nations, the primary indoor air health risks are cigarette smoke and radon.  figure \(\pageindex{1}\):  sources of indoor air pollution. image source: epa http://www.epa.gov/iaq/pdfs/careforyourair.pdf",t_cf84c3166522,other,0
c_6299b96127dd,"sal uses an area model to multiply 78x65.  i'm going to multiply 78 times 65 in a little less than standard way, but hopefully it'll make some sense, and you'll realize that there's multiple ways that you can multiply. and this is actually the way that i multiply numbers in my head. so 78 times 65. and then we're actually going to think about what the different parts of this process represent on this area model. so 78 times 65. so i'm going to start just the way we normally start when we multiply. i'm going to start with this 5 in this ones place, and i'm going to say 5 times 8 is 40. and instead of just writing a 0 and carrying a 4 right over here, i'm just going to write the number 40. so this was the 5 times the 8. now, i'm going to multiply the 5 times the 7. and we have to be a little bit careful here because 5 times-- this isn't just any 7, this is a 70. so what is 5 times 70? well, 5 times 7 would be 35, so five times 70 is 350. so i'll write that down, 350. so just as a review, 5 times 8 is 40, 5 times 7 is 350. if you add these two together, this is going to be 5 times 78. now let's go over to the 6. so let's multiply the 6 times the 8. now we have to be careful again. this 6 is not just a regular 6, it's in the tens place. this is a 60. 60 times 8. well, 6 times 8 is 48, so 60 times 8 is going to be 480. so it's going to be 480. and then 6 times 7. well, that would be 42, but we have to be careful. this is 60 times 70, so we're going to have two zeroes at the end. this is 4,200, not just 42. so 6 times 7 is 4,200. and now we can add everything together. and this is a very similar process to what we do when we do the traditional method of multiplying. i just made it a little bit more explicit what parts are from multiplying which digits. but we can add everything together. in the ones place, we have a 0. in the tens place, we have 4 plus 5 is 9. 9 plus 8 is 17. and now we can carry a 1. 1 plus 3 is 4. 4 plus 4 is 8. 8 plus 2 is 10. carry a 1, regroup of 1 even, and then you have a 5 right over there. so you get 5,070. now, i want to think about-- i want to visualize what was going on here using this area model. so once again, we had 78. so i'm going to make this vertical length represent 78. so this distance right over here represents the 70. that's the 70, and then we'll make this distance right over here represent the 8. let me make that a little bit cleaner so you see what i'm talking about. so this distance right over here represents the 8 and then we're going to multiply that times 65. so this distance right over here-- it's not drawn perfectly to scale, but it gives the idea-- this is 60. and then this distance right over here is the 5. so this whole distance is 65. this entire distance is 78. so when you multiply-- if you had a rectangle that's 65 units wide and you multiplied it, and it had a height of 78 units, then its area is going to be 78 times 65. it's area is going to be 5,070. now, each of these parts we can map to one part of this area model right over here. when we multiplied the 5 times the 8 and got the 40, that was this section right over here, 5 times 8 is equal to 40. when we multiplied 5 times 70, and got 350, that's this right over here. 5 times 70, and we got 350. when we multiplied 60-- the 6 in the tens place-- 60 times 8 and got 480-- that's this right over here-- this is 60 times 8 is equal to 480. and then finally when we multiplied 60 times 70 and got 4,200-- that's this area right over here-- this area is 60 wide, 70 tall. so this is 60 times 70, which is equal to 4,200. and then when we added everything up to get 5,070, we were essentially just adding up the areas of each of these tiles. this big one is 4,200, that makes up most of the area, and we get 480 from this magenta one, then 350 from this greenish-yellow one, and then 40 from this greenish-blue one to get 5,070. so the area of this entire thing is 5,070 square units.",t_dd702171c0ee,other,0
c_c02eb3f87022,"stunning beadwork and a story of forced migration. [see learning resources here.](https://smarthistory.org/seeing-america-2/bandolier-bag-sa/)      shoulder bag, 1840-1850, delaware, lenni lenape, cotton, wool, silk, glass beads, tinned iron, brass, bone, 29 1/2 inces high (newark museum of art, purchase 2017 mr. and mrs. william v. griffin fund  2017.10) a conversation with dr. adriana greci gree(jazzy piano music) - [male narrator] we're in the newark museum looking at a shoulder bag by delaware artist. it was made about 1840, 1860 in either kansas or oklahoma. but what's interesting in that the delaware were originally an east coast nation. - [female narrator] their original territory is up along the hudson and down the delaware river so here new jersey is at the core of their traditional territory. - [male narrator] and the delaware were one of the native american groups in north america that were in first contact with europeans but this bag dates to centuries later. - [female narrator] the delaware get pushed out of the eastern seaboard early on in the 17th century. by the period of the american revolution, they are primarily in western pennsylvania, the ohio river valley, and eventually there's a treaty that provides for a reservation in kansas. but they also end up in oklahoma. delaware's a colonial term really. governor of the territory attached to the lanape after colonization. - [male narrator] we're seeing a type of bag that is often referred to as a bandolier bag and this is a type of object that is made by more than one nation. - [female narrator] the bandolier bag, also known as a shoulder bag, is common among anishinaabe, objibwa, potawatomi, and also delaware, miami, shawnee, it's sort of a common genre early on in the 18th century. an earlier style would've been made with quillwork on black buckskin. the basic structure is the same. they're made out of cloth. the strap in the back of the bag and sometimes the inside of the bag are lined with beautiful printed cotton cloth, usually referred to as a calico, coming from either england or even india originally. part of that global exchange that really has expression in the 18th century. the bag is constructed in layers. the beadwork is often done on its own backing of trade cloth and then there is the calico backing behind it that is a decorative element. - [male narrator] and it's no surprise to me that this was a popular type of bag because they are spectacular. the bag in front of us is exceptionally beautiful with incredibly fine beadwork. - [female narrator] on the front, mostly what we see is the very bold beadwork. - [male narrator] the motifs are bold but organic. there's also a real geometry to them. - [female narrator] and so there's this whole aesthetic that has to do with dualities of upper worlds and lower worlds and other aspects that we may not know about but that really are seen through this aesthetic, this play with negative and positive space and so every element is really thought through with these configurations in mind. - [male narrator] and i think it's really important to remember that here in the gallery, we're not seeing the bag as it was intended to be seen. this is meant to be worn. it's meant to move through space and the conical tinklers would have produced a sound. there are bells at the end of the tassels and so this would've moved with its wearer and it would've made sound, it would've reflected light differently. it's worth remembering that while the bags were made by women, they were intended to be worn by men. - [female narrator] like most artwork in native america, it was made by women. (upbeat jazzy music)",t_55ec231a29a9,other,0
c_e71c50be0cab,"gene expression  ""northern blots"" or rna blot‑hybridization  in the reverse of southern blot‑hybridizations, one can separate rnas by size on a denaturing agarose gel, and transfer them to nylon or other appropriate solid support. labeled dna can then be used to visualize the corresponding mrna (fig. 3.33). ed southern initially used labeled rrna to find the complementary regions in immobilized, digested dna, so this ""reverse"" of southern blot-hybridizations, i.e. using a labeled dna probe to hybridize to immobilized rna, is often referred to as ""northern"" blot‑hybridizations.  one can hybridize a labeled dna clone to a panel of rna samples from a wide variety of tissues to determine in what tissues a particular cloned gene is expressed (top panel of fig. 3.33. more precisely, this technique reveals the tissues in which the genes is transcribed into stable rna. the results allow one to determine the tissue specificity of expression, e.g. a gene may only be expressed in liver, or only in erythroid cells (e.g. the b-globin gene). this helps give some general idea of the possible function of the gene, since it should reflect the function of that tissue. other genes are expressed in almost all cells or tissue types (such as gapdh); these are referred to as housekeeping genes. they are involved in functions common to all cells, such as basic energy metabolism, cell structure, etc. the relative amounts of rna in the different lanes can be directly compared to see, e.g., which tissues express the gene most abundantly.  one can hybridize a labeled dna clone to a panel of rna samples from a progressive stages of development to determine the developmental stagewhen during development a particular cloned gene is expressed as rna (bottom panel of fig. 3.33). for instance, a gene product may be required for determination decisions early in development, and only be expressed in early embryos.  once the dna sequence of the gene of interest is known, and its intron-exon structure determined, highly sensitive rt-pcr assayscan be designed (fig. 3.34). the rna from the cell or tissue of interest is copied into cdna using reverse transcriptase and dntps, and then primers are annealed for pcr. ideally, the primers are in different exons so that the product of amplifying the cdna will be smaller than the product of amplifying the genomic dna.  figure 3.33.  figure 3.34.reverse transcription-pcr (rt-pcr) assay for mrna.  in situ hybridizations / immunochemistry  in complementary approaches, the labeled dna can be hybridized in situto thin sections of a tissue or embryo or other specimen, and the resulting pattern of grains visualized along the specimen in the microscope (fig. 3.35). also, antibody probes against the protein product can be used to localize it in the specimen. this gives a more detailed picture of the pattern of expression, with resolution to the particular cells that are expressing the gene. the rna blot-hybridization techniques described in a. above look at the rna in all the cells from a tissue, and do not provide the level of resolution to single cells.  figure 3.35.  microarrays  as large numbers of sequenced mrnas and genes become available, technology has been developed to look at expression of very large numbers of genes simulatneously. dna sequences specific for each gene in a bacterium or yeast can be spotted in a high-density array with 400 r more spots. some technologies use many more spots, with mutliple sequences per gene. microarrays, or “gene chips” are available for many species, some with tens of thousands of different sequences or “probes.” rna from different tissues can be converted to cdna with a distinctive fluorescent label, and then hybridized to the gene chip. differences in level of expression can be measured. thus global changes in gene expression can now be measured.  figure 3.36.hybridization of rna to high density microarrays of gene sequences, or “gene chips”.  database searches  an increasingly powerful approach is to determine candidates for the the function of your gene by searching the databaseswith the sequence, looking for matches to known proteins and genes. these matches provide clues as to protein function.  the power of this approach increases as the amount of sequences deposited in databases expand.  sequences of many genes are already known. the sequenced genes from more complex organisms, such as plants and animals, tend to be the ones more easily isolated using the techniques discussed in recombinant dna technology. however, the sequences of genes expressed at a low level are starting to accumulate in the databases.  one remarkable advance in the past few years is the increasing number of organisms whose entire genome has been sequenced. about 10 bacterial genomes have been sequenced, and the number increases every few months. genomics sequences for two eukaryotes are now available. that of the yeast saccharomyces cerevisiaehas been known for a few years, and the genome of the nematode caenorhabditis eleganswas completed in 1998. these sequences are being analyzed intensively, and a very high fraction of all the genes in each genome can be reliably detected using computational tools (one part of bioinformatics). it has become clear that many of the enzymes used in basic metabolism, regulation of the cell cycle, cellular signaling cascades, etc. are highly conserved across a broad phylogenetic spectrum. thus it is common to find significant sequence matches in the genomes of model organisms when they are queried by the sequence of a previously unknown gene, e.g. from humans or mouse. the function already established for that gene in worms or yeast is a highly reliable guide to the function of the homologous gene in humans. the worm c. elegansis multicellular, and fate of each of its cells during development has been mapped. thus it is possible that many functions involved in cellular interactions and cell-cell signaling will be conserved in this species, thus expanding the list of potential targets for a search in the databases.  this potential is being realized as working draft sequences of the human and mouse genomes are being analyzed. within these data is a good approximation of sequences from virtually all human and mouse genes. random clones have been partially sequenced from libraries of cdnas from various human tissues, normalized to remove much of the products of abundant mrnas and thus increasing the frequency of products of rare mrnas. these sequences from the ends of the cdna clones are called xpressed equence ags, or ests.  the name is derived from the fact that since they are in cdna libraries, they are obviously expressed at the level of mrna, and some are used as tags in generating high-resolution maps of human chromosome. hundreds of thousands of these have now been sequenced in collaborative efforts between pharmaceutical companies, other companies and universities. the database dbest records all those in the public domain, and it is a strong complement to the databases recording all known sequences of genes. many different parts of the same, or highly related, cdnas, are recorded as separate entries in dbest. projects are underway to group all the sequences from the same (or highly related) gene into a a unified sequence. one example is the unigene project at ncbi.  the number of entries grows continually, but in the summer of 1998 there are about 50,000 entries, each representing about one gene. the number is higher now. current estimates of the number of human genes are around 30,000, so it is possible that some unigene clusters represent only parts of genes, and some genes match more than one cluster.  e  s  t  very efficient search engines have been designed for handling queries to these databases, and several are freely available over the world wide web. one of the most popular and useful sites for this and related activities is maintained by the national center for biotechnology information (http://www.ncbi.nlm.nih.gov/ (http://www.ncbi.nlm.nih.gov/)). their entrez browser provides integrated access to sequence, mapping and some functional information, pubmed provides access to abstracts of papers in journals in the national library of medicine, and the blast server allows rapid searches through various sequence databases. dbest and the unigene collection are maintained here, many genome maps are available, and three-dimensional structures of proteins and nucleic acids are available.  make the protein product and analyze it  it is often possible to express the gene and make the encoded protein in large amounts. the protein can be purified and assayed for various enzymatic or other activities. hypotheses for such activities may come from database searches.  directed mutation  the previously describe approaches give some idea about gene function, but they do not firmly establish those functions. indeed, this is a modern problem of trying to assign a function to an isolated gene. several “reverse genetic” approaches can now be taken to tackle this problem. the most powerful approach to determining the physiological role(s) of a gene product is to mutate the gene in an appropriate organism and search for an altered phenotype.  the easiest experiment to do, but sometimes most difficult to interpret, is a gain of function assay. in this case, one forces expression of the gene in a transgenic organism, which often already has a wild type copy of the gene. one can look for a phenotype resulting from over-expression in tissues where it is normally expressed, or ectopic expression in tissues where it is normally silent.  in some organisms, it is possible to engineer a loss of functionof the gene. the most effective method is to use homologous recombination to replace the wild type gene with one engineered to have no function. this knock-outmutation will prevent expression of the endogenous gene and one can see the effects on the whole organism. unfortunately, the efficiency of homologous recombination is low in many organisms and cell lines, so this is not always feasible. other methods for knocking out expression are being developed, although the mechanism for their effect (when successful) is still being studied. in some cases, one can block expression of the endogenous gene by forcing production of antisenserna. another method that is effective in some, but currently not all organisms, is the use of double-stranded, interfering rna (rnai). duplex rnas less than 30 nucleotide pairs long from the gene of interest can prevent expression of genes in worms, flies, and plants. some success in mammals was recently reported.  another way to generate a loss-of-function phenotype is to express dominant negative alleles of the gene. these mutant alleles encode stable proteins that form an aberrant structure that prevents functioning of the endogenous protein. this usually requires some protein-protein interaction (e.g. homodimers or heterodimers).  localization on a genetic map  sometimes the gene you have isolated maps to a region on a chromosome with a known function. of course, many genes are probably located in that region, so it is critical to show that a candidate gene really is the one that when mutated causes an altered phenotype. this can be done by showing that a wild type copy of the candidate gene will restore a normal phenotype to the mutant. if a marker is known to be very tightly linked to the candidate gene, one can test whether this marker is always in linkage disequilibrium with the determinant of the mutant phenotype, i.e. in a large number of crosses, the marker for the candidate gene and the mutant phenotype never separated by recombination.  the mapping is often done with gene‑specific probes for in situ hybridizations to mitotic chromosomes. one then aligns the hybridization pattern with the chromosome banding patterns to map the isolated gene. another method is to hybridize to a panel of dnas from hybrid cells that contain only part of the chromosomal complement of the genome of interest. this is particularly powerful with radiation hybrid panels.  contributors  ross c. hardison (http://bmb.psu.edu/directory/rch8), t. ming chu professor of biochemistry and molecular biology (http://bmb.psu.edu/) (the pennsylvania state university (http://www.psu.edu/))",t_3e11b2ce2cec,other,0
c_b736410817b1,"introduction to 45-45-90 triangles  welcome to the presentation on 45-45-90 triangles. let me write that down. how come the pen-- oh, there you go. 45-45-90 triangles. or we could say 45-45-90 right triangles, but that might be redundant, because we know any angle that has a 90 degree measure in it is a right triangle. and as you can imagine, the 45-45-90, these are actually the degrees of the angles of the triangle. so why are these triangles special? well, if you saw the last presentation i gave you a little theorem that told you that if two of the base angles of a triangle are equal-- and it's i guess only a base angle if you draw it like this. you could draw it like this, in which case it's maybe not so obviously a base angle, but it would still be true. if these two angles are equal, then the sides that they don't share-- so this side and this side in this example, or this side and this side in this example-- then the two sides are going to be equal. so what's interesting about a 45-45-90 triangle is that it is a right triangle that has this property. and how do we know that it's the only right triangle that has this property? well, you could imagine a world where i told you that this is a right triangle. this is 90 degrees, so this is the hypotenuse. right, it's the side opposite the 90 degree angle. and if i were to tell you that these two angles are equal to each other, what do those two angles have to be? well if we call these two angles x, we know that the angles in a triangle add up to 180. so we'd say x plus x plus-- this is 90-- plus 90 is equal to 180. or 2x plus 90 is equal to 180. or 2x is equal to 90. or x is equal to 45 degrees. so the only right triangle in which the other two angles are equal is a 45-45-90 triangle. so what's interesting about a 45-45-90 triangle? well other than what i just told you-- let me redraw it. i'll redraw it like this. so we already know this is 90 degrees, this is 45 degrees, this is 45 degrees. and based on what i just told you, we also know that the sides that the 45 degree angles don't share are equal. so this side is equal to this side. and if we're viewing it from a pythagorean theorem point of view, this tells us that the two sides that are not the hypotenuse are equal. so this is a hypotenuse. so let's call this side a and this side b. we know from the pythagorean theorem-- let's say the hypotenuse is equal to c-- the pythagorean theorem tells us that a squared plus b squared is equal to c squared. right? well we know that a equals b, because this is a 45-45-90 triangle. so we could substitute a for b or b for a. but let's just substitute b for a. so we could say b squared plus b squared is equal to c squared. or 2b squared is equal to c squared. or b squared is equal to c squared over 2. or b is equal to the square root of c squared over 2. which is equal to c-- because we just took the square root of the numerator and the square root of the denominator-- c over the square root of 2. and actually, even though this is a presentation on triangles, i'm going to give you a little bit of actually information on something called rationalizing denominators. so this is perfectly correct. we just arrived at b-- and we also know that a equals b-- but that b is equal to c divided by the square root of 2. it turns out that in most of mathematics, and i never understood quite exactly why this was the case, people don't like square root of 2s in the denominator. or in general they don't like irrational numbers in the denominator. irrational numbers are numbers that have decimal places that never repeat and never end. so the way that they get rid of irrational numbers in the denominator is that you do something called rationalizing the denominator. and the way you rationalize a denominator-- let's take our example right now. if we had c over the square root of 2, we just multiply both the numerator and the denominator by the same number, right? because when you multiply the numerator and the denominator by the same number, that's just like multiplying it by 1. the square root of 2 over the square root of 2 is 1. and as you see, the reason we're doing this is because square root of 2 times square root of 2, what's the square root of 2 times square root of 2? right, it's 2. right? we just said, something times something is 2, well the square root of 2 times square root of 2, that's going to be 2. and then the numerator is c times the square root of 2. so notice, c times the square root of 2 over 2 is the same thing as c over the square root of 2. and this is important to realize, because sometimes while you're taking a standardized test or you're doing a test in class, you might get an answer that looks like this, has a square root of 2, or maybe even a square root of 3 or whatever, in the denominator. and you might not see your answer if it's a multiple choice question. what you ned to do in that case is rationalize the denominator. so multiply the numerator and the denominator by square root of 2 and you'll get square root of 2 over 2. but anyway, back to the problem. so what did we learn? this is equal to b, right? so turns out that b is equal to c times the square root of 2 over 2. so let me write that. so we know that a equals b, right? and that equals the square root of 2 over 2 times c. now you might want to memorize this, though you can always derive it if you use the pythagorean theorem and remember that the sides that aren't the hypotenuse in a 45-45-90 triangle are equal to each other. but this is very good to know. because if, say, you're taking the sat and you need to solve a problem really fast, and if you have this memorized and someone gives you the hypotenuse, you can figure out what are the sides very fast, or i8f someone gives you one of the sides, you can figure out the hypotenuse very fast. let's try that out. i'm going to erase everything. so we learned just now that a is equal to b is equal to the square root of 2 over 2 times c. so if i were to give you a right triangle, and i were to tell you that this angle is 90 and this angle is 45, and that this side is, let's say this side is 8. i want to figure out what this side is. well first of all, let's figure out what side is the hypotenuse. well the hypotenuse is the side opposite the right angle. so we're trying to actually figure out the hypotenuse. let's call the hypotenuse c. and we also know this is a 45-45-90 triangle, right? because this angle is 45, so this one also has to be 45, because 45 plus 90 plus 90 is equal to 180. so this is a 45-45-90 triangle, and we know one of the sides-- this side could be a or b-- we know that 8 is equal to the square root of 2 over 2 times c. c is what we're trying to figure out. so if we multiply both sides of this equation by 2 times the square root of 2-- i'm just multiplying it by the inverse of the coefficient on c. because the square root of 2 cancels out that square root of 2, this 2 cancels out with this 2. we get 2 times 8, 16 over the square root of 2 equals c. which would be correct, but as i just showed you, people don't like having radicals in the denominator. so we can just say c is equal to 16 over the square root of 2 times the square root of 2 over the square root of 2. so this equals 16 square roots of 2 over 2. which is the same thing as 8 square roots of 2. so c in this example is 8 square roots of 2. and we also knows, since this is a 45-45-90 triangle, that this side is 8. hope that makes sense. in the next presentation i'm going to show you a different type of triangle. actually, i might even start off with a couple more examples of this, because i feel i might have rushed it a bit. but anyway, i'll see you soon in the next presentation.",t_7190db04758b,other,0
c_a13d65638532,"life and photosynthesis start to thrive in the archean eon  we finished off the last video in the hadean eon. it was named for hades or the ancient greek underworld. hades is also the name of the god that ran the greek underworld, zeus's oldest brother. and it was an appropriate name, although the idea of, the ancient greek notion of the underworld isn't exactly the more modern notion of hell. but it was a hellish environment. you had all this lava flowing around. you had things impacting the earth from space. and as far as we can tell right now, it was completely inhospitable to life. and to make matters worse, even though the earth started to cool down a little bit, maybe the crust became a little bit more solid. maybe the collisions started to happen less and less, as we started to go a few hundred million years fast forward. after the theia rammed into the early earth and formed the moon, there was something called the late heavy bombardment. and right now, the consensus is that life, whatever we are descended from, would have had to come about after the late heavy bombardment. because this was a time where so many things from outer space were hitting earth, that it was so violent, that it might have killed off any kind of primitive, self-replicating organisms or molecules that might have existed before it. and i won't go into the physics of the late heavy bombardment. but we believe that it happened, because uranus and neptune-- so if this is the sun right here-- that is the sun. this is the asteroid belt. that's outside the orbits of the inner, rocky planets. that uranus and neptune, their orbits moved outward. and i'm not going to go into the physics. but what that caused is, gravitationally, it caused a lot of the asteroids in the asteroid belt to move inward and start impacting the inner planets. and of course, earth was one of the inner planets. and i should make the sun like orange or something, not blue. i don't want you to think that's earth. and it also impacted the moon. and it's more obvious on the moon, because the moon does not have an atmosphere to kind of smooth over the impact. so the consensus is that only after the late heavy bombardment was earth kind of ready for life. and we believe that the first life formed 3.824 billion years ago. remember, g for giga, for billion years ago. and when we talk about life at this period, we're not talking about squirrels or panda bears. we're talking about extremely simple life forms. we're talking about prokaryotes. and let me give you a little primer on that right now, though we go into much more detail in the biology playlist. we're talking about prokaryotes. and i'll compare them to eukaryotes. prokaryotes are, for the most part, unicellular organisms that have no nucleuses. they also don't have any other membrane-bound what we call organelles or these little parts of the cells that perform specific functions, like mitochondria. so their dna is just kind of floating around. so let me draw this character's dna. so it's just floating around, just like that. and prokaryote literally means before kernel or before a nucleus. eukaryotes do have a nucleus, where all of their dna is. so this is the nuclear membrane. and then all of its dna is floating inside of the nucleus. and then it also has other membrane-bound organelles. mitochondria is kind of the most famous of them. so it also has things like mitochondria. we'll learn more about that in future videos. mitochondria, we believe, is essentially one prokaryote crawling inside of another prokaryote and kind of starting to become a symbiotic organism with each other. but i won't go into that right now. but when we talk about life at this period, we're talking about prokaryotes. and we still have prokaryotes on the planet. bacteria and archaea are examples of prokaryotes. and just to give you a little bit of a tidbit right here, this kind of shows our current understanding of where we think things branched off from. so at this point of the tree is some common ancestor to prokaryotes and eukaryotes. so these are the prokaryotes right over here, the bacteria and the archaea. and here is the eukaryote. and this first living thing, or this first set of living things, we think might have just been some type of self-replicating molecules. and slowly, some membrane might have come around, and it became a little bit more organized. dna, rna-- maybe rna was that original self-replicating molecule-- became the method of kind of transmitting information from one generation to the next. so it's really still an open question of exactly what that first life is or even how do you define that first life. but based on studying the genetic makeup of molecules of current organisms, this is how we think the tree of life came about. so we have one common ancestor. then they broke apart. and then the archaea and eukaryotes have a common ancestor that's different from the bacteria. and we'll talk more about that in the future. and this right here, just so you can visualize it, this is an example of bacteria. this is e. coli or escherichia coli. it's just an example of bacteria. it comes in a bunch of shapes and forms. but it's a prokaryotic life form. and the earliest life forms, we also think were anaerobes. these are things that did not-- one, that they did not need oxygen. and they, for the most part, found oxygen poisonous. and the earliest life forms also probably did not perform photosynthesis. they might have gotten their energy from other sources, chemically, from this kind of extremely volatile environment that they were in at that time. so if we fast forward a little bit-- and this is actually a major event in the history of earth. and these are huge time scales we're talking about. remember, i'm kind of just nonchalantly saying, oh, 4.6 billion years ago to 3.8 billion. oh, that's just 800 million years. remember-- and i'll talk about this. grass has only existed for 50 million years. this is 800 million years. humans and chimpanzees only diverged 5 million years ago. this is 800 million years we're talking about, from ancient greece to now, we're only talking about 2,500 years. you multiply that times 1,000, you get 2 and 1/2 a million years. and this is 800 million years we're talking about. so these are extremely huge periods of time. and that's why we call them eons. eons are 500 million to a billion years. now, the dividing line between the hadean eon and the archean eon-- and it's kind of a fuzzy dividing line, but most people place it about 3.8 billion years ago. it's kind of the earliest rocks that we can observe. and so we have rocks from, that are roughly 3.8 billion years ago. so we kind of put that as the beginning of the archean eon. and so there's two things there. one, rocks have survived from the beginning of the archean eon. and also, that's roughly when we think that the first life existed. and so we're now in the archean eon. and you might say, oh, maybe earth is a more pleasant place now. but it would not be. it still has no to little oxygen in the environment. if you were to go to earth at that time, it might have looked something like this. it would have a been a reddish sky. you would have had nitrogen and methane and carbon dioxide in the atmosphere. there would have been nothing for you to breathe. there still would have been a lot of volcanic activity. this right here, these are pictures of stromatolites. and these are formed from bacteria that are bringing in sediment particles. and over time, these things get built up. but the most significant event in the archean period, at least in my humble opinion, was what we believe started to happen about 3.5 billion years ago. and this is prokaryotes, or especially bacteria, evolving to actually utilize energy from the sun, to actually do photosynthesis. and the real fascinating byproduct of that, other than the fact that they can now use energy directly from the sun, is that it started to produce oxygen, so starts to produce oxygen. and at first, this oxygen, even though it was being produced by the cyanobacteria, by this blue-green bacteria, it really didn't accumulate in the atmosphere. because you had all of this iron that was dissolved in the oceans. and let me be clear. all of the life that we're going to be talking about for really the next several billion years, it all occurred in the ocean. we had no ozone layer now. the land was being irradiated. the land was just a completely inhospitable environment for life. so all of this was occurring in the ocean. and so the first oxygen that actually got produced, it actually, instead of just being released into the atmosphere, it ended up bonding with the iron that was dissolved in the ocean at that time. so it actually didn't have a chance to accumulate in the atmosphere. and when we fast forward past the archean period, we're going to see, that once a lot of that iron was oxidized and the oxygen really did start to get released in the atmosphere, it actually had-- it's funny to say-- a cataclysmic effect or a catastrophic effect on the other anaerobic life on the planet at the time. and it's funny to say that because it was a catastrophe for them. but it was kind of a necessary thing that had to happen for us to happen. so for us, it was a blessing that this cyanobacteria started to pump out a lot of oxygen and eventually oxidized all of the iron and eventually released a lot of oxygen into the atmosphere and killed off all of this anaerobic bacteria, so that eventually we could-- us oxygen-breathing organisms could come about. but that's not going to happen for a while. we still have a few billion years before things start flopping around on the land. anyway, see you in the next video.",t_b002c8d45350,other,0
c_906e13fb2690,"take a peek at duendes performing at our annual spring gala event in the kanbar forum! more than 400 guests attended the april 6 event, themed play is serious business! the gala highlighted how the exploratorium’s creative and hands-on approach to education is essential to producing generations of confident individuals with critical thinking skills, bold creativity, and lifelong curiosity.  roberto corrias      guitar  jose blanco          guitar vocals percussion  david mclean         guitar  marlon aldana        hand percussion /cajon  clara rodriguez      dancer percussion hand claps",t_8080b3a86407,other,0
c_80c10e62aee3,"chapter 7 of the book on react js.chapter 7: forms and user input section 7.1: controlled components controlled form components are deﬁned with a value property. the value of controlled inputs is managed by react, user inputs will not have any direct inﬂuence on the rendered input. instead, a change to the value property needs to reﬂect this change. class form extends react.component { constructor(props) { super(props); this.onchange = this.onchange.bind(this); this.state = { name: '' }; } onchange(e) { this.setstate({ name: e.target.value }); } render() { return ( <div> <label for='name-input'>name: </label> <input id='name-input' onchange={this.onchange} value={this.state.name} /> </div> ) } }  the above example demonstrates how the value property deﬁnes the current value of the input and the onchange event handler updates the component's state with the user's input. form inputs should be deﬁned as controlled components where possible. this ensures that the component state and the input value is in sync at all times, even if the value is changed by a trigger other than a user input.  section 7.2: uncontrolled components uncontrolled components are inputs that do not have a value property. in opposite to controlled components, it is the application's responsibility to keep the component state and the input value in sync. class form extends react.component { constructor(props) { super(props); this.onchange = this.onchange.bind(this); this.state = { name: 'john'  goalkicker.com – react js notes for professionals  42  }; } onchange(e) { this.setstate({ name: e.target.value }); } render() { return ( <div> <label for='name-input'>name: </label> <input id='name-input' onchange={this.onchange} defaultvalue={this.state.name} /> </div> ) } }  here, the component's state is updated via the onchange event handler, just as for controlled components. however, instead of a value property, a defaultvalue property is supplied. this determines the initial value of the input during the ﬁrst render. any subsequent changes to the component's state are not automatically reﬂected by the input value; if this is required, a controlled component should be used instead.  goalkicker.com – react js notes for professionals  43",t_5a4483298428,other,0
c_bd38d2cc743c,"sal uses the number 37 to explain why we use a ""ones place"" and a ""tens place"" when writing numbers.  voiceover:let's say that you wanna count the days since your last birthday because you just wanna know how long its been. and so one day after your birthday you put a mark on a wall. then the next day you put another mark on the wall. the day after that you put another mark on the wall. so out that day you say well how many days has it been? well you can say look there's been one, two, three days. so one way to think about it is this set of symbols right over here represents the number three. but then you keep going. the fourth day, you put another mark. fifth day, you put another mark. and then you keep going like that day after day each day you add another mark. and this is actually the earliest way, the most basic way of representing numbers. the number is represented by the number of marks. so after bunch of days you get here and you're like on well how many days has it been? well you just recount everything. you say one, two, three, four, five, six, seven, eight, nine, 10, 11, 12, 13, 14, 15, 16, 17 days. so well you know this number representation it took me little bit of time to realize that this is 17 but it seems to be working so you just keep going. day after day after day after day you just keep marking off the days on your wall just to sense you're counting the days since your last birthday. but at some point you realize every time you wanna know how may days its been to count it is a little bit painful. and not only that, is this is taking up a lot of space on your wall. you wish that there was an easier way to represent whatever number this is. so first of all let's just think about what number this actually is. one, two, three, four, five, six, seven, eight, nine, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37. so you wish that there was a better way to represent this number which we now call 37. and maybe when you're first trying you might have even called it something called 37. you would just call it this, this number. this number of days since my birthday. and i say well look. what if there was an easier way to group the numbers? you know i have 10 fingers on my hands. what if i were to group them into 10s? and then i would say just how many groups of 10 i have and then how many ones do i have left over. maybe that would be an easier way to represent, to represent this quantity here. and so let's do that. so one, two, three, four, five, six, seven, eight, nine, 10. so that's a group of 10 right over there. and then you have one, two, three, four, five, six, seven, eight, nine, 10. so this is another group of 10 right over here. and then let's see. we have one, two, three, four, five, six, seven, eight, nine, 10. so that is another group of 10 right over there. and then finally you have one, two, three, four, five, six, seven. so you don't get a whole group of 10 so you don't circle em. so just by doing this very simple thing now all of a sudden it's much easier to realize how many days have passed. you don't have to count everything. you just have to say okay. one group of 10. two groups of 10. three groups of 10. or you can say one, two, three 10s. and so that's essentially 30. and then i have another one, two, three, four, five, six, seven. and so you say oh i have 30 and then seven if you knew to use those words which we now use. now this is essentially what our number system does using the 10 digits we know of. the 10 digits we know of are zero, one, two, three, four, five, six, seven, eight, nine. now what our number system allows us to do is using only these 10 digits we can essentially represent any number we want in a very quick way, a very easy way for our brains to understand it. so here if we want to represent three 10s, we would have put a three in what we would call the 10s place. we would put a three in the 10s place. and then we would put the ones, one, two, three, four, five, six, seven. we'd put the seven in the ones place. and so how do you know which place is which? well the first place starting from the right, the first place is the ones place. and then you go one space to the left of it, you get to the 10s place. and as we'll see you go one more space you go to the 100s space. but we'll cover that in a future video. so this essentially tells us the exact same thing. this tells us the exact same thing as this does right over here. this tells us three 10s. one, two, three. three 10s three groups of 10. and then another set of ones. so we could rewrite this. this is equal to, this is equal to three 10s three 10s plus, plus seven ones. or another way to think about it what are the three 10s? well if use the same number system to represent three 10s you would write that down as 30. and then seven ones. once again if you use our same number system you would represent that as seven. so these are all different ways of representing 37. and hopefully this allows you to appreciate how neat our number system is. where even a number like 37 as soon as you just write scratches on a wall, it becomes pretty hard to read. and you can imagine when you get to much much larger numbers like 1,052 to have to count that many marks every time. but our number system gives us a way of dealing with it.",t_528959c19342,other,0
c_bd47dbaa9d93,"this video will teach you an exercise to practice with a partner to improve your balance and help prevent falls improving your balance in pairs: standing on one foot in this video, you’re going to learn how to perform an exercise that improves your balance, with the help of a partner. please ensure that your physical fitness to perform this exercise is checked by a doctor beforehand the purpose of this task is to improve the stability of your ankles, knees and hips which are essential for maintaining good balance and preventing falls. this exercise is composed of two stages: positioning, then movement. firstly, positioning. the older adult should stand with feet hip-width apart stretch out your spine by making yourself taller lift the back of the head making yourself as tall as possible, while tucking your chin in and looking in front of you. so as not to arch your back, tighten your abdominals and buttocks as the supporting partner: face your partner and align your left shoulder with theirs. grasp the underside of the recipient’s left forearm while ensuring your elbow rests against your body. secondly, movement. for the older adult: support yourself on your partner’s forearm and lift one foot so that you are balancing on only one leg. take a deep breath and then, as you exhale, slowly lift your heel off the ground on the leg you are using to balance. hold the position for 2 seconds then place your heel back on the ground. repeat two more times with the same leg. to help with your balance, focus your eyes on a fixed point in front of you. then perform the same exercise again, on the other leg. gradually, after days of practice you will be able to stay in the balanced position  for longer periods of time. by carrying out exercises that work your balance, muscles and flexibility you will improve your posture and stability. over to you!",t_121826ed4c87,other,0
c_3496cad205cb,"the calvin cycle is organized into three basic stages: fixation, reduction, and regeneration.  learning objectives  describe the calvin cycle  key takeaways  key points  the calvin cycle refers to the light-independent reactions in photosynthesis that take place in three key steps.  although the calvin cycle is not directly dependent on light, it is indirectly dependent on light since the necessary energy carriers ( atp and nadph) are products of light-dependent reactions.  in fixation, the first stage of the calvin cycle, light-independent reactions are initiated; co2 is fixed from an inorganic to an organic molecule.  in the second stage, atp and nadph are used to reduce 3-pga into g3p; then atp and nadph are converted to adp and nadp+, respectively.  in the last stage of the calvin cycle, rubp is regenerated, which enables the system to prepare for more co2 to be fixed.  key terms  light-independent reaction: chemical reactions during photosynthesis that convert carbon dioxide and other compounds into glucose, taking place in the stroma  rubisco: (ribulose bisphosphate carboxylase) a plant enzyme which catalyzes the fixing of atmospheric carbon dioxide during photosynthesis by catalyzing the reaction between carbon dioxide and rubp  ribulose bisphosphate: an organic substance that is involved in photosynthesis, reacts with carbon dioxide to form 3-pga  the calvin cycle  in plants, carbon dioxide (co2) enters the leaves through stomata, where it diffuses over short distances through intercellular spaces until it reaches the mesophyll cells. once in the mesophyll cells, co2 diffuses into the stroma of the chloroplast, the site of light-independent reactions of photosynthesis. these reactions actually have several names associated with them. other names for light-independent reactions include the calvin cycle, the calvin-benson cycle, and dark reactions. the most outdated name is dark reactions, which can be misleading because it implies incorrectly that the reaction only occurs at night or is independent of light, which is why most scientists and instructors no longer use it.  light reactions: light-dependent reactions harness energy from the sun to produce chemical bonds, atp, and nadph. these energy-carrying molecules are made in the stroma where the calvin cycle takes place. the calvin cycle is not totally independent of light since it relies on atp and nadh, which are products of the light-dependent reactions.  the light-independent reactions of the calvin cycle can be organized into three basic stages: fixation, reduction, and regeneration.  stage 1: fixation  in the stroma, in addition to co2,two other components are present to initiate the light-independent reactions: an enzyme called ribulose bisphosphate carboxylase (rubisco) and three molecules of ribulose bisphosphate (rubp). rubp has five atoms of carbon, flanked by two phosphates. rubisco catalyzes a reaction between co2 and rubp. for each co2 molecule that reacts with one rubp, two molecules of 3-phosphoglyceric acid (3-pga) form. 3-pga has three carbons and one phosphate. each turn of the cycle involves only one rubp and one carbon dioxide and forms two molecules of 3-pga. the number of carbon atoms remains the same, as the atoms move to form new bonds during the reactions (3 atoms from 3co2 + 15 atoms from 3rubp = 18 atoms in 3 atoms of 3-pga). this process is called carbon fixation because co2 is “fixed” from an inorganic form into organic molecules.  the calvin cycle: the calvin cycle has three stages. in stage 1, the enzyme rubisco incorporates carbon dioxide into an organic molecule, 3-pga. in stage 2, the organic molecule is reduced using electrons supplied by nadph. in stage 3, rubp, the molecule that starts the cycle, is regenerated so that the cycle can continue. only one carbon dioxide molecule is incorporated at a time, so the cycle must be completed three times to produce a single three-carbon ga3p molecule, and six times to produce a six-carbon glucose molecule.  stage 2: reduction  atp and nadph are used to convert the six molecules of 3-pga into six molecules of a chemical called glyceraldehyde 3-phosphate (g3p). this is a reduction reaction because it involves the gain of electrons by 3-pga. recall that a reduction is the gain of an electron by an atom or molecule. six molecules of both atp and nadph are used. for atp, energy is released with the loss of the terminal phosphate atom, converting it to adp; for nadph, both energy and a hydrogen atom are lost, converting it into nadp+. both of these molecules return to the nearby light-dependent reactions to be reused and reenergized.  stage 3: regeneration  at this point, only one of the g3p molecules leaves the calvin cycle and is sent to the cytoplasm to contribute to the formation of other compounds needed by the plant. because the g3p exported from the chloroplast has three carbon atoms, it takes three “turns” of the calvin cycle to fix enough net carbon to export one g3p. but each turn makes two g3ps, thus three turns make six g3ps. one is exported while the remaining five g3p molecules remain in the cycle and are used to regenerate rubp, which enables the system to prepare for more co2 to be fixed. three more molecules of atp are used in these regeneration reactions.",t_1b5eac12ab9a,other,0
c_06e2a273fdb0,"chapter 61 of the book on sql.chapter 61: clean code in sql how to write good, readable sql queries, and example of good practices.  section 61.1: formatting and spelling of keywords and names table/column names two common ways of formatting table/column names are camelcase and snake_case: select firstname, lastname from employees where salary > 500; select first_name, last_name from employees where salary > 500;  names should describe what is stored in their object. this implies that column names usually should be singular. whether table names should use singular or plural is a heavily discussed question, but in practice, it is more common to use plural table names. adding preﬁxes or suﬃxes like tbl or col reduces readability, so avoid them. however, they are sometimes used to avoid conﬂicts with sql keywords, and often used with triggers and indexes (whose names are usually not mentioned in queries). keywords sql keywords are not case sensitive. however, it is common practice to write them in upper case.  section 61.2: indenting there is no widely accepted standard. what everyone agrees on is that squeezing everything into a single line is bad: select d.name, count(*) as employees from departments as d join employees as e on d.id = e.departmentid where d.name != 'hr' having count(*) > 10 order by count(*) desc;  at the minimum, put every clause into a new line, and split lines if they would become too long otherwise: select d.name, count(*) as employees from departments as d join employees as e on d.id = e.departmentid where d.name != 'hr' having count(*) > 10 order by count(*) desc;  sometimes, everything after the sql keyword introducing a clause is indented to the same column: select from join where having  d.name, count(*) as employees departments as d employees as e on d.id = e.departmentid d.name != 'hr' count(*) > 10  goalkicker.com – sql notes for professionals  150  order by count(*) desc;  (this can also be done while aligning the sql keywords right.) another common style is to put important keywords on their own lines: select d.name, count(*) as employees from departments as d join employees as e on d.id = e.departmentid where d.name != 'hr' having count(*) > 10 order by count(*) desc;  vertically aligning multiple similar expressions improves readability: select model, employeeid from cars where customerid = 42 and status = 'ready';  using multiple lines makes it harder to embed sql commands into other programming languages. however, many languages have a mechanism for multi-line strings, e.g., @""..."" in c#, """"""..."""""" in python, or r""(...)"" in c++.  section 61.3: select * select * returns all columns in the same order as they are deﬁned in the table.  when using select *, the data returned by a query can change whenever the table deﬁnition changes. this increases the risk that diﬀerent versions of your application or your database are incompatible with each other. furthermore, reading more columns than necessary can increase the amount of disk and network i/o. so you should always explicitly specify the column(s) you actually want to retrieve: --select * select id, fname, lname, phonenumber from emplopees;  don't -- do  (when doing interactive queries, these considerations do not apply.) however, select * does not hurt in the subquery of an exists operator, because exists ignores the actual data anyway (it checks only if at least one row has been found). for the same reason, it is not meaningful to list any speciﬁc column(s) for exists, so select * actually makes more sense: -- list departments where nobody was hired recently select id, name from departments  goalkicker.com – sql notes for professionals  151  where not exists (select * from employees where departmentid = departments.id and hiredate >= '2015-01-01');  section 61.4: joins explicit joins should always be used; implicit joins have several problems: the join condition is somewhere in the where clause, mixed up with any other ﬁlter conditions. this makes it harder to see which tables are joined, and how. due to the above, there is a higher risk of mistakes, and it is more likely that they are found later. in standard sql, explicit joins are the only way to use outer joins: select d.name, e.fname || e.lname as empname from departments as d left join employees as e on d.id = e.departmentid;  explicit joins allow using the using clause: select recipeid, recipes.name, count(*) as numberofingredients from recipes left join ingredients using (recipeid);  (this requires that both tables use the same column name. using automatically removes the duplicate column from the result, e.g., the join in this query returns a single recipeid column.)  goalkicker.com – sql notes for professionals  152",t_a798d52b0c79,other,0
c_c74e47861691,"learn how to find the circumference, the distance around a circle, when given the area.  if we know some circle has an area of 36pi-- so it has an area of 36pi-- can we figure out what the circumference of this circle is? and i encourage you to pause this video, and try to think about that question. well, from the area, we could figure out what the radius is, and then from that radius, we can figure out what its circumference is. so we know that the area, which is 36pi, is equal to pi r squared. and so if you look at it on both sides of this equation, if we divide-- let me rewrite it so it's a little bit clearer in a different color. so we could set up an equation pi r squared is equal to 36pi. now, if we want to solve for the radius the first thing that we might want to do is divide both sides by pi. then, we're left with r squared is equal to 36. now, if we just solve this as a pure math equation, you might say, ok, we could take the positive and negative square root of 36. r could be plus or minus 6, but we need to remember that r is a distance, so we only care about the positive. so if we take the principal root of 36, we get r is equal to 6. from there, we can use this to figure out the circumference. so the circumference is equal to 2 pi r. circumference is equal to 2 pi r. and in this case, r is equal to 6. so it's equal to 2 pi times 6, which is going to be equal to 12pi. so that's straightforward, area 36pi, we leverage pi r squared to figure out that the radius was 6, and then from that we were able to figure out that the circumference was 12pi.",t_1350a60a2ab4,other,0
c_2447c9de80f2,"the social network perspective emphasizes multiple levels of analysis. differences among actors are traced to the constraints and opportunities that arise from how they are embedded in networks; the structure and behavior of networks grounded in, and enacted by local interactions among actors. as we examine some of the basic concepts and definitions of network analysis in this and the next several chapters, this duality of individual and structure will be highlighted again and again.  in this chapter we will examine some of the most obvious and least complex ideas of formal network analysis methods. despite the simplicity of the ideas and definitions, there are good theoretical reasons (and some empirical evidence) to believe that these basic properties of social networks have very important consequences. for both individuals and for structures, one main question is connections. typically, some actors have lots of connections, others have fewer. some networks are well-connected or ""cohesive"", others are not. the extent to which individuals are connected to others, and the extent to which the network as a whole is integrated are two sides of the same coin.  differences among individuals in how connected they are can be extremely consequential for understanding their attributes and behavior. more connections often mean that individuals are exposed to more, and more diverse, information. highly connected individuals may be more influential, and may be more influenced by others. differences among whole populations in how connected they are can be quite consequential as well. disease and rumors spread more quickly where there are high rates of connection. but, so too does useful information. more connected populations may be better able to mobilize their resources, and may be better able to bring multiple and diverse perspectives to bear to solve problems. in between the individual and the whole population, there is another level of analysis - that of ""composition"". some populations may be composed of individuals who are all pretty much alike in the extent to which they are connected. other populations may display sharp differences, with a small elite of central and highly connected persons, and larger masses of persons with fewer connections. differences in connections can tell us a good bit about the stratification order of social groups. a great deal of recent work by duncan watts, doug white and many others outside of the social sciences is focusing on the consequences of variation in the degree of connection of actors.  because most individuals are not usually connected directly to most other individuals in a population, it can be quite important to go beyond simply examining the immediate connections of actors, and the overall density of direct connections in populations. the second major (but closely related) set of approaches that we will examine in this chapter have to do with the idea of the distance between actors (or, conversely, how close they are to one another). some actors may be able to reach most other members of the population with little effort: they tell their friends, who tell their friends, and ""everyone"" knows. other actors may have difficulty being heard. they may tell people, but the people they tell are not well connected, and the message doesn't go far. thinking about it the other way around, if all of my friends have one another as friends, my network is fairly limited - even though i may have quite a few friends. but, if my friends have many non-overlapping connections, the range of my connection is expanded. if individuals differ in their closeness to other actors, then the possibility of stratification along this dimension arises. indeed, one major difference among ""social classes"" is not so much in the number of connections that actors have, but in whether these connections overlap and ""constrain"" or extend outward and provide ""opportunity"". populations as a whole, then, can also differ in how close actors are to other actors, on the average. such differences may help us to understand diffusion, homogeneity, solidarity, and other differences in macro properties of social groups.  social network methods have a vocabulary for describing connectedness and distance that might, at first, seem rather formal and abstract. this is not surprising, as many of the ideas are taken directly from the mathematical theory of graphs. but it is worth the effort to deal with the jargon. the precision and rigor of the definitions allow us to communicate more clearly about important properties of social structures - and often lead to insights that we would not have had if we used less formal approaches.  an example: knoke's information exchange  the basic properties of networks are easier to learn and understand by example. studying an example also shows sociologically meaningful applications of the formalisms. in this chapter, we will look at a single directed binary network that describes the flow of information among 10 formal organizations concerned with social welfare issues in one mid-western u.s. city (knoke and burke). of course, network data come in many forms (undirected, multiple ties, valued ties, etc.) and one example can't capture all of the possibilities. still, it can be rather surprising how much information can be ""squeezed out"" of a single binary matrix by using basic graph concepts.  for small networks, it is often useful to examine graphs. figure 7.1 shows the di-graph (directed graph) for the knoke information exchange data:  figure 7.1: knoke information exchange directed graph  your trained eye should immediately perceive a number of things in looking at the graph. there is a limited number of actors here (ten, actually), and all of them are ""connected"". but, clearly not every possible connection is present, and there are ""structural holes"" (or at least ""thin spots"" in the fabric). there appear to be some differences among the actors in how connected they are (compare actor number 7, a newspaper, to actor number 6, a welfare rights advocacy organization). if you look closely, you can see that some actors' connections are likely to be reciprocated (that is, if a shares information with b, b also shares information with a); some other actors (e.g. 6 and 10), are more likely to be senders than receivers of information. as a result of the variation in how connected individuals are, and whether the ties are reciprocated, some actors may be at quite some ""distance"" from other actors. there appear to be groups of actors who differ in this regard (2, 5, and 7 seem to be in the center of the action; 6, 9, and 10 seem to be more peripheral).  a careful look at the graph can be very useful in getting an intuitive grasp of the important features of a social network. with larger populations or more connections, however, graphs may not be much help. looking at a graph can give a good intuitive sense of what is going on, but our descriptions of what we see are rather imprecise (the previous paragraph is an example of this). to get more precise, and to use computers to apply algorithms to calculate mathematical measures of graph properties, it is necessary to work with the adjacency matrix instead of the graph. the knoke data graphed above are shown as an asymmetric adjacency matrix in figure 7.2.  figure 7.2: knoke information exchange adjacency matrix  using data&gt;display, we can look at the network in matrix form. there are ten rows and columns, the data are binary, and the matrix is asymmetric. as we mentioned in the chapter on using matrices to represent networks, the row is treated as the source of information and the columns as the receiver. by doing some very simple operations on this matrix it is possible to develop systematic and useful index numbers, or measures, of some of the network properties that our eye discerns in the graph.",t_40b7296ee1dc,other,0
c_a0c550b4a04e,"let's ease into this, shall we? here's an introduction to basic algebraic equations of the form ax=b. remember that you can check to see if you have the right answer by substituting it for the variable!  let's say we have the equation 7 times x is equal to 14. now before even trying to solve this equation, what i want to do is think a little bit about what this actually means. 7x equals 14, this is the exact same thing as saying 7 times x -- let me write it this way -- 7 times x -- we'll do the x in orange again -- 7 times x is equal to 14. now you might be able to do this in your head. you could literally go through the 7 times table. you say well 7 times 1 is equal to 7, so that won't work. 7 times 2 is equal to 14, so 2 works here. so you would immediately be able to solve it. you would immediately, just by trying different numbers out, say hey, that's going to be a 2. but what we're going to do in this video is to think about how to solve this systematically. because what we're going to find is as these equations get more and more complicated, you're not going to be able to just think about it and do it in your head. so it's really important that one, you understand how to manipulate these equations, but even more important to understand what they actually represent. this literally just says 7 times x is equal to 14. in algebra we don't write the times there. when you write two numbers next to each other or a number next to a variable like this, it just means that you are multiplying. it's just a shorthand, a shorthand notation. and in general we don't use the multiplication sign because it's confusing, because x is the most common variable used in algebra. and if i were to write 7 times x is equal to 14, if i write my times sign or my x a little bit strange, it might look like xx or times times. so in general when you're dealing with equations, especially when one of the variables is an x, you wouldn't use the traditional multiplication sign. you might use something like this -- you might use dot to represent multiplication. so you might have 7 times is equal to 14. but this is still a little unusual. if you have something multiplying by a variable you'll just write 7x. that literally means 7 times x. now, to understand how you can manipulate this equation to solve it, let's visualize this. so 7 times x, what is that? that's the same thing -- so i'm just going to re-write this equation, but i'm going to re-write it in visual form. so 7 times x. so that literally means x added to itself 7 times. that's the definition of multiplication. so it's literally x plus x plus x plus x plus x -- let's see, that's 5 x's -- plus x plus x. so that right there is literally 7 x's. this is 7x right there. let me re-write it down. this right here is 7x. now this equation tells us that 7x is equal to 14. so just saying that this is equal to 14. let me draw 14 objects here. so let's say i have 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14. so literally we're saying 7x is equal to 14 things. these are equivalent statements. now the reason why i drew it out this way is so that you really understand what we're going to do when we divide both sides by 7. so let me erase this right here. so the standard step whenever -- i didn't want to do that, let me do this, let me draw that last circle. so in general, whenever you simplify an equation down to a -- a coefficient is just the number multiplying the variable. so some number multiplying the variable or we could call that the coefficient times a variable equal to something else. what you want to do is just divide both sides by 7 in this case, or divide both sides by the coefficient. so if you divide both sides by 7, what do you get? 7 times something divided by 7 is just going to be that original something. 7's cancel out and 14 divided by 7 is 2. so your solution is going to be x is equal to 2. but just to make it very tangible in your head, what's going on here is when we're dividing both sides of the equation by 7, we're literally dividing both sides by 7. this is an equation. it's saying that this is equal to that. anything i do to the left hand side i have to do to the right. if they start off being equal, i can't just do an operation to one side and have it still be equal. they were the same thing. so if i divide the left hand side by 7, so let me divide it into seven groups. so there are seven x's here, so that's one, two, three, four, five, six, seven. so it's one, two, three, four, five, six, seven groups. now if i divide that into seven groups, i'll also want to divide the right hand side into seven groups. one, two, three, four, five, six, seven. so if this whole thing is equal to this whole thing, then each of these little chunks that we broke into, these seven chunks, are going to be equivalent. so this chunk you could say is equal to that chunk. this chunk is equal to this chunk -- they're all equivalent chunks. there are seven chunks here, seven chunks here. so each x must be equal to two of these objects. so we get x is equal to, in this case -- in this case we had the objects drawn out where there's two of them. x is equal to 2. now, let's just do a couple more examples here just so it really gets in your mind that we're dealing with an equation, and any operation that you do on one side of the equation you should do to the other. so let me scroll down a little bit. so let's say i have i say i have 3x is equal to 15. now once again, you might be able to do is in your head. you're saying this is saying 3 times some number is equal to 15. you could go through your 3 times tables and figure it out. but if you just wanted to do this systematically, and it is good to understand it systematically, say ok, this thing on the left is equal to this thing on the right. what do i have to do to this thing on the left to have just an x there? well to have just an x there, i want to divide it by 3. and my whole motivation for doing that is that 3 times something divided by 3, the 3's will cancel out and i'm just going to be left with an x. now, 3x was equal to 15. if i'm dividing the left side by 3, in order for the equality to still hold, i also have to divide the right side by 3. now what does that give us? well the left hand side, we're just going to be left with an x, so it's just going to be an x. and then the right hand side, what is 15 divided by 3? well it is just 5. now you could also done this equation in a slightly different way, although they are really equivalent. if i start with 3x is equal to 15, you might say hey, sal, instead of dividing by 3, i could also get rid of this 3, i could just be left with an x if i multiply both sides of this equation by 1/3. so if i multiply both sides of this equation by 1/3 that should also work. you say look, 1/3 of 3 is 1. when you just multiply this part right here, 1/3 times 3, that is just 1, 1x. 1x is equal to 15 times 1/3 third is equal to 5. and 1 times x is the same thing as just x, so this is the same thing as x is equal to 5. and these are actually equivalent ways of doing it. if you divide both sides by 3, that is equivalent to multiplying both sides of the equation by 1/3. now let's do one more and i'm going to make it a little bit more complicated. and i'm going to change the variable a little bit. so let's say i have 2y plus 4y is equal to 18. now all of a sudden it's a little harder to do it in your head. we're saying 2 times something plus 4 times that same something is going to be equal to 18. so it's harder to think about what number that is. you could try them. say if y was 1, it'd be 2 times 1 plus 4 times 1, well that doesn't work. but let's think about how to do it systematically. you could keep guessing and you might eventually get the answer, but how do you do this systematically. let's visualize it. so if i have two y's, what does that mean? it literally means i have two y's added to each other. so it's literally y plus y. and then to that i'm adding four y's. to that i'm heading four y's, which are literally four y's added to each other. so it's y plus y plus y plus y. and that has got to be equal to 18. so that is equal to 18. now, how many y's do i have here on the left hand side? how many y's do i have? i have one, two, three, four, five, six y's. so you could simplify this as 6y is equal to 18. and if you think about it it makes complete sense. so this thing right here, the 2y plus the 4y is 6y. so 2y plus 4y is 6y, which makes sense. if i have 2 apples plus 4 apples, i'm going to have 6 apples. if i have 2 y's plus 4 y's i'm going to have 6 y's. now that's going to be equal to 18. and now, hopefully, we understand how to do this. if i have 6 times something is equal to 18, if i divide both sides of this equation by 6, i'll solve for the something. so divide the left hand side by 6, and divide the right hand side by 6. and we are left with y is equal to 3. and you could try it out. that's what's cool about an equation. you can always check to see if you got the right answer. let's see if that works. 2 times 3 plus 4 times 3 is equal to what? 2 times 3, this right here is 6. and then 4 times 3 is 12. 6 plus 12 is, indeed, equal to 18. so it works out.",t_0dbcec548885,other,0
c_400f40a0ae3d,"join us as we celebrate the beginning of summer in the arctic and the long, cold winter in antarctica. we'll connect live to two polar field sites: summit camp atop greenland's vast ice sheet, where the sun will be shining 24 hours a day, and the south pole research station, now in the middle of 6 months of darkness.",t_1736b64bf087,t_1736b64bf087,1
c_ae1892f82135,"amanda grannas' research group at villanova university studies a wide range of topics under the umbrella of ""analytical environmental chemistry"", including the impacts of pollutants in the snow and ice. we'll chat with amanda about her current research in the arctic.",t_1736b64bf087,t_1736b64bf087,1
c_e57bfd1aa14c,dr. vladimir romanovsky is researching permafrost geophysics: the relationship between the frozen ground (permafrost) and climate. join host julie konop as she asks vladimir about his most recent data.,t_1736b64bf087,t_1736b64bf087,1
c_6b2c237d646e,"the jakobshavn isbrae is among the fastest-moving glaciers in the world. the jakobshavn is an outlet glacier, one of the few places where the giant greenland ice sheet can shed ice in the form of gigantic icebergs. this timelapse video  by jason amundson of the university of alaska fairbanks shows one of these massive calving events. notice the dark blue ice that surfaces when the iceberg flips over in the ice-choked ilulissat icefjord.",t_1736b64bf087,t_1736b64bf087,1
c_f965fd6b1c10,"the census of marine life is a growing global network of researchers in more than 70 nations engaged in a ten year (2000-2010) mission to assess and explain the diversity, distribution, and abundance of marine life in the oceans. rolf gradinger is an expert in sea ice communities, studying the tiny animals that actually live inside the ice and those that live on the bottom of the ice sheets. we'll chat with rolf about his current work, drilling ice cores just off barrow, and looking for some of the world's most unique fauna.",t_1736b64bf087,t_1736b64bf087,1
c_7204558f20e5,"chapter 28 of the book on ios developer.chapter 28: uibarbuttonitem parameter title the uibarbuttonitem title  description  style  the style of the uibarbuttonitem  target  the object to receive the uibarbuttonitem action  action  the selector (method) to be performed when the uibarbuttonitem is pressed  section 28.1: creating a uibarbuttonitem in the interface builder the example below shows how to add a navigation bar button (called a uibarbuttonitem) in the interface builder. add a navigation controller to your storyboard select your view controller and then in the xcode menu choose editor > embed in > navigation controller.  alternatively, you could add a uinavigationbar from the object library. add a bar button item drag a uibarbuttonitem from the object library to the top navigation bar.  goalkicker.com – ios® developer notes for professionals  164  it should look like this:  set the attributes you could double-click ""item"" to change the text to something like ""refresh"", but there is an actual icon for refresh that you can use. just select the attributes inspector for the uibarbuttonitem and for system item choose refresh.  goalkicker.com – ios® developer notes for professionals  165  that will give you the default refresh icon.  add an ib action control drag from the uibarbuttonitem to the view controller to add an @ibaction. class viewcontroller: uiviewcontroller { @ibaction func refreshbarbuttonitemtap(sender: uibarbuttonitem) { print(""how refreshing!"") } }  that's it. goalkicker.com – ios® developer notes for professionals  166  notes this example originally comes from this stack overﬂow answer.  section 28.2: creating a uibarbuttonitem //swift let barbuttonitem = uibarbuttonitem(title: ""greetings!"", style: .plain, target: self, action: #selector(barbuttontapped)) self.navigationitem.rightbarbuttonitem = barbuttonitem //objective-c uibarbuttonitem *barbuttonitem = [[uibarbuttonitem alloc] initwithtitle:@""greetings!"" style:uibarbuttonitemstyleplain target:self action:@selector(barbuttontaped)]; self.navigationitem.rightbarbuttonitem = barbuttonitem;  section 28.3: bar button item original image with no tint color provided that barbuttonitem has a non-null image property (e.g. set in the interface builder). objective-c barbuttonitem.image = [barbuttonitem.image imagewithrenderingmode:uiimagerenderingmodealwaysoriginal];  goalkicker.com – ios® developer notes for professionals  167",t_17bf2af6d82b,t_17bf2af6d82b,2
c_efa08bac3a8e,"chapter 111 of the book on ios developer.chapter 111: initialization idioms section 111.1: factory method with block internal func init<type>(value : type, block: @noescape (object: type) -> void) -> type { block(object: value) return value }  usage: init(uilabel(frame: cgrect.zero)) { $0.backgroundcolor = uicolor.blackcolor() }  section 111.2: set to tuples to avoid code repetition avoid code repetition in constructors by setting a tuple of variables with a one liner: class contact: uiview { private var message: uilabel private var phone: uitextview required init?(coder adecoder: nscoder) { (message, phone) = self.dynamictype.setup() super.init(coder: adecoder) } override func awakefromnib() { (message, phone) = self.dynamictype.setup() super.awakefromnib() } override init(frame: cgrect) { (message, phone) = self.dynamictype.setup() super.init(frame: frame) } private static func setup(){ let message = uilabel() // ... let phone = uitextview() // ... return (message, phone) } }  section 111.3: initialize with positional constants let myswitch: uiswitch = { view.addsubview($0) $0.addtarget(self, action: ""action"", forcontrolevents: .touchupinside) return $0 }(uiswitch())  goalkicker.com – ios® developer notes for professionals  587  section 111.4: initialize attributes in didset @iboutlet weak var title: uilabel! { didset { label.textcolor = uicolor.redcolor() label.font = uifont.systemfontofsize(20) label.backgroundcolor = uicolor.bluecolor() } }  it's also possible to both set a value and initialize it: private var loginbutton = uibutton() { didset(oldvalue) { loginbutton.addtarget(self, action: #selector(logincontroller.didclicklogin), forcontrolevents: .touchupinside) } }  section 111.5: group outlets in a custom nsobject move every outlet to an nsobject. then drag an object from the library to the controller scene of the storyboard and hook the elements there. class contactformstyle: nsobject { @iboutlet private weak var message: uilabel! { didset { message.font = uifont.systemfontofsize(12) message.textcolor = uicolor.blackcolor() } } } class contactformvc: uiviewcontroller { @iboutlet private var style: contactformstyle! }  section 111.6: initialize with then this is similar in syntax to the example that initializes using positional constants, but requires the then extension from https://github.com/devxoul/then (attached below). let label = uilabel().then { $0.textalignment = .center $0.textcolor = uicolor.blackcolor( $0.text = ""hello, world!"" }  the then extension: import foundation public protocol then {} extension then  goalkicker.com – ios® developer notes for professionals  588  { public func then(@noescape block: inout self -> void) -> self { var copy = self block(&copy) return copy } } extension nsobject: then {}  goalkicker.com – ios® developer notes for professionals  589",t_17bf2af6d82b,t_17bf2af6d82b,2
c_c1bea2e8550c,"chapter 53 of the book on ios developer.chapter 53: uibezierpath section 53.1: designing and drawing a bezier path this example shows the process from designing the shape you want to drawing it on a view. a speciﬁc shap is used but the concepts you learn can be applied to any shape. how to draw a bézier path in a custom view these are the main steps: 1. design the outline of the shape you want. 2. divide the outline path into segments of lines, arcs, and curves. 3. build that path programmatically. 4. draw the path either in drawrect or using a cashapelayer. design shape outline you could do anything, but as an example i have chosen the shape below. it could be a popup key on a keyboard.  divide the path into segments look back at your shape design and break it down into simpler elements of lines (for straight lines), arcs (for circles and round corners), and curves (for anything else). here is what our example design would look like:  goalkicker.com – ios® developer notes for professionals  298  black are line segments light blue are arc segments red are curves orange dots are the control points for the curves green dots are the points between path segments dotted lines show the bounding rectangle dark blue numbers are the segments in the order that they will be added programmatically build the path programmatically we'll arbitrarily start in the bottom left corner and work clockwise. i'll use the grid in the image to get the x and y values for the points. i'll hardcode everything here, but of course you wouldn't do that in a real project. the basic process is: 1. create a new uibezierpath 2. choose a starting point on the path with movetopoint 3. add segments to the path line: addlinetopoint arc: addarcwithcenter curve: addcurvetopoint 4. close the path with closepath here is the code to make the path in the image above. func createbezierpath() -> uibezierpath { // create a new path let path = uibezierpath()  goalkicker.com – ios® developer notes for professionals  299  // starting point for the path (bottom left) path.movetopoint(cgpoint(x: 2, y: 26)) // ********************* // ***** left side ***** // ********************* // segment 1: line path.addlinetopoint(cgpoint(x: 2, y: 15)) // segment 2: curve path.addcurvetopoint(cgpoint(x: 0, y: 12), // ending point controlpoint1: cgpoint(x: 2, y: 14), controlpoint2: cgpoint(x: 0, y: 14)) // segment 3: line path.addlinetopoint(cgpoint(x: 0, y: 2)) // ********************* // ****** top side ***** // ********************* // segment 4: arc path.addarcwithcenter(cgpoint(x: 2, y: 2), // center point of circle radius: 2, // this will make it meet our path line startangle: cgfloat(m_pi), // π radians = 180 degrees = straight left endangle: cgfloat(3*m_pi_2), // 3π/2 radians = 270 degrees = straight up clockwise: true) // startangle to endangle goes in a clockwise direction // segment 5: line path.addlinetopoint(cgpoint(x: 8, y: 0)) // segment 6: arc path.addarcwithcenter(cgpoint(x: 8, y: 2), radius: 2, startangle: cgfloat(3*m_pi_2), // straight up endangle: cgfloat(0), // 0 radians = straight right clockwise: true) // ********************* // ***** right side **** // ********************* // segment 7: line path.addlinetopoint(cgpoint(x: 10, y: 12)) // segment 8: curve path.addcurvetopoint(cgpoint(x: 8, y: 15), // ending point controlpoint1: cgpoint(x: 10, y: 14), controlpoint2: cgpoint(x: 8, y: 14)) // segment 9: line path.addlinetopoint(cgpoint(x: 8, y: 26)) // ********************* // **** bottom side **** // ********************* // segment 10: line path.closepath() // draws the final line to close the path  goalkicker.com – ios® developer notes for professionals  300  return path }  note: some of the above code can be reduced by adding a line and an arc in a single command (since the arc has an implied starting point). see here for more details. draw the path we can draw the path either in a layer or in drawrect. method 1: draw path in a layer our custom class looks like this. we add our bezier path to a new cashapelayer when the view is initialized. import uikit class mycustomview: uiview { override init(frame: cgrect) { super.init(frame: frame) setup() } required init?(coder adecoder: nscoder) { super.init(coder: adecoder) setup() } func setup() { // create a cashapelayer let shapelayer = cashapelayer() // the bezier path that we made needs to be converted to // a cgpath before it can be used on a layer. shapelayer.path = createbezierpath().cgpath // apply other properties related to the path shapelayer.strokecolor = uicolor.bluecolor().cgcolor shapelayer.fillcolor = uicolor.whitecolor().cgcolor shapelayer.linewidth = 1.0 shapelayer.position = cgpoint(x: 10, y: 10) // add the new layer to our custom view self.layer.addsublayer(shapelayer) } func createbezierpath() -> uibezierpath { // see previous code for creating the bezier path } }  and creating our view in the view controller like this override func viewdidload() { super.viewdidload() // create a new uiview and add it to the view controller let myview = mycustomview() myview.frame = cgrect(x: 100, y: 100, width: 50, height: 50)  goalkicker.com – ios® developer notes for professionals  301  myview.backgroundcolor = uicolor.yellowcolor() view.addsubview(myview) }  we get...  hmm, that's a little small because i hardcoded all the numbers in. i can scale the path size up, though, like this: let path = createbezierpath() let scale = cgaffinetransformmakescale(2, 2) path.applytransform(scale) shapelayer.path = path.cgpath  method 2: draw path in drawrect using drawrect is slower than drawing to the layer, so this is not the recommended method if you don't need it. here is the revised code for our custom view: import uikit class mycustomview: uiview { override func drawrect(rect: cgrect) { // create path (see previous code) let path = createbezierpath() // fill let fillcolor = uicolor.whitecolor() fillcolor.setfill() // stroke path.linewidth = 1.0 let strokecolor = uicolor.bluecolor()  goalkicker.com – ios® developer notes for professionals  302  strokecolor.setstroke() // move the path to a new location path.applytransform(cgaffinetransformmaketranslation(10, 10)) // fill and stroke the path (always do these last) path.fill() path.stroke() } func createbezierpath() -> uibezierpath { // see previous code for creating the bezier path } }  which gives us the same result...  further study excellent articles for understanding bezier paths. thinking like a bézier path (everything i've ever read from this author is good and the inspiration for my example above came from here.) coding math: episode 19 - bezier curves (entertaining and good visual illustrations) bezier curves (how they are used in graphics applications) bezier curves (good description of how the mathematical formulas are derived) notes this example originally comes from this stack overﬂow answer. in your actual projects you probably shouldn't use hard coded numbers, but rather get the sizes from your view's bounds.  section 53.2: how to apply corner radius to rectangles drawn by uibezierpath corner radius for all 4 edges:  goalkicker.com – ios® developer notes for professionals  303  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) cornerradius: 11]; [uicolor.graycolor setfill]; [rectanglepath fill];  corner radius for top-left edge:  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) byroundingcorners: uirectcornertopleft cornerradii: cgsizemake(11, 11)]; [rectanglepath closepath]; [uicolor.graycolor setfill]; [rectanglepath fill];  corner radius for top-right edge:  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) byroundingcorners: uirectcornertopright cornerradii: cgsizemake(11, 11)]; [rectanglepath closepath]; [uicolor.graycolor setfill]; [rectanglepath fill];  corner radius for bottom-left edge:  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) byroundingcorners: uirectcornerbottomleft cornerradii: cgsizemake(11, 11)]; [rectanglepath closepath]; [uicolor.graycolor setfill]; [rectanglepath fill];  corner radius for bottom-right edge:  goalkicker.com – ios® developer notes for professionals  304  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) byroundingcorners: uirectcornerbottomright cornerradii: cgsizemake(11, 11)]; [rectanglepath closepath]; [uicolor.graycolor setfill]; [rectanglepath fill];  corner radius for bottom edges:  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) byroundingcorners: uirectcornerbottomleft | uirectcornerbottomright cornerradii: cgsizemake(11, 11)]; [rectanglepath closepath]; [uicolor.graycolor setfill]; [rectanglepath fill];  corner radius for top edges:  uibezierpath* rectanglepath = [uibezierpath bezierpathwithroundedrect: cgrectmake(x,y,width,height) byroundingcorners: uirectcornertopleft | uirectcornertopright cornerradii: cgsizemake(11, 11)]; [rectanglepath closepath]; [uicolor.graycolor setfill]; [rectanglepath fill];  section 53.3: how to apply shadows to uibezierpath consider a simple rectangle that is drawn by the bezier path.  goalkicker.com – ios® developer notes for professionals  305  uibezierpath* rectanglepath = [uibezierpath bezierpathwithrect: cgrectmake(x,y,width,height)]; [uicolor.graycolor setfill]; [rectanglepath fill];  basic outer-ﬁll shadow:  cgcontextref context = uigraphicsgetcurrentcontext(); nsshadow* shadow = [[nsshadow alloc] init]; [shadow setshadowcolor: uicolor.blackcolor]; [shadow setshadowoffset: cgsizemake(7.1, 5.1)]; [shadow setshadowblurradius: 5]; uibezierpath* rectanglepath = [uibezierpath bezierpathwithrect: cgrectmake(x,y,width,height)]; cgcontextsavegstate(context); cgcontextsetshadowwithcolor(context, shadow.shadowoffset, shadow.shadowblurradius, [shadow.shadowcolor cgcolor]); [uicolor.graycolor setfill]; [rectanglepath fill]; cgcontextrestoregstate(context);  basic inner ﬁll shadow:  cgcontextref context = uigraphicsgetcurrentcontext(); nsshadow* shadow = [[nsshadow alloc] init]; [shadow setshadowcolor: uicolor.blackcolor]; [shadow setshadowoffset: cgsizemake(9.1, -7.1)]; [shadow setshadowblurradius: 6];  goalkicker.com – ios® developer notes for professionals  306  uibezierpath* rectanglepath = [uibezierpath bezierpathwithrect: cgrectmake(x,y,width,height)]; [uicolor.graycolor setfill]; [rectanglepath fill]; cgcontextsavegstate(context); uirectclip(rectanglepath.bounds); cgcontextsetshadowwithcolor(context, cgsizezero, 0, null); cgcontextsetalpha(context, cgcolorgetalpha([shadow.shadowcolor cgcolor])); cgcontextbegintransparencylayer(context, null); { uicolor* opaqueshadow = [shadow.shadowcolor colorwithalphacomponent: 1]; cgcontextsetshadowwithcolor(context, shadow.shadowoffset, shadow.shadowblurradius, [opaqueshadow cgcolor]); cgcontextsetblendmode(context, kcgblendmodesourceout); cgcontextbegintransparencylayer(context, null); [opaqueshadow setfill]; [rectanglepath fill]; cgcontextendtransparencylayer(context); } cgcontextendtransparencylayer(context); cgcontextrestoregstate(context);  section 53.4: how to create a simple shapes using uibezierpath for a simple circle:  uibezierpath* ovalpath = [uibezierpath bezierpathwithovalinrect: cgrectmake(0,0,50,50)]; [uicolor.graycolor setfill]; [ovalpath fill];  swift: let ovalpath = uibezierpath(ovalinrect: cgrect(x: 0, y: 0, width: 50, height: 50)) uicolor.graycolor().setfill() ovalpath.fill()  for a simple rectangle:  goalkicker.com – ios® developer notes for professionals  307  uibezierpath* rectanglepath = [uibezierpath bezierpathwithrect: cgrectmake(0,0,50,50)]; [uicolor.graycolor setfill]; [rectanglepath fill];  swift: let rectanglepath = uibezierpath(rect: cgrect(x: 0, y: 0, width: 50, height: 50)) uicolor.graycolor().setfill() rectanglepath.fill()  for a simple line:  uibezierpath* bezierpath = [uibezierpath bezierpath]; [bezierpath movetopoint: cgpointmake(x1,y1)]; [bezierpath addlinetopoint: cgpointmake(x2,y2)]; [uicolor.blackcolor setstroke]; bezierpath.linewidth = 1; [bezierpath stroke];  swift: let bezierpath = uibezierpath() bezierpath.movetopoint(cgpoint(x: x1, y: y1)) bezierpath.addlinetopoint(cgpoint(x: x2, y: y2)) uicolor.blackcolor().setstroke() bezierpath.linewidth = 1 bezierpath.stroke()  for a half circle:  cgrect ovalrect = cgrectmake(x,y,width,height); uibezierpath* ovalpath = [uibezierpath bezierpath]; [ovalpath addarcwithcenter: cgpointmake(0, 0) radius: cgrectgetwidth(ovalrect) / 2 startangle: 180 * m_pi/180 endangle: 0 * m_pi/180 clockwise: yes]; [ovalpath addlinetopoint: cgpointmake(0, 0)]; [ovalpath closepath]; cgaffinetransform ovaltransform = cgaffinetransformmaketranslation(cgrectgetmidx(ovalrect), cgrectgetmidy(ovalrect)); ovaltransform = cgaffinetransformscale(ovaltransform, 1, cgrectgetheight(ovalrect) / cgrectgetwidth(ovalrect));  goalkicker.com – ios® developer notes for professionals  308  [ovalpath applytransform: ovaltransform]; [uicolor.graycolor setfill]; [ovalpath fill];  swift: let ovalrect = cgrect(x: 0, y: 0, width: 50, height: 50) let ovalpath = uibezierpath() ovalpath.addarcwithcenter(cgpoint.zero, radius: ovalrect.width / 2, startangle: 180 * cgfloat(m_pi)/180, endangle: 0 * cgfloat(m_pi)/180, clockwise: true) ovalpath.addlinetopoint(cgpoint.zero) ovalpath.closepath() var ovaltransform = cgaffinetransformmaketranslation(cgrectgetmidx(ovalrect), cgrectgetmidy(ovalrect)) ovaltransform = cgaffinetransformscale(ovaltransform, 1, ovalrect.height / ovalrect.width) ovalpath.applytransform(ovaltransform) uicolor.graycolor().setfill() ovalpath.fill()  for a simple triangle:  uibezierpath* polygonpath = [uibezierpath bezierpath]; [polygonpath movetopoint: cgpointmake(x1, y1)]; [polygonpath addlinetopoint: cgpointmake(x2, y2)]; [polygonpath addlinetopoint: cgpointmake(x3, y2)]; [polygonpath closepath]; [uicolor.graycolor setfill]; [polygonpath fill];  swift: let polygonpath = uibezierpath() polygonpath.movetopoint(cgpoint(x: x1, y: y1)) polygonpath.addlinetopoint(cgpoint(x: x2, y: y2)) polygonpath.addlinetopoint(cgpoint(x: x3, y: y3)) polygonpath.closepath() uicolor.graycolor().setfill() polygonpath.fill()  section 53.5: uibezierpath + autolayout for bezier path to get resized based on the view frame, override the drawrect of view that you are drawing the bezier path : - (void)drawrect:(cgrect)frame { uibezierpath* rectanglepath = [uibezierpath bezierpathwithrect: cgrectmake(cgrectgetminx(frame), cgrectgetminy(frame), cgrectgetwidth(frame), cgrectgetheight(frame))];  goalkicker.com – ios® developer notes for professionals  309  [uicolor.graycolor setfill]; [rectanglepath fill]; }  section 53.6: pie view & column view with uibezierpath pie view  - (void)drawrect:(cgrect)rect { nsarray *data = @[@30, @15, @5, @17, @3, @10, @20]; // 1. context cgcontextref cxtref = uigraphicsgetcurrentcontext(); cgpoint center = cgpointmake(150, 150); cgfloat radius = 150; __block cgfloat startangle = 0; [data enumerateobjectsusingblock:^(nsnumber * _nonnull obj, nsuinteger idx, bool * _nonnull stop) { // 2. create path cgfloat endangle = obj.floatvalue / 100 * m_pi * 2 + startangle; uibezierpath *circlepath = [uibezierpath bezierpathwitharccenter:center radius:radius startangle:startangle endangle:endangle clockwise:yes]; [circlepath addlinetopoint:center]; // 3. add path cgcontextaddpath(cxtref, circlepath.cgpath); // set color [[uicolor colorwithred:((float)arc4random_uniform(256) / 255.0) green:((float)arc4random_uniform(256) / 255.0) blue:((float)arc4random_uniform(256) / 255.0) alpha:1.0] setfill]; // 4. render cgcontextdrawpath(cxtref, kcgpathfill); // reset angle startangle = endangle; }]; } override func draw(_ rect: cgrect) { // define data to create pie chart let data: [int] = [30, 15, 5, 17, 3, 10, 20] // 1. find center of draw rect  goalkicker.com – ios® developer notes for professionals  310  let center: cgpoint = cgpoint(x: rect.midx, y: rect.midy) // 2. calculate radius of pie let radius = min(rect.width, rect.height) / 2.0 var startangle: cgfloat = 0.0 for value in data { // 3. calculate end angle for slice let endangle = cgfloat(value) / 100.0 * cgfloat.pi * 2.0 + startangle // 4. create uibezierpath for slide let circlepath = uibezierpath(arccenter: center, radius: radius, startangle: startangle, endangle: endangle, clockwise: true) // 5. add line to center to close path circlepath.addline(to: center) // 6. set fill color for current slice uicolor(red: (cgfloat(arc4random_uniform(256)) / 255.0), green: (cgfloat(arc4random_uniform(256)) / 255.0), blue: (cgfloat(arc4random_uniform(256)) / 255.0), alpha: 1.0).setfill() // 7. fill slice path circlepath.fill() // 8. set end angle as start angle for next slice startangle = endangle } }  column view  - (void)drawrect:(cgrect)rect { nsarray *data = @[@300, @150.65, @55.3, @507.7, @95.8, @700, @650.65]; // 1. cgcontextref cxtref = uigraphicsgetcurrentcontext(); nsinteger columncount = 7; cgfloat width = self.bounds.size.width / (columncount + columncount - 1); for (nsinteger i = 0; i < columncount; i++) { // 2. cgfloat height = [data[i] floatvalue] / 1000 * self.bounds.size.height; // floatvalue cgfloat x = 0 + width * (2 * i); cgfloat y = self.bounds.size.height - height; uibezierpath *rectpath = [uibezierpath bezierpathwithrect:cgrectmake(x, y, width, height)];  goalkicker.com – ios® developer notes for professionals  311  cgcontextaddpath(cxtref, rectpath.cgpath); // 3. [[uicolor colorwithred:((float)arc4random_uniform(256) / 255.0) green:((float)arc4random_uniform(256) / 255.0) blue:((float)arc4random_uniform(256) / 255.0) alpha:1.0] setfill]; cgcontextdrawpath(cxtref, kcgpathfill); } } override func draw(_ rect: cgrect) { // define data for chart let data: [cgfloat] = [300, 150.65, 55.3, 507.7, 95.8, 700, 650.65] // 1. calculate number of columns let columncount = data.count // 2. calculate column width let columnwidth = rect.width / cgfloat(columncount + columncount - 1) for (columnindex, value) in data.enumerated() { // 3. calculate column height let columnheight = value / 1000.0 * rect.height // 4. calculate column origin let columnorigin = cgpoint(x: (columnwidth * 2.0 * cgfloat(columnindex)), y: (rect.height columnheight)) // 5. create path for column let columnpath = uibezierpath(rect: cgrect(origin: columnorigin, size: cgsize(width: columnwidth, height: columnheight))) // 6. set fill color for current column uicolor(red: (cgfloat(arc4random_uniform(256)) / 255.0), green: (cgfloat(arc4random_uniform(256)) / 255.0), blue: (cgfloat(arc4random_uniform(256)) / 255.0), alpha: 1.0).setfill() // 7. fill column path columnpath.fill() } }  goalkicker.com – ios® developer notes for professionals  312",t_17bf2af6d82b,t_17bf2af6d82b,2
c_c38536b4a5ac,"chapter 155 of the book on ios developer.chapter 155: navigation bar section 155.1: swift example navigationcontroller?.navigationbar.titletextattributes = [nsforegroundcolorattributename: uicolor.white, nsfontattributename:uifont(name: ""helveticaneue-condensedbold"", size: 17)!,] navigationcontroller?.navigationbar.tintcolor = .white navigationcontroller?.navigationbar.bartintcolor = .red navigationcontroller?.navigationbar.istranslucent = false navigationcontroller?.navigationbar.barstyle = .black  section 155.2: customize default navigation bar appearance // default uinavigationbar appearance throughout the app [[uinavigationbar appearance] settitletextattributes:@{nsforegroundcolorattributename: [uicolor whitecolor], nsfontattributename : [uifont fontwithname:@""helveticaneue-condensedbold"" size:17], }]; [[uinavigationbar [[uinavigationbar [[uinavigationbar [[uinavigationbar [[uibarbuttonitem knggray]];  appearance] settintcolor:[uicolor whitecolor]]; appearance] setbartintcolor:[uicolor kngred]]; appearance] settranslucent:no]; appearance] setbarstyle:uibarstyleblack]; appearancewhencontainedin: [uisearchbar class], nil] settintcolor:[uicolor  goalkicker.com – ios® developer notes for professionals  723",t_17bf2af6d82b,t_17bf2af6d82b,2
c_eecac2b3473a,"chapter 100 of the book on ios developer.chapter 100: pdf creation in ios section 100.1: create pdf uigraphicsbeginpdfcontexttofile(filename, cgrectzero, nil); uigraphicsbeginpdfpagewithinfo(cgrectmake(0, 0, 612, 792), nil); [self drawtext]; uigraphicsendpdfcontext();  ﬁlename is the document ﬁle where you are going to append or attach nsstring* temporaryfile = @""firstios.pdf""; nsarray *arraypaths = nssearchpathfordirectoriesindomains( nsdocumentdirectory, nsuserdomainmask, yes); nsstring *path = [arraypaths objectatindex:0]; nsstring* filename = [path stringbyappendingpathcomponent:filename];  where drawtext is (void)drawtext { nsstring* texttodraw = @""lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.""; cfstringref stringref = (__bridge cfstringref)texttodraw; cfattributedstringref currenttext = cfattributedstringcreate(null, stringref, null); ctframesetterref framesetter = ctframesettercreatewithattributedstring(currenttext); cgrect framerect = cgrectmake(0, 0, 300, 100); cgmutablepathref framepath = cgpathcreatemutable(); cgpathaddrect(framepath, null, framerect); cfrange currentrange = cfrangemake(0, 0); ctframeref frameref = ctframesettercreateframe(framesetter, currentrange, framepath, null); cgpathrelease(framepath); cgcontextref currentcontext = uigraphicsgetcurrentcontext();  cgcontextsettextmatrix(currentcontext, cgaffinetransformidentity);  cgcontexttranslatectm(currentcontext, 0, 450); cgcontextscalectm(currentcontext, 2, -2);  goalkicker.com – ios® developer notes for professionals  544  ctframedraw(frameref, currentcontext); cfrelease(frameref); cfrelease(stringref); cfrelease(framesetter); }  section 100.2: show pdf nsstring* filename = @""firstios.pdf"";  nsarray *arraypaths = nssearchpathfordirectoriesindomains( nsdocumentdirectory, nsuserdomainmask, yes); nsstring *path = [arraypaths objectatindex:0]; nsstring* pdffilename = [path stringbyappendingpathcomponent:filename]; uiwebview* webview = [[uiwebview alloc] initwithframe:cgrectmake(0, 0, 320, 480)]; nsurl *url = [nsurl fileurlwithpath:pdffilename]; nsurlrequest *request = [nsurlrequest requestwithurl:url];  goalkicker.com – ios® developer notes for professionals  545  [webview setscalespagetofit:yes]; [webview loadrequest:request]; [self.view addsubview:webview];  section 100.3: multiple page pdf uigraphicsbeginpdfcontexttofile(filename, cgrectzero, nil); uigraphicsbeginpdfpagewithinfo(cgrectmake(0, 0, 600, 792), nil); uigraphicsbeginpdfpagewithinfo(cgrectmake(0, 0, 600, 792), nil); uigraphicsbeginpdfpagewithinfo(cgrectmake(0, 0, 600, 792), nil); uigraphicsendpdfcontext();  section 100.4: create pdf from any microsoft document loaded in uiwebview #define kpapersizea4 cgsizemake(595.2,841.8)  first of all implement uiprintpagerenderer protocol @interface uiprintpagerenderer (pdf) - (nsdata*) printtopdf; @end @implementation uiprintpagerenderer (pdf) - (nsdata*) printtopdf { nsmutabledata *pdfdata = [nsmutabledata data]; uigraphicsbeginpdfcontexttodata( pdfdata, self.paperrect, nil ); [self preparefordrawingpages: nsmakerange(0, self.numberofpages)]; cgrect bounds = uigraphicsgetpdfcontextbounds(); for ( int i = 0 ; i < self.numberofpages ; i++ ) { uigraphicsbeginpdfpage(); [self drawpageatindex: i inrect: bounds]; } uigraphicsendpdfcontext(); return pdfdata; } @end  then, call below method after document ﬁnished loading in uiwebview -(void)createpdf:(uiwebview *)webview { uiprintpagerenderer *render = [[uiprintpagerenderer alloc] init]; [render addprintformatter:webview.viewprintformatter startingatpageatindex:0]; float padding = 10.0f; cgrect paperrect = cgrectmake(0, 0, kpapersizea4.width, kpapersizea4.height);  goalkicker.com – ios® developer notes for professionals  546  cgrect printablerect = cgrectmake(padding, padding, kpapersizea4.width-(padding * 2), kpapersizea4.height-(padding * 2)); [render setvalue:[nsvalue valuewithcgrect:paperrect] forkey:@""paperrect""]; [render setvalue:[nsvalue valuewithcgrect:printablerect] forkey:@""printablerect""]; nsdata *pdfdata = [render printtopdf]; dispatch_async(dispatch_get_global_queue(dispatch_queue_priority_default, 0), ^{ if (pdfdata) { [pdfdata writetofile:directorypath atomically: yes]; } else { nslog(@""pdf couldnot be created""); } });}  goalkicker.com – ios® developer notes for professionals  547",t_17bf2af6d82b,t_17bf2af6d82b,2
c_e7c8b6d7fb31,"chapter 83 of the book on ios developer.chapter 83: nspredicate section 83.1: form validation using nspredicate nsstring *emailregex = @""[a-z0-9a-z]([a-z0-9a-z._-]{0,64})+[a-z0-9a-z]+@[a-z0-9a-z]+([a-za-z0-9.]{0,64})+([a-z0-9a-z])+\\.[a-za-z]{2,4}""; nsstring *firstnameregex = @""[0-9a-za-z\""'-]{2,32}$""; nsstring *firstnameregex = @""[ 0-9a-za-z]{2,32}$""; nsstring *lastnameregex = @""[0-9a-za-z\""'-]{2,32}$""; nsstring *mobilenumberregex = @""^[0-9]{10}$""; nsstring *zipcoderegex = @""^[0-9]{5}$""; nsstring *ssnregex = @""^\\d{3}-?\\d{2}-?\\d{4}$""; nsstring *addressregex = @""^[ a-za-z0-9]{2,32}$""; nsstring *cityregex = @""^[ a-za-z0-9]{2,25}$""; nsstring *pinregex = @""^[0-9]{4}$""; nsstring *driversliscregex = @""^[0-9a-za-z]{5,20}$""; -(bool)validateemail { //email address field should give an error when the email address begins with ""."",""-"",""_"" . nspredicate *emailpredicate = [nspredicate predicatewithformat:@""self matches %@"", emailregex]; return ([emailpredicate evaluatewithobject:self.text] && self.text.length <= 64 && ([self.text rangeofstring:@""..""].location == nsnotfound)); } - (bool)validatefirstname { nspredicate *firstnamepredicate = [nspredicate predicatewithformat:@""self matches %@"", firstnameregex]; return [firstnamepredicate evaluatewithobject:self.text]; } - (bool)validatelastname { nspredicate *lastnamepredicate = [nspredicate predicatewithformat:@""self matches %@"", lastnameregex]; return [lastnamepredicate evaluatewithobject:self.text]; } - (bool)validatealphanumericmin2max32 { nspredicate *firstnamepredicate = [nspredicate predicatewithformat:@""self matches %@"", firstnameregex]; return [firstnamepredicate evaluatewithobject:self.text]; } - (bool)validatemobilenumber { nsstring *strippedmobilenumber = withstring:@""""]  [[[[self.text stringbyreplacingoccurrencesofstring:@""("" stringbyreplacingoccurrencesofstring:@"")"" withstring:@""""] stringbyreplacingoccurrencesofstring:@""-"" withstring:@""""] stringbyreplacingoccurrencesofstring:@"" "" withstring:@""""];  nspredicate *mobilenumberpredicate = [nspredicate predicatewithformat:@""self matches %@"", mobilenumberregex]; return [mobilenumberpredicate evaluatewithobject:strippedmobilenumber]; } - (bool)validatezipcode { nspredicate *zipcodepredicate = [nspredicate predicatewithformat:@""self matches %@"", zipcoderegex]; return [zipcodepredicate evaluatewithobject:self.text];  goalkicker.com – ios® developer notes for professionals  487  } - (bool)validatessn { nspredicate *predicate = [nspredicate predicatewithformat:@""self matches %@"", ssnregex]; return [predicate evaluatewithobject:self.text]; } - (bool)validateaddress { nspredicate *predicate = [nspredicate predicatewithformat:@""self matches %@"", addressregex]; return [predicate evaluatewithobject:self.text]; } - (bool)validatecity { nspredicate *predicate = [nspredicate predicatewithformat:@""self matches %@"", cityregex]; return [predicate evaluatewithobject:self.text]; } - (bool)validatepin { nspredicate *predicate = [nspredicate predicatewithformat:@""self matches %@"", pinregex]; return [predicate evaluatewithobject:self.text]; } - (bool)validatedriversliscnumber { if([self.text length] > 20) { return no; } nspredicate *driversliscpredicate = [nspredicate predicatewithformat:@""self matches %@"", driversliscregex]; return [driversliscpredicate evaluatewithobject:self.text]; }  section 83.2: creating an nspredicate using predicatewithblock objective-c nspredicate *predicate = [nspredicate predicatewithblock:^bool(id item, nsdictionary *bindings) { return [item iskindofclass:[uilabel class]]; }];  swift let predicate = nspredicate { (item, bindings) -> bool in return item.iskindofclass(uilabel.self) }  in this example, the predicate will match items that are of the class uilabel.  section 83.3: creating an nspredicate using predicatewithformat objective-c nspredicate *predicate = [nspredicate predicatewithformat: @""self[size] = %d"", 5)];  swift  goalkicker.com – ios® developer notes for professionals  488  let predicate = nspredicate(format: ""self[size] >= %d"", 5)  in this example, the predicate will match items that are arrays with length of at least 5.  section 83.4: creating an nspredicate with substitution variables an nspredicate can use substitution variables to allow values to be bound on the ﬂy. objective-c nspredicate *template = [nspredicate predicatewithformat: @""self beginswith $letter""]; nsdictionary *variables = @{ @""letter"": @""r"" }; nspredicate *beginswithr = [template predicatewithsubstitutionvariables: variables];  swift let template = nspredicate(format: ""self beginswith $letter"") let variables = [""letter"": ""r""] let beginswithr = template.predicatewithsubstitutionvariables(variables)  the template predicate is not modiﬁed by predicatewithsubstitutionvariables. instead, a copy is created, and that copy receives the substitution variables.  section 83.5: nspredicate with `and`, `or` and `not` condition conditional predicate will be cleaner and safer by using the nscompoundpredicate class which provides basic boolean operators for the given predicates. objective-c and - condition nspredicate *predicate = [nspredicate predicatewithformat:@""samplepredicate""]; nspredicate *anotherpredicate = [nspredicate predicatewithformat:@""anotherpredicate""]; nspredicate *combinedpredicate = [nscompoundpredicate andpredicatewithsubpredicates: @[predicate,anotherpredicate]];  or - condition nspredicate *predicate = [nspredicate predicatewithformat:@""samplepredicate""]; nspredicate *anotherpredicate = [nspredicate predicatewithformat:@""anotherpredicate""]; nspredicate *combinedpredicate = [nscompoundpredicate orpredicatewithsubpredicates: @[predicate,anotherpredicate]];  not - condition nspredicate *predicate = [nspredicate predicatewithformat:@""samplepredicate""]; nspredicate *anotherpredicate = [nspredicate predicatewithformat:@""anotherpredicate""]; nspredicate *combinedpredicate = [nscompoundpredicate notpredicatewithsubpredicate: @[predicate,anotherpredicate]];  section 83.6: using nspredicate to filter an array objective-c nsarray *heroes = @[@""tracer"", @""bastion"", @""reaper"", @""junkrat"", @""roadhog""]; nspredicate *template = [nspredicate predicatewithformat:@""self beginswith $letter""];  goalkicker.com – ios® developer notes for professionals  489  nsdictionary *beginswithrvariables = @{ @""letter"": @""r""}; nspredicate *beginswithr = [template predicatewithsubstitutionvariables: beginswithrvariables]; nsarray *beginswithrheroes = [heroes filteredarrayusingpredicate: beginswithr]; // [""reaper"", ""roadhog""] nsdictionary *beginswithtvariables = @{ @""letter"": @""t""}; nspredicate *beginswitht = [template predicatewithsubstitutionvarables: beginswithtvariables]; nsarray *beginswiththeroes = [heroes filteredarrayusingpredicate: beginswitht]; // [""tracer""]  swift let heroes = [""tracer"", ""bastion"", ""reaper"", ""junkrat"", ""roadhog""] let template = nspredicate(format: ""self beginswith $letter"") let beginswithrvariables = [""letter"": ""r""] let beginswithr = template.predicatewithsubstitutionvariables(beginswithrvariables) let beginswithrheroes = heroes.filter { beginswithr.evaluatewithobject($0) } // [""reaper"", ""roadhog""] let beginswithtvariables = [""letter"": ""t""] let beginswitht = template.predicatewithsubstitutionvariables(beginswithtvariables) let beginswiththeroes = heroes.filter { beginswitht.evaluatewithobject($0) } // [""tracer""]  goalkicker.com – ios® developer notes for professionals  490",t_17bf2af6d82b,t_17bf2af6d82b,2
c_28a34caba5dd,"chapter 188 of the book on ios developer.chapter 188: mvp architecture components:  model is an interface responsible for the domain data (to be displayed or otherwise acted upon in the gui) view is responsible for the presentation layer (gui) presenter is the ""middle-man"" between model and view. it reacts to the user’s actions performed on the view, retrieves data from the model, and formats it for display in the view component duties: model view communicates with db layer renders data  presenter performs queries to the model  raising appropriate events  formats data from model  receives events  very basic validation logic sends formatted data to the view complex validation logic  diﬀerences between mvc and mvp: view in mvc is tightly coupled with the controller, the view part of the mvp consists of both uiviews and uiviewcontroller mvp view is as dumb as possible and contains almost no logic (like in mvvm), mvc view has some business logic and can query the model mvp view handles user gestures and delegates interaction to the presenter, in mvc the controller handles gestures and commands model mvp pattern highly supports unit testing, mvc has limited support mvc controller has lots of uikit dependencies, mvp presenter has none pros: mvp makes uiviewcontroller a part of the view component it's dumb, passive and...less massive ;] most of the business logic is incapsulated due to the dumb views, this gives an excellent testability. mock objects can be introduced to test the domain part. separated entities are easier to keep in head, responsibilities are clearly divided. cons you will write more code. barrier for unexperienced developers or for those who don't yet work with the pattern.  goalkicker.com – ios® developer notes for professionals  796  mvp is an architectural pattern, a derivation of the model–view–controller. it's represented by three distinct components: model, view and the presenter. it was engineered to facilitate automated unit testing and improve the separation of concerns in presentation logic. in examples you'll ﬁnd a simple project built with mvp pattern in mind.  section 188.1: dog.swift import foundation enum breed: string { case bulldog = ""bulldog"" case doberman = ""doberman"" case labrador = ""labrador"" } struct dog { let name: string let breed: string let age: int }  section 188.2: doggyservice.swift import foundation typealias result = ([dog]) -> void class doggyservice { func deliverdoggies(_ result: @escaping result) { let firstdoggy = dog(name: ""alfred"", breed: breed.labrador.rawvalue, age: 1) let seconddoggy = dog(name: ""vinny"", breed: breed.doberman.rawvalue, age: 5) let thirddoggy = dog(name: ""lucky"", breed: breed.labrador.rawvalue, age: 3) let delay = dispatchtime.now() + double(int64(double(nsec_per_sec)*2)) / double(nsec_per_sec) dispatchqueue.main.asyncafter(deadline: delay) { result([firstdoggy, seconddoggy, thirddoggy]) } } }  section 188.3: doggypresenter.swift import foundation class doggypresenter { // mark: - private fileprivate let dogservice: doggyservice weak fileprivate var dogview: doggyview? init(dogservice: doggyservice){  goalkicker.com – ios® developer notes for professionals  797  self.dogservice = dogservice } func attachview(_ attach: bool, view: doggyview?) { if attach { dogview = nil } else { if let view = view { dogview = view } } } func getdogs(){ self.dogview?.startloading() dogservice.deliverdoggies { [weak self] doggies in self?.dogview?.finishloading() if doggies.count == 0 { self?.dogview?.setempty() } else { self?.dogview?.setdoggies(doggies.map { return doggyviewdata(name: ""\($0.name) \($0.breed)"", age: ""\($0.age)"") }) } } } } struct doggyviewdata { let name: string let age: string }  section 188.4: doggyview.swift import foundation protocol func func func func }  doggyview: nsobjectprotocol { startloading() finishloading() setdoggies(_ doggies: [doggyviewdata]) setempty()  section 188.5: doggylistviewcontroller.swift import uikit class doggylistviewcontroller: uiviewcontroller, uitableviewdatasource { @iboutlet weak var emptyview: uiview? @iboutlet weak var tableview: uitableview? @iboutlet weak var spinner: uiactivityindicatorview? fileprivate let dogpresenter = doggypresenter(dogservice: doggyservice()) fileprivate var dogstodisplay = [doggyviewdata]() override func viewdidload() { super.viewdidload()  goalkicker.com – ios® developer notes for professionals  798  tableview?.datasource = self spinner?.hideswhenstopped = true dogpresenter.attachview(true, view: self) dogpresenter.getdogs() } // mark: datasource func tableview(_ tableview: uitableview, numberofrowsinsection section: int) -> int { return dogstodisplay.count } func tableview(_ tableview: uitableview, cellforrowat indexpath: indexpath) -> uitableviewcell { let cell = uitableviewcell(style: .subtitle, reuseidentifier: ""cell"") let userviewdata = dogstodisplay[indexpath.row] cell.textlabel?.text = userviewdata.name cell.detailtextlabel?.text = userviewdata.age return cell } } extension doggylistviewcontroller: doggyview { func startloading() { spinner?.startanimating() } func finishloading() { spinner?.stopanimating() } func setdoggies(_ doggies: [doggyviewdata]) { dogstodisplay = doggies tableview?.ishidden = false emptyview?.ishidden = true; tableview?.reloaddata() } func setempty() { tableview?.ishidden = true emptyview?.ishidden = false; } }  goalkicker.com – ios® developer notes for professionals  799",t_17bf2af6d82b,t_17bf2af6d82b,2
c_a84668082ebc,"chapter 20 of the book on ios developer.chapter 20: uiview section 20.1: make the view rounded to make a rounded uiview, specify a cornerradius for the view's layer. this also applies any class which inherits from uiview, such as uiimageview. programmatically swift code someimageview.layoutifneeded() someimageview.clipstobounds = true someimageview.layer.cornerradius = 10  objective-c code [someimageview layoutifneeded]; someimageview.clipstobounds = yes; someimageview.layer.cornerradius = 10;  example //swift code topimageview.layoutifneeded() bottomimageview.layoutifneeded() topimageview.clipstobounds = true topimageview.layer.cornerradius = 10 bottomimageview.clipstobounds = true bottomimageview.layer.cornerradius = bottomimageview.frame.width / 2 //objective-c code [topimageview layoutifneeded] [bottomimageview layoutifneeded]; topimageview.clipstobounds = yes; topimageview.layer.cornerradius = 10; bottomimageview.clipstobounds = yes; bottomimageview.cornerradius = cgrectgetwidth(bottomimageview.frame) / 2;  here is the result, showing the rounded view eﬀect using the speciﬁed corner radius:  goalkicker.com – ios® developer notes for professionals  116  note to do this you need to include the quartzcore framework. #import <quartzcore/quartzcore.h>  storyboard conﬁguration a rounded view eﬀect can also be achieved non-programmatically by setting the corresponding properties in storyboard.  since layer properties aren't exposed in storyboard, you have to modify the cornerradius attribute via the user deﬁned runtime attributes section.  goalkicker.com – ios® developer notes for professionals  117  swift extension you can use this handy extension to apply rounded view as long as it has same width and height. extension uiview { @discardableresult public func setascircle() -> self { self.clipstobounds = true let framesize = self.frame.size self.layer.cornerradius = min(framesize.width, framesize.height) / 2.0 return self } }  to use it: yourview.setascircle()  section 20.2: using ibinspectable and ibdesignable one (or two) of the coolest new features in recent xcode releases are the ibinspectable properties and ibdesignable uiviews. these have nothing to do with the functionality of your application but instead impact the  developer experience in xcode. the goal is to be able to visually inspect custom views in your ios application without running it. so assume that you have a custom view creatively named customview that inherits from uiview. in this custom view, it will display a string of text with a designated color. you can also choose not to display any text. we'll need three properties: var textcolor: uicolor = uicolor.blackcolor() var text: string? var showtext: bool = true  we can then override the drawrect function in the class: if showtext { if let text = text { let s = nsstring(string: text) s.drawinrect(rect,  goalkicker.com – ios® developer notes for professionals  118  withattributes: [ nsforegroundcolorattributename: textcolor, nsfontattributename: uifont(name: ""helvetica neue"", size: 18)! ]) } }  assuming that the text property is set, this will draw a string in the upper left hand corner of the view when the application is run. the problem is we won't know what it looks like without running the application. this is where ibinspectable and ibdesignable come in. ibinspectable allows us to visually set property values of the view in  xcode, just like with the built in controls. ibdesignable will show us a visual preview in the storyboard. here is how the class should look: @ibdesignable class customview: uiview { @ibinspectable var textcolor: uicolor = uicolor.blackcolor() @ibinspectable var text: string? @ibinspectable var showtext: bool = true override func drawrect(rect: cgrect) { // ... } }  or in objective c: ib_designable @interface customview: uiview @property (nonatomic, strong) ibinspectable uicolor* textcolor; @property (nonatomic, strong) ibinspectable nsstring* text; @property (nonatomic, assign) ibinspectable bool showtext; @end @implementation customview - (instancetype)init { if(self = [super init]) { self.textcolor = [uicolor blackcolor]; self.showtext = yes; } return self; } - (void)drawrect:(cgrect)rect { //... } @end  the next screenshots show what happens in xcode. the ﬁrst one is what happens after adding the revised class. notice that there are three new ui elements for the three properties. the text color will display a color picker, text is just an input box and show text will give us the options for off and on which are false and true respectively.  goalkicker.com – ios® developer notes for professionals  119  the next is after changing the text color to red using the color picker. also, some text has been provided to make the drawrect function display it. notice that the view in interface builder has been updated as well.  finally, setting show text to off in the property inspector makes the text display in interface builder disappear.  however, we all come up situation when we need to create rounded uiview at multiple views in your storyboard.instead of declaring ibdesignable to every views of storyboard, its better to create an extension of uiview and get a user interface built just for your every uiview through out the project to create rounded view by  setting corner radius.a conﬁgurable border radius on any uiview you create in storyboard. extension uiview { @ibinspectable var cornerradius:cgfloat { set { layer.cornerradius = newvalue clipstobounds = newvalue > 0 } get { return layer.cornerradius } }  goalkicker.com – ios® developer notes for professionals  120  }  section 20.3: taking a snapshot you can take a snapshot from a uiview like this: swift let snapshot = view.snapshotview(afterscreenupdates: true)  objective-c uiview *snapshot = [view snapshotviewafterscreenupdates: yes];  section 20.4: create a uiview objective-c cgrect myframe = cgrectmake(0, 0, 320, 35) uiview *view = [[uiview alloc] initwithframe:myframe]; //alternative way of defining the frame uiview *view = [[uiview alloc] init]; cgrect myframe = view.frame; myframe.size.width = 320; myframe.size.height = 35; myframe.origin.x = 0; myframe.origin.y = 0; view.frame = myframe;  swift let myframe = cgrect(x: 0, y: 0, width: 320, height: 35) let view = uiview(frame: myframe)  section 20.5: shake a view extension uiview { func shake() { let animation = cakeyframeanimation(keypath: ""transform.translation.x"") animation.timingfunction = camediatimingfunction(name: kcamediatimingfunctionlinear) animation.duration = 0.6 animation.values = [-10.0, 10.0, -7.0, 7.0, -5.0, 5.0, 0.0 ] layer.add(animation, forkey: ""shake"")  goalkicker.com – ios® developer notes for professionals  121  } }  this function can be used to draw attention to a speciﬁc view by shaking it a bit.  section 20.6: utilizing intrinsic content size when creating a uiview subclass, intrinsic content size helps to avoid setting hardcoded height and width constraints a basic glimpse into how a class can utilize this class imageview: uiview { var image: uiimage { didset { invalidateintrinsiccontentsize() } } // omitting initializers // convenience init(image: uiimage) override func intrinsiccontentsize() -> cgsize { return cgsize(width: image.size.width, height: image.size.height) } }  if you only want to provide one size intrinsically, you can provide the value uiviewnointrinsicmetric for the value that you wish to ignore. override func intrinsiccontentsize() -> cgsize { return cgsize(width: uiviewnointrinsicmetric, height: image.size.width) }  beneﬁts when using with autolayout and interface builder one could take this imageview (or uiimageview) and set the horizontal alignment to superview center x and the vertical alignment to superview center y.  goalkicker.com – ios® developer notes for professionals  122  interface builder will complain to you at this point giving the following warning:  this is where placeholder intrinsic size comes in. going into the size inspector panel, and down to the intrinsic size dropdown, you can switch this value from default to placeholder. goalkicker.com – ios® developer notes for professionals  123  and now interface builder will remove the previous warnings and you can use this size to have dynamically sized views laid out in interface builder.  section 20.7: programmatically manage uiview insertion and deletion into and from another uiview suppose you have a parentview into which you want to insert a new subview programmatically (eg. when you want to insert an uiimageview into a uiviewcontroller's view), than you can do it as below. objective-c [parentview addsubview:subview];  swift parentview.addsubview(subview)  you can also add the subview below another subview2, which is already a sub view of parentview using the following code: objective-c [parentview insertsubview:subview belowsubview:subview2];  swift parentview.insertsubview(subview, belowsubview: subview2)  if you want to insert it above subview2 you can do it this way:  goalkicker.com – ios® developer notes for professionals  124  objective-c [parentview insertsubview:subview abovesubview:subview2];  swift parentview.insertsubview(subview, abovesubview: subview2)  if somewhere in your code you need to bring a certain subview to front, so above all the others parentview's subviews, you can do it like this: objective-c [parentview bringsubviewtofront:subview];  swift parentview.bringsubviewtofront(subview)  finally, if you want to remove subview from parentview, you can do as below: objective-c [subview removefromsuperview];  swift subview.removefromsuperview()  section 20.8: create uiview using autolayout uiview *view = [[uiview alloc] init]; [self.view addsubview:view]; //use the function if you want to use height as constraint [self addview:view onparentview:self.view withheight:200.f];  //use this function if you want to add view with respect to parent and should resize with it [self addfullresizeconstraintforsubview:view addedonparentview:self.view];  functions function to add view with ﬁxed height using autolayout constraints -(void)addview:(uiview*)subview onparentview:(uiview*)parentview withheight:(cgfloat)height{ subview.translatesautoresizingmaskintoconstraints = no; nslayoutconstraint *trailing =[nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributetrailing relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributetrailing  goalkicker.com – ios® developer notes for professionals  125  multiplier:1.0 constant:10.f];  nslayoutconstraint *top = [nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributetop relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributetop multiplier:1.0 constant:10.f]; nslayoutconstraint *leading = [nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributeleading relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributeleading multiplier:1.0 constant:10.f]; [parent addconstraint:trailing]; [parent addconstraint:top]; [parent addconstraint:leading]; nslayoutconstraint *heightconstraint =[nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributeheight relatedby:nslayoutrelationequal toitem:nil attribute:0 multiplier:0.0 constant:height]; [subview addconstraint:heightconstraint]; }  function add full resize constraint for created uiview. -(void)addfullresizeconstraintforsubview:(uiview*)subview addedonparentview:(uiview*)parentview{ subview.translatesautoresizingmaskintoconstraints = no; nslayoutconstraint *trailing =[nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributetrailing relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributetrailing multiplier:1.0 constant:10.f];  nslayoutconstraint *top = [nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributetop relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributetop multiplier:1.0  goalkicker.com – ios® developer notes for professionals  126  constant:10.f]; nslayoutconstraint *leading = [nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributeleading relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributeleading multiplier:1.0 constant:10.f]; nslayoutconstraint *bottom =[nslayoutconstraint constraintwithitem:subview attribute:nslayoutattributebottom relatedby:nslayoutrelationequal toitem:parent attribute:nslayoutattributebottom multiplier:1.0 constant:0.f]; [parent addconstraint:trailing]; [parent addconstraint:top]; [parent addconstraint:leading]; [parent addconstraint:bottom]; }  section 20.9: animating a uiview let view = uiview(frame: cgrect(x: 0, y: 0, width: 100, height: 100)) view.backgroundcolor = uicolor.orange self.view.addsubview(view) uiview.animate(withduration: 0.75, delay: 0.5, options: .curveeasein, animations: { //this will cause view to go from (0,0) to // (self.view.frame.origin.x,self.view.frame.origin.y) view.frame.origin.x = self.view.frame.origin.x view.frame.origin.y = self.view.frame.origin.y }) { (finished) in view.backgroundcolor = uicolor.bluecolor() }  section 20.10: uiview extension for size and frame attributes if we want to get the x-cordinate of origin of the view, then we need to write like: view.frame.origin.x  for width, we need to write: view.frame.size.width  but if we add a simple extension to an uiview, we can get all the attributes very simply, like: view.x view.y view.width view.height  it will also help setting these attributes like:  goalkicker.com – ios® developer notes for professionals  127  view.x = 10 view.y = 10 view.width = 100 view.height = 200  and the simple extension would be: extension uiview { var x: cgfloat { get { return self.frame.origin.x } set { self.frame = cgrect(x: newvalue, y: self.frame.origin.y, width: self.frame.size.width, height: self.frame.size.height) } } var y: cgfloat { get { return self.frame.origin.y } set { self.frame = cgrect(x: self.frame.origin.x, y: newvalue, width: self.frame.size.width, height: self.frame.size.height) } } var width: cgfloat { get { return self.frame.size.width } set { self.frame = cgrect(x: self.frame.origin.x, y: self.frame.origin.y, width: newvalue, height: self.frame.size.height) } } var height: cgfloat { get { return self.frame.height } set { self.frame = cgrect(x: self.frame.origin.x, y: self.frame.origin.y, width: self.frame.size.width, height: newvalue) } } }  we need to add this class ﬁle in a project and it'll be available to use throughout the project!  goalkicker.com – ios® developer notes for professionals  128",t_17bf2af6d82b,t_17bf2af6d82b,2
c_d6f16b519f5a,"chapter 108 of the book on ios developer.chapter 108: extension for rich push notiﬁcation - ios 10. ios 10 gave us usernotifications.framework, the new api for local/remote notiﬁcations. it oﬀers viewing media attachments or responding to messages right from the notiﬁcation. notiﬁcation content consists of: title, subtitle, body and attachment. attachment can contain images/gifs/videos up to 50 mb.  section 108.1: notiﬁcation content extension why do we need it? content extension helps us to create custom user interface upon notiﬁcation expanasion. you use this framework to deﬁne an extension that receives the notiﬁcation data and provides the corresponding visual representation. your extension can also respond to custom actions associated with those notiﬁcations.  section 108.2: implementation 1. in xcode navigator window go to targets section. press add new target. 2. select notification content extension template:  3. in your info.plist ﬁle set the identiﬁer for unnotificationextensioncategory key:  goalkicker.com – ios® developer notes for professionals  578  nsextensionattributes: unnotificationextensioncategory (required)  the value of this key is a string or an array of strings. each string contains the identiﬁer of a category declared by the app using the unnotiﬁcation​category class. unnotificationextensioninitialcontentsizeratio (required)  number that represents the initial size of your view controller’s view expressed as a ratio of its height to its width. unnotificationextensiondefaultcontenthidden (optional)  when set to yes, the system displays only your custom view controller in the notiﬁcation interface. when set to no, the system displays the default notiﬁcation content in addition to your view controller’s content. unnotificationextensionoverridesdefaulttitle (optional)  the value of this key is a boolean. when set to true, the system uses the title property of your view controller as the title of the notiﬁcation. when set to false, the system sets the notiﬁcation's title to the name of your app. if you do not specify this key, the default value is set to false. 4. create custom view in notificationviewcontroller.swift ﬁle 5. add new category key and set its value to what we typed in the info.plist (step 3): push: { aps: { alert: { … }, category: 'io.swifting.notification-category' } }  local: let mutablenotificationcontent = unmutablenotificationcontent() mutablenotificationcontent.category = ""io.swifting.notification-category"" mutablenotificationcontent.title = ""swifting.io notifications"" mutablenotificationcontent.subtitle = ""swifting.io presents"" mutablenotificationcontent.body = ""custom notifications""  also check out the oﬃcial api reference: https://developer.apple.com/reference/usernotiﬁcationsui/unnotiﬁcationcontentextension?utm_source=swifting.io &utm_medium=web&utm_campaign=blog%20post  goalkicker.com – ios® developer notes for professionals  579",t_17bf2af6d82b,t_17bf2af6d82b,2
c_c7107a11d3ff,"chapter 189 of the book on ios developer.chapter 189: conﬁgure beacons with corebluetooth hot to read and write data to a bluetooth low energy device.  section 189.1: showing names of all bluetooth low energy (ble) for this example i have a controlled room with a single ble device enable. your class should extend cbcentralmanagerdelegate. implement the method: centralmanagerdidupdatestate(_ central: cbcentralmanager). use global queue to not freeze the screen while searching for a device. instantiate cbcentralmanager and wait for callback centralmanagerdidupdatestate response. class blecontroller: cbcentralmanagerdelegate{ var cb_manager: cbcentralmanager! var bles : [cbperipheral] = [] override func viewdidload() { super.viewdidload() cb_manager = cbcentralmanager(delegate: self, queue: dispatchqueue.global()) } func centralmanagerdidupdatestate(_ central: cbcentralmanager) { print(""update state - \(central)"") } }  callback to centralmanagerdidupdatestate indicates that corebluetooth is ready, so you can search for ble now. update centralmanagerdidupdatestate code to search for all ble device when it is ready. func centralmanagerdidupdatestate(_ central: cbcentralmanager) { print(""update state - \(central)"") searchble() } func searchble(){ cb_manager.scanforperipherals(withservices: nil, options: nil) stopsearchble() } func stopsearchble() { let when = dispatchtime.now() + 5 // change 5 to desired number of seconds dispatchqueue.main.asyncafter(deadline: when) { self.cb_manager.stopscan() } }  searchble() search for ble devices and stop searching after 5s cb_manager.scanforperipherals(withservices: nil, options: nil) looks for every ble in range with you. stopsearchble() will stop the search after 5s. each ble found will callback func centralmanager(_ central: cbcentralmanager, diddiscover peripheral: cbperipheral, advertisementdata: [string : any], rssi rssi: nsnumber) func centralmanager(_ central: cbcentralmanager, diddiscover peripheral:  goalkicker.com – ios® developer notes for professionals  800  cbperipheral, advertisementdata: [string : any], rssi rssi: nsnumber) { guard let name = peripheral.name else { return } print(name) bles.append(peripheral) }  section 189.2: connect and read major value i'm in a controlled room with a single minew beacon that use ibeacon protocol. blecontroller needs to extend cbperipheraldelegate i'll use the ﬁrst ble to connect after the search has stop. modify the method stopsearchble() class blecontroller: cbcentralmanagerdelegate, cbperipheraldelegate{ //... func stopsearchminiewbeacon() { let when = dispatchtime.now() + 5 // change 2 to desired number of seconds dispatchqueue.main.asyncafter(deadline: when) { self.cb_manager.stopscan() self.cb_manager.connect(bles.first) } } /... }  in the documention of your ble device, you should look for the service uuid and major uuid characteristic var service_uuid = cbuuid(string: ""0000fff0-0000-1000-8000-00805f9b34fb"") var major_uuid = cbuuid(string: ""0000fff2-0000-1000-8000-00805f9b34fb"") func centralmanager(_ central: cbcentralmanager, didconnect peripheral: cbperipheral) { peripheral.delegate = self peripheral.discoverservices([service_uuid]) } func peripheral(_ peripheral: cbperipheral, diddiscoverservices error: error?) { print(""service: \(service)\n error: \(error)"") peripheral.discovercharacteristics([major_uuid], for: (peripheral.services?[0])!) }  create a variable 'service_uuid' and 'major_uuid' like code above. '-0000-1000-8000-00805f9b34fb' is part of the standard. 'ﬀf0' is my service uuid, 'ﬀf2' is my major uuid characteristic and '0000' are required to ﬁll the 4 bytes uuid 1º block. discovercharacteristics([major_uuid], for: (peripheral.services?[0])!) will get major characteristic from my device gatt server and it will have nil as value for now. (peripheral.services?[0])! - 0 beacuse will return a single value once i did peripheral.discoverservices([service_uuid]) func peripheral(_ peripheral: cbperipheral, diddiscovercharacteristicsfor service: cbservice, error: error?) { for characteristic in service.characteristics! { print(""characteristic: \(characteristic)\n error: \(error)"") if(characteristic.uuid.uuidstring == ""fff2""){ peripheral.readvalue(for: characteristic) }  goalkicker.com – ios® developer notes for professionals  801  } } func peripheral(_ peripheral: cbperipheral, didupdatevaluefor characteristic: cbcharacteristic, error: error?) { print(""characteristic read: \(characteristic)\n error: \(error)"") let major = uint16.init(bigendian: uint16(data: characteristic.value!)!) print(""major: \(major)"") }  characteristic value will only be readable after call peripheral.readvalue(for: characteristic) readvalue will result in func peripheral(_ peripheral: cbperipheral, didupdatevaluefor characteristic: cbcharacteristic, error: error?) with value in data type.  section 189.3: write major value you need discover the services and characteristic you don't need read value from the characteristic before writing over it. will continue for, for this example, after read value. modify func peripheral(_ peripheral: cbperipheral, didupdatevaluefor characteristic: cbcharacteristic, error: error?) add a variable new_major and reset_characteristic var reset_characteristic : cbcharacteristic! func peripheral(_ peripheral: cbperipheral, diddiscovercharacteristicsfor service: cbservice, error: error?) { for characteristic in service.characteristics! { print(""characteristic: \(characteristic)\n error: \(error)"") if(characteristic.uuid.uuidstring == ""fff2""){ peripheral.readvalue(for: characteristic) } if(characteristic.uuid.uuidstring == ""ffff""){ reset_characteristic = characteristic } } } let new_major : uint16 = 100 func peripheral(_ peripheral: cbperipheral, didupdatevaluefor characteristic: cbcharacteristic, error: error?) { print(""characteristic read: \(characteristic)\n error: \(error)"") let major = uint16.init(bigendian: uint16(data: characteristic.value!)!) print(""major: \(major)"") peripheral.writevalue(new_major.data, for: characteristic, type: cbcharacteristicwritetype.withresponse) }  iphone by default will send and receive bytes in little endian format, but my device minew witch chipset nrf51822 have arm architecture and need bytes in big endian format, so i have to swap it. ble device documentation will say what type of input and output each characteristic will have and if you can read it like above (cbcharacteristicwritetype.withresponse). func peripheral(_ peripheral: cbperipheral, didwritevaluefor characteristic: cbcharacteristic, error: error?) { print(""characteristic write: \(characteristic)\n error: \(error)"") if(characteristic.uuid.uuidstring == ""fff2""){ print(""resetting"") peripheral.writevalue(""minew123"".data(using: string.encoding.utf8)!, for: reset_characteristic, type: cbcharacteristicwritetype.withresponse) } if(characteristic.uuid.uuidstring == ""ffff""){  goalkicker.com – ios® developer notes for professionals  802  print(""reboot finish"") cb_manager.cancelperipheralconnection(peripheral) } }  to update a gatt server information you have to reboot it programmatically or save data to it and turn oﬀ and turn on manually. ffff is characteristic that do it in this device. 'minew123' is the default password for reboot o save information in this case. run your app and watch you console for any error, i hope none, but you will not see the new value yet. func peripheral(_ peripheral: cbperipheral, didupdatevaluefor characteristic: cbcharacteristic, error: error?) { print(""characteristic read: \(characteristic)\n error: \(error)"") let major = uint16.init(bigendian: uint16(data: characteristic.value!)!) print(""major: \(major)"") //peripheral.writevalue(new_major.data, for: characteristic, type: cbcharacteristicwritetype.withresponse)  } last step is to comment last line in method didupdatevaluefor and rerun the app, now you will the new value.  goalkicker.com – ios® developer notes for professionals  803",t_17bf2af6d82b,t_17bf2af6d82b,2
c_488ad4d24b77,"chapter 169 of the book on ios developer.chapter 169: core spotlight in ios section 169.1: core-spotlight objective-c 1. create a new ios project and add corespotlight and mobilecoreservices framework to your project.  2. create the actual cssearchableitem and associating the uniqueidentiﬁer, domainidentiﬁer and the attributeset. finally index the cssearchableitem using [[cssearchableindex defaultsearchableindex]...] as show below.  goalkicker.com – ios® developer notes for professionals  757  3. ok!test the index!  goalkicker.com – ios® developer notes for professionals  758",t_17bf2af6d82b,t_17bf2af6d82b,2
c_ca177269ee84,"chapter 67 of the book on c++.chapter 67: sorting section 67.1: sorting and sequence containers std::sort, found in the standard library header algorithm, is a standard library algorithm for sorting a range of  values, deﬁned by a pair of iterators. std::sort takes as the last parameter a functor used to compare two values; this is how it determines the order. note that std::sort is not stable. the comparison function must impose a strict, weak ordering on the elements. a simple less-than (or greater-than) comparison will suﬃce. a container with random-access iterators can be sorted using the std::sort algorithm: version ≥ c++11  #include <vector> #include <algorithm> std::vector<int> myvector = {3, 1, 2} //default comparison of < std::sort(myvector.begin(), myvector.end()); std::sort requires that its iterators are random access iterators. the sequence containers std::list and std::forward_list (requiring c++11) do not provide random access iterators, so they cannot be used with std::sort. however, they do have sort member functions which implement a sorting algorithm that works with  their own iterator types. version ≥ c++11  #include <list> #include <algorithm> std::list<int> mylist = {3, 1, 2} //default comparison of < //whole list only. mylist.sort();  their member sort functions always sort the entire list, so they cannot sort a sub-range of elements. however, since list and forward_list have fast splicing operations, you could extract the elements to be sorted from the list, sort them, then stuﬀ them back where they were quite eﬃciently like this: void sort_sublist(std::list<int>& mylist, std::list<int>::const_iterator start, std::list<int>::const_iterator end) { //extract and sort half-open sub range denoted by start and end iterator std::list<int> tmp; tmp.splice(tmp.begin(), list, start, end); tmp.sort(); //re-insert range at the point we extracted it from list.splice(end, tmp); }  section 67.2: sorting with std::map (ascending and descending) this example sorts elements in ascending order of a key using a map. you can use any type, including class, goalkicker.com – c++ notes for professionals  349  instead of std::string, in the example below. #include <iostream> #include <utility> #include <map> int main() { std::map<double, std::string> sorted_map; // sort the names of the planets according to their size sorted_map.insert(std::make_pair(0.3829, ""mercury"")); sorted_map.insert(std::make_pair(0.9499, ""venus"")); sorted_map.insert(std::make_pair(1, ""earth"")); sorted_map.insert(std::make_pair(0.532, ""mars"")); sorted_map.insert(std::make_pair(10.97, ""jupiter"")); sorted_map.insert(std::make_pair(9.14, ""saturn"")); sorted_map.insert(std::make_pair(3.981, ""uranus"")); sorted_map.insert(std::make_pair(3.865, ""neptune"")); for (auto const& entry: sorted_map) { std::cout << entry.second << "" ("" << entry.first << "" of earth's radius)"" << '\n'; } }  output: mercury (0.3829 of earth's radius) mars (0.532 of earth's radius) venus (0.9499 of earth's radius) earth (1 of earth's radius) neptune (3.865 of earth's radius) uranus (3.981 of earth's radius) saturn (9.14 of earth's radius) jupiter (10.97 of earth's radius)  if entries with equal keys are possible, use multimap instead of map (like in the following example). to sort elements in descending manner, declare the map with a proper comparison functor (std::greater<>): #include <iostream> #include <utility> #include <map> int main() { std::multimap<int, std::string, std::greater<int>> sorted_map; // sort the names of animals in descending order of the number of legs sorted_map.insert(std::make_pair(6, ""bug"")); sorted_map.insert(std::make_pair(4, ""cat"")); sorted_map.insert(std::make_pair(100, ""centipede"")); sorted_map.insert(std::make_pair(2, ""chicken"")); sorted_map.insert(std::make_pair(0, ""fish"")); sorted_map.insert(std::make_pair(4, ""horse"")); sorted_map.insert(std::make_pair(8, ""spider"")); for (auto const& entry: sorted_map) { std::cout << entry.second << "" (has "" << entry.first << "" legs)"" << '\n';  goalkicker.com – c++ notes for professionals  350  } }  output centipede (has 100 legs) spider (has 8 legs) bug (has 6 legs) cat (has 4 legs) horse (has 4 legs) chicken (has 2 legs) fish (has 0 legs)  section 67.3: sorting sequence containers by overloaded less operator if no ordering function is passed, std::sort will order the elements by calling operator< on pairs of elements, which must return a type contextually convertible to bool (or just bool). basic types (integers, ﬂoats, pointers etc) have already build in comparison operators. we can overload this operator to make the default sort call work on user-deﬁned types. // include sequence containers #include <vector> #include <deque> #include <list> // insert sorting algorithm #include <algorithm> class base { public: // constructor that set variable to the value of v base(int v): variable(v) { } // use variable to provide total order operator less //`this` always represents the left-hand side of the compare. bool operator<(const base &b) const { return this->variable < b.variable; } int variable; }; int main() { std::vector <base> vector; std::deque <base> deque; std::list <base> list; // create 2 elements to sort base a(10); base b(5); // insert them into backs of containers vector.push_back(a); vector.push_back(b);  goalkicker.com – c++ notes for professionals  351  deque.push_back(a); deque.push_back(b); list.push_back(a); list.push_back(b); // now sort data using operator<(const base &b) function std::sort(vector.begin(), vector.end()); std::sort(deque.begin(), deque.end()); // list must be sorted differently due to its design list.sort(); return 0; }  section 67.4: sorting sequence containers using compare function // include sequence containers #include <vector> #include <deque> #include <list> // insert sorting algorithm #include <algorithm> class base { public: // constructor that set variable to the value of v base(int v): variable(v) { } int variable; }; bool compare(const base &a, const base &b) { return a.variable < b.variable; } int main() { std::vector <base> vector; std::deque <base> deque; std::list <base> list; // create 2 elements to sort base a(10); base b(5); // insert them into backs of containers vector.push_back(a); vector.push_back(b); deque.push_back(a); deque.push_back(b); list.push_back(a); list.push_back(b); // now sort data using comparing function  goalkicker.com – c++ notes for professionals  352  std::sort(vector.begin(), vector.end(), compare); std::sort(deque.begin(), deque.end(), compare); list.sort(compare); return 0; }  section 67.5: sorting sequence containers using lambda expressions (c++11) version ≥ c++11  // include sequence containers #include <vector> #include <deque> #include <list> #include <array> #include <forward_list> // include sorting algorithm #include <algorithm> class base { public: // constructor that set variable to the value of v base(int v): variable(v) { } int variable; };  int main() { // create 2 elements to sort base a(10); base b(5); // we're using c++11, so let's use initializer lists to insert items. std::vector <base> vector = {a, b}; std::deque <base> deque = {a, b}; std::list <base> list = {a, b}; std::array <base, 2> array = {a, b}; std::forward_list<base> flist = {a, b}; // we can sort data using an inline lambda expression std::sort(std::begin(vector), std::end(vector), [](const base &a, const base &b) { return a.variable < b.variable;}); // we can also pass a lambda object as the comparator // and reuse the lambda multiple times auto compare = [](const base &a, const base &b) { return a.variable < b.variable;}; std::sort(std::begin(deque), std::end(deque), compare); std::sort(std::begin(array), std::end(array), compare); list.sort(compare); flist.sort(compare); return 0; }  goalkicker.com – c++ notes for professionals  353  section 67.6: sorting built-in arrays the sort algorithm sorts a sequence deﬁned by two iterators. this is enough to sort a built-in (also known as cstyle) array. version ≥ c++11  int arr1[] = {36, 24, 42, 60, 59}; // sort numbers in ascending order sort(std::begin(arr1), std::end(arr1)); // sort numbers in descending order sort(std::begin(arr1), std::end(arr1), std::greater<int>());  prior to c++11, end of array had to be ""calculated"" using the size of the array: version < c++11  // use a hard-coded number for array size sort(arr1, arr1 + 5); // alternatively, use an expression const size_t arr1_size = sizeof(arr1) / sizeof(*arr1); sort(arr1, arr1 + arr1_size);  section 67.7: sorting sequence containers with specifed ordering if the values in a container have certain operators already overloaded, std::sort can be used with specialized functors to sort in either ascending or descending order: version ≥ c++11  #include <vector> #include <algorithm> #include <functional> std::vector<int> v = {5,1,2,4,3}; //sort in ascending order (1,2,3,4,5) std::sort(v.begin(), v.end(), std::less<int>()); // or just: std::sort(v.begin(), v.end()); //sort in descending order (5,4,3,2,1) std::sort(v.begin(), v.end(), std::greater<int>()); //or just: std::sort(v.rbegin(), v.rend()); version ≥ c++14  in c++14, we don't need to provide the template argument for the comparison function objects and instead let the object deduce based on what it gets passed in: std::sort(v.begin(), v.end(), std::less<>()); std::sort(v.begin(), v.end(), std::greater<>());  goalkicker.com – c++ notes for professionals  // ascending order // descending order  354",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_85068c4692ed,"chapter 57 of the book on c++.chapter 57: std::iomanip section 57.1: std::setprecision when used in an expression out << setprecision(n) or in >> setprecision(n), sets the precision parameter of the stream out or in to exactly n. parameter of this function is integer, which is new value for precision. example: #include <iostream> #include <iomanip> #include <cmath> #include <limits> int main() { const long double pi = std::acos(-1.l); std::cout << ""default precision (6): "" << pi << '\n' << ""std::precision(10): "" << std::setprecision(10) << pi << '\n' << ""max precision: "" << std::setprecision(std::numeric_limits<long double>::digits10 + 1) << pi << '\n'; } //output //default precision (6): 3.14159 //std::precision(10): 3.141592654 //max precision: 3.141592653589793239  section 57.2: std::setﬁll when used in an expression out << setfill(c) sets the ﬁll character of the stream out to c. note: the current ﬁll character may be obtained with std::ostream::fill. example: #include <iostream> #include <iomanip> int main() { std::cout << ""default fill: "" << std::setw(10) << 42 << '\n' << ""setfill('*'): "" << std::setfill('*') << std::setw(10) << 42 << '\n'; } //output:: //default fill: 42 //setfill('*'): ********42  section 57.3: std::setiosﬂags when used in an expression out << setiosflags(mask) or in >> setiosflags(mask), sets all format ﬂags of the stream out or in as speciﬁed by the mask. list of all std::ios_base::fmtflags : dec - use decimal base for integer i/o oct - use octal base for integer i/o  goalkicker.com – c++ notes for professionals  314  hex - use hexadecimal base for integer i/o basefield - dec|oct|hex|0 useful for masking operations left - left adjustment(add ﬁll characters to the right) right - right adjustment (adds ﬁll characters to the left) internal - internal adjustment (adds ﬁll characters to the internal designated point) adjustfield - left|right|internal. useful for masking operations scientific - generate ﬂoating point types using scientiﬁc notation, or hex notation if combined with ﬁxed fixed - generate ﬂoating point types using ﬁxed notation, or hex notation if combined with scientiﬁc floatfield - scientific|fixed|(scientific|fixed)|0. useful for masking operations boolalpha - insert and extract bool type in alphanumeric format showbase - generate a preﬁx indicating the numeric base for integer output, require the currency indicator in  monetary i/o showpoint - generate a decimal-point character unconditionally for ﬂoating-point number output showpos - generate a + character for non-negative numeric output skipws - skip leading whitespace before certain input operations unitbuf ﬂush the output after each output operation uppercase - replace certain lowercase letters with their uppercase equivalents in certain output output  operations example of manipulators: #include <iostream> #include <string> #include<iomanip> int main() { int l_itemp = 47; std::cout<< std::resetiosflags(std::ios_base::basefield); std::cout<<std::setiosflags( std::ios_base::oct)<<l_itemp<<std::endl; //output: 57 std::cout<< std::resetiosflags(std::ios_base::basefield); std::cout<<std::setiosflags( std::ios_base::hex)<<l_itemp<<std::endl; //output: 2f std::cout<<std::setiosflags( std::ios_base::uppercase)<<l_itemp<<std::endl; //output 2f std::cout<<std::setfill('0')<<std::setw(12); std::cout<<std::resetiosflags(std::ios_base::uppercase); std::cout<<std::setiosflags( std::ios_base::right)<<l_itemp<<std::endl; //output: 00000000002f std::cout<<std::resetiosflags(std::ios_base::basefield|std::ios_base::adjustfield); std::cout<<std::setfill('.')<<std::setw(10); std::cout<<std::setiosflags( std::ios_base::left)<<l_itemp<<std::endl; //output: 47........ std::cout<<std::resetiosflags(std::ios_base::adjustfield)<<std::setfill('#'); std::cout<<std::setiosflags(std::ios_base::internal|std::ios_base::showpos); std::cout<<std::setw(10)<<l_itemp<<std::endl; //output +#######47 double l_dtemp = -1.2; double pi = 3.14159265359; std::cout<<pi<<"" ""<<l_dtemp<<std::endl; //output +3.14159 -1.2 std::cout<<std::setiosflags(std::ios_base::showpoint)<<l_dtemp<<std::endl; //output -1.20000 std::cout<<setiosflags(std::ios_base::scientific)<<pi<<std::endl; //output: +3.141593e+00  goalkicker.com – c++ notes for professionals  315  std::cout<<std::resetiosflags(std::ios_base::floatfield); std::cout<<setiosflags(std::ios_base::fixed)<<pi<<std::endl; //output: +3.141593 bool b = true; std::cout<<std::setiosflags(std::ios_base::unitbuf|std::ios_base::boolalpha)<<b; //output: true return 0; }  section 57.4: std::setw int val = 10; // val will be printed to the extreme left end of the output console: std::cout << val << std::endl; // val will be printed in an output field of length 10 starting from right end of the field: std::cout << std::setw(10) << val << std::endl;  this outputs: 10 10 1234567890  (where the last line is there to aid in seeing the character oﬀsets). sometimes we need to set the width of the output ﬁeld, usually when we need to get the output in some structured and proper layout. that can be done using std::setw of std::iomanip. the syntax for std::setw is: std::setw(int n)  where n is the length of the output ﬁeld to be set  goalkicker.com – c++ notes for professionals  316",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_8fcdd908e02c,"chapter 10 of the book on c++.chapter 10: basic input/output in c++ section 10.1: user input and standard output #include <iostream> int main() { int value; std::cout << ""enter a value: "" << std::endl; std::cin >> value; std::cout << ""the square of entered value is: "" << value * value << std::endl; return 0; }  goalkicker.com – c++ notes for professionals  43",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_861fdf5b92cf,"chapter 23 of the book on c++.chapter 23: keywords keywords have ﬁxed meaning deﬁned by the c++ standard and cannot be used as identiﬁers. it is illegal to redeﬁne keywords using the preprocessor in any translation unit that includes a standard library header. however, keywords lose their special meaning inside attributes.  section 23.1: asm the asm keyword takes a single operand, which must be a string literal. it has an implementation-deﬁned meaning, but is typically passed to the implementation's assembler, with the assembler's output being incorporated into the translation unit. the asm statement is a deﬁnition, not an expression, so it may appear either at block scope or namespace scope (including global scope). however, since inline assembly cannot be constrained by the rules of the c++ language, asm may not appear inside a constexpr function.  example: [[noreturn]] void halt_system() { asm(""hlt""); }  section 23.2: dierent keywords void c++ 1. when used as a function return type, the void keyword speciﬁes that the function does not return a value. when used for a function's parameter list, void speciﬁes that the function takes no parameters. when used in the declaration of a pointer, void speciﬁes that the pointer is ""universal."" 2. if a pointer's type is void *, the pointer can point to any variable that is not declared with the const or volatile keyword. a void pointer cannot be dereferenced unless it is cast to another type. a void pointer can be converted into any other type of data pointer. 3. a void pointer can point to a function, but not to a class member in c++. void vobject; // c2182 void *pv; // okay int *pint; int i; int main() { pv = &i; // cast optional in c required in c++ pint = (int *)pv;  volatile c++ 1. a type qualiﬁer that you can use to declare that an object can be modiﬁed in the program by the hardware. volatile declarator ;  goalkicker.com – c++ notes for professionals  114  virtual c++ 1. the virtual keyword declares a virtual function or a virtual base class. virtual [type-specifiers] member-function-declarator virtual [access-specifier] base-class-name  parameters 1. type-speciﬁers speciﬁes the return type of the virtual member function. 2. member-function-declarator declares a member function. 3. access-speciﬁer deﬁnes the level of access to the base class, public, protected or private. can appear before or after the virtual keyword. 4. base-class-name identiﬁes a previously declared class type  this pointer 1. the this pointer is a pointer accessible only within the nonstatic member functions of a class, struct, or union type. it points to the object for which the member function is called. static member functions do not have a this pointer. this->member-identifier  an object's this pointer is not part of the object itself; it is not reﬂected in the result of a sizeof statement on the object. instead, when a nonstatic member function is called for an object, the address of the object is passed by the compiler as a hidden argument to the function. for example, the following function call: mydate.setmonth( 3 );  can be interpreted this way: setmonth( &mydate, 3 );  the object's address is available from within the member function as the this pointer. most uses of this are implicit. it is legal, though unnecessary, to explicitly use this when referring to members of the class. for example: void date::setmonth( int mn ) { month = mn; // these three statements this->month = mn; // are equivalent (*this).month = mn; }  the expression *this is commonly used to return the current object from a member function: return *this; the this pointer is also used to guard against self-reference: if (&object != this) { // do not execute in cases of self-reference  try, throw, and catch statements (c++) goalkicker.com – c++ notes for professionals  115  1. to implement exception handling in c++, you use try, throw, and catch expressions. 2. first, use a try block to enclose one or more statements that might throw an exception. 3. a throw expression signals that an exceptional condition—often, an error—has occurred in a try block. you can use an object of any type as the operand of a throw expression. typically, this object is used to communicate information about the error. in most cases, we recommend that you use the std::exception class or one of the derived classes that are deﬁned in the standard library. if one of those is not appropriate, we recommend that you derive your own exception class from std::exception. 4. to handle exceptions that may be thrown, implement one or more catch blocks immediately following a try block. each catch block speciﬁes the type of exception it can handle. mydata md; try { // code that could throw an exception md = getnetworkresource(); } catch (const networkioexception& e) { // code that executes when an exception of type // networkioexception is thrown in the try block // ... // log error message in the exception object cerr << e.what(); } catch (const mydataformatexception& e) { // code that handles another exception type // ... cerr << e.what(); } // the following syntax shows a throw expression mydata getnetworkresource() { // ... if (iosuccess == false) throw networkioexception(""unable to connect""); // ... if (readerror) throw mydataformatexception(""format error""); // ... }  the code after the try clause is the guarded section of code. the throw expression throws—that is, raises—an exception. the code block after the catch clause is the exception handler. this is the handler that catches the exception that's thrown if the types in the throw and catch expressions are compatible.  try { throw csomeotherexception(); } catch(...) { // catch all exceptions – dangerous!!! // respond (perhaps only partially) to the exception, then // re-throw to pass the exception to some other handler // ... throw; }  friend (c++) goalkicker.com – c++ notes for professionals  116  1. in some circumstances, it is more convenient to grant member-level access to functions that are not members of a class or to all members in a separate class. only the class implementer can declare who its friends are. a function or class cannot declare itself as a friend of any class. in a class deﬁnition, use the friend keyword and the name of a non-member function or other class to grant it access to the private and protected members of your class. in a template deﬁnition, a type parameter can be declared as a friend. 2. if you declare a friend function that was not previously declared, that function is exported to the enclosing nonclass scope. class friend f friend f; class forwarddeclared;// class name is known. class hasfriends { friend int forwarddeclared::isafriend();// c2039 error expected };  friend functions 1. a friend function is a function that is not a member of a class but has access to the class's private and protected members.friend functions are not considered class members; they are normal external functions that are given special access privileges. 2. friends are not in the class's scope, and they are not called using the member-selection operators (. and –>) unless they are members of another class. 3. a friend function is declared by the class that is granting access. the friend declaration can be placed anywhere in the class declaration. it is not aﬀected by the access control keywords. #include <iostream> using namespace std; class point { friend void changeprivate( point & ); public: point( void ) : m_i(0) {} void printprivate( void ){cout << m_i << endl; } private: int m_i; }; void changeprivate ( point &i ) { i.m_i++; } int main() { point spoint; spoint.printprivate(); changeprivate(spoint); spoint.printprivate(); // output: 0 1 }  goalkicker.com – c++ notes for professionals  117  class members as friends class b; class a { public: int func1( b& b ); private: int func2( b& b ); }; class b { private: int _b; // a::func1 is a friend function to class b // so a::func1 has access to all members of b friend int a::func1( b& ); }; int a::func1( b& b ) { return b._b; } int a::func2( b& b ) { return b._b; }  // ok // c2248  section 23.3: typename 1. when followed by a qualiﬁed name, typename speciﬁes that it is the name of a type. this is often required in templates, in particular, when the nested name speciﬁer is a dependent type other than the current instantiation. in this example, std::decay<t> depends on the template parameter t, so in order to name the nested type type, we need to preﬁx the entire qualiﬁed name with typename. for more deatils, see where and why do i have to put the ""template"" and ""typename"" keywords? template <class t> auto decay_copy(t&& r) -> typename std::decay<t>::type;  2. introduces a type parameter in the declaration of a template. in this context, it is interchangeable with class. template <typename t> const t& min(const t& x, const t& y) { return b < a ? b : a; } version ≥ c++17  3. typename can also be used when declaring a template template parameter, preceding the name of the parameter, just like class. template <template <class t> typename u> void f() { u<int>::do_it(); u<double>::do_it(); }  goalkicker.com – c++ notes for professionals  118  section 23.4: explicit 1. when applied to a single-argument constructor, prevents that constructor from being used to perform implicit conversions. class myvector { public: explicit myvector(uint64_t size); }; myvector v1(100); // ok uint64_t len1 = 100; myvector v2{len1}; // ok, len1 is uint64_t int len2 = 100; myvector v3{len2}; // ill-formed, implicit conversion from int to uint64_t  since c++11 introduced initializer lists, in c++11 and later, explicit can be applied to a constructor with any number of arguments, with the same meaning as in the single-argument case. struct s { explicit s(int x, int y); }; s f() { return {12, 34}; // ill-formed return s{12, 34}; // ok } version ≥ c++11  2. when applied to a conversion function, prevents that conversion function from being used to perform implicit conversions. class c { const int x; public: c(int x) : x(x) {} explicit operator int() { return x; } }; c c(42); int x = c; // ill-formed int y = static_cast<int>(c); // ok; explicit conversion  section 23.5: sizeof a unary operator that yields the size in bytes of its operand, which may be either an expression or a type. if the operand is an expression, it is not evaluated. the size is a constant expression of type std::size_t. if the operand is a type, it must be parenthesized. it is illegal to apply sizeof to a function type. it is illegal to apply sizeof to an incomplete type, including void. if sizeof is applied to a reference type t& or t&&, it is equivalent to sizeof(t). when sizeof is applied to a class type, it yields the number of bytes in a complete object of that type, including any padding bytes in the middle or at the end. therefore, a sizeof expression can never have a value of 0. see layout of object types for more details. goalkicker.com – c++ notes for professionals  119  the char, signed char, and unsigned char types have a size of 1. conversely, a byte is deﬁned to be the amount of memory required to store a char object. it does not necessarily mean 8 bits, as some systems have char objects longer than 8 bits. if expr is an expression, sizeof(expr) is equivalent to sizeof(t) where t is the type of expr. int a[100]; std::cout << ""the number of bytes in `a` is: "" << sizeof a; memset(a, 0, sizeof a); // zeroes out the array version ≥ c++11  the sizeof... operator yields the number of elements in a parameter pack. template <class... t> void f(t&&...) { std::cout << ""f was called with "" << sizeof...(t) << "" arguments\n""; }  section 23.6: noexcept version ≥ c++11  1. a unary operator that determines whether the evaluation of its operand can propagate an exception. note that the bodies of called functions are not examined, so noexcept can yield false negatives. the operand is not evaluated. #include <iostream> #include <stdexcept> void foo() { throw std::runtime_error(""oops""); } void bar() {} struct s {}; int main() { std::cout << noexcept(foo()) << '\n'; // prints std::cout << noexcept(bar()) << '\n'; // prints std::cout << noexcept(1 + 1) << '\n'; // prints std::cout << noexcept(s()) << '\n'; // prints }  0 0 1 1  in this example, even though bar() can never throw an exception, noexcept(bar()) is still false because the fact that bar() cannot propagate an exception has not been explicitly speciﬁed. 2. when declaring a function, speciﬁes whether or not the function can propagate an exception. alone, it declares that the function cannot propagate an exception. with a parenthesized argument, it declares that the function can or cannot propagate an exception depending on the truth value of the argument. void f1() { throw std::runtime_error(""oops""); } void f2() noexcept(false) { throw std::runtime_error(""oops""); } void f3() {} void f4() noexcept {} void f5() noexcept(true) {} void f6() noexcept { try { f1(); } catch (const std::runtime_error&) {} }  goalkicker.com – c++ notes for professionals  120  in this example, we have declared that f4, f5, and f6 cannot propagate exceptions. (although an exception can be thrown during execution of f6, it is caught and not allowed to propagate out of the function.) we have declared that f2 may propagate an exception. when the noexcept speciﬁer is omitted, it is equivalent to noexcept(false), so we have implicitly declared that f1 and f3 may propagate exceptions, even though  exceptions cannot actually be thrown during the execution of f3.  version ≥ c++17  whether or not a function is noexcept is part of the function's type: that is, in the example above, f1, f2, and f3 have diﬀerent types from f4, f5, and f6. therefore, noexcept is also signiﬁcant in function pointers, template arguments, and so on. void void void void void void  g1() {} g2() noexcept {} (*p1)() noexcept = &g1; // ill-formed, since g1 is not noexcept (*p2)() noexcept = &g2; // ok; types match (*p3)() = &g1; // ok; types match (*p4)() = &g2; // ok; implicit conversion  goalkicker.com – c++ notes for professionals  121",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_b9b2ca559017,"chapter 97 of the book on c++.chapter 97: typedef and type aliases the typedef and (since c++11) using keywords can be used to give a new name to an existing type.  section 97.1: basic typedef syntax a typedef declaration has the same syntax as a variable or function declaration, but it contains the word typedef. the presence of typedef causes the declaration to declare a type instead of a variable or function. int t; // t has type int typedef int t; // t is an alias for int int a[100]; // a has type ""array of 100 ints"" typedef int a[100]; // a is an alias for the type ""array of 100 ints""  once a type alias has been deﬁned, it can be used interchangeably with the original name of the type. typedef int a[100]; // s is a struct containing an array of 100 ints struct s { a data; }; typedef never creates a distinct type. it only gives another way of referring to an existing type. struct s { int f(int); }; typedef int i; // ok: defines int s::f(int) i s::f(i x) { return x; }  section 97.2: more complex uses of typedef the rule that typedef declarations have the same syntax as ordinary variable and function declarations can be used to read and write more complex declarations. void (*f)(int); // f has type ""pointer to function of int returning void"" typedef void (*f)(int); // f is an alias for ""pointer to function of int returning void""  this is especially useful for constructs with confusing syntax, such as pointers to non-static members. void (foo::*pmf)(int);  // // typedef void (foo::*pmf)(int); // //  pmf has type ""pointer to member function of foo taking int and returning void"" pmf is an alias for ""pointer to member function of foo taking int and returning void""  it is hard to remember the syntax of the following function declarations, even for experienced programmers: void (foo::*foo::f(const char*))(int); int (&g())[100]; typedef can be used to make them easier to read and write: typedef void (foo::pmf)(int);  // pmf is a pointer to member function type  goalkicker.com – c++ notes for professionals  503  pmf foo::f(const char*);  // f is a member function of foo  typedef int (&ra)[100]; ra g();  // ra means ""reference to array of 100 ints"" // g returns reference to array of 100 ints  section 97.3: declaring multiple types with typedef the typedef keyword is a speciﬁer, so it applies separately to each declarator. therefore, each name declared refers to the type that that name would have in the absence of typedef. int *x, (*p)(); // x has type int*, and p has type int(*)() typedef int *x, (*p)(); // x is an alias for int*, while p is an alias for int(*)()  section 97.4: alias declaration with ""using"" version ≥ c++11  the syntax of using is very simple: the name to be deﬁned goes on the left hand side, and the deﬁnition goes on the right hand side. no need to scan to see where the name is. using using using using  i = int; a = int[100]; fp = void(*)(int); mp = void (foo::*)(int);  // array of 100 ints // pointer to function of int returning void // pointer to member function of foo of int returning void  creating a type alias with using has exactly the same eﬀect as creating a type alias with typedef. it is simply an alternative syntax for accomplishing the same thing. unlike typedef, using can be templated. a ""template typedef"" created with using is called an alias template.  goalkicker.com – c++ notes for professionals  504",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_ba855d7395dd,"chapter 42 of the book on c++.chapter 42: constant class member functions section 42.1: constant member function #include <iostream> #include <map> #include <string> using namespace std; class a { public: map<string, string> * mapofstrings; public: a() { mapofstrings = new map<string, string>(); } void insertentry(string const & key, string const & value) const { (*mapofstrings)[key] = value; // this works? yes it does. delete mapofstrings; // this also works mapofstrings = new map<string, string>(); // this * does * not work } void refresh() { delete mapofstrings; mapofstrings = new map<string, string>(); // works as refresh is non const function } void getentry(string const & key) const { cout << mapofstrings->at(key); } }; int main(int argc, char* argv[]) { a var; var.insertentry(""abc"", ""abcvalue""); var.getentry(""abc""); getchar(); return 0; }  goalkicker.com – c++ notes for professionals  235",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_87239d7defb4,"chapter 94 of the book on c++.chapter 94: return type covariance section 94.1: covariant result version of the base example, static type checking // 2. covariant result version of the base example, static type checking. class top { public: virtual top* clone() const = 0; virtual ~top() = default; // necessary for `delete` via top*. }; class d : public top { public: d* /* ← covariant return */ clone() const override { return new d( *this ); } }; class dd : public d { private: int answer_ = 42; public: int answer() const { return answer_;} dd* /* ← covariant return */ clone() const override { return new dd( *this ); } }; #include <iostream> using namespace std; int main() { dd* p1 = new dd(); dd* p2 = p1->clone(); // correct dynamic type dd for *p2 is guaranteed by the static type checking. cout << p2->answer() << endl; delete p2; delete p1;  // ""42""  }  section 94.2: covariant smart pointer result (automated cleanup) // 3. covariant smart pointer result (automated cleanup). #include <memory> using std::unique_ptr; template< class type > auto up( type* p ) { return unique_ptr<type>( p ); }  goalkicker.com – c++ notes for professionals  495  class top { private: virtual top* virtual_clone() const = 0; public: unique_ptr<top> clone() const { return up( virtual_clone() ); } virtual ~top() = default;  // necessary for `delete` via top*.  }; class d : public top { private: d* /* ← covariant return */ virtual_clone() const override { return new d( *this ); } public: unique_ptr<d> /* ← apparent covariant return */ clone() const { return up( virtual_clone() ); } }; class dd : public d { private: int answer_ = 42; dd* /* ← covariant return */ virtual_clone() const override { return new dd( *this ); } public: int answer() const { return answer_;} unique_ptr<dd> /* ← apparent covariant return */ clone() const { return up( virtual_clone() ); } }; #include <iostream> using namespace std; int main() { auto p1 = unique_ptr<dd>(new dd()); auto p2 = p1->clone(); // correct dynamic type dd for *p2 is guaranteed by the static type checking. cout << p2->answer() << endl; // ""42"" // cleanup is automated via unique_ptr. }  goalkicker.com – c++ notes for professionals  496",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_45f912292534,"chapter 52 of the book on c++.chapter 52: std::function: to wrap any element that is callable section 52.1: simple usage #include <iostream> #include <functional> std::function<void(int , const std::string&)> myfuncobj; void thefunc(int i, const std::string& s) { std::cout << s << "": "" << i << std::endl; } int main(int argc, char *argv[]) { myfuncobj = thefunc; myfuncobj(10, ""hello world""); }  section 52.2: std::function used with std::bind think about a situation where we need to callback a function with arguments. std::function used with std::bind gives a very powerful design construct as shown below. class a { public: std::function<void(int, const std::string&)> m_cbfunc = nullptr; void foo() { if (m_cbfunc) { m_cbfunc(100, ""event fired""); } } }; class b { public: b() { auto afunc = std::bind(&b::eventhandler, this, std::placeholders::_1, std::placeholders::_2); anobja.m_cbfunc = afunc; } void eventhandler(int i, const std::string& s) { std::cout << s << "": "" << i << std::endl; } void dosomethingona() { anobja.foo(); } a anobja; };  goalkicker.com – c++ notes for professionals  299  int main(int argc, char *argv[]) { b anobjb; anobjb.dosomethingona(); }  section 52.3: binding std::function to a dierent callable types /* * this example show some ways of using std::function to call * a) c-like function * b) class-member function * c) operator() * d) lambda function * * function call can be made: * a) with right arguments * b) argumens with different order, types and count */ #include <iostream> #include <functional> #include <iostream> #include <vector> using std::cout; using std::endl; using namespace std::placeholders;  // simple function to be called double foo_fn(int x, float y, double z) { double res = x + y + z; std::cout << ""foo_fn called with arguments: "" << x << "", "" << y << "", "" << z << "" result is : "" << res << std::endl; return res; } // structure with member function to call struct foo_struct { // member function to call double foo_fn(int x, float y, double z) { double res = x + y + z; std::cout << ""foo_struct::foo_fn called with arguments: "" << x << "", "" << y << "", "" << z << "" result is : "" << res << std::endl; return res; } // this member function has different signature - but it can be used too // please not that argument order is changed too double foo_fn_4(int x, double z, float y, long xx) { double res = x + y + z + xx; std::cout << ""foo_struct::foo_fn_4 called with arguments: ""  goalkicker.com – c++ notes for professionals  300  << x << "", "" << z << "", "" << y << "", "" << xx << "" result is : "" << res << std::endl; return res; } // overloaded operator() makes whole object to be callable double operator()(int x, float y, double z) { double res = x + y + z; std::cout << ""foo_struct::operator() called with arguments: "" << x << "", "" << y << "", "" << z << "" result is : "" << res << std::endl; return res; } };  int main(void) { // typedefs using function_type = std::function<double(int, float, double)>; // foo_struct instance foo_struct fs; // here we will store all binded functions std::vector<function_type> bindings; // var #1 - you can use simple function function_type var1 = foo_fn; bindings.push_back(var1); // var #2 - you can use member function function_type var2 = std::bind(&foo_struct::foo_fn, fs, _1, _2, _3); bindings.push_back(var2); // var #3 - you can use member function with different signature // foo_fn_4 has different count of arguments and types function_type var3 = std::bind(&foo_struct::foo_fn_4, fs, _1, _3, _2, 0l); bindings.push_back(var3); // var #4 - you can use object with overloaded operator() function_type var4 = fs; bindings.push_back(var4); // var #5 - you can use lambda function function_type var5 = [](int x, float y, double z) { double res = x + y + z; std::cout << ""lambda called with arguments: "" << x << "", "" << y << "", "" << z << "" result is : "" << res << std::endl; return res; }; bindings.push_back(var5); std::cout << ""test stored functions with arguments: x = 1, y = 2, z = 3"" << std::endl; for (auto f : bindings)  goalkicker.com – c++ notes for professionals  301  f(1, 2, 3); }  live output: test stored functions with arguments: x = 1, y = 2, z = 3 foo_fn called with arguments: 1, 2, 3 result is : 6 foo_struct::foo_fn called with arguments: 1, 2, 3 result is : 6 foo_struct::foo_fn_4 called with arguments: 1, 3, 2, 0 result is : 6 foo_struct::operator() called with arguments: 1, 2, 3 result is : 6 lambda called with arguments: 1, 2, 3 result is : 6  section 52.4: storing function arguments in std::tuple some programs need so store arguments for future calling of some function. this example shows how to call any function with arguments stored in std::tuple #include #include #include #include  <iostream> <functional> <tuple> <iostream>  // simple function to be called double foo_fn(int x, float y, double z) { double res = x + y + z; std::cout << ""foo_fn called. x = "" << x << "" y = "" << y << "" z = "" << z << "" res="" << res; return res; } // helpers for tuple unrolling template<int ...> struct seq {}; template<int n, int ...s> struct gens : gens<n-1, n-1, s...> {}; template<int ...s> struct gens<0, s...>{ typedef seq<s...> type; }; // invocation helper template<typename fn, typename p, int ...s> double call_fn_internal(const fn& fn, const p& params, const seq<s...>) { return fn(std::get<s>(params) ...); } // call function with arguments stored in std::tuple template<typename ret, typename ...args> ret call_fn(const std::function<ret(args...)>& fn, const std::tuple<args...>& params) { return call_fn_internal(fn, params, typename gens<sizeof...(args)>::type()); }  int main(void) { // arguments std::tuple<int, float, double> t = std::make_tuple(1, 5, 10); // function to call  goalkicker.com – c++ notes for professionals  302  std::function<double(int, float, double)> fn = foo_fn; // invoke a function with stored arguments call_fn(fn, t); }  live output: foo_fn called. x = 1 y = 5 z = 10 res=16  section 52.5: std::function with lambda and std::bind #include <iostream> #include <functional> using std::placeholders::_1; // to be used in std::bind example int stdf_foobar (int x, std::function<int(int)> moo) { return x + moo(x); // std::function moo called } int foo (int x) { return 2+x; } int foo_2 (int x, int y) { return 9*x + y; } int main() { int a = 2; /* function pointers */ std::cout << stdf_foobar(a, &foo) << std::endl; // 6 ( 2 + (2+2) ) // can also be: stdf_foobar(2, foo) /* lambda expressions */ /* an unnamed closure from a lambda expression can be * stored in a std::function object: */ int capture_value = 3; std::cout << stdf_foobar(a, [capture_value](int param) -> int { return 7 + capture_value * param; }) << std::endl; // result: 15 == value + (7 * capture_value * value) == 2 + (7 + 3 * 2) /* std::bind expressions */ /* the result of a std::bind expression can be passed. * for example by binding parameters to a function pointer call: */ int b = stdf_foobar(a, std::bind(foo_2, _1, 3)); std::cout << b << std::endl; // b == 23 == 2 + ( 9*2 + 3 ) int c = stdf_foobar(a, std::bind(foo_2, 5, _1)); std::cout << c << std::endl; // c == 49 == 2 + ( 9*5 + 2 ) return 0; }  goalkicker.com – c++ notes for professionals  303  section 52.6: `function` overhead std::function can cause signiﬁcant overhead. because std::function has [value semantics][1], it must copy or  move the given callable into itself. but since it can take callables of an arbitrary type, it will frequently have to allocate memory dynamically to do this. some function implementations have so-called ""small object optimization"", where small types (like function pointers, member pointers, or functors with very little state) will be stored directly in the function object. but even this only works if the type is noexcept move constructible. furthermore, the c++ standard does not require that all implementations provide one. consider the following: //header file using mypredicate = std::function<bool(const myvalue &, const myvalue &)>; void sortmycontainer(mycontainer &c, const mypredicate &pred); //source file void sortmycontainer(mycontainer &c, const mypredicate &pred) { std::sort(c.begin(), c.end(), pred); }  a template parameter would be the preferred solution for sortmycontainer, but let us assume that this is not possible or desirable for whatever reason. sortmycontainer does not need to store pred beyond its own call. and yet, pred may well allocate memory if the functor given to it is of some non-trivial size. function allocates memory because it needs something to copy/move into; function takes ownership of the  callable it is given. but sortmycontainer does not need to own the callable; it's just referencing it. so using function here is overkill; it may be eﬃcient, but it may not. there is no standard library function type that merely references a callable. so an alternate solution will have to be found, or you can choose to live with the overhead. also, function has no eﬀective means to control where the memory allocations for the object come from. yes, it has constructors that take an allocator, but [many implementations do not implement them correctly... or even at all][2]. version ≥ c++17  the function constructors that take an allocator no longer are part of the type. therefore, there is no way to manage the allocation. calling a function is also slower than calling the contents directly. since any function instance could hold any callable, the call through a function must be indirect. the overhead of calling function is on the order of a virtual function call.  goalkicker.com – c++ notes for professionals  304",t_1d7ae58a79e6,t_1d7ae58a79e6,3
c_ded3b86d8c61,"what happens when the characteristic equation only has 1 repeated root?  let's say we have the following second order differential equation. we have second derivative of y, plus 4 times the first derivative, plus 4y is equal to 0. and we're asked to find the general solution to this differential equation. so the first thing we do, like we've done in the last several videos, we'll get the characteristic equation. that's r squared plus 4r plus 4 is equal to 0. this one is fairly easy to factor. we don't need the quadratic equation here. this is r plus 2 times r plus 2. and now something interesting happens, something that we haven't seen before. the two roots of our characteristic equation are actually the same number, r is equal to minus 2. so you could say we only have one solution, or one root, or a repeated root. however you want to say it, we only have one r that satisfies the characteristic equation. you might say, well that's fine. maybe my general solution is just y is equal to some constant times e to the minus 2x, using my one solution. and my reply to you is, this is a solution. and if you don't believe me you can test it out. but it's not the general solution. and why do i say that? because this is a second order differential equation. and if someone wanted a particular solution, they would have to give you two initial conditions. the two initial conditions we've been using so far are, what y of 0 equals, and what y prime of 0 equals. they could give you what y of 5 equals, who knows. but in general, when you have a second order differential equation, they have to give you two initial conditions. now the problem with this solution, and why it's not the general solution, is if you use one of these initial conditions, you can solve for a c, right? you'll get an answer. you'll solve for that c. but then there's nothing to do with the second initial condition. in fact, except for only in one particular case, whatever c you get for the first initial condition, it won't be that-- this equation won't be true for the second initial condition. and you could try it out. i mean, if we said, y of 0 is equal to a and y prime of 0 is equal to 5a. let's see if these work. if y of 0 is equal to a, that tells us that a is equal to c times e to the minus 2 times 0. so e to the 0. or c is equal to a, right? so if you just had this first initial condition, say fine, my particular solution is y is equal to a times e to the minus 2x. let's see if this particular solution satisfies the second initial condition. so what is the derivative of this? y prime is equal to minus 2ae to the minus 2x. and it says that 5a-- this initial condition says that 5a is equal to minus 2a times e to the minus 2 times 0, so e to the 0. or another way of saying that, e to the 0 is just 1. it says that 5a is equal to minus 2a, which we know is not true. so note, when we only have this general, or pseudo-general, solution, it can only satisfy, generally, one of the initial conditions. and if we're really lucky, both initial conditions. so that at least gives you an intuitive feel of why this isn't the general solution. so let me clean that up a little bit so that i-- i have a feeling i'll have to use this real estate. so what do we do? we can use a technique called reduction of order. and it really just says, well let's just guess a second solution. in general when we first thought about these linear constant coefficient differential equations, we said, well e to rx might be a good guess. and why is that? because all of the derivatives of e are kind of multiples of the original function, and that's why we used it. so if we're looking for a second solution, it doesn't hurt to kind of make the same guess. and in order be a little bit more general, let's make our guess for our second solution-- i'll call this g for guess-- let's say it's some function of x times our first solution, e to the minus 2x. i could say some function of x times c times e to the minus 2x, but the c is kind of encapsulated. it could be part of this some random function of x. so let's be as general as possible. so let's assume that this is a solution and then substitute it back into our original differential equation, and see if we can actually solve for v that makes it all work. so before we do that, let's get its first and second derivatives. so the first derivative of g is equal to-- well this is product rule. and i'll drop the v of x, we know that v is a function and not a constant. so, product rule, derivative of the first, v prime times the second expression, e to the minus 2x, plus the first function, or expression, times the derivative of the second. so minus 2 times e to the minus 2x. or, just to write it a little bit neater, g prime is equal to v prime e to the minus 2x minus 2ve to the minus 2x. now we have to get the second derivative. i'll do it in a different color, just to fight the monotony of it. so the second derivative-- we're going to have to do the product rule twice-- derivative of this first expression. it's going to be v prime prime e to the minus 2x, minus 2v prime e to the minus 2x. that was just the product rule again. and then the derivative of the second expression is going to be-- let's see, derivative of the first one is v prime-- so it's going to be minus 2v prime e to the minus 2x, plus 4ve to the minus 2x. i hope i haven't made a careless mistake. and we can simplify this a little bit. so we get the second derivative of g, which is our guess solution, is equal to the second derivative of v prime, e to the minus 2x minus 2v prime-- no, minus 4, sorry, because we have minus 2, minus 2-- minus 4v prime e to the minus 2x, plus 4ve to the minus 2x. and now, before we substitute it into this, we can just make one observation. that will just make the algebra a little bit simpler. notice that g is something times e to the minus 2x. g prime is-- we could factor out an e to the minus 2x. and g prime prime, we can factor out an e to the minus 2x. so let's factor them out, essentially. so when we write this, we can write-- so the second derivative is g prime prime, which we can write as-- and i'm going to try to do this-- it's e to the minus 2x times the second derivative. so now we can get rid of the e to the minus 2x terms. so that's v prime prime minus 4v prime plus 4v, right? if i just distribute this out i get the second derivative, which is this. plus 4 times the first derivative. and i'm also going to factor out the e to the minus 2x. so, plus 4 times this. so it's going to be plus 4v prime minus 8v, right? once again, i factored out the e to the minus 2x, right? plus 4 times y. we factored out the e to the minus 2x-- so plus 4 times v. i did that, because if i didn't do that i'd be writing e to the minus 2x, and i'd probably make a careless mistake, and i'd run out of space, et cetera. but anyway, i essentially-- to get this, i just substituted the second derivative, the first derivative, and g back into the differential equation. and we know that that has to equal 0. and let's see if we can simplify this a little bit more. and then hopefully solve for v. so let's see, some things are popping out at me. so i have plus 4v plus 4v, that's plus 8v, minus 8v, right? so plus 4 minus 8 plus 4, those cancel out. it's plus 8 minus 8, those cancel out. and i also have minus 4v prime plus 4v prime. so those cancel out. and lo and behold, we've done some serious simplification. it ends up being e to the minus 2x times v prime prime-- we could call that v prime prime of x, now that we've saved so much space-- is equal to 0. we know this could never equal to 0. so, essentially, we have now established that this expression has to be equal to 0. and we get a separable second order differential equation. we get that the second derivative of v with respect to x-- or it's a function of x-- is equal to 0. so now we just have to differentiate both sides of this equation twice. you differentiate once, you get what? v prime of x is equal to, let's call it c1. and if we were to take the anti-derivative of both sides again, we get v of x is equal to c1 x plus some other c2, right? now remember, what was our guess? our guess was that our general solution was going to be some arbitrary function v times that first solution we found, e to the minus 2x. and when we actually took that guess and we substituted it in, we actually were able to solve for that v. and we got that v is equal to this. so this is interesting. so what is g, or what does our guess function equal? and it's no longer a guess. we've kind of established that it works. g, which we can call our solution, is equal to v of x, times e to the minus 2x. well, that equals this, c1 x plus c2 e to the minus 2x. that equals c1 xe to the minus 2x, plus c2 e to the minus 2x. and now we have a truly general solution. we have two constants, so we can satisfy two initial conditions. and if you were looking for a pattern, this is the pattern. when you have a repeated root of your characteristic equation, the general solution is going to be-- you're going to use that e to the, that whatever root is, twice. but one time you're going to have an x in front of it. and this works every time for second order homogeneous constant coefficient linear equations. i will see you in the next video.",t_329497f8cf41,t_329497f8cf41,4
c_fa4e7e217868,"sometimes, before differentiating a function, we can rewrite it so the process of differentiation is faster and easier.  - [instructor] what i have listed here is several of the derivative rules that we've used in previous videos. if these things look unfamiliar to you i encourage you to maybe to not watch this video because in this video we're going to think about when do we apply these rules? what strategies and can we algebraically convert expressions so that we can use a simpler rule? but this is a quick review, this is of course the power rule right over here, very handy for taking derivatives of x raised to some power. it's also we can use that with the derivative properties of sums of derivatives or differences of derivatives to take derivatives of polynomials. this right over here is the product rule. if i have an expression that i want to take the derivative of and i can think of it as the product of two functions, well then the derivative is going to be the derivative of the first function times the second function plus the first function times the derivative of the second. once again if this looks completely unfamiliar to you or you're a little shaky, go watch the videos, do the practice on the power rule and the product rule, or in this case the quotient rule. and the quotient rule is a little bit more involved and we have practicing videos on that and i always have mixed feelings about it because if you don't remember the quotient rule, you can usually or you can always convert a quotient into a product by expressing this thing at the bottom as f of x times g of x to the negative one. so you could take the derivative with a combination of the products and this fourth rule over here, the chain rule. and if any of this is looking unfamiliar again don't watch this video, this video is for folks who are familiar with each of these derivative rules or derivative techniques and now want to think about well what are strategies for deciding when to apply which. so let's do that. let's say that i have the expression, let's say i'm interested in taking the derivative of x squared plus x minus two over x minus one. which of these rules or techniques would you use? well you might immediately say hey look this looks like a rational expression, i could say this is my f of x right over here, i could say this is my g of x right over here and i could apply the quotient rule, this looks like a quotient of two expressions. and you could do that and if you do all the mathematics correctly, you will get the correct answer. but in this case it's good to just take a little time to realize well can i simplify this algebraically so maybe i can do a little bit less work? and if you look at it that way, you might realize wait what if i factored this numerator i can factor it as x plus two times x minus one. and then i could cancel these two characters out and i can say hey you know what this is going to be the same thing as the derivative with respect to x of x plus two. derivative with respect to x of x plus two, which is much much much much more straightforward than trying to apply the quotient rule. here you would just take the derivative with respect to x of x which is just going to be one and the derivative with respect to x of two is just going to be zero and so all of this is going to simplify to one. if we're taking the derivative of that, you're essentially just using the power rule. and so once again just a simple algebraic recognition things become much more simple. let's do another example. so let's say that you were to see, or someone were to ask you to take the derivative with respect to x of, let me see, so let's say you had x squared plus two x minus five over x. so once again you might be tempted to use the quotient rule, this looks like the quotient of two expressions. but then you might realize there's some algebraic manipulations i could do to make this simpler. you could express this as a product, you could say that this is the same thing as, and i'm just going to focus on what's inside the parentheses or inside the brackets, this is the same thing as x to the negative one times x squared plus 2x minus five and then you might want to apply the product rule. but there's even a better simplification here. you could just divide each of these terms by x or one way to think about it distribute this one over x across all the terms, x to the negative one is the same thing as one over x and if you do that x squared divided by x is going to be x. 2x divided by x is going to be two and then negative five divided by x, well you could write that as negative five over x or negative five x to the negative one. and now i'm taking the derivative of this with respect to x is much easier than using either the quotient or the power rule. this is going to be, let's see the derivative of that is going to be one, derivative of two is going to be zero and here even though you have a negative exponent, it might look a little intimidating, this is just taken using the power rule. so negative one times negative five is positive five x to the, if we take one less than negative one we're going to go the negative two power. so once again making this algebraic recognition simplified things a good bit. let's do a few more examples of just starting to recognize when we might be able to simplify things to do things a little bit easier. so let's say that someone said hey you take the derivative with respect to x and i'm using x as our variable that we're taking the derivative of with respect to but obviously this works for any variables that we are using. so let's say we're saying square root of x over x squared. pause this video and think about how would you approach this if you want to take the derivative with respect to x of the square root of x over x squared. well once again you might say this is a quotient of two expressions, might try to apply the quotient rule, or you might recognize well look this is the same thing, let me just focus on what's inside the brackets, you could view this as x to the negative two times the square root of x and then you might want to use the product rule but you could simplify this even better. you could say this is the same thing as x to the negative two times x to the one half power and now just using our exponent properties, negative two plus one half is negative three halves, so this is the derivative x to the negative three halves power. and so here once again we took something that we thought we might have to use the quotient rule or use the product rule and now this just becomes a straightforward using the power rule. so this is just going to be equal to, so bring the negative three halves out front, negative three halves, x to the negative three halves minus one is negative five halves power. so once again just before you, especially if you're about to apply the quotient rule and sometimes even the product rule, just see is there an algebraic simplification, sometimes a trigonometric simplification that you can make that eases your job that makes things less hairy? as a general tip i can't say this is going to be always true but if you're taking some type of exam and you're going down some really hairy route which the quotient rule will often take you, it's a good sign that hey take a pause before trying to run through all of that algebra to apply the quotient rule and see if you can simplify things. so let's give another example. in this one there's not an obvious way and it really depends on what folks' preferences are, but let's say you want to take the derivative with respect to x of one over 2x to the negative five, sorry, one over 2x minus five i should say. well here you could immediately apply the quotient rule here the numerator you view that as f of x. you could view this as the same thing as the derivative with respect to x. instead of 2x minus five, let me do that in the blue color. 2x minus five to the negative one power. in this situation, you would use a combination of the power rule and the chain rule. you would say okay my g of x is 2x minus five and f of g of x is going to be this whole expression. and so if you applied the chain rule, this is going to be the derivative of the outside function, our f of x with respect to the inside function. the derivative of f of g of x with respect to g of x. so it's going to be negative, we'll bring that negative out front, so we're essentially just going to use the power rule here. negative 2x minus five to the negative two and then we multiply that times the derivative of the inside function. so the inside function's derivative, the derivative of 2x is two, the derivative of negative five is zero so it's going to be times two and of course you can simplify so it's a negative two times all of this business. let me do one more example here just to hit the point home and once again there isn't a must way, there isn't a way that you have to do this, but just let you appreciate that there's multiple ways to approach these types of derivatives. so let's say someone said take the derivative of 2x plus one squared. pause the video and think about how you would do that. well one way to do it is just to apply the chain rule just like we just did. so you could say alright here's going to be the derivative of the outside with respect to the inside. so it's going to be two times 2x plus one to the first power, taking one less than that times the derivative of the inside which is just going to be two and so this is going to be equal to four times 2x plus one, which is equal to, if we want to distribute the four, we could say it's 8x plus four. that's a completely legitimate way of doing it. now there are other ways of doing it. you could expand out to x plus one squared. you could say hey this is the same thing as the derivative with respect to x of 2x squared is going to be 4x squared and then two times the product of these terms is going to be plus 4x plus one. and now you would just apply the power rule. it's a little bit of extra algebra up front but you can just go straightforward with the power rule and you're going to get this exact same thing. so the whole takeaway here is pause look at your expression. see if there's a way to simplify it and it's especially a good thing if you can get out of using the quotient rule 'cause that sometimes is just hard to know or remember and even when you do remember it, it can get quite hairy quite fast.",t_329497f8cf41,t_329497f8cf41,4
c_92cb5a0bdca2,"sal differentiates ∜(x³+4x²+7) and evaluates the derivative at x=-3.  - [voiceover] let's see if we can take the derivative with respect to x of the fourth root of x to the third power plus four x squared plus seven. and at first you might say, ""all right, ""how do i take the derivative of the fourth root ""of something, it looks like i have a composite function, ""i'm taking the fourth root of another expression?"" and you'd be right. and if you're dealing with a composite function, the chain rule should be front of mind. but first, let's just make this fourth root a little bit more tractable for us. and just realize that this fourth root is nothing but a fractional exponent. so this is the same thing as the derivative with respect to x of x to the third plus four x squared plus seven to the 1/4 power, to the 1/4 power. now, how do we take the derivative of this? well, we can view this, as i said a few seconds ago, we can view this as a composite function. what do we do first with our x? well, we do all of this business, and we can call this u of x. and then whatever we get for u of x, we raise that to the fourth power. so the way that we would take the derivative, we would take the derivative of this, you could view it as the outer function with respect to u of x and then multiply that times the derivative of u with respect to x. so let's do that. so what this is going to be, this is going to be equal to, so we're gonna take our outside function, which i'm highlighting in green now, so, or i take something to the 1/4, i'm gonna take the derivative of that with respect to the inside, with respect to u of x. well, i'm just gonna use the power rule here. i'm just gonna bring that 1/4 out front, so it's gonna be 1/4 times whatever i'm taking the derivative with respect to, to the 1/4 minus one power. look, all i did was use the power rule here. i didn't have an x here. now i'm taking the derivative with respect to u of x, with respect to this polynomial expression here. so i could just throw the u of x in here if i like, actually let me just do that. so, this is going to be x to the third plus four x squared plus seven. and then i wanna multiply that, and this is the chain rule. i took the derivative of the outside with respect to the inside and then i'm gonna multiply that times the derivative of the inside. so what's the derivative of u of x? u prime of x, let's see we just gonna use the power rule a bunch of times, it's gonna be three x squared plus two times four is eight x to the two minus one is just one power, first power, so i can just write that as eight x, and then the derivative with respect to x of seven, well, the derivative with respect to x of a constant is just gonna be zero. so that's u prime of x. so then i'm just gonna multiply by u prime of x which is three x squared plus, three x squared plus eight x. and so, well, i can clean this up a little bit, so this would be equal to, this would be equal to. actually let me just rewrite that exponent there. so this 1/4 minus one, i can rewrite it, 1/4 minus one is negative 3/4, negative 3/4, negative 3/4 power. and you can manipulate this in different ways, if you like, but the key is to just recognize that this is an application of the chain rule. derivative of the outside, well, actually, the first thing to realize is the fourth root is the same thing as taking something to the 1/4 power, basic exponent property, and then realize, okay, i have a composite function here. so i can take the derivative of the outside with respect to the inside, that's what we did here, times the derivative of the inside with respect to x. and so if someone were to tell you, if someone were to say, ""all right, f of x, ""f of x is equal to the fourth root of ""x to the third plus four x squared plus seven,"" and then they said, ""well, what is f prime of ""i don't know, negative three?"" well, you would evaluate this at negative three. so let me just do that. so it's 1/4 times, see, you have negative 27, i hope this works out reasonably well, plus 36, plus 36, plus 7 to the negative 3/4, what does this result to? this is going to be equal to, this right over here is 16, right? negative 27 plus seven is negative 20 plus 36, so this is 16. i think this is going to work out nicely. and then times three times negative, so three times nine, which is 27 minus 24. so this is going to be right over here, that is going to be three. now, what is 16 to the negative 3/4? so this is 1/4 times, so 16 times to the 1/4 is two and then you raise that to the, let me, actually i don't want to skip steps here. at this point we're dealing with algebra, or maybe even pre-algebra. so this is going to be times, times, 16 to the 1/4, and then we're gonna raise that to the negative three times that three out front. so we could put that three there. 16 to the 1/4 is two, two to the third is eight, so two to the negative third power is 1/8, so that is 1/8. so we have 3/4 times 1/8 which is equal to three over 32, 3/32. so that would be the slope of the tangent line of the graph y is equal to f of x when x is equal to negative three.",t_329497f8cf41,t_329497f8cf41,4
c_9ea0df84b137,"addressing treating differentials algebraically  - [instructor] so when you first learn calculus, you learn that the derivative of some function f, could be written as f prime of x is equal to the limit as, then there's multiple ways of doing this, the change in x approaches zero of f of x plus our change in x, minus f of x, over our change in x. and you learn multiple notations for this. for example, if you that y is equal f of x, you might write this as y prime. you might write this as d-y, d-x, which you'll often hear me say is the derivative of y, with respect to x, and that you can do the derivative of f with respect to x because y is equal to our function. but then later on when you, especially when you start getting into differential equations, you see people start to treat this notation as an actual algebraic expression. for example, you will learn or you might have already seen. if you're trying to solve the differential equation, the derivative of y with respect to x, is equal to y. so the rate of change of y with respect to x is equal to the value of y itself. this is one of, the most basic differential equations you might see. you'll see this technique, where people just say, ""well, let's just multiply both sides by d-x."" just treating d-x like as if it's some algebraic expression. so you multiply both sides by d-x and then you have, so that would cancel out algebraically, and so you see people treat it like that. so you have d-y is equal to y times d-x, and then they'll say, ""okay let's divide both sides by y."" which is a reasonable thing to do. y is an algebraic expression. so if you divide both sides by y, you get one over y, d-y is equal to d-x. and then folks will integrate both sides to find a general solution to this differential equation. but my point on this video isn't to think about how do you solve a differential equation here, but to think about this notion of using, what we call differentials. so a d-x, or a d-y, and treating them algebraically like this. treating them as algebraic expressions, where i can just multiply both sides by just d-x or d-y, or divide both sides by d-x or d-y. and i don't normally say this, but the rigor you need to show that this is okay in this situation, is not an easy thing to say. and so to just feel reasonably okay about doing this, this is a little bit hand wavy, it's not super mathematically rigorous. but it has proven to be a useful tool for us, to find these solutions. and conceptually the way that i think about a d-y, or a d-x, is this is the super small change in y, in response to a super small change in x. and that's essentially what this definition of the limit is telling us. especially as delta x approaches zero, we're going to have a super small change in x, as delta x approaches zero. and then we're going to have a resulting super small change in y. so that's one way that you can feel a little bit better, of... and this is actually one of the justifications for this type of notation. as you can view this, what's the resulting super small, or what's the super small change in y, for a given super small change in x? which is giving us the sense of what's the limiting value of the slope? as we go from the slope of the secant line to a tangent line? and if you view it that way you might feel a little bit better about using the differentials, or creating them algebraically. let me just multiply both sides by that super small change in x. so the big picture is, this is a technique that you'll often see, in introductory differential equations classes. introductory multi-variable classes and introductory calculus classes. but it's not very mathematically rigorous, to just treat differentials like algebraic expressions. but even thought it's not very mathematically rigorous to do it willy nilly like that. it has proven to be very useful. now as you get more sophisticated in your mathematics there are rigorous definitions of a differential. where you can get a better sense of where it is mathematically rigorous to use it and where it isn't. but the whole point here is, if you felt a little weird feeling about multiplying both sides by d-x or dividing both sides by d-x or d-y. your feeling was mathematically justified, because it's not a very rigorous thing to do. at least until you have more rigor behind it, but i will tell you that if you're an introductory student it is a reasonable thing to do as you explore and manipulate some of these basic differential equations.",t_329497f8cf41,t_329497f8cf41,4
c_2d649a063558,"sal analyzes two attempts of students to differentiate linear functions.  - [voiceover] so we have two examples here of someone trying to find the derivative of an expression. on the left-hand side, it says ""avery tried to find the derivative, ""of seven minus five x using basic differentiation rules. ""here is her work,"" and on the right-hand side it says ""hannah tried to find the derivative, ""of negative three plus eight x, ""using basic differentiation rules, ""here is her work."" and these are two different examples of differentiation rules exercise on khan academy, and i thought i would just do them side by side, because we can kind of think about what each of these people are doing correct or incorrect. so these are similar expressions, we have a constant and then we have a first degree term, a constant and then first degree term. so they're gonna take the derivative, so let's see, step one for avery. she took, she's separately taking the derivative of seven, and separately taking the derivative of five x. so this my spider senses already going off here, because what happened to this negative right over here? so it would've sense for her to do the derivative of seven, and she could've said minus the derivative, of five x, that's one possibility that she could've done. the derivative of a difference is equal to the difference of the derivatives, we've seen that property. or, she could've said, the derivative, she could've said this was equal to the derivative of seven, plus the derivative with respect to x of negative five x. these two things would've been equivalent to this one. but for this one, she somehow forgot to, include the negative. so i think she had a problem right at step one. now, if you just follow her logic after step one, let's see if she makes any more mistakes. so, she takes the derivative of a constant, so constant isn't going to change with respect to x. so that makes sense, that that derivative is zero. and so we still have the derivative of five x, and remember, it should've been negative five x, or minus the derivative of five x. and let's see what she does here. so that zero disappears, and now she takes the constant, she takes the constant out, and that's true, the derivative of a constant times something, is equal to the constant times the derivative of that something. and then, she finds the derivative with respect to x of x is one, and that's true, if the slope, if you had the graph of y equals x, the slope there is one, or what's the rate of change at which x changes with respect to x? well, that's gonna be one for one. so that the slope here is one, so this is gonna be five times one. which is equal to five, and at the end they just say, at what step did avery make a mistake? so she clearly made a mistake at step one, this right of here, should've been a negative, that's a negative, then that would've been a negative. and this would've been a negative. and that would've been a negative. and then her final answer should have been, should have been a negative five. now let's go back to hannah. to see if she made any mistakes and where. so she's differentiating a similar expression, so first she takes the derivative of the constant, plus the derivative of the first degree term. derivative of constant is zero, that looks good. so you get the zero, and then you have the derivative of the first degree term. that's what she's trying to figure out. and then, let's see, she's taking... let's see, so this seems off. she is assuming that the derivative of a product is equal to the product of the derivatives. that is not the case. and especially, and if you have a constant here, there's actually a much simpler way of thinking about it. frankly the way that avery thought about it, avery had made a mistake at step one, but this is actually going to be equal to the derivative of a constant times an expression, is equal to the same thing as the constant times the derivative of, of the expression. so this would've been the correct way to go, and the derivative of x with respect to x, well that's just going to be one. so this should've all simplified to eight. what she did is, she is assuming, she tried to take the derivative of eight and multiply that times the derivative of x, that is not the way it works. in the future you will learn something called the product rule, but you won't even have to apply that here, because one of these, one of these components i guess you could say, is a constant. so this is the wrong step. this is where hannah makes a mistake. and you could see, instead of getting a final answer of eight, she is getting a final answer of, she assumes well the derivative of eight is zero, times the derivative of x is one, zero times one. and she gets zero, which is not the right answer. so she makes a mistake at step three, and avery made a mistake at step one.",t_329497f8cf41,t_329497f8cf41,4
c_09c37cd4cf34,"given that the derivative of a function is zero, we can justify whether the function has a relative maximum point by looking at the second derivative.  - [instructor] we're told that given that h prime of negative four is equal to zero, what is an appropriate calculus-based justification for the fact that h has a relative maximum at x is equal to negative four? so right over here, we actually have the graph of our function h. this is the graph y is equal to h of x. and we don't have graphed the first derivative, but we do have graphed the second derivative right here in this orange color, h prime prime. so they're telling us, given that h prime of negative four is equal to zero, so that's saying that given that the first derivative at x equals negative four is equal to zero, and you can see that the slope of the tangent line when x is equal to negative four does indeed equal zero. so given that, what is a calculus-based, let me underline that, a calculus-based justification for the fact that h has a relative maximum at x equals negative four? so this first one says that the second derivative at x equals negative four is negative. now, what does that tell us? if the second derivative is negative, that means that the first derivative is decreasing, which is another way of saying that we are dealing with a situation where, at least at x equals negative four, we are concave downwards, downwards, which means that the general shape of our curve is going to look something like this around x equals negative four. and if the slope at x equals negative four is zero, well, that tells us that, yes, we indeed are dealing with a relative maximum point. if the second derivative at that point was positive, then we would be concave upwards. and then if our derivative is zero there, we'd say, okay, that's a relative minimum point. but this is indeed true. the second derivative is negative at x equals negative four, which means we are concave downwards, which means that we are a upside u, and that point where the derivative is zero is indeed a relative maximum. so let me, so that is the answer. and we're done, but let's just rule out the other ones. h increase before x equals negative four. that is indeed true. before x equals negative four, we are increasing, and h decreases after it. that is true, and that is one rationale for thinking that, hey, we must have a maximum point, assuming that our function is continuous at x equals negative four. so this is true. it is a justification for a relative maximum, but it is not calculus-based. and so that's why we can rule this one out. the second derivative has a relative minimum at x equals negative four. well, it does indeed seem to be true. there's a relative minimum there, but that's not a justification for why this is why h of negative four or why we have a relative maximum at x equals negative four. for example, this, you could have a relative minimum in your second derivative, but your second derivative could still be positive there. so what if the second derivative was like that? that would still be a relative minimum. but if it was positive at that point, then you would be concave upwards, which would mean that at x equals negative four, your original function wouldn't have a maximum point, it would have a minimum point. and so just a relative minimum isn't enough. in order to know that you are dealing with a relative maximum, you would have to know that the second derivative is negative there. now, this fourth choice, h prime prime is concave up, it does indeed look like the second derivative is concave up, but that, by itself, does not justify that the original function is concave up. for example, well, i could use this example right here. this is a potential second derivative that is concave upwards, but it is positive the entire time. and if your second derivative is positive the entire time, that means that your first derivative is increasing the entire time, which means that your original function is going to be concave upwards the entire time. and so if you're concave upwards the entire time, then you would not have a relative maximum at x equals negative four. so we would rule that one out as well.",t_329497f8cf41,t_329497f8cf41,4
c_fa6421960916,"sal finds the derivatives of tan(x) and cot(x) by writing them as quotients of sin(x) and cos(x) and using quotient rule.  - [voiceover] we already know the derivatives of sine and cosine. we know that the derivative with respect to x of sine of x is equal to cosine of x. we know that the derivative with respect to x of cosine of x is equal to negative sine of x. and so what we want to do in this video is find the derivatives of the other basic trig functions. so, in particular, we know, let's figure out what the derivative with respect to x, let's first do tangent of x. tangent of x, well this is the same thing as trying to find the derivative with respect to x of, well, tangent of x is just sine of x, sine of x over cosine of x. and since it can be expressed as the quotient of two functions, we can apply the quotient rule here to evaluate this, or to figure out what this is going to be. the quotient rule tells us that this is going to be the derivative of the top function, which we know is cosine of x times the bottom function which is cosine of x, so times cosine of x minus, minus the top function, which is sine of x, sine of x, times the derivative of the bottom function. so the derivative of cosine of x is negative sine of x, so i can put the sine of x there, but where the negative can just cancel that out. and it's going to be over, over the bottom function squared. so cosine squared of x. now, what is this? well, what we have here, this is just a cosine squared of x, this is just sine squared of x. and we know from the pythagorean identity, and this is really just out of, comes out of the unit circle definition, the cosine squared of x plus sine squared of x, well that's gonna be equal to one for any x. so all of this is equal to one. and so we end up with one over cosine squared x, which is the same thing as, which is the same thing as, the secant of x squared. one over cosine of x is secant, so this is just secant of x squared. so that was pretty straightforward. now, let's just do the inverse of the, or you could say the reciprocal, i should say, of the tangent function, which is the cotangent. oh, that was fun, so let's do that, d dx of cotangent, not cosine, of cotangent of x. well, same idea, that's the derivative with respect to x, and this time, let me make some sufficiently large brackets. so now this is cosine of x over sine of x, over sine of x. but once again, we can use the quotient rule here, so this is going to be the derivative of the top function which is negative, use that magenta color. that is negative sine of x times the bottom function, so times sine of x, sine of x, minus, minus the top function, cosine of x, cosine of x, times the derivative of the bottom function which is just going to be another cosine of x, and then all of that over the bottom function squared. so sine of x squared. now what does this simplify to? up here, let's see, this is sine squared of x, we have a negative there, minus cosine squared of x. but we could factor out the negative and this would be negative sine squared of x plus cosine squared of x. well, this is just one by the pythagorean identity, and so this is negative one over sine squared x, negative one over sine squared x. and that is the same thing as negative cosecant squared, i'm running out of space, of x. there you go.",t_329497f8cf41,t_329497f8cf41,4
c_8aaea9f00493,"solving a separable differential equation given initial conditions. in this video, the equation is dy/dx=2y² with y(1)=1.  - let's now get some practice with separable differential equations, so let's say i have the differential equation, the derivative of y with respect to x is equal to two y-squared, and let's say that the graph of a particular solution to this, the graph of a particular solution, passes through the point one comma negative one, so my question to you is, what is y, what is y when x is equal to three for this particular solution, so the particular solution to the differential equation that passes through the point one comma negative one, what is y when x is equal to three, and i encourage you to pause the video, and try to work through it on your own. so i'm assuming you had a go at it, and the key with a separable differential equation, and that's a big clue that i'm even calling it a separable differential equation, is that you separate the xs from the ys. or all the xs and the dxs from the ys and dys. so how do you do that here? well, what i could do, let me just rewrite it. so it's gonna be dy dx is equal to two y-squared, is equal to two y, equal to two y-squared. so let's see, we can multiply both sides by dx, and let's see, so then we're gonna have, that cancels with that if we treat it as just a value, or as a variable. we're gonna have dy is equal to two y squared dx. well, we're not quite done yet. we gotta get this two y squared on the left hand side. so we can divide both sides by two y-squared. so if we divide both sides by two y-squared, two y-squared, the left hand side, we could rewrite this as 1/2 y to the negative two power, is going to be equal to dy, dy is equal to dx, and now, we can integrate both sides. so we can integrate both sides. let me give myself a little bit more space. and so, what is, what is this left hand side going to be? well, we increment the exponent, and then divide by that value, so y to the negative two, if your increment is y to the negative one, and then divide by negative one, so this is going to be -1/2 y to the negative one power, and we could do a plus c like we did in the previous video, but we're gonna have a plus c on both sides, and you could subtract, or you know, you have different arbitrary constants on both sides and you could subtract them from each other, so i'm just gonna write the constant only on one side. so you have that is equal to, well if i integrate just dx, that's just going to give me x, that's just gonna give me x. so this right over here is x, and of course i can have a plus c over there, and if i want i can, i can solve for y if i multiply, let's see, i can multiply both sides by negative two, and then i'm gonna have, the left hand side you're just gonna have y to the negative one, or 1/y is equal to, if i multiply the right hand side times negative two, i'm gonna have negative two times x plus, well it's some arbitrary constant, it's still going to, it's gonna be negative two times this arbitrary constant but i could still just call it some arbitrary constant, and then if we want we can take the reciprocal of both sides, and so we will get y is equal to, is equal to 1/-2x+c. and now we can use, we can use the information they gave us right over here, the fact that our particular solution needs to go through this point to solve for c. so, when x is negative one, so when x is negative one. oh sorry, when x is one, when x is one, y is negative one, so we get negative one is equal to 1/-2+c, or we could say c minus two, we could multiply both sides times c minus two, if then we will get, actually let me just scroll down a little bit, so if you multiply both sides times c minus two, negative one times c minus two is going to be negative c plus two or two minus c is equal to one. all i did is i multiplied c minus two times both sides, and then, let's see, i can subtract two from both sides, so negative c is equal to negative one, and then if i multiply both sides by negative one, we get c is equal to one. so our particular solution is y is equal to 1/-2x+1. and we are almost done, they didn't just ask for, we didn't just ask for the particular solution, we asked, what is y when x is equal to three. so y is going to be equal to one over, three times negative two is negative six plus one, which is equal to negative, is going to be equal to 1/-5, or -1/5. and we are done.",t_329497f8cf41,t_329497f8cf41,4
c_b61aabb9366c,"chapter 65 of the book on node.js.chapter 65: sending a ﬁle stream to client section 65.1: using fs and pipe to stream static files from the server a good vod (video on demand) service should start with the basics. lets say you have a directory on your server that is not publicly accessible, yet through some sort of portal or paywall you want to allow users to access your media. var movie = path.resolve('./public/' + req.params.filename); fs.stat(movie, function (err, stats) { var range = req.headers.range; if (!range) { return res.sendstatus(416); } //chunk logic here var positions = range.replace(/bytes=/, """").split(""-""); var start = parseint(positions[0], 10); var total = stats.size; var end = positions[1] ? parseint(positions[1], 10) : total - 1; var chunksize = (end - start) + 1; res.writehead(206, { 'transfer-encoding': 'chunked', ""content-range"": ""bytes "" + start + ""-"" + end + ""/"" + total, ""accept-ranges"": ""bytes"", ""content-length"": chunksize, ""content-type"": mime.lookup(req.params.filename) }); var stream = fs.createreadstream(movie, { start: start, end: end, autoclose: true }) .on('end', function () { console.log('stream done'); }) .on(""error"", function (err) { res.end(err); }) .pipe(res, { end: true }); });  goalkicker.com – node.js notes for professionals  205  the above snippet is a basic outline for how you would like to stream your video to a client. the chunk logic depends on a variety of factors, including network traﬃc and latency. it is important to balance chuck size vs. quantity. finally, the .pipe call lets node.js know to keep a connection open with the server and to send additional chunks as needed.  section 65.2: streaming using ﬂuent-mpeg you can also use ﬂent-ﬀmpeg to convert .mp4 ﬁles to .ﬂv ﬁles, or other types: res.contenttype('ﬂv'); var pathtomovie = './public/' + req.params.filename; var proc = ffmpeg(pathtomovie) .preset('flashvideo') .on('end', function () { console.log('stream done'); }) .on('error', function (err) { console.log('an error happened: ' + err.message); res.send(err.message); }) .pipe(res, { end: true });  goalkicker.com – node.js notes for professionals  206",t_3bea3588613c,t_3bea3588613c,5
c_bf51165b578c,"chapter 52 of the book on node.js.chapter 52: remote debugging in node.js section 52.1: use the proxy for debugging via port on linux if you start your application on linux, use the proxy for debugging via port, for example: socat tcp-listen:9958,fork tcp:127.0.0.1:5858 &  use port 9958 for remote debugging then.  section 52.2: nodejs run conﬁguration to set up node remote debugging, simply run the node process with the --debug ﬂag. you can add a port on which the debugger should run using --debug=<port>. when your node process starts up you should see the message debugger listening on port <port>  which will tell you that everything is good to go. then you set up the remote debugging target in your speciﬁc ide.  section 52.3: intellij/webstorm conﬁguration 1. make sure that the nodejs plugin is enabled 2. select your run conﬁgurations (screen)  3. select + > node.js remote debug  goalkicker.com – node.js notes for professionals  178  4. make sure you enter the port selected above as well as the correct host  once those are conﬁgured simply run the debug target as you normally would and it will stop on your breakpoints.  goalkicker.com – node.js notes for professionals  179",t_3bea3588613c,t_3bea3588613c,5
c_fb56968b9f70,"chapter 17 of the book on node.js.chapter 17: keep a node application constantly running section 17.1: use pm2 as a process manager pm2 lets you run your nodejs scripts forever. in the event that your application crashes, pm2 will also restart it for you. install pm2 globally to manager your nodejs instances npm install pm2 -g  navigate to the directory in which your nodejs script resides and run the following command each time you want to start a nodejs instance to be monitored by pm2: pm2 start server.js --name ""app1""  useful commands for monitoring the process 1. list all nodejs instances managed by pm2 pm2 list  2. stop a particular nodejs instance pm2 stop <instance named>  3. delete a particular nodejs instance pm2 delete <instance name>  4. restart a particular nodejs instance pm2 restart <instance name>  5. monitoring all nodejs instances  goalkicker.com – node.js notes for professionals  86  pm2 monit  6. stop pm2 pm2 kill  7. as opposed to restart, which kills and restarts the process, reload achieves a 0-second-downtime reload pm2 reload <instance name>  8. view logs pm2 logs <instance_name>  section 17.2: running and stopping a forever daemon to start the process: $ forever start index.js warn: --minuptime not set. defaulting to: 1000ms warn: --spinsleeptime not set. your script will exit if it does not stay up for at least 1000ms info: forever processing file: index.js  list running forever instances: $ forever list info: forever processes running |data: | index | uid | command | script |forever pid|id | logfile |uptime | |------|-------|-----|------------------|-------------|-----------|-----|------------------------  goalkicker.com – node.js notes for professionals  87  |--------------| |data: | [0] |f4kt |/usr/bin/nodejs 0:0:0:11.485 |  | src/index.js|2131  | 2146|/root/.forever/f4kt.log |  stop the ﬁrst process: $ forever stop 0 $ forever stop 2146 $ forever stop --uid f4kt $ forever stop --pidfile 2131  section 17.3: continuous running with nohup an alternative to forever on linux is nohup. to start a nohup instance 1. cd to the location of app.js or wwwfolder 2. run nohup nodejs app.js & to kill the process 1. run ps -ef|grep nodejs 2. kill -9 <the process number>  goalkicker.com – node.js notes for professionals  88",t_3bea3588613c,t_3bea3588613c,5
c_54b1e89d0fcd,"chapter 5 of the book on node.js.chapter 5: exporting and consuming modules section 5.1: creating a hello-world.js module node provides the module.exports interface to expose functions and variables to other ﬁles. the most simple way to do so is to export only one object (function or variable), as shown in the ﬁrst example. hello-world.js module.exports = function(subject) { console.log('hello ' + subject); };  if we don't want the entire export to be a single object, we can export functions and variables as properties of the exports object. the three following examples all demonstrate this in slightly diﬀerent ways :  hello-venus.js : the function deﬁnition is done separately then added as a property of module.exports hello-jupiter.js : the functions deﬁnitions are directly put as the value of properties of module.exports hello-mars.js : the function deﬁnition is directly declared as a property of exports which is a short version of module.exports  hello-venus.js function hello(subject) { console.log('venus says hello ' + subject); } module.exports = { hello: hello };  hello-jupiter.js module.exports = { hello: function(subject) { console.log('jupiter says hello ' + subject); }, bye: function(subject) { console.log('jupiter says goodbye ' + subject); } };  hello-mars.js exports.hello = function(subject) { console.log('mars says hello ' + subject); };  loading module with directory name we have a directory named hello which includes the following ﬁles: index.js goalkicker.com – node.js notes for professionals  53  // hello/index.js module.exports = function(){ console.log('hej'); };  main.js // hello/main.js // we can include the other files we've defined by using the `require()` method var hw = require('./hello-world.js'), hm = require('./hello-mars.js'), hv = require('./hello-venus.js'), hj = require('./hello-jupiter.js'), hu = require('./index.js'); // because we assigned our function to the entire `module.exports` object, we // can use it directly hw('world!'); // outputs ""hello world!"" // in this case, we assigned our function to the `hello` property of exports, so we must // use that here too hm.hello('solar system!'); // outputs ""mars says hello solar system!"" // the result of assigning module.exports at once is the same as in hello-world.js hv.hello('milky way!'); // outputs ""venus says hello milky way!"" hj.hello('universe!'); // outputs ""jupiter says hello universe!"" hj.bye('universe!'); // outputs ""jupiter says goodbye universe!"" hu(); //output 'hej'  section 5.2: loading and using a module a module can be ""imported"", or otherwise ""required"" by the require() function. for example, to load the http module that ships with node.js, the following can be used: const http = require('http');  aside from modules that are shipped with the runtime, you can also require modules that you have installed from npm, such as express. if you had already installed express on your system via npm install express, you could simply write: const express = require('express');  you can also include modules that you have written yourself as part of your application. in this case, to include a ﬁle named lib.js in the same directory as current ﬁle: const mylib = require('./lib');  note that you can omit the extension, and .js will be assumed. once you load a module, the variable is populated with an object that contains the methods and properties published from the required ﬁle. a full example: const http = require('http'); // the `http` module has the property `status_codes` console.log(http.status_codes[404]); // outputs 'not found'  goalkicker.com – node.js notes for professionals  54  // also contains `createserver()` http.createserver(function(req, res) { res.writehead(200, {'content-type': 'text/html'}); res.write('<html><body>module test</body></html>'); res.end(); }).listen(80);  section 5.3: folder as a module modules can be split across many .js ﬁles in the same folder. an example in a my_module folder: function_one.js module.exports = function() { return 1; }  function_two.js module.exports = function() { return 2; }  index.js exports.f_one = require('./function_one.js'); exports.f_two = require('./function_two.js');  a module like this one is used by referring to it by the folder name: var split_module = require('./my_module');  please note that if you required it by omitting ./ or any indication of a path to a folder from the require function argument, node will try to load a module from the node_modules folder. alternatively you can create in the same folder a package.json ﬁle with these contents: { ""name"": ""my_module"", ""main"": ""./your_main_entry_point.js"" }  this way you are not required to name the main module ﬁle ""index"".  section 5.4: every module injected only once nodejs executes the module only the ﬁrst time you require it. any further require functions will re-use the same object, thus not executing the code in the module another time. also node caches the modules ﬁrst time they are loaded using require. this reduces the number of ﬁle reads and helps to speed up the application. mymodule.js console.log(123) ; exports.var1 = 4 ;  goalkicker.com – node.js notes for professionals  55  index.js var a=require('./mymodule') ; // output 123 var b=require('./mymodule') ; // no output console.log(a.var1) ; // output 4 console.log(b.var1) ; // output 4 a.var2 = 5 ; console.log(b.var2) ; // output 5  section 5.5: module loading from node_modules modules can be required without using relative paths by putting them in a special directory called node_modules. for example, to require a module called foo from a ﬁle index.js, you can use the following directory structure: index.js \- node_modules \- foo |- foo.js \- package.json  modules should be placed inside a directory, along with a package.json ﬁle. the main ﬁeld of the package.json ﬁle should point to the entry point for your module--this is the ﬁle that is imported when users do require('yourmodule'). main defaults to index.js if not provided. alternatively, you can refer to ﬁles relative to your module  simply by appending the relative path to the require call: require('your-module/path/to/file'). modules can also be required from node_modules directories up the ﬁle system hierarchy. if we have the following directory structure: my-project \- node_modules |- foo // the foo module \- ... \- baz // the baz module \- node_modules \- bar // the bar module  we will be able to require the module foo from any ﬁle within bar using require('foo'). note that node will only match the module that is closest to the ﬁle in the ﬁlesystem hierarchy, starting from (the ﬁle's current directory/node_modules). node matches directories this way up to the ﬁle system root. you can either install new modules from the npm registry or other npm registries, or make your own.  section 5.6: building your own modules you can also reference an object to publicly export and continuously append methods to that object: const auth = module.exports = {} const config = require('../config') const request = require('request') auth.email = function (data, callback) { // authenticate with an email address } auth.facebook = function (data, callback) {  goalkicker.com – node.js notes for professionals  56  // authenticate with a facebook account } auth.twitter = function (data, callback) { // authenticate with a twitter account } auth.slack = function (data, callback) { // authenticate with a slack account } auth.stack_overflow = function (data, callback) { // authenticate with a stack overflow account }  to use any of these, just require the module as you normally would: const auth = require('./auth') module.exports = function (req, res, next) { auth.facebook(req.body, function (err, user) { if (err) return next(err) req.user = user next() }) }  section 5.7: invalidating the module cache in development, you may ﬁnd that using require() on the same module multiple times always returns the same module, even if you have made changes to that ﬁle. this is because modules are cached the ﬁrst time they are loaded, and any subsequent module loads will load from the cache. to get around this issue, you will have to delete the entry in the cache. for example, if you loaded a module: var a = require('./a');  you could then delete the cache entry: var rpath = require.resolve('./a.js'); delete require.cache[rpath];  and then require the module again: var a = require('./a');  do note that this is not recommended in production because the delete will only delete the reference to the loaded module, not the loaded data itself. the module is not garbage collected, so improper use of this feature could lead to leaking memory.  goalkicker.com – node.js notes for professionals  57",t_3bea3588613c,t_3bea3588613c,5
c_ef0dfab9d3b4,"chapter 3 of the book on node.js.chapter 3: web apps with express parameter path  details speciﬁes the path portion or the url that the given callback will handle.  middleware  one or more functions which will be called before the callback. essentially a chaining of multiple callback functions. useful for more speciﬁc handling for example authorization or error handling.  callback  a function that will be used to handle requests to the speciﬁed path. it will be called like callback(request, response, next), where request, response, and next are described below.  callback request an object encapsulating details about the http request that the callback is being called to handle. response  an object that is used to specify how the server should respond to the request.  next  a callback that passes control on to the next matching route. it accepts an optional error object.  express is a minimal and ﬂexible node.js web application framework, providing a robust set of features for building web applications. the oﬃcial website of express is expressjs.com. the source can be found on github.  section 3.1: getting started you will ﬁrst need to create a directory, access it in your shell and install express using npm by running npm install express --save  create a ﬁle and name it app.js and add the following code which creates a new express server and adds one endpoint to it (/ping) with the app.get method: const express = require('express'); const app = express(); app.get('/ping', (request, response) => { response.send('pong'); }); app.listen(8080, 'localhost');  to run your script use the following command in your shell: > node app.js  your application will accept connections on localhost port 8080. if the hostname argument to app.listen is omitted, then server will accept connections on the machine's ip address as well as localhost. if port value is 0, the operating system will assign an available port. once your script is running, you can test it in a shell to conﬁrm that you get the expected response, ""pong"", from the server: > curl http://localhost:8080/ping pong  you can also open a web browser, navigate to the url http://localhost:8080/ping to view the output  goalkicker.com – node.js notes for professionals  30  section 3.2: basic routing first create an express app: const express = require('express'); const app = express();  then you can deﬁne routes like this: app.get('/someuri', function (req, res, next) {})  that structure works for all http methods, and expects a path as the ﬁrst argument, and a handler for that path, which receives the request and response objects. so, for the basic http methods, these are the routes // get www.domain.com/mypath app.get('/mypath', function (req, res, next) {}) // post www.domain.com/mypath app.post('/mypath', function (req, res, next) {}) // put www.domain.com/mypath app.put('/mypath', function (req, res, next) {}) // delete www.domain.com/mypath app.delete('/mypath', function (req, res, next) {})  you can check the complete list of supported verbs here. if you want to deﬁne the same behavior for a route and all http methods, you can use: app.all('/mypath', function (req, res, next) {})  or app.use('/mypath', function (req, res, next) {})  or app.use('*', function (req, res, next) {}) // * wildcard will route for all paths  you can chain your route deﬁnitions for a single path app.route('/mypath') .get(function (req, res, next) {}) .post(function (req, res, next) {}) .put(function (req, res, next) {})  you can also add functions to any http method. they will run before the ﬁnal callback and take the parameters (req, res, next) as arguments. // get www.domain.com/mypath app.get('/mypath', myfunction, function (req, res, next) {})  your ﬁnal callbacks can be stored in an external ﬁle to avoid putting too much code in one ﬁle: goalkicker.com – node.js notes for professionals  31  // other.js exports.dosomething = function(req, res, next) {/* do some stuff */};  and then in the ﬁle containing your routes: const other = require('./other.js'); app.get('/someuri', myfunction, other.dosomething);  this will make your code much cleaner.  section 3.3: modular express application to make express web application modular use router factories: module: // greet.js const express = require('express'); module.exports = function(options = {}) { // router factory const router = express.router(); router.get('/greet', (req, res, next) => { res.end(options.greeting); }); return router; };  application: // app.js const express = require('express'); const greetmiddleware = require('./greet.js'); express() .use('/api/v1/', greetmiddleware({ greeting:'hello world' })) .listen(8080);  this will make your application modular, customisable and your code reusable. when accessing http://<hostname>:8080/api/v1/greet the output will be hello world more complicated example example with services that shows middleware factory advantages. module: // greet.js const express = require('express'); module.exports = function(options = {}) { // router factory const router = express.router(); // get controller const {service} = options; router.get('/greet', (req, res, next) => {  goalkicker.com – node.js notes for professionals  32  res.end( service.creategreeting(req.query.name || 'stranger') ); }); return router; };  application: // app.js const express = require('express'); const greetmiddleware = require('./greet.js'); class greetingservice { constructor(greeting = 'hello') { this.greeting = greeting; } creategreeting(name) { return `${this.greeting}, ${name}!`; } } express() .use('/api/v1/service1', greetmiddleware({ service: new greetingservice('hello'), })) .use('/api/v1/service2', greetmiddleware({ service: new greetingservice('hi'), })) .listen(8080);  when accessing http://<hostname>:8080/api/v1/service1/greet?name=world the output will be hello, world and accessing http://<hostname>:8080/api/v1/service2/greet?name=world the output will be hi, world.  section 3.4: using a template engine using a template engine the following code will setup jade as template engine. (note: jade has been renamed to pug as of december 2015.) const express = require('express'); //imports the express module const app = express(); //creates an instance of the express module const port = 3000; //randomly chosen port app.set('view engine','jade'); //sets jade as the view engine / template engine app.set('views','src/views'); //sets the directory where all the views (.jade files) are stored. //creates a root route app.get('/',function(req, res){ res.render('index'); //renders the index.jade file into html and returns as a response. the render function optionally takes the data to pass to the view. }); //starts the express server with a callback app.listen(port, function(err) { if (!err) { console.log('server is running at port', port);  goalkicker.com – node.js notes for professionals  33  } else { console.log(json.stringify(err)); } });  similarly, other template engines could be used too such as handlebars(hbs) or ejs. remember to npm install the template engine too. for handlebars we use hbs package, for jade we have a jade package and for ejs, we have an ejs package.  ejs template example with ejs (like other express templates), you can run server code and access your server variables from you html. in ejs it's done using ""<%"" as start tag and ""%>"" as end tag, variables passed as the render params can be accessed using <%=var_name%> for instance, if you have supplies array in your server code you can loop over it using <h1><%= title %></h1> <ul> <% for(var i=0; i<supplies.length; i++) { %> <li> <a href='supplies/<%= supplies[i] %>'> <%= supplies[i] %> </a> </li> <% } %>  as you can see in the example every time you switch between server side code and html you need to close the current ejs tag and open a new one later, here we wanted to create li inside the for command so we needed to close our ejs tag at the end of the for and create new tag just for the curly brackets another example if we want to put input default version to be a variable from the server side we use <%= for example: message:<br> <input type=""text"" value=""<%= message %>"" name=""message"" required>  here the message variable passed from your server side will be the default value of your input, please be noticed that if you didn't pass message variable from your server side, ejs will throw an exception. you can pass parameters using res.render('index', {message: message}); (for ejs ﬁle called index.ejs). in the ejs tags you can also use if , while or any other javascript command you want.  section 3.5: json api with expressjs var express = require('express'); var cors = require('cors'); // use cors module for enable cross-origin resource sharing var app = express(); app.use(cors()); // for all routes var port = process.env.port || 8080; app.get('/', function(req, res) { var info = { 'string_value': 'stackoverflow',  goalkicker.com – node.js notes for professionals  34  'number_value': 8476 } res.json(info); // or /* res.send(json.stringify({ string_value: 'stackoverflow', number_value: 8476 })) */ //you can add a status code to the json response /* res.status(200).json(info) */ }) app.listen(port, function() { console.log('node.js listening on port ' + port) })  on http://localhost:8080/ output object { string_value: ""stackoverflow"", number_value: 8476 }  section 3.6: serving static ﬁles when building a webserver with express it's often required to serve a combination of dynamic content and static ﬁles. for example, you may have index.html and script.js which are static ﬁles kept in the ﬁle system. it is common to use folder named 'public' to have static ﬁles. in this case the folder structure may look like: project root ├── server.js ├── package.json └── public ├── index.html └── script.js  this is how to conﬁgure express to serve static ﬁles: const express = require('express'); const app = express(); app.use(express.static('public'));  note: once the folder is conﬁgured, index.html, script.js and all the ﬁles in the ""public"" folder will be available in at the root path (you must not specify /public/ in the url). this is because, express looks up for the ﬁles relative to the static folder conﬁgured. you can specify virtual path preﬁx as shown below: app.use('/static', express.static('public'));  will make the resources available under the /static/ preﬁx. multiple folders goalkicker.com – node.js notes for professionals  35  it is possible to deﬁne multiple folders at the same time: app.use(express.static('public')); app.use(express.static('images')); app.use(express.static('files'));  when serving the resources express will examine the folder in deﬁnition order. in case of ﬁles with the same name, the one in the ﬁrst matching folder will be served.  section 3.7: adding middleware middleware functions are functions that have access to the request object (req), the response object (res), and the next middleware function in the application’s request-response cycle. middleware functions can execute any code, make changes to res and req objects, end response cycle and call next middleware. very common example of middleware is cors module. to add cors support, simply install it, require it and put this line: app.use(cors());  before any routers or routing functions.  section 3.8: error handling basic error handling by default, express will look for an 'error' view in the /views directory to render. simply create the 'error' view and place it in the views directory to handle errors. errors are written with the error message, status and stack trace, for example: views/error.pug html body h1= message h2= error.status p= error.stack  advanced error handling deﬁne your error-handling middleware functions at the very end of the middleware function stack. these have four arguments instead of three (err, req, res, next) for example: app.js // catch 404 and forward to error handler app.use(function(req, res, next) { var err = new error('not found'); err.status = 404; //pass error to the next matching route. next(err); });  goalkicker.com – node.js notes for professionals  36  // handle error, print stacktrace app.use(function(err, req, res, next) { res.status(err.status || 500); res.render('error', { message: err.message, error: err }); });  you can deﬁne several error-handling middleware functions, just as you would with regular middleware functions.  section 3.9: getting info from the request to get info from the requesting url (notice that req is the request object in the handler function of routes). consider this route deﬁnition /settings/:user_id and this particular example /settings/32135?field=name // get the full path req.originalurl // => /settings/32135?field=name // get the user_id param req.params.user_id // => 32135 // get the query value of the field req.query.field // => 'name'  you can also get headers of the request, like this req.get('content-type') // ""text/plain""  to simplify getting other info you can use middlewares. for example, to get the body info of the request, you can use the body-parser middleware, which will transform raw request body into usable format. var app = require('express')(); var bodyparser = require('body-parser'); app.use(bodyparser.json()); // for parsing application/json app.use(bodyparser.urlencoded({ extended: true })); // for parsing application/x-www-form-urlencoded  now suppose a request like this put /settings/32135 { ""name"": ""peter"" }  you can access the posted name like this req.body.name // ""peter""  in a similar way, you can access cookies from the request, you also need a middleware like cookie-parser req.cookies.name  goalkicker.com – node.js notes for professionals  37  section 3.10: error handling in express in express, you can deﬁne uniﬁed error handler for handling errors occurred in application. deﬁne then handler at the end of all routes and logic code. example var express = require('express'); var app = express(); //get /names/john app.get('/names/:name', function(req, res, next){ if (req.params.name == 'john'){ return res.send('valid name'); } else{ next(new error('not valid name')); //pass to error handler } }); //error handler app.use(function(err, req, res, next){ console.log(err.stack); // e.g., not valid name return res.status(500).send('internal server occurred'); }); app.listen(3000);  section 3.11: hook: how to execute code before any req and after any res app.use() and middleware can be used for ""before"" and a combination of the close and ﬁnish events can be used  for ""after"". app.use(function (req, res, next) { function afterresponse() { res.removelistener('finish', afterresponse); res.removelistener('close', afterresponse); // actions after response } res.on('finish', afterresponse); res.on('close', afterresponse); // action before request // eventually calling `next()` next(); }); ... app.use(app.router);  an example of this is the logger middleware, which will append to the log after the response by default. just make sure this ""middleware"" is used before app.router as order does matter. original post is here  goalkicker.com – node.js notes for professionals  38  section 3.12: setting cookies with cookie-parser the following is an example for setting and reading cookies using the cookie-parser module: var express = require('express'); var cookieparser = require('cookie-parser'); // module for parsing cookies var app = express(); app.use(cookieparser()); app.get('/setcookie', function(req, res){ // setting cookies res.cookie('username', 'john doe', { maxage: 900000, httponly: true }); return res.send('cookie has been set'); }); app.get('/getcookie', function(req, res) { var username = req.cookies['username']; if (username) { return res.send(username); } return res.send('no cookie found'); }); app.listen(3000);  section 3.13: custom middleware in express in express, you can deﬁne middlewares that can be used for checking requests or setting some headers in response. app.use(function(req, res, next){ });  // signature  example the following code adds user to the request object and pass the control to the next matching route. var express = require('express'); var app = express(); //each request will pass through it app.use(function(req, res, next){ req.user = 'testuser'; next(); // it will pass the control to next matching route }); app.get('/', function(req, res){ var user = req.user; console.log(user); // testuser return res.send(user); }); app.listen(3000);  section 3.14: named routes in django-style one big problem is that valuable named routes is not supported by express out of the box. solution is to install supported third-party package, for example express-reverse: goalkicker.com – node.js notes for professionals  39  npm install express-reverse  plug it in your project: var app = require('express')(); require('express-reverse')(app);  then use it like: app.get('test', '/hello', function(req, res) { res.end('hello'); });  the downside of this approach is that you cant use route express module as shown in advanced router usage. the workaround is to pass your app as a parameter to you router factory: require('./middlewares/routing')(app);  and use it like: module.exports = (app) => { app.get('test', '/hello', function(req, res) { res.end('hello'); }); };  you can ﬁgure it out from now on, how deﬁne functions to merge it with speciﬁed custom namespaces and point at appropriate controllers.  section 3.15: hello world here we create a basic hello world server using express. routes: '/' '/wiki' and for rest will give ""404"" , i.e. page not found. 'use strict'; const port = process.env.port || 3000; var app = require('express')(); app.listen(port); app.get('/',(req,res)=>res.send('helloworld!')); app.get('/wiki',(req,res)=>res.send('this is wiki page.')); app.use((req,res)=>res.send('404-pagenotfound'));  note: we have put 404 route as the last route as express stacks routes in order and processes them for each request sequentially.  section 3.16: using middleware and the next callback express passes a next callback to every route handler and middleware function that can be used to break logic for goalkicker.com – node.js notes for professionals  40  single routes across multiple handlers. calling next() with no arguments tells express to continue to the next matching middleware or route handler. calling next(err) with an error will trigger any error handler middleware. calling next('route') will bypass any subsequent middleware on the current route and jump to the next matching route. this allows domain logic to be decoupled into reusable components that are self-contained, simpler to test, and easier to maintain and change. multiple matching routes requests to /api/foo or to /api/bar will run the initial handler to look up the member and then pass control to the actual handler for each route. app.get('/api', function(req, res, next) { // both /api/foo and /api/bar will run this lookupmember(function(err, member) { if (err) return next(err); req.member = member; next(); }); }); app.get('/api/foo', function(req, res, next) { // only /api/foo will run this dosomethingwithmember(req.member); }); app.get('/api/bar', function(req, res, next) { // only /api/bar will run this dosomethingdifferentwithmember(req.member); });  error handler error handlers are middleware with the signature function(err, req, res, next). they could be set up per route (e.g. app.get('/foo', function(err, req, res, next)) but typically, a single error handler that renders an error page is suﬃcient. app.get('/foo', function(req, res, next) { dosomethingasync(function(err, data) { if (err) return next(err); renderpage(data); }); }); // in the case that dosomethingasync return an error, this special // error handler middleware will be called with the error as the // first parameter. app.use(function(err, req, res, next) { rendererrorpage(err); });  middleware each of the functions above is actually a middleware function that is run whenever a request matches the route deﬁned, but any number of middleware functions can be deﬁned on a single route. this allows middleware to be deﬁned in separate ﬁles and common logic to be reused across multiple routes. app.get('/bananas', function(req, res, next) { getmember(function(err, member) {  goalkicker.com – node.js notes for professionals  41  if (err) return next(err); // if there's no member, don't try to look // up data. just go render the page now. if (!member) return next('route'); // otherwise, call the next middleware and fetch // the member's data. req.member = member; next(); }); }, function(req, res, next) { getmemberdata(req.member, function(err, data) { if (err) return next(err); // if this member has no data, don't bother // parsing it. just go render the page now. if (!data) return next('route'); // otherwise, call the next middleware and parse // the member's data. then render the page. req.member.data = data; next(); }); }, function(req, res, next) { req.member.parseddata = parsememberdata(req.member.data); next(); }); app.get('/bananas', function(req, res, next) { renderbananas(req.member); });  in this example, each middleware function would be either in it's own ﬁle or in a variable elsewhere in the ﬁle so that it could be reused in other routes.  section 3.17: error handling basic docs can be found here app.get('/path/:id(\\d+)', function (req, res, next) { // please note: ""next"" is passed if (req.params.id == 0) // validate param return next(new error('id is 0')); // go to first error handler, see below // catch error on sync operation var data; try { data = json.parse('/file.json'); } catch (err) { return next(err); } // if some critical error then stop application if (!data) throw new error('smth wrong'); // if you need send extra info to error handler // then send custom error (see appendix b) if (smth) next(new myerror('smth wrong', arg1, arg2)) // finish request by res.render or res.end res.status(200).end('ok'); });  goalkicker.com – node.js notes for professionals  42  // be sure: order of app.use have matter // error handler app.use(function(err, req, res, next)) { if (smth-check, e.g. req.url != 'post') return next(err); // go-to error handler 2. console.log(req.url, err.message); if (req.xhr) // if req via ajax then send json else render error-page res.json(err); else res.render('error.html', {error: err.message}); }); // error handler 2 app.use(function(err, req, res, next)) { // do smth here e.g. check that error is myerror if (err instanceof myerror) { console.log(err.message, err.arg1, err.arg2); } ... res.end(); });  appendix a // ""in express, 404 responses are not the result of an error, // so the error-handler middleware will not capture them."" // you can change it. app.use(function(req, res, next) { next(new error(404)); });  appendix b // how to define custom error var util = require('util'); ... function myerror(message, arg1, arg2) { this.message = message; this.arg1 = arg1; this.arg2 = arg2; error.capturestacktrace(this, myerror); } util.inherits(myerror, error); myerror.prototype.name = 'myerror';  section 3.18: handling post requests just like you handle get requests in express with app.get method, you can use app.post method to handle post requests. but before you can handle post requests, you will need to use the body-parser middleware. it simply parses the body of post, put, delete and other requests. body-parser middleware parses the body of the request and turns it into an object available in req.body var bodyparser = require('body-parser');  goalkicker.com – node.js notes for professionals  43  const express = require('express'); const app = express(); // parses the body for post, put, delete, etc. app.use(bodyparser.json()); app.use(bodyparser.urlencoded({ extended: true })); app.post('/post-data-here', function(req, res, next){ console.log(req.body); // req.body contains the parsed body of the request. }); app.listen(8080, 'localhost');  goalkicker.com – node.js notes for professionals  44",t_3bea3588613c,t_3bea3588613c,5
c_08a28aca83aa,"chapter 20 of the book on node.js.chapter 20: http section 20.1: http server a basic example of http server. write following code in http_server.js ﬁle: var http = require('http'); var httpport = 80; http.createserver(handler).listen(httpport, start_callback); function handler(req, res) { var clientip = req.connection.remoteaddress; var connectusing = req.connection.encrypted ? 'ssl' : 'http'; console.log('request received: '+ connectusing + ' ' + req.method + ' ' + req.url); console.log('client ip: ' + clientip); res.writehead(200, ""ok"", {'content-type': 'text/plain'}); res.write(""ok""); res.end(); return; } function start_callback(){ console.log('start http on port ' + httpport) }  then from your http_server.js location run this command: node http_server.js  you should see this result: > start http on port 80  now you need to test your server, you need to open your internet browser and navigate to this url: http://127.0.0.1:80  if your machine running linux server you can test it like this: curl 127.0.0.1:80  you should see following result: ok  in your console, that running the app, you will see this results: > request received: http get / > client ip: ::ffff:127.0.0.1  goalkicker.com – node.js notes for professionals  93  section 20.2: http client a basic example for http client: write the follwing code in http_client.js ﬁle: var http = require('http'); var options = { hostname: '127.0.0.1', port: 80, path: '/', method: 'get' }; var req = http.request(options, function(res) { console.log('status: ' + res.statuscode); console.log('headers: ' + json.stringify(res.headers)); res.setencoding('utf8'); res.on('data', function (chunk) { console.log('response: ' + chunk); }); res.on('end', function (chunk) { console.log('response ended'); }); }); req.on('error', function(e) { console.log('problem with request: ' + e.message); });  req.end();  then from your http_client.js location run this command: node http_client.js  you should see this result: > status: 200 > headers: {""content-type"":""text/plain"",""date"":""thu, 21 jul 2016 11:27:17 gmt"",""connection"":""close"",""transfer-encoding"":""chunked""} > response: ok > response ended  note: this example depend on http server example.  goalkicker.com – node.js notes for professionals  94",t_3bea3588613c,t_3bea3588613c,5
c_7e510150e332,"chapter 55 of the book on android.chapter 55: fingerprint api in android section 55.1: how to use android fingerprint api to save user passwords this example helper class interacts with the ﬁnger print manager and performs encryption and decryption of password. please note that the method used for encryption in this example is aes. this is not the only way to encrypt and other examples exist. in this example the data is encrypted and decrypted in the following manner: encryption: 1. user gives helper the desired non-encrypted password. 2. user is required to provide ﬁngerprint. 3. once authenticated, the helper obtains a key from the keystore and encrypts the password using a cipher. 4. password and iv salt (iv is recreated for every encryption and is not reused) are saved to shared preferences to be used later in the decryption process. decryption: 1. user requests to decrypt the password. 2. user is required to provide ﬁngerprint. 3. the helper builds a cipher using the iv and once user is authenticated, the keystore obtains a key from the keystore and deciphers the password. public class fingerprintauthhelper { private private private private  static static static static  final final final final  string string string string  finger_print_helper = ""fingerprintauthhelper""; encrypted_pass_shared_pref_key = ""encrypted_pass_shared_pref_key""; last_used_iv_shared_pref_key = ""last_used_iv_shared_pref_key""; my_app_alias = ""my_app_alias"";  private keyguardmanager keyguardmanager; private fingerprintmanager fingerprintmanager; private final context context; private keystore keystore; private keygenerator keygenerator; private string lasterror;  public interface callback { void onsuccess(string savedpass); void onfailure(string message); void onhelp(int helpcode, string helpstring); } public fingerprintauthhelper(context context) { this.context = context; } public string getlasterror() { return lasterror; }  goalkicker.com – android™ notes for professionals  414  @targetapi(build.version_codes.m) public boolean init() { if (build.version.sdk_int < build.version_codes.m) { seterror(""this android version does not support fingerprint authentication""); return false; } keyguardmanager = (keyguardmanager) context.getsystemservice(keyguard_service); fingerprintmanager = (fingerprintmanager) context.getsystemservice(fingerprint_service); if (!keyguardmanager.iskeyguardsecure()) { seterror(""user hasn't enabled lock screen""); return false; } if (!haspermission()) { seterror(""user hasn't granted permission to use fingerprint""); return false; } if (!fingerprintmanager.hasenrolledfingerprints()) { seterror(""user hasn't registered any fingerprints""); return false; } if (!initkeystore()) { return false; } return false; } @nullable @requiresapi(api = build.version_codes.m) private cipher createcipher(int mode) throws nosuchpaddingexception, nosuchalgorithmexception, unrecoverablekeyexception, keystoreexception, invalidkeyexception, invalidalgorithmparameterexception { cipher cipher = cipher.getinstance(keyproperties.key_algorithm_aes + ""/"" + keyproperties.block_mode_cbc + ""/"" + keyproperties.encryption_padding_pkcs7); key key = keystore.getkey(my_app_alias, null); if (key == null) { return null; } if(mode == cipher.encrypt_mode) { cipher.init(mode, key); byte[] iv = cipher.getiv(); saveiv(iv); } else { byte[] lastiv = getlastiv(); cipher.init(mode, key, new ivparameterspec(lastiv)); } return cipher; } @nonnull @requiresapi(api = build.version_codes.m) private keygenparameterspec createkeygenparameterspec() { return new keygenparameterspec.builder(my_app_alias, keyproperties.purpose_encrypt | keyproperties.purpose_decrypt) .setblockmodes(keyproperties.block_mode_cbc) .setuserauthenticationrequired(true)  goalkicker.com – android™ notes for professionals  415  .setencryptionpaddings(keyproperties.encryption_padding_pkcs7) .build(); } @requiresapi(api = build.version_codes.m) private boolean initkeystore() { try { keystore = keystore.getinstance(""androidkeystore""); keygenerator = keygenerator.getinstance(keyproperties.key_algorithm_aes, ""androidkeystore""); keystore.load(null); if (getlastiv() == null) { keygenparameterspec keygeneratorspec = createkeygenparameterspec(); keygenerator.init(keygeneratorspec); keygenerator.generatekey(); } } catch (throwable t) { seterror(""failed init of keystore & keygenerator: "" + t.getmessage()); return false; } return true; } @requiresapi(api = build.version_codes.m) private void authenticate(cancellationsignal cancellationsignal, fingerprintauthenticationlistener authlistener, int mode) { try { if (haspermission()) { cipher cipher = createcipher(mode); fingerprintmanager.cryptoobject crypto = new fingerprintmanager.cryptoobject(cipher); fingerprintmanager.authenticate(crypto, cancellationsignal, 0, authlistener, null); } else { authlistener.getcallback().onfailure(""user hasn't granted permission to use fingerprint""); } } catch (throwable t) { authlistener.getcallback().onfailure(""an error occurred: "" + t.getmessage()); } } private string getsavedencryptedpassword() { sharedpreferences sharedpreferences = getsharedpreferences(); if (sharedpreferences != null) { return sharedpreferences.getstring(encrypted_pass_shared_pref_key, null); } return null; } private void saveencryptedpassword(string encryptedpassword) { sharedpreferences.editor edit = getsharedpreferences().edit(); edit.putstring(encrypted_pass_shared_pref_key, encryptedpassword); edit.commit(); } private byte[] getlastiv() { sharedpreferences sharedpreferences = getsharedpreferences(); if (sharedpreferences != null) { string ivstring = sharedpreferences.getstring(last_used_iv_shared_pref_key, null); if (ivstring != null) { return decodebytes(ivstring);  goalkicker.com – android™ notes for professionals  416  } } return null; } private void saveiv(byte[] iv) { sharedpreferences.editor edit = getsharedpreferences().edit(); string string = encodebytes(iv); edit.putstring(last_used_iv_shared_pref_key, string); edit.commit(); } private sharedpreferences getsharedpreferences() { return context.getsharedpreferences(finger_print_helper, 0); } @requiresapi(api = build.version_codes.m) private boolean haspermission() { return activitycompat.checkselfpermission(context, manifest.permission.use_fingerprint) == packagemanager.permission_granted; } @requiresapi(api = build.version_codes.m) public void savepassword(@nonnull string password, cancellationsignal cancellationsignal, callback callback) { authenticate(cancellationsignal, new fingerprintencryptpasswordlistener(callback, password), cipher.encrypt_mode); } @requiresapi(api = build.version_codes.m) public void getpassword(cancellationsignal cancellationsignal, callback callback) { authenticate(cancellationsignal, new fingerprintdecryptpasswordlistener(callback), cipher.decrypt_mode); } @requiresapi(api = build.version_codes.m) public boolean encryptpassword(cipher cipher, string password) { try { // encrypt the text if(password.isempty()) { seterror(""password is empty""); return false; } if (cipher == null) { seterror(""could not create cipher""); return false; } bytearrayoutputstream outputstream = new bytearrayoutputstream(); cipheroutputstream cipheroutputstream = new cipheroutputstream(outputstream, cipher); byte[] bytes = password.getbytes(charset.defaultcharset()); cipheroutputstream.write(bytes); cipheroutputstream.flush(); cipheroutputstream.close(); saveencryptedpassword(encodebytes(outputstream.tobytearray())); } catch (throwable t) { seterror(""encryption failed "" + t.getmessage()); return false; } return true;  goalkicker.com – android™ notes for professionals  417  } private byte[] decodebytes(string s) { final int len = s.length(); // ""111"" is not a valid hex encoding. if( len%2 != 0 ) throw new illegalargumentexception(""hexbinary needs to be even-length: ""+s); byte[] out = new byte[len/2]; for( int i=0; i<len; i+=2 ) { int h = hextobin(s.charat(i )); int l = hextobin(s.charat(i+1)); if( h==-1 || l==-1 ) throw new illegalargumentexception(""contains illegal character for hexbinary: ""+s); out[i/2] = (byte)(h*16+l); } return out; } private static int if( '0'<=ch && if( 'a'<=ch && if( 'a'<=ch && return -1; }  hextobin( char ch ) ch<='9' ) return ch<='f' ) return ch<='f' ) return  { ch-'0'; ch-'a'+10; ch-'a'+10;  private static final char[] hexcode = ""0123456789abcdef"".tochararray(); public string encodebytes(byte[] data) { stringbuilder r = new stringbuilder(data.length*2); for ( byte b : data) { r.append(hexcode[(b >> 4) & 0xf]); r.append(hexcode[(b & 0xf)]); } return r.tostring(); } @nonnull private string decipher(cipher cipher) throws ioexception, illegalblocksizeexception, badpaddingexception { string retval = null; string savedencryptedpassword = getsavedencryptedpassword(); if (savedencryptedpassword != null) { byte[] decodedpassword = decodebytes(savedencryptedpassword); cipherinputstream cipherinputstream = new cipherinputstream(new bytearrayinputstream(decodedpassword), cipher); arraylist<byte> values = new arraylist<>(); int nextbyte; while ((nextbyte = cipherinputstream.read()) != -1) { values.add((byte) nextbyte); } cipherinputstream.close(); byte[] bytes = new byte[values.size()]; for (int i = 0; i < values.size(); i++) { bytes[i] = values.get(i).bytevalue(); }  goalkicker.com – android™ notes for professionals  418  retval = new string(bytes, charset.defaultcharset()); } return retval; } private void seterror(string error) { lasterror = error; log.w(finger_print_helper, lasterror); } @requiresapi(build.version_codes.m) protected class fingerprintauthenticationlistener extends fingerprintmanager.authenticationcallback { protected final callback callback; public fingerprintauthenticationlistener(@nonnull callback callback) { this.callback = callback; } public void onauthenticationerror(int errorcode, charsequence errstring) { callback.onfailure(""authentication error ["" + errorcode + ""] "" + errstring); } /** * called when a recoverable error has been encountered during authentication. the help * string is provided to give the user guidance for what went wrong, such as * ""sensor dirty, please clean it."" * @param helpcode an integer identifying the error message * @param helpstring a human-readable string that can be shown in ui */ public void onauthenticationhelp(int helpcode, charsequence helpstring) { callback.onhelp(helpcode, helpstring.tostring()); } /** * called when a fingerprint is recognized. * @param result an object containing authentication-related data */ public void onauthenticationsucceeded(fingerprintmanager.authenticationresult result) { } /** * called when a fingerprint is valid but not recognized. */ public void onauthenticationfailed() { callback.onfailure(""authentication failed""); } public @nonnull callback getcallback() { return callback; } } @requiresapi(api = build.version_codes.m) private class fingerprintencryptpasswordlistener extends fingerprintauthenticationlistener { private final string password; public fingerprintencryptpasswordlistener(callback callback, string password) {  goalkicker.com – android™ notes for professionals  419  super(callback); this.password = password; } public void onauthenticationsucceeded(fingerprintmanager.authenticationresult result) { cipher cipher = result.getcryptoobject().getcipher(); try { if (encryptpassword(cipher, password)) { callback.onsuccess(""encrypted""); } else { callback.onfailure(""encryption failed""); } } catch (exception e) { callback.onfailure(""encryption failed "" + e.getmessage()); } } } @requiresapi(build.version_codes.m) protected class fingerprintdecryptpasswordlistener extends fingerprintauthenticationlistener { public fingerprintdecryptpasswordlistener(@nonnull callback callback) { super(callback); } public void onauthenticationsucceeded(fingerprintmanager.authenticationresult result) { cipher cipher = result.getcryptoobject().getcipher(); try { string savedpass = decipher(cipher); if (savedpass != null) { callback.onsuccess(savedpass); } else { callback.onfailure(""failed deciphering""); } } catch (exception e) { callback.onfailure(""deciphering failed "" + e.getmessage()); } } } }  this activity below is a very basic example of how to get a user saved password and interact with the helper. public class mainactivity extends appcompatactivity { private textview passwordtextview; private fingerprintauthhelper fingerprintauthhelper; @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); passwordtextview = (textview) findviewbyid(r.id.password); errortextview = (textview) findviewbyid(r.id.error); view savepasswordbutton = findviewbyid(r.id.set_password_button); savepasswordbutton.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { if (build.version.sdk_int >= build.version_codes.m) {  goalkicker.com – android™ notes for professionals  420  fingerprintauthhelper.savepassword(passwordtextview.gettext().tostring(), new cancellationsignal(), getauthlistener(false)); } } }); view getpasswordbutton = findviewbyid(r.id.get_password_button); getpasswordbutton.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { if (build.version.sdk_int >= build.version_codes.m) { fingerprintauthhelper.getpassword(new cancellationsignal(), getauthlistener(true)); } } }); } // start the finger print helper. in case this fails show error to user private void startfingerprintauthhelper() { fingerprintauthhelper = new fingerprintauthhelper(this); if (!fingerprintauthhelper.init()) { errortextview.settext(fingerprintauthhelper.getlasterror()); } } @nonnull private fingerprintauthhelper.callback getauthlistener(final boolean isgetpass) { return new fingerprintauthhelper.callback() { @override public void onsuccess(string result) { if (isgetpass) { errortextview.settext(""success!!! pass = "" + result); } else { errortextview.settext(""encrypted pass = "" + result); } } @override public void onfailure(string message) { errortextview.settext(""failed - "" + message); } @override public void onhelp(int helpcode, string helpstring) { errortextview.settext(""help needed - "" + helpstring); } }; } }  section 55.2: adding the fingerprint scanner in android application android supports ﬁngerprint api from android 6.0 (marshmallow) sdk 23 to use this feature in your app, ﬁrst add the use_fingerprint permission in your manifest.  <uses-permission  goalkicker.com – android™ notes for professionals  421  android:name=""android.permission.use_fingerprint"" />  here the procedure to follow first you need to create a symmetric key in the android key store using keygenerator which can be only be used after the user has authenticated with ﬁngerprint and pass a keygenparameterspec.  keypairgenerator.getinstance(keyproperties.key_algorithm_ec, ""androidkeystore""); keypairgenerator.initialize( new keygenparameterspec.builder(key_name, keyproperties.purpose_sign) .setdigests(keyproperties.digest_sha256) .setalgorithmparameterspec(new ecgenparameterspec(""secp256r1"")) .setuserauthenticationrequired(true) .build()); keypairgenerator.generatekeypair();  by setting keygenparameterspec.builder.setuserauthenticationrequired to true, you can permit the use of the key only after the user authenticate it including when authenticated with the user's ﬁngerprint.  keystore keystore = keystore.getinstance(""androidkeystore""); keystore.load(null); publickey publickey = keystore.getcertificate(mainactivity.key_name).getpublickey(); keystore keystore = keystore.getinstance(""androidkeystore""); keystore.load(null); privatekey key = (privatekey) keystore.getkey(key_name, null);  then start listening to a ﬁngerprint on the ﬁngerprint sensor by calling fingerprintmanager.authenticate with a cipher initialized with the symmetric key created. or alternatively you can fall back to server-side veriﬁed password as an authenticator. create and initialise the fingerprintmanger from fingerprintmanger.class getcontext().getsystemservice(fingerprintmanager.class)  to authenticate use fingerprintmanger api and create subclass using fingerprintmanager.authenticationcallback and override the methods onauthenticationerror onauthenticationhelp onauthenticationsucceeded onauthenticationfailed  to start to startlistening the ﬁngerprint event call authenticate method with crypto fingerprintmanager .authenticate(cryptoobject, mcancellationsignal, 0 , this, null);  goalkicker.com – android™ notes for professionals  422  cancel to stop listenting the scanner call android.os.cancellationsignal;  once the ﬁngerprint (or password) is veriﬁed, the fingerprintmanager.authenticationcallback#onauthenticationsucceeded() callback is called.  @override public void onauthenticationsucceeded(authenticationresult result) { }  goalkicker.com – android™ notes for professionals  423",t_58ca0afc0bae,t_58ca0afc0bae,6
c_9d2183672a1c,"chapter 68 of the book on android.chapter 68: spannablestring section 68.1: add styles to a textview in the following example, we create an activity to display a single textview. the textview will use a spannablestring as its content, which will illustrate some of the available styles. here' what we're gonna do with the text : make it larger bold underline italicize strike-through colored highlighted show as superscript show as subscript show as a link make it clickable. @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); spannablestring styledstring = new spannablestring(""large\n\n"" // index 0 - 5 + ""bold\n\n"" // index 7 - 11 + ""underlined\n\n"" // index 13 - 23 + ""italic\n\n"" // index 25 - 31 + ""strikethrough\n\n"" // index 33 - 46 + ""colored\n\n"" // index 48 - 55 + ""highlighted\n\n"" // index 57 - 68 + ""k superscript\n\n"" // ""superscript"" index 72 - 83 + ""k subscript\n\n"" // ""subscript"" index 87 - 96 + ""url\n\n"" // index 98 - 101 + ""clickable\n\n""); // index 103 - 112 // make the text twice as large styledstring.setspan(new relativesizespan(2f), 0, 5, 0); // make text bold styledstring.setspan(new stylespan(typeface.bold), 7, 11, 0); // underline text styledstring.setspan(new underlinespan(), 13, 23, 0); // make text italic styledstring.setspan(new stylespan(typeface.italic), 25, 31, 0); styledstring.setspan(new strikethroughspan(), 33, 46, 0); // change text color styledstring.setspan(new foregroundcolorspan(color.green), 48, 55, 0); // highlight text styledstring.setspan(new backgroundcolorspan(color.cyan), 57, 68, 0);  goalkicker.com – android™ notes for professionals  476  // superscript styledstring.setspan(new superscriptspan(), 72, 83, 0); // make the superscript text smaller styledstring.setspan(new relativesizespan(0.5f), 72, 83, 0); // subscript styledstring.setspan(new subscriptspan(), 87, 96, 0); // make the subscript text smaller styledstring.setspan(new relativesizespan(0.5f), 87, 96, 0); // url styledstring.setspan(new urlspan(""http://www.google.com""), 98, 101, 0); // clickable text clickablespan clickablespan = new clickablespan() { @override public void onclick(view widget) { // we display a toast. you could do anything you want here. toast.maketext(spanexample.this, ""clicked"", toast.length_short).show(); } }; styledstring.setspan(clickablespan, 103, 112, 0);  // give the styled string to a textview textview textview = new textview(this); // this step is mandated for the url and clickable styles. textview.setmovementmethod(linkmovementmethod.getinstance()); // make it neat textview.setgravity(gravity.center); textview.setbackgroundcolor(color.white); textview.settext(styledstring); setcontentview(textview); }  goalkicker.com – android™ notes for professionals  477  and the result will look like this:  section 68.2: multi string , with multi color method: setspancolor public spanned setspancolor(string string, int color){ spannablestringbuilder builder = new spannablestringbuilder(); spannablestring ss = new spannablestring(string); ss.setspan(new foregroundcolorspan(color), 0, string.length(), 0); builder.append(ss); return ss; }  goalkicker.com – android™ notes for professionals  478  usage: string a = getstring(r.string.string1); string b = getstring(r.string.string2); spanned color1 = setspancolor(a,color.cyan); spanned color2 = setspancolor(b,color.red); spanned mixedcolor = textutils.concat(color1, "" "", color2); // now we use `mixedcolor`  goalkicker.com – android™ notes for professionals  479",t_58ca0afc0bae,t_58ca0afc0bae,6
c_de19cf14c3d8,"chapter 133 of the book on android.chapter 133: capturing screenshots section 133.1: taking a screenshot of a particular view if you want to take a screenshot of a particular view v, then you can use the following code: bitmap viewbitmap = bitmap.createbitmap(v.getwidth(), v.getheight(), bitmap.config.rgb_565); canvas viewcanvas = new canvas(viewbitmap); drawable backgrounddrawable = v.getbackground(); if(backgrounddrawable != null){ // draw the background onto the canvas. backgrounddrawable.draw(viewcanvas); } else{ viewcanvas.drawcolor(color.green); // draw the view onto the canvas. v.draw(viewcanvas) } // write the bitmap generated above into a file. string filestamp = new simpledateformat(""yyyymmdd_hhmmss"").format(new date()); outputstream outputstream = null; try{ imgfile = new file(environment.getexternalstoragepublicdirectory(environment.directory_pictures), filestamp + "".png""); outputstream = new fileoutputstream(imgfile); viewbitmap.compress(bitmap.compressformat.png, 40, outputstream); outputstream.close(); } catch(exception e){ e.printstacktrace(); }  section 133.2: capturing screenshot via android studio 1. open android monitor tab 2. click on screen capture button  goalkicker.com – android™ notes for professionals  752  section 133.3: capturing screenshot via adb and saving directly in your pc if you use linux (or windows with cygwin), you can run: adb shell screencap -p | sed 's/\r$//' > screenshot.png  section 133.4: capturing screenshot via android device monitor 1. open android device monitor ( ie c:<android_sdk_location>\tools\monitor.bat) 2. select your device 3. click on screen capture button  goalkicker.com – android™ notes for professionals  753  section 133.5: capturing screenshot via adb example below saves a screenshot on devices's internal storage. adb shell screencap /sdcard/screen.png  goalkicker.com – android™ notes for professionals  754",t_58ca0afc0bae,t_58ca0afc0bae,6
c_1e2f653cfcf5,"chapter 194 of the book on android.chapter 194: android things section 194.1: controlling a servo motor this example assumes you have a servo with the following characteristics, which happen to be typical: movement between 0 and 180 degrees pulse period of 20 ms minimum pulse length of 0.5 ms maximum pulse length of 2.5 ms you need to check if those values match your hardware, since forcing it to go outside its speciﬁed operating range can damage the servo. a damaged servo in turn has the potential to damage your android things device. the example servocontroller class consists of two methods, setup() and setposition(): public class servocontroller { private double periodms, maxtimems, mintimems; private pwm pin; public void setup(string pinname) throws ioexception { periodms = 20; maxtimems = 2.5; mintimems = 0.5; peripheralmanagerservice service = new peripheralmanagerservice(); pin = service.openpwm(pinname); pin.setpwmfrequencyhz(1000.0d / periodms); setposition(90); pin.setenabled(true); } public void setposition(double degrees) { double pulselengthms = (degrees / 180.0 * (maxtimems - mintimems)) + mintimems; if (pulselengthms < mintimems) { pulselengthms = mintimems; } else if (pulselengthms > maxtimems) { pulselengthms = maxtimems; } double dutycycle = pulselengthms / periodms * 100.0; log.i(tag, ""duty cycle = "" + dutycycle + "" pulse length = "" + pulselengthms); try { pin.setpwmdutycycle(dutycycle); } catch (ioexception e) { e.printstacktrace(); } } }  you can discover pin names that support pwm on your device as follows: peripheralmanagerservice service = new peripheralmanagerservice(); for (string pinname : service.getpwmlist() ) {  goalkicker.com – android™ notes for professionals  947  log.i(""servocontrolled"",""pwm pin found: "" + pinname); }  in order to make your servo swinging forever between 80 degrees and 100 degrees, you can simply use the following code: final servocontroller servocontroller = new servocontroller(pinname); thread th = new thread(new runnable() { @override public void run() { while (true) { try { servocontroller.setposition(80); thread.sleep(500); servocontroller.setposition(100); thread.sleep(500); } catch (interruptedexception e) { e.printstacktrace(); } } } }); th.start();  you can compile and deploy all of the above code without actually hooking any servo motors to the computing device. for the wiring, refer to your computing device pinout chart (e.g. a raspberry pi 3 pinout chart is available here). then you need to hook your servo to vcc, gnd, and signal.  goalkicker.com – android™ notes for professionals  948",t_58ca0afc0bae,t_58ca0afc0bae,6
c_8db1b372c58e,"chapter 6 of the book on android.chapter 6: autosizing textviews a textview that automatically resizes text to ﬁt perfectly within its bounds. android o allows you to instruct a textview to let the size of the text expand or contract automatically to ﬁll its layout based on the textview’s characteristics and boundaries. you can set up the textview autosizing in either code or xml. there are two ways to set autosizing textview: granularity and preset sizes  section 6.1: granularity in java: call the setautosizetexttypeuniformwithconfiguration() method: setautosizetexttypeuniformwithconfiguration(int autosizemintextsize, int autosizemaxtextsize, int autosizestepgranularity, int unit)  in xml: use the autosizemintextsize, autosizemaxtextsize, and autosizestepgranularity attributes to set the autosizing dimensions in the layout xml ﬁle: <textview android:id=”@+id/autosizing_textview_presetsize” android:layout_width=”wrap_content” android:layout_height=”250dp” android:layout_marginleft=”0dp” android:layout_margintop=”0dp” android:autosizemaxtextsize=”100sp” android:autosizemintextsize=”12sp” android:autosizestepgranularity=”2sp” android:autosizetext=”uniform” android:text=”hello world!” android:textsize=”100sp” app:layout_constraintleft_toleftof=”parent” app:layout_constrainttop_totopof=”parent” />  check out the autosizingtextviews-demo at github for more details.  section 6.2: preset sizes in java: call the setautosizetexttypeuniformwithpresetsizes() method: setautosizetexttypeuniformwithpresetsizes(int[] presetsizes, int unit)  in xml: use the autosizepresetsizes attribute in the layout xml ﬁle: <textview android:id=”@+id/autosizing_textview_presetsize”  goalkicker.com – android™ notes for professionals  50  android:layout_width=”wrap_content” android:layout_height=”250dp” android:layout_marginleft=”0dp” android:layout_margintop=”0dp” android:autosizetext=”uniform” android:autosizepresetsizes=”@array/autosize_text_sizes” android:text=”hello world!” android:textsize=”100sp” app:layout_constraintleft_toleftof=”parent” app:layout_constrainttop_totopof=”parent” />  to access the array as a resource, deﬁne the array in the res/values/arrays.xml ﬁle: <array name=”autosize_text_sizes”> <item>10sp</item> <item>12sp</item> <item>20sp</item> <item>40sp</item> <item>100sp</item> </array>  check out the autosizingtextviews-demo at github for more details.  goalkicker.com – android™ notes for professionals  51",t_58ca0afc0bae,t_58ca0afc0bae,6
c_2a41f6263baf,"chapter 24 of the book on android.chapter 24: webview webview is a view that display web pages inside your application. by this you can add your own url.  section 24.1: troubleshooting webview by printing console messages or by remote debugging printing webview console messages to logcat to handle console messages from web page you can override onconsolemessage in webchromeclient: final class chromeclient extends webchromeclient { @override public boolean onconsolemessage(consolemessage msg) { log.d( ""webview"", string.format(""%s %s:%d"", msg.message(), msg.linenumber(), msg.sourceid()) ); return true; } }  and set it in your activity or fragment: webview.setwebchromeclient(new chromeclient());  so this sample page: <html> <head> <script type=""text/javascript""> console.log('test message'); </script> </head> <body> </body> </html>  will write log 'test message' to logcat: webview: test message sample.html:4 console.info(), console.warn() and console.error() are also supported by chrome-client.  remote debugging android devices with chrome your can remote debug webview based application from you desktop chrome. enable usb debugging on your android device on your android device, open up settings, ﬁnd the developer options section, and enable usb debugging. connect and discover your android device  goalkicker.com – android™ notes for professionals  193  open page in chrome following page: chrome://inspect/#devices from the inspect devices dialog, select your device and press inspect. a new instance of chrome's devtools opens up on your development machine. more detailed guideline and description of devtools can be found on developers.google.com  section 24.2: communication from javascript to java (android) android activity package com.example.myapp; import android.os.bundle; import android.app.activity; import android.webkit.webview; public class webviewactivity extends activity { @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); webview webview = new webview(this); setcontentview(webview); /* * note the label android, this is used in the javascript side of things * you can of course change this. */ webview.addjavascriptinterface(new javascripthandler(), ""android""); webview.loadurl(""http://example.com""); } }  java javascript handler import android.webkit.javascriptinterface; public class javascripthandler { /** * key point here is the annotation @javascriptinterface * */ @javascriptinterface public void jscallback() { // do something } @javascriptinterface public void jscallbacktwo(string dummydata) { // do something } }  web page, javascript call  goalkicker.com – android™ notes for professionals  194  <script> ... android.jscallback(); ... android.jscallback('hello test'); ... </script>  extra tip passing in a complex data structure, a possible solution is use json. android.jscallback('{ ""fake-var"" : ""fake-value"", ""fake-array"" : [0,1,2] }');  on the android side use your favorite json parser ie: jsonobject  section 24.3: communication from java to javascript basic example package com.example.myapp; import android.os.bundle; import android.app.activity; import android.webkit.webview; public class webviewactivity extends activity { private webview webview; @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); webview = new webview(this); webview.getsettings().setjavascriptenabled(true); setcontentview(webview); webview.loadurl(""http://example.com""); /* * invoke javascript function */ webview.loadurl(""javascript:testjsfunction('hello world!')""); } /** * invoking a javascript function */ public void dosomething() { this.webview.loadurl(""javascript:testanotherfunction('hello world again!')""); } }  section 24.4: open dialer example if the web page a contains phone number you can make a call using your phone's dialer. this code checks for the goalkicker.com – android™ notes for professionals  195  url which starts with tel: then make an intent to open dialer and you can make a call to the clicked phone number: public boolean shouldoverrideurlloading(webview view, string url) { if (url.startswith(""tel:"")) { intent intent = new intent(intent.action_dial, uri.parse(url)); startactivity(intent); }else if(url.startswith(""http:"") || url.startswith(""https:"")) { view.loadurl(url); } return true; }  section 24.5: open local file / create dynamic content in webview layout.xml <webview android:id=""@+id/webviewtodisplay"" android:layout_width=""fill_parent"" android:layout_height=""fill_parent"" android:layout_gravity=""center"" android:fadescrollbars=""false"" />  load data into webviewtodisplay webview webviewdisplay; stringbuffer loadweb1; webviewdisplay = (webview) findviewbyid(r.id.webviewtodisplay); loadweb1 = new stringbuffer(); loadweb1.append(""<html><body><h1>my first heading</h1><p>my first paragraph.</p>""); //sample code to read parameters at run time string strname = ""test paragraph""; loadweb1.append(""<br/><p>""+strname+""</p>""); string result = loadweb1.append(""</body></html>"").tostring(); websettings websettings = webviewdisplay.getsettings(); websettings.setjavascriptenabled(true); webviewdisplay.getsettings().setbuiltinzoomcontrols(true); if (android.os.build.version.sdk_int >= 11){ webviewdisplay.setlayertype(view.layer_type_software, null); webviewdisplay.getsettings().setdisplayzoomcontrols(false); } webviewdisplay.loaddatawithbaseurl(null, result, ""text/html"", ""utf-8"", null); //to load local file directly from assets folder use below code //webviewdisplay.loadurl(""file:///android_asset/aboutapp.html"");  section 24.6: javascript alert dialogs in webview - how to make them work by default, webview does not implement javascript alert dialogs, ie. alert() will do nothing. in order to make you need to ﬁrstly enable javascript (obviously..), and then set a webchromeclient to handle requests for alert dialogs from the page:  goalkicker.com – android™ notes for professionals  196  webview.setwebchromeclient(new webchromeclient() { //other methods for your webchromeclient here, if needed.. @override public boolean onjsalert(webview view, string url, string message, jsresult result) { return super.onjsalert(view, url, message, result); } });  here, we override onjsalert, and then we call through to the super implementation, which gives us a standard android dialog. you can also use the message and url yourself, for example if you want to create a custom styled dialog or if you want to log them.  goalkicker.com – android™ notes for professionals  197",t_58ca0afc0bae,t_58ca0afc0bae,6
c_5240b653a0a2,"chapter 218 of the book on android.chapter 218: json in android with org.json section 218.1: creating a simple json object create the jsonobject using the empty constructor and add ﬁelds using the put() method, which is overloaded so that it can be used with diﬀerent types: try { // create a new instance of a jsonobject final jsonobject object = new jsonobject(); // with put you can add a name/value pair to the jsonobject object.put(""name"", ""test""); object.put(""content"", ""hello world!!!1""); object.put(""year"", 2016); object.put(""value"", 3.23); object.put(""member"", true); object.put(""null_value"", jsonobject.null); // calling tostring() on the jsonobject returns the json in string format. final string json = object.tostring(); } catch (jsonexception e) { log.e(tag, ""failed to create jsonobject"", e); }  the resulting json string looks like this: { ""name"":""test"", ""content"":""hello world!!!1"", ""year"":2016, ""value"":3.23, ""member"":true, ""null_value"":null }  section 218.2: create a json string with null value if you need to produce a json string with a value of null like this: { ""name"":null }  then you have to use the special constant jsonobject.null. functioning example: jsonobject.put(""name"", jsonobject.null);  section 218.3: add jsonarray to jsonobject // create a new instance of a jsonarray jsonarray array = new jsonarray();  goalkicker.com – android™ notes for professionals  1013  // with put() you can add a value to the array. array.put(""asdf""); array.put(""qwerty""); // create a new instance of a jsonobject jsonobject obj = new jsonobject(); try { // add the jsonarray to the jsonobject obj.put(""the_array"", array); } catch (jsonexception e) { e.printstacktrace(); } string json = obj.tostring();  the resulting json string looks like this: { ""the_array"":[ ""asdf"", ""qwerty"" ] }  section 218.4: parse simple json object consider the following json string: { ""title"": ""test"", ""content"": ""hello world!!!"", ""year"": 2016, ""names"" : [ ""hannah"", ""david"", ""steve"" ] }  this json object can be parsed using the following code: try { // create a new instance from a string jsonobject jsonobject = new jsonobject(jsonasstring); string title = jsonobject.getstring(""title""); string content = jsonobject.getstring(""content""); int year = jsonobject.getint(""year""); jsonarray names = jsonobject.getjsonarray(""names""); //for an array of string objects } catch (jsonexception e) { log.w(tag,""could not parse json. error: "" + e.getmessage()); }  here is another example with a jsonarray nested inside jsonobject: { ""books"":[ { ""title"":""android json parsing"",  goalkicker.com – android™ notes for professionals  1014  ""times_sold"":186 } ] }  this can be parsed with the following code: jsonobject root = new jsonobject(booksjson); jsonarray booksarray = root.getjsonarray(""books""); jsonobject firstbook = booksarray.getjsonobject(0); string title = firstbook.getstring(""title""); int timessold = firstbook.getint(""times_sold"");  section 218.5: check for the existence of ﬁelds on json sometimes it's useful to check if a ﬁeld is present or absent on your json to avoid some jsonexception on your code. to achieve that, use the jsonobject#has(string) or the method, like on the following example: sample json { ""name"":""james"" }  java code string jsonstr = "" { \""name\"":\""james\"" }""; jsonobject json = new jsonobject(jsonstr); // check if the field ""name"" is present string name, surname; // this will be true, since the field ""name"" is present on our json. if (json.has(""name"")) { name = json.getstring(""name""); } else { name = ""john""; } // this will be false, since our json doesn't have the field ""surname"". if (json.has(""surname"")) { surname = json.getstring(""surname""); } else { surname = ""doe""; } // here name == ""james"" and surname == ""doe"".  section 218.6: create nested json object to produce nested json object, you need to simply add one json object to another: jsonobject mainobject = new jsonobject(); jsonobject requestobject = new jsonobject();  // host object // included object  try {  goalkicker.com – android™ notes for professionals  1015  requestobject.put(""lastname"", lastname); requestobject.put(""phone"", phone); requestobject.put(""latitude"", lat); requestobject.put(""longitude"", lon); requestobject.put(""theme"", theme); requestobject.put(""text"", message); mainobject.put(""claim"", requestobject); } catch (jsonexception e) { return ""json error""; }  now mainobject contains a key called claim with the whole requestobject as a value.  section 218.7: updating the elements in the json sample json to update { ""student"":{""name"":""rahul"", ""lastname"":""sharma""}, ""marks"":{""maths"":""88""} }  to update the elements value in the json we need to assign the value and update. try { // create a new instance of a jsonobject final jsonobject object = new jsonobject(jsonstring); jsonobject studentjson = object.getjsonobject(""student""); studentjson.put(""name"",""kumar""); object.remove(""student""); object.put(""student"",studentjson); // calling tostring() on the jsonobject returns the json in string format. final string json = object.tostring(); } catch (jsonexception e) { log.e(tag, ""failed to create jsonobject"", e); }  updated value { ""student"":{""name"":""kumar"", ""lastname"":""sharma""}, ""marks"":{""maths"":""88""} }  section 218.8: using jsonreader to read json from a stream jsonreader reads a json encoded value as a stream of tokens. public list<message> readjsonstream(inputstream in) throws ioexception { jsonreader reader = new jsonreader(new inputstreamreader(in, ""utf-8"")); try { return readmessagesarray(reader);  goalkicker.com – android™ notes for professionals  1016  } finally { reader.close(); } } public list<message> readmessagesarray(jsonreader reader) throws ioexception { list<message> messages = new arraylist<message>(); reader.beginarray(); while (reader.hasnext()) { messages.add(readmessage(reader)); } reader.endarray(); return messages; } public message readmessage(jsonreader reader) throws ioexception { long id = -1; string text = null; user user = null; list<double> geo = null; reader.beginobject(); while (reader.hasnext()) { string name = reader.nextname(); if (name.equals(""id"")) { id = reader.nextlong(); } else if (name.equals(""text"")) { text = reader.nextstring(); } else if (name.equals(""geo"") && reader.peek() != jsontoken.null) { geo = readdoublesarray(reader); } else if (name.equals(""user"")) { user = readuser(reader); } else { reader.skipvalue(); } } reader.endobject(); return new message(id, text, user, geo); } public list<double> readdoublesarray(jsonreader reader) throws ioexception { list<double> doubles = new arraylist<double>(); reader.beginarray(); while (reader.hasnext()) { doubles.add(reader.nextdouble()); } reader.endarray(); return doubles; } public user readuser(jsonreader reader) throws ioexception { string username = null; int followerscount = -1; reader.beginobject(); while (reader.hasnext()) { string name = reader.nextname(); if (name.equals(""name"")) { username = reader.nextstring(); } else if (name.equals(""followers_count"")) {  goalkicker.com – android™ notes for professionals  1017  followerscount = reader.nextint(); } else { reader.skipvalue(); } } reader.endobject(); return new user(username, followerscount); }  section 218.9: working with null-string when parsing json { ""some_string"": null, ""ather_string"": ""something"" }  if we will use this way: jsonobject json = new jsonobject(jsonstr); string somestring = json.optstring(""some_string"");  we will have output: somestring = ""null"";  so we need to provide this workaround: /** * according to http://stackoverflow.com/questions/18226288/json-jsonobject-optstring-returns-string-null * we need to provide a workaround to opt string from json that can be null. * <strong></strong> */ public static string optnullablestring(jsonobject jsonobject, string key) { return optnullablestring(jsonobject, key, """"); } /** * according to http://stackoverflow.com/questions/18226288/json-jsonobject-optstring-returns-string-null * we need to provide a workaround to opt string from json that can be null. * <strong></strong> */ public static string optnullablestring(jsonobject jsonobject, string key, string fallback) { if (jsonobject.isnull(key)) { return fallback; } else { return jsonobject.optstring(key, fallback); } }  and then call: jsonobject json = new jsonobject(jsonstr); string somestring = optnullablestring(json, ""some_string""); string somestring2 = optnullablestring(json, ""some_string"", """");  and we will have output as we expected: goalkicker.com – android™ notes for professionals  1018  somestring = null; //not ""null"" somestring2 = """";  section 218.10: handling dynamic key for json response this is an example for how to handle dynamic key for response. here a and b are dynamic keys it can be anything response { ""response"": [ { ""a"": [ { ""name"": }, { ""name"": } ], ""b"": [ { ""name"": }, { ""name"": } ] } ]  ""tango""  ""ping""  ""jon""  ""mark""  }  java code // responsedata is raw string of response jsonobject responsedataobj = new jsonobject(responsedata); jsonarray responsearray = responsedataobj.getjsonarray(""response""); for (int i = 0; i < responsearray.length(); i++) { // nodes arraylist<arraylist<string>> declared globally nodes = new arraylist<arraylist<string>>(); jsonobject obj = responsearray.getjsonobject(i); iterator keys = obj.keys(); while(keys.hasnext()) { // loop to get the dynamic key string currentdynamickey = (string)keys.next(); // get the value of the dynamic key jsonarray currentdynamicvalue = obj.getjsonarray(currentdynamickey); int jsonarraysize = currentdynamicvalue.length(); if(jsonarraysize > 0) { for (int ii = 0; ii < jsonarraysize; ii++) { // namelist arraylist<string> declared globally namelist = new arraylist<string>(); if(ii == 0) { jsonobject nameobj = currentdynamicvalue.getjsonobject(ii); string name = nameobj.getstring(""name""); system.out.print(""name = "" + name); // store name in an array list namelist.add(name); } }  goalkicker.com – android™ notes for professionals  1019  } nodes.add(namelist); } }  goalkicker.com – android™ notes for professionals  1020",t_58ca0afc0bae,t_58ca0afc0bae,6
c_5935ac833aea,"chapter 162 of the book on android.chapter 162: vector drawables parameter  details  <vector>  used to deﬁne a vector drawable  <group>  deﬁnes a group of paths or subgroups, plus transformation information. the transformations are deﬁned in the same coordinates as the viewport. and the transformations are applied in the order of scale, rotate then translate.  <path>  deﬁnes paths to be drawn.  <clip-path>  deﬁnes path to be the current clip. note that the clip path only apply to the current group and its children.  as the name implies, vector drawables are based on vector graphics. vector graphics are a way of describing graphical elements using geometric shapes. this lets you create a drawable based on an xml vector graphic. now there is no need to design diﬀerent size image for mdpi, hdpi, xhdpi and etc. with vector drawable you need to create image only once as an xml ﬁle and you can scale it for all dpi and for diﬀerent devices. this also not save space but also simpliﬁes maintenance.  section 162.1: importing svg ﬁle as vectordrawable you can import an svg ﬁle as a vectordrawable in android studio, follow these steps : ""right-click"" on the res folder and select new > vector asset.  goalkicker.com – android™ notes for professionals  848  select the local file option and browse to your .svg ﬁle. change the options to your liking and hit next. done.  goalkicker.com – android™ notes for professionals  849  section 162.2: vectordrawable usage example here’s an example vector asset which we’re actually using in appcompat: res/drawable/ic_search.xml <vector xmlns:android=""..."" android:width=""24dp"" android:height=""24dp"" android:viewportwidth=""24.0"" android:viewportheight=""24.0"" android:tint=""?attr/colorcontrolnormal""> <path android:pathdata=""..."" android:fillcolor=""@android:color/white""/> </vector>  using this drawable, an example imageview declaration would be: <imageview  goalkicker.com – android™ notes for professionals  850  android:layout_width=""wrap_content"" android:layout_height=""wrap_content"" app:srccompat=""@drawable/ic_search""/>  you can also set it at run-time: imageview iv = (imageview) findviewbyid(...); iv.setimageresource(r.drawable.ic_search);  the same attribute and calls work for imagebutton too.  section 162.3: vectordrawable xml example here is a simple vectordrawable in this vectordrawable.xml ﬁle. <vector xmlns:android=""http://schemas.android.com/apk/res/android"" android:height=""64dp"" android:width=""64dp"" android:viewportheight=""600"" android:viewportwidth=""600"" > <group android:name=""rotationgroup"" android:pivotx=""300.0"" android:pivoty=""300.0"" android:rotation=""45.0"" > <path android:name=""v"" android:fillcolor=""#000000"" android:pathdata=""m300,70 l 0,-70 70,70 0,0 -70,70z"" /> </group> </vector>  goalkicker.com – android™ notes for professionals  851",t_58ca0afc0bae,t_58ca0afc0bae,6
c_c25696bc9352,"chapter 170 of the book on android.chapter 170: audiotrack section 170.1: generate tone of a speciﬁc frequency to play a sound of with a speciﬁc tone,we ﬁrst have to create a sine wave sound.this is done in the following way. final int duration = 10; // duration of sound final int samplerate = 22050; // hz (maximum frequency is 7902.13hz (b8)) final int numsamples = duration * samplerate; final double samples[] = new double[numsamples]; final short buffer[] = new short[numsamples]; for (int i = 0; i < numsamples; ++i) { samples[i] = math.sin(2 * math.pi * i / (samplerate / note[0])); // sine wave buffer[i] = (short) (samples[i] * short.max_value); // higher amplitude increases volume }  now we have to conﬁgure audiotrack to play in accordance with the generated buﬀer . it is done in the following manner audiotrack audiotrack = new audiotrack(audiomanager.stream_music, samplerate, audioformat.channel_out_mono, audioformat.encoding_pcm_16bit, buffer.length, audiotrack.mode_static);  write the generated buﬀer and play the track audiotrack.write(buffer, 0, buffer.length); audiotrack.play();  hope this helps :)  goalkicker.com – android™ notes for professionals  877",t_58ca0afc0bae,t_58ca0afc0bae,6
c_d99b7bbce0ca,"chapter 238 of the book on android.chapter 238: google awareness apis section 238.1: get changes for location within a certain range using fence api if you want to detect when your user enters a speciﬁc location, you can create a fence for the speciﬁc location with a radius you want and be notiﬁed when your user enters or leaves the location. // your own action filter, like the ones used in the manifest private static final string fence_receiver_action = buildconfig.application_id + ""fence_receiver_action""; private static final string fence_key = ""locationfencekey""; private fencereceiver mfencereceiver; private pendingintent mpendingintent; // make sure to initialize your client as described in the remarks section protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); // etc // the 0 is a standard activity request code that can be changed for your needs mpendingintent = pendingintent.getbroadcast(this, 0, new intent(fence_receiver_action), 0); registerreceiver(mfencereceiver, new intentfilter(fence_receiver_action)); // create the fence awarenessfence fence = locationfence.entering(48.136334, 11.581660, 25); // register the fence to receive callbacks. awareness.fenceapi.updatefences(client, new fenceupdaterequest.builder() .addfence(fence_key, fence, mpendingintent) .build()) .setresultcallback(new resultcallback<status>() { @override public void onresult(@nonnull status status) { if (status.issuccess()) { log.i(fence_key, ""successfully registered.""); } else { log.e(fence_key, ""could not be registered: "" + status); } } }); } }  now create a broadcastreciver to recive updates in user state: public class fencereceiver extends broadcastreceiver { private static final string tag = ""fencereceiver""; @override public void onreceive(context context, intent intent) { // get the fence state fencestate fencestate = fencestate.extract(intent); switch (fencestate.getcurrentstate()) { case fencestate.true: log.i(tag, ""user is in location""); break;  goalkicker.com – android™ notes for professionals  1128  case fencestate.false: log.i(tag, ""user is not in location""); break; case fencestate.unknown: log.i(tag, ""user is doing something unknown""); break; } } }  section 238.2: get current location using snapshot api // remember to intialize your client as described in the remarks section awareness.snapshotapi.getlocation(client) .setresultcallback(new resultcallback<locationresult>() { @override public void onresult(@nonnull locationresult locationresult) { location location = locationresult.getlocation(); log.i(getclass().getsimplename(), ""coordinates: ""location.getlatitude() + "","" + location.getlongitude() + "", radius : "" + location.getaccuracy()); } });  section 238.3: get changes in user activity with fence api if you want to detect when your user starts or ﬁnishes an activity such as walking, running, or any other activity of the detectedactivityfence class, you can create a fence for the activity that you want to detect, and get notiﬁed when your user starts/ﬁnishes this activity. by using a broadcastreceiver, you will get an intent with data that contains the activity: // your own action filter, like the ones used in the manifest. private static final string fence_receiver_action = buildconfig.application_id + ""fence_receiver_action""; private static final string fence_key = ""walkingfencekey""; private fencereceiver mfencereceiver; private pendingintent mpendingintent; // make sure to initialize your client as described in the remarks section. protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); // etc. // the 0 is a standard activity request code that can be changed to your needs. mpendingintent = pendingintent.getbroadcast(this, 0, new intent(fence_receiver_action), 0); registerreceiver(mfencereceiver, new intentfilter(fence_receiver_action)); // create the fence. awarenessfence fence = detectedactivityfence.during(detectedactivityfence.walking); // register the fence to receive callbacks. awareness.fenceapi.updatefences(client, new fenceupdaterequest.builder() .addfence(fence_key, fence, mpendingintent) .build()) .setresultcallback(new resultcallback<status>() { @override public void onresult(@nonnull status status) { if (status.issuccess()) { log.i(fence_key, ""successfully registered.""); } else {  goalkicker.com – android™ notes for professionals  1129  log.e(fence_key, ""could not be registered: "" + status); } } }); } }  now you can receive the intent with a broadcastreceiver to get callbacks when the user changes the activity: public class fencereceiver extends broadcastreceiver { private static final string tag = ""fencereceiver""; @override public void onreceive(context context, intent intent) { // get the fence state fencestate fencestate = fencestate.extract(intent); switch (fencestate.getcurrentstate()) { case fencestate.true: log.i(tag, ""user is walking""); break; case fencestate.false: log.i(tag, ""user is not walking""); break; case fencestate.unknown: log.i(tag, ""user is doing something unknown""); break; } } }  section 238.4: get current user activity using snapshot api for one-time, non-constant requests for a user's physical activity, use the snapshot api: // remember to initialize your client as described in the remarks section awareness.snapshotapi.getdetectedactivity(client) .setresultcallback(new resultcallback<detectedactivityresult>() { @override public void onresult(@nonnull detectedactivityresult detectedactivityresult) { if (!detectedactivityresult.getstatus().issuccess()) { log.e(getclass().getsimplename(), ""could not get the current activity.""); return; } activityrecognitionresult result = detectedactivityresult .getactivityrecognitionresult(); detectedactivity probableactivity = result.getmostprobableactivity(); log.i(getclass().getsimplename(), ""activity received : "" + probableactivity.tostring()); } });  section 238.5: get headphone state with snapshot api // remember to initialize your client as described in the remarks section awareness.snapshotapi.getheadphonestate(client) .setresultcallback(new resultcallback<headphonestateresult>() { @override  goalkicker.com – android™ notes for professionals  1130  public void onresult(@nonnull headphonestateresult headphonestateresult) { log.i(tag, ""headphone state connection state: "" + headphonestateresult.getheadphonestate() .getstate() == headphonestate.plugged_in)); } });  section 238.6: get nearby places using snapshot api // remember to initialize your client as described in the remarks section awareness.snapshotapi.getplaces(client) .setresultcallback(new resultcallback<placesresult>() { @override public void onresult(@nonnull placesresult placesresult) { list<placelikelihood> likelihoodlist = placesresult.getplacelikelihoods(); if (likelihoodlist == null || likelihoodlist.isempty()) { log.e(getclass().getsimplename(), ""no likely places""); } } });  as for getting the data in those places, here are some options: place place = placelikelihood.getplace(); string likelihood = placelikelihood.getlikelihood(); place place = likelihood.getplace(); string placename = place.getname(); string placeaddress = place.getaddress(); string placecoords = place.getlatlng(); string locale = extractfromlocale(place.getlocale()));  section 238.7: get current weather using snapshot api // remember to initialize your client as described in the remarks section awareness.snapshotapi.getweather(client) .setresultcallback(new resultcallback<weatherresult>() { @override public void onresult(@nonnull weatherresult weatherresult) { weather weather = weatherresult.getweather(); if (weather == null) { log.e(getclass().getsimplename(), ""no weather received""); } else { log.i(getclass().getsimplename(), ""temperature is "" + weather.gettemperature(weather.celsius) + "", feels like "" + weather.getfeelsliketemperature(weather.celsius) + "", humidity is "" + weather.gethumidity()); } } });  goalkicker.com – android™ notes for professionals  1131",t_58ca0afc0bae,t_58ca0afc0bae,6
c_c3387324ff9e,"chapter 2 of the book on android.chapter 2: android studio section 2.1: setup android studio system requirements microsoft® windows® 8/7/vista/2003 (32 or 64-bit). mac® os x® 10.8.5 or higher, up to 10.9 (mavericks) gnome or kde desktop installation window 1. download and install jdk (java development kit) version 8 2. download android studio 3. launch android studio.exe then mention jdk path and download the latest sdk linux 1. download and install jdk (java development kit) version 8 2. download android studio 3. extract the zip ﬁle 4. open terminal, cd to the extracted folder, cd to bin (example cd android-studio/bin) 5. run ./studio.sh  section 2.2: view and add shortcuts in android studio by going to settings >> keymap a window will popup showing all the editor actions with the their name and shortcuts. some of the editor actions do not have shortcuts. so right click on that and add a new shortcut to that. check the image below  goalkicker.com – android™ notes for professionals  23  section 2.3: android studio useful shortcuts the following are some of the more common/useful shortcuts. these are based on the default intellij shortcut map. you can switch to other common ide shortcut maps via file -> settings -> keymap -> <choose eclipse/visual studio/etc from keymaps dropdown>  format code  action  shortcut ctrl + alt + l  add unimplemented methods  ctrl + i  show logcat  alt + 6  build  ctrl + f9  build and run  ctrl + f10  find  ctrl + f  find in project  ctrl + shift + f  find and replace  ctrl + r  find and replace in project  ctrl + shift + r  override methods  ctrl + o  show project  alt + 1  hide project - logcat  shift + esc  collapse all  ctrl + shift + numpad +  view debug points  ctrl + shift + f8  expand all  ctrl + shift + numpad -  open settings  alt + s  goalkicker.com – android™ notes for professionals  24  select target (open current ﬁle in project view) alt + f1 → enter search everywhere  shift → shift (double shift)  code | surround with  ctrl → alt + t  create method form selected code  alt + ctrl  refactor: action refactor this (menu/picker for all applicable refactor actions of the current element) rename  shortcut mac ctrl + t - win/linux ctrl + alt + t shift + f6  extract method  mac cmd + alt + m - win/linux ctrl + alt + m  extract parameter  mac cmd + alt + p - win/linux ctrl + alt + p  extract variable  mac cmd + alt + v - win/linux ctrl + alt + v  section 2.4: android studio improve performance tip enable oﬄine work: 1. click file -> settings. search for ""gradle"" and click in offline work box. 2. go to compiler (in same settings dialog just below gradle) and add --offline to command-line options text box. improve gradle performance add following two line of code in your gradle.properties ﬁle. org.gradle.daemon=true org.gradle.parallel=true  increasing the value of -xmx and -xms in studio.vmoptions ﬁle -xms1024m -xmx4096m -xx:maxpermsize=1024m -xx:reservedcodecachesize=256m -xx:+usecompressedoops  window %userprofile%.{folder_name}\studio.exe.vmoptions and/or %userprofile%.{folder_name}\studio64.exe.vmoptions mac ~/library/preferences/{folder_name}/studio.vmoptions linux ~/.{folder_name}/studio.vmoptions and/or ~/.{folder_name}/studio64.vmoptions goalkicker.com – android™ notes for professionals  25  section 2.5: gradle build project takes forever android studio -> preferences -> gradle -> tick oﬄine work and then restart your android studio. reference screenshot:  section 2.6: enable/disable blank line copy ctrl + alt + shift + / (cmd + alt + shift + / on macos) should show you the following dialog:  clicking on registry you will get  goalkicker.com – android™ notes for professionals  26  the key you want to enable/disable is editor.skip.copy.and.cut.for.empty.selection  tested on linux ubuntu and macos.  section 2.7: custom colors of logcat message based on message importance go to file -> settings -> editor -> colors & fonts -> android logcat change the colors as you need:  goalkicker.com – android™ notes for professionals  27  choose the appropriate color:  section 2.8: filter logs from ui android logs can be ﬁltered directly from the ui. using this code  goalkicker.com – android™ notes for professionals  28  public class mainactivity extends appcompatactivity { private final static string tag1 = mainactivity.class.getsimplename(); private final static string tag2 = mainactivity.class.getcanonicalname(); @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); setcontentview(r.layout.activity_main); log.e(tag1,""log from oncreate method with tag1""); log.i(tag2,""log from oncreate method with tag2""); } }  if i use the regex tag1|tag2 and the level verbose i get 01-14 10:34:46.961 12880-12880/android.doc.so.thiebaudthomas.sodocandroid e/mainactivity: log from oncreate method with tag1 01-14 10:34:46.961 12880-12880/android.doc.so.thiebaudthomas.sodocandroid i/androdi.doc.so.thiebaudthomas.sodocandroid.mainactivity: log from oncreate method with tag2  the level can be set to get logs with given level and above. for example the verbose level will catch verbose, debug, info, warn, error and assert logs.  using the same example, if i set the level to error, i only get 01-14 10:34:46.961 12880-12880/androdi.doc.so.thiebaudthomas.sodocandroid e/mainactivity: log from oncreate method with tag1  section 2.9: create ﬁlters conﬁguration custom ﬁlters can be set and save from the ui. in the androidmonitor tab, click on the right dropdown (must contains show only selected application or no filters) and select edit filter configuration. enter the ﬁlter you want  goalkicker.com – android™ notes for professionals  29  and use it (you can selected it from the same dropdown)  important if you add an input in the ﬁlter bar, android studio will consider both your ﬁlter and your input. with both input and ﬁlter there is no output  without ﬁlter, there is some outputs  section 2.10: create assets folder right click in main folder > new > folder > assets folder. assets folder will be under main folder with the same symbol as res folder. in this example i put a font ﬁle.  goalkicker.com – android™ notes for professionals  30  goalkicker.com – android™ notes for professionals  31",t_58ca0afc0bae,t_58ca0afc0bae,6
c_cfbcf1279b63,"chapter 14 of the book on android.chapter 14: cardview parameter cardbackgroundcolor  background color for cardview.  details  cardcornerradius  corner radius for cardview.  cardelevation  elevation for cardview.  cardmaxelevation  maximum elevation for cardview.  cardpreventcorneroverlap  add padding to cardview on v20 and before to prevent intersections between the card content and rounded corners.  cardusecompatpadding  add padding in api v21+ as well to have the same measurements with previous versions. may be a boolean value, such as ""true"" or ""false"".  contentpadding  inner padding between the edges of the card and children of the cardview.  contentpaddingbottom  inner padding between the bottom edge of the card and children of the cardview.  contentpaddingleft  inner padding between the left edge of the card and children of the cardview.  contentpaddingright  elevation for cardview.  cardelevation  inner padding between the right edge of the card and children of the cardview.  contentpaddingtop  inner padding between the top edge of the card and children of the cardview.  a framelayout with a rounded corner background and shadow. cardview uses elevation property on lollipop for shadows and falls back to a custom emulated shadow implementation on older platforms. due to expensive nature of rounded corner clipping, on platforms before lollipop, cardview does not clip its children that intersect with rounded corners. instead, it adds padding to avoid such intersection (see setpreventcorneroverlap(boolean) to change this behavior).  section 14.1: getting started with cardview cardview is a member of the android support library, and provides a layout for cards.  to add cardview to your project, add the following line to your build.gradle dependencies. compile 'com.android.support:cardview-v7:25.1.1'  a number of the latest version may be found here in your layout you can then add the following to get a card. <android.support.v7.widget.cardview xmlns:card_view=""http://schemas.android.com/apk/res-auto"" android:layout_width=""match_parent"" android:layout_height=""wrap_content""> <!-- one child layout containing other layouts or views --> </android.support.v7.widget.cardview>  you can then add other layouts inside this and they will be encompassed in a card. also, cardview can be populated with any ui element and manipulated from code. <?xml version=""1.0"" encoding=""utf-8""?>  goalkicker.com – android™ notes for professionals  92  <android.support.v7.widget.cardview xmlns:android=""http://schemas.android.com/apk/res/android"" xmlns:card_view=""http://schemas.android.com/apk/res-auto"" android:layout_width=""match_parent"" android:layout_height=""wrap_content"" android:id=""@+id/card_view"" android:layout_margin=""5dp"" card_view:cardbackgroundcolor=""#81c784"" card_view:cardcornerradius=""12dp"" card_view:cardelevation=""3dp"" card_view:contentpadding=""4dp"" > <relativelayout android:layout_width=""match_parent"" android:layout_height=""wrap_content"" android:padding=""16dp"" > <imageview android:layout_width=""100dp"" android:layout_height=""100dp"" android:id=""@+id/item_image"" android:layout_alignparentleft=""true"" android:layout_alignparenttop=""true"" android:layout_marginright=""16dp"" /> <textview android:layout_width=""wrap_content"" android:layout_height=""wrap_content"" android:id=""@+id/item_title"" android:layout_torightof=""@+id/item_image"" android:layout_alignparenttop=""true"" android:textsize=""30sp"" /> <textview android:layout_width=""wrap_content"" android:layout_height=""wrap_content"" android:id=""@+id/item_detail"" android:layout_torightof=""@+id/item_image"" android:layout_below=""@+id/item_title"" /> </relativelayout> </android.support.v7.widget.cardview>  section 14.2: adding ripple animation to enable the ripple animation in a cardview, add the following attributes: <android.support.v7.widget.cardview ... android:clickable=""true"" android:foreground=""?android:attr/selectableitembackground""> ... </android.support.v7.widget.cardview>  section 14.3: customizing the cardview cardview provides a default elevation and corner radius so that cards have a consistent appearance across the goalkicker.com – android™ notes for professionals  93  platforms. you can customize these default values using these attributes in the xml ﬁle: 1. card_view:cardelevation attribute add elevation in cardview. 2. card_view:cardbackgroundcolor attribute is used to customize background color of cardview's background(you can give any color). 3. card_view:cardcornerradius attribute is used to curve 4 edges of cardview 4. card_view:contentpadding attribute add padding between card and children of card note: card_view is a namespace deﬁned in topmost parent layout view. xmlns:card_view=""http://schemas.android.com/apk/res-auto"" here an example: <android.support.v7.widget.cardview xmlns:card_view=""http://schemas.android.com/apk/res-auto"" android:layout_width=""match_parent"" android:layout_height=""wrap_content"" card_view:cardelevation=""4dp"" card_view:cardbackgroundcolor=""@android:color/white"" card_view:cardcornerradius=""8dp"" card_view:contentpadding=""16dp""> <!-- one child layout containing other layouts or views --> </android.support.v7.widget.cardview>  you can also do it programmatically using: card.setcardbackgroundcolor(....); card.setcardelevation(...); card.setradius(....); card.setcontentpadding();  check the oﬃcial javadoc for additional properties.  section 14.4: using images as background in cardview (prelollipop device issues) while using image/colour as an background in a cardview, you might end up with slight white paddings (if default card colour is white) on the edges. this occurs due to the default rounded corners in the card view. here is how to avoid those margins in pre-lollipop devices. we need to use an attribute card_view:cardpreventcorneroverlap=""false"" in the cardview. 1). in xml use the following snippet. <android.support.v7.widget.cardview xmlns:card_view=""http://schemas.android.com/apk/res-auto"" android:layout_width=""match_parent"" card_view:cardpreventcorneroverlap=""false"" android:layout_height=""wrap_content""> <imageview android:id=""@+id/row_wallet_redeem_img"" android:layout_width=""match_parent"" android:layout_height=""match_parent"" android:adjustviewbounds=""true""  goalkicker.com – android™ notes for professionals  94  android:scaletype=""centercrop"" android:src=""@drawable/bg_image"" /> </android.support.v7.widget.cardview>  2. in java like this cardview.setpreventcorneroverlap(false). doing so removes an unwanted padding on the card's edges. here are some visual examples related to this implementation. 1 card with image background in api 21 (perfectly ﬁne)  2 card with image background in api 19 without attribute (notice the paddings around image)  3 fixed card with image background in api 19 with attribute cardview.setpreventcorneroverlap(false) (issue now ﬁxed)  goalkicker.com – android™ notes for professionals  95  also read about this on documentation here original sof post here  section 14.5: animate cardview background color with transitiondrawable public void setcardcolortran(cardview card) { colordrawable[] color = {new colordrawable(color.blue), new colordrawable(color.red)}; transitiondrawable trans = new transitiondrawable(color); if(build.version.sdk_int > build.version_codes.ice_cream_sandwich_mr1) { card.setbackground(trans); } else { card.setbackgrounddrawable(trans); } trans.starttransition(5000); }  goalkicker.com – android™ notes for professionals  96",t_58ca0afc0bae,t_58ca0afc0bae,6
c_779a1928b8b3,"chapter 106 of the book on android.chapter 106: detect shake event in android section 106.1: shake detector in android example public class shakedetector implements sensoreventlistener {  private static final float shake_threshold_gravity = 2.7f; private static final int shake_slop_time_ms = 500; private static final int shake_count_reset_time_ms = 3000; private onshakelistener mlistener; private long mshaketimestamp; private int mshakecount; public void setonshakelistener(onshakelistener listener) { this.mlistener = listener; } public interface onshakelistener { public void onshake(int count); } @override public void onaccuracychanged(sensor sensor, int accuracy) { // ignore } @override public void onsensorchanged(sensorevent event) { if (mlistener float x = float y = float z =  != null) { event.values[0]; event.values[1]; event.values[2];  float gx = x / sensormanager.gravity_earth; float gy = y / sensormanager.gravity_earth; float gz = z / sensormanager.gravity_earth; // gforce will be close to 1 when there is no movement. float gforce = floatmath.sqrt(gx * gx + gy * gy + gz * gz); if (gforce > shake_threshold_gravity) { final long now = system.currenttimemillis(); // ignore shake events too close to each other (500ms) if (mshaketimestamp + shake_slop_time_ms > now) { return; } // reset the shake count after 3 seconds of no shakes if (mshaketimestamp + shake_count_reset_time_ms < now) { mshakecount = 0; } mshaketimestamp = now; mshakecount++;  goalkicker.com – android™ notes for professionals  659  mlistener.onshake(mshakecount); } } } }  section 106.2: using seismic shake detection seismic is an android device shake detection library by square. to use it just start listening to the shake events emitted by it. @override protected void oncreate(bundle savedinstancestate) { sm = (sensormanager) getsystemservice(sensor_service); sd = new shakedetector(() -> { /* react to detected shake */ }); } @override protected void onresume() { sd.start(sm); } @override protected void onpause() { sd.stop(); }  to deﬁne the a diﬀerent acceleration threshold use sd.setsensitivity(sensitivity) with a sensitivity of sensitivity_light, sensitivity_medium, sensitivity_hard or any other reasonable integer value. the given  default values range from 11 to 15. installation compile 'com.squareup:seismic:1.0.2'  goalkicker.com – android™ notes for professionals  660",t_58ca0afc0bae,t_58ca0afc0bae,6
c_e04a23aac784,"section ""you may also like"" of the book on android.you may also like",t_58ca0afc0bae,t_58ca0afc0bae,6
c_124272ff39ef,"chapter 114 of the book on r.chapter 114: reshape using tidyr tidyr has two tools for reshaping data: gather (wide to long) and spread (long to wide). see reshaping data for other options.  section 114.1: reshape from long to wide format with spread() library(tidyr) ## example data set.seed(123) df <- data.frame( name = rep(c(""firstname"", ""secondname""), each=4), numbers = rep(1:4, 2), value = rnorm(8) ) df # name numbers value # 1 firstname 1 -0.56047565 # 2 firstname 2 -0.23017749 # 3 firstname 3 1.55870831 # 4 firstname 4 0.07050839 # 5 secondname 1 0.12928774 # 6 secondname 2 1.71506499 # 7 secondname 3 0.46091621 # 8 secondname 4 -1.26506123  we can ""spread"" the 'numbers' column, into separate columns: spread(data = df, key = numbers, value = value) # name 1 2 3 4 # 1 firstname -0.5604756 -0.2301775 1.5587083 0.07050839 # 2 secondname 0.1292877 1.7150650 0.4609162 -1.26506123  or spread the 'name' column into separate columns: spread(data = df, key = name, value = value) # numbers firstname secondname # 1 1 -0.56047565 0.1292877 # 2 2 -0.23017749 1.7150650 # 3 3 1.55870831 0.4609162 # 4 4 0.07050839 -1.2650612  section 114.2: reshape from wide to long format with gather() library(tidyr) ## example data df <- read.table(text ="" numbers 1 1 1.5862639 0.4087477 2 2 0.1499581 0.9963923  firstname secondname  goalkicker.com – r notes for professionals  419  3 3 0.4117353 0.3740009 4 4 -0.4926862 0.4437916"", header = t) df # numbers firstname secondname # 1 1 1.5862639 0.4087477 # 2 2 0.1499581 0.9963923 # 3 3 0.4117353 0.3740009 # 4 4 -0.4926862 0.4437916  we can gather the columns together using 'numbers' as the key column: gather(data = df, key = numbers, value = myvalue) # numbers numbers myvalue # 1 1 firstname 1.5862639 # 2 2 firstname 0.1499581 # 3 3 firstname 0.4117353 # 4 4 firstname -0.4926862 # 5 1 secondname 0.4087477 # 6 2 secondname 0.9963923 # 7 3 secondname 0.3740009 # 8 4 secondname 0.4437916  goalkicker.com – r notes for professionals  420",t_59bf60f88801,t_59bf60f88801,7
c_cb5bab5f3b3f,"chapter 21 of the book on r.chapter 21: pipe operators (%>% and others) lhs rhs a value or the magrittr placeholder. a function call using the magrittr semantics pipe operators, available in magrittr, dplyr, and other r packages, process a data-object using a sequence of operations by passing the result of one step as input for the next step using inﬁx-operators rather than the more typical r method of nested function calls. note that the intended aim of pipe operators is to increase human readability of written code. see remarks section for performance considerations.  section 21.1: basic use and chaining the pipe operator, %>%, is used to insert an argument into a function. it is not a base feature of the language and can only be used after attaching a package that provides it, such as magrittr. the pipe operator takes the left-hand side (lhs) of the pipe and uses it as the ﬁrst argument of the function on the right-hand side (rhs) of the pipe. for example: library(magrittr) 1:10 %>% mean # [1] 5.5 # is equivalent to mean(1:10) # [1] 5.5  the pipe can be used to replace a sequence of function calls. multiple pipes allow us to read and write the sequence from left to right, rather than from inside to out. for example, suppose we have years deﬁned as a factor but want to convert it to a numeric. to prevent possible information loss, we ﬁrst convert to character and then to numeric: years <- factor(2008:2012) # nesting as.numeric(as.character(years)) # piping years %>% as.character %>% as.numeric  if we don't want the lhs (left hand side) used as the ﬁrst argument on the rhs (right hand side), there are workarounds, such as naming the arguments or using . to indicate where the piped input goes. # example with grepl # its syntax: # grepl(pattern, x, ignore.case = false, perl = false, fixed = false, usebytes = false) # note that the `substring` result is the *2nd* argument of grepl grepl(""wo"", substring(""hello world"", 7, 11)) # piping while naming other arguments ""hello world"" %>% substring(7, 11) %>% grepl(pattern = ""wo"")  goalkicker.com – r notes for professionals  71  # piping with . ""hello world"" %>% substring(7, 11) %>% grepl(""wo"", .) # piping with . and curly braces ""hello world"" %>% substring(7, 11) %>% { c(paste('hi', .)) } #[1] ""hi world"" #using lhs multiple times in argument with curly braces and . ""hello world"" %>% substring(7, 11) %>% { c(paste(. ,'hi', .)) } #[1] ""world hi world""  section 21.2: functional sequences given a sequence of steps we use repeatedly, it's often handy to store it in a function. pipes allow for saving such functions in a readable format by starting a sequence with a dot as in: . %>% rhs  as an example, suppose we have factor dates and want to extract the year: library(magrittr) # needed to include the pipe operators library(lubridate) read_year <- . %>% as.character %>% as.date %>% year # creating a dataset df <- data.frame(now = ""2015-11-11"", before = ""2012-01-01"") # now before # 1 2015-11-11 2012-01-01 # example 1: applying `read_year` to a single character-vector df$now %>% read_year # [1] 2015 # example 2: applying `read_year` to all columns of `df` df %>% lapply(read_year) %>% as.data.frame # implicit `lapply(df, read_year) # now before # 1 2015 2012 # example 3: same as above using `mutate_all` library(dplyr) df %>% mutate_all(funs(read_year)) # if an older version of dplyr use `mutate_each` # now before # 1 2015 2012  we can review the composition of the function by typing its name or using functions: read_year # functional sequence with the following components: # # 1. as.character(.) # 2. as.date(.) # 3. year(.) # # use 'functions' to extract the individual functions.  we can also access each function by its position in the sequence: read_year[[2]]  goalkicker.com – r notes for professionals  72  # function (.) # as.date(.)  generally, this approach may be useful when clarity is more important than speed.  section 21.3: assignment with %<>% the magrittr package contains a compound assignment inﬁx-operator, %<>%, that updates a value by ﬁrst piping it into one or more rhs expressions and then assigning the result. this eliminates the need to type an object name twice (once on each side of the assignment operator <-). %<>% must be the ﬁrst inﬁx-operator in a chain: library(magrittr) library(dplyr) df <- mtcars  instead of writing df <- df %>% select(1:3) %>% filter(mpg > 20, cyl == 6)  or df %>% select(1:3) %>% filter(mpg > 20, cyl == 6) -> df  the compound assignment operator will both pipe and reassign df: df %<>% select(1:3) %>% filter(mpg > 20, cyl == 6)  section 21.4: exposing contents with %$% the exposition pipe operator, %$%, exposes the column names as r symbols within the left-hand side object to the right-hand side expression. this operator is handy when piping into functions that do not have a data argument (unlike, say, lm) and that don't take a data.frame and column names as arguments (most of the main dplyr functions). the exposition pipe operator %$% allows a user to avoid breaking a pipeline when needing to refer to column names. for instance, say you want to ﬁlter a data.frame and then run a correlation test on two columns with cor.test: library(magrittr) library(dplyr) mtcars %>% filter(wt > 2) %$% cor.test(hp, mpg) #> #> #> #> #> #> #> #> #> #>  pearson's product-moment correlation data: hp and mpg t = -5.9546, df = 26, p-value = 2.768e-06 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.8825498 -0.5393217 sample estimates: cor  goalkicker.com – r notes for professionals  73  #> -0.7595673  here the standard %>% pipe passes the data.frame through to filter(), while the %$% pipe exposes the column names to cor.test(). the exposition pipe works like a pipe-able version of the base r with() functions, and the same left-hand side objects are accepted as inputs.  section 21.5: creating side eects with %t>% some functions in r produce a side eﬀect (i.e. saving, printing, plotting, etc) and do not always return a meaningful or desired value. %t>% (tee operator) allows you to forward a value into a side-eﬀect-producing function while keeping the original lhs value intact. in other words: the tee operator works like %>%, except the return values is lhs itself, and not the  result of the rhs function/expression. example: create, pipe, write, and return an object. if %>% were used in place of %t>% in this example, then the variable all_letters would contain null rather than the value of the sorted object. all_letters <- c(letters, letters) %>% sort %t>% write.csv(file = ""all_letters.csv"") read.csv(""all_letters.csv"") %>% head() # x # 1 a # 2 a # 3 b # 4 b # 5 c # 6 c  warning: piping an unnamed object to save() will produce an object named . when loaded into the workspace with load(). however, a workaround using a helper function is possible (which can also be written inline as an anonymous function). all_letters <- c(letters, letters) %>% sort %t>% save(file = ""all_letters.rdata"") load(""all_letters.rdata"", e <- new.env()) get(""all_letters"", envir = e) # error in get(""all_letters"", envir = e) : object 'all_letters' not found get(""."", envir # [1] ""a"" ""a"" # [21] ""k"" ""k"" # [41] ""u"" ""u""  = e) ""b"" ""b"" ""c"" ""c"" ""d"" ""d"" ""e"" ""e"" ""f"" ""f"" ""g"" ""g"" ""h"" ""h"" ""i"" ""i"" ""j"" ""j"" ""l"" ""l"" ""m"" ""m"" ""n"" ""n"" ""o"" ""o"" ""p"" ""p"" ""q"" ""q"" ""r"" ""r"" ""s"" ""s"" ""t"" ""t"" ""v"" ""v"" ""w"" ""w"" ""x"" ""x"" ""y"" ""y"" ""z"" ""z""  # work-around save2 <- function(. = ., name, file = stop(""'file' must be specified"")) { assign(name, .) call_save <- call(""save"", ... = name, file = file) eval(call_save) }  goalkicker.com – r notes for professionals  74  all_letters <- c(letters, letters) %>% sort %t>% save2(""all_letters"", ""all_letters.rdata"")  section 21.6: using the pipe with dplyr and ggplot2 the %>% operator can also be used to pipe the dplyr output into ggplot. this creates a uniﬁed exploratory data analysis (eda) pipeline that is easily customizable. this method is faster than doing the aggregations internally in ggplot and has the added beneﬁt of avoiding unnecessary intermediate variables. library(dplyr) library(ggplot)  diamonds %>% filter(depth > 60) %>% group_by(cut) %>% summarize(mean_price = mean(price)) %>% ggplot(aes(x = cut, y = mean_price)) + geom_bar(stat = ""identity"")  goalkicker.com – r notes for professionals  75",t_59bf60f88801,t_59bf60f88801,7
c_ae579d2282d6,"chapter 86 of the book on r.chapter 86: network analysis with the igraph package section 86.1: simple directed and non-directed network graphing the igraph package for r is a wonderful tool that can be used to model networks, both real and virtual, with simplicity. this example is meant to demonstrate how to create two simple network graphs using the igraph package within r v.3.2.3. non-directed network the network is created with this piece of code: g<-graph.formula(node1-node2, node1-node3, node4-node1) plot(g)  directed network dg<-graph.formula(tom-+mary, tom-+bill, tom-+sam, sue+-mary, bill-+sue) plot(dg)  this code will then generate a network with arrows:  goalkicker.com – r notes for professionals  341  code example of how to make a double sided arrow: dg<-graph.formula(tom-+mary, tom-+bill, tom-+sam, sue+-mary, bill++sue) plot(dg)  goalkicker.com – r notes for professionals  342",t_59bf60f88801,t_59bf60f88801,7
c_2f5ffc245c03,"chapter 75 of the book on r.chapter 75: fourier series and transformations the fourier transform decomposes a function of time (a signal) into the frequencies that make it up, similarly to how a musical chord can be expressed as the amplitude (or loudness) of its constituent notes. the fourier transform of a function of time itself is a complex-valued function of frequency, whose absolute value represents the amount of that frequency present in the original function, and whose complex argument is the phase oﬀset of the basic sinusoid in that frequency. the fourier transform is called the frequency domain representation of the original signal. the term fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of time. the fourier transform is not limited to functions of time, but in order to have a uniﬁed language, the domain of the original function is commonly referred to as the time domain. for many functions of practical interest one can deﬁne an operation that reverses this: the inverse fourier transformation, also called fourier synthesis, of a frequency domain representation combines the contributions of all the diﬀerent frequencies to recover the original function of time. linear operations performed in one domain (time or frequency) have corresponding operations in the other domain, which are sometimes easier to perform. the operation of diﬀerentiation in the time domain corresponds to multiplication by the frequency, so some diﬀerential equations are easier to analyze in the frequency domain. also, convolution in the time domain corresponds to ordinary multiplication in the frequency domain. concretely, this means that any linear time-invariant system, such as an electronic ﬁlter applied to a signal, can be expressed relatively simply as an operation on frequencies. so signiﬁcant simpliﬁcation is often achieved by transforming time functions to the frequency domain, performing the desired operations, and transforming the result back to time. harmonic analysis is the systematic study of the relationship between the frequency and time domains, including the kinds of functions or operations that are ""simpler"" in one or the other, and has deep connections to almost all areas of modern mathematics. functions that are localized in the time domain have fourier transforms that are spread out across the frequency domain and vice versa. the critical case is the gaussian function, of substantial importance in probability theory and statistics as well as in the study of physical phenomena exhibiting normal distribution (e.g., diﬀusion), which with appropriate normalizations goes to itself under the fourier transform. joseph fourier introduced the transform in his study of heat transfer, where gaussian functions appear as solutions of the heat equation. the fourier transform can be formally deﬁned as an improper riemann integral, making it an integral transform, although this deﬁnition is not suitable for many applications requiring a more sophisticated integration theory. for example, many relatively simple applications use the dirac delta function, which can be treated formally as if it were a function, but the justiﬁcation requires a mathematically more sophisticated viewpoint. the fourier transform can also be generalized to functions of several variables on euclidean space, sending a function of 3dimensional space to a function of 3-dimensional momentum (or a function of space and time to a function of 4momentum). this idea makes the spatial fourier transform very natural in the study of waves, as well as in quantum mechanics, where it is important to be able to represent wave solutions either as functions either of space or momentum and sometimes both. in general, functions to which fourier methods are applicable are complex-valued, and possibly vector-valued. still further generalization is possible to functions on groups, which, besides the original fourier transform on ℝ or ℝn (viewed as groups under addition), notably includes the discrete-time fourier transform (dtft, group = ℤ), the discrete fourier transform (dft, group = ℤ mod n) and the fourier series or circular fourier transform (group = s1, the unit circle ≈ closed ﬁnite interval with endpoints identiﬁed). the latter is routinely goalkicker.com – r notes for professionals  296  employed to handle periodic functions. the fast fourier transform (fft) is an algorithm for computing the dft.  section 75.1: fourier series joseph fourier showed that any periodic wave can be represented by a sum of simple sine waves. this sum is called the fourier series. the fourier series only holds while the system is linear. if there is, eg, some overﬂow eﬀect (a threshold where the output remains the same no matter how much input is given), a non-linear eﬀect enters the picture, breaking the sinusoidal wave and the superposition principle. # sine waves xs <- seq(-2*pi,2*pi,pi/100) wave.1 <- sin(3*xs) wave.2 <- sin(10*xs) par(mfrow = c(1, 2)) plot(xs,wave.1,type=""l"",ylim=c(-1,1)); abline(h=0,lty=3) plot(xs,wave.2,type=""l"",ylim=c(-1,1)); abline(h=0,lty=3) # complex wave wave.3 <- 0.5 * wave.1 + 0.25 * wave.2 plot(xs,wave.3,type=""l""); title(""eg complex wave""); abline(h=0,lty=3)  goalkicker.com – r notes for professionals  297  wave.4 <- wave.3 wave.4[wave.3>0.5] <- 0.5 plot(xs,wave.4,type=""l"",ylim=c(-1.25,1.25)) title(""overflowed, non-linear complex wave"") abline(h=0,lty=3)  goalkicker.com – r notes for professionals  298  also, the fourier series only holds if the waves are periodic, ie, they have a repeating pattern (non periodic waves are dealt by the fourier transform, see below). a periodic wave has a frequency f and a wavelength λ (a wavelength is the distance in the medium between the beginning and end of a cycle, λ=v/f0, where v is the wave velocity) that are deﬁned by the repeating pattern. a non-periodic wave does not have a frequency or wavelength. some concepts: the fundamental period, t, is the period of all the samples taken, the time between the ﬁrst sample and the last the sampling rate, sr, is the number of samples taken over a time period (aka acquisition frequency). for simplicity we will make the time interval between samples equal. this time interval is called the sample interval, si, which is the fundamental period time divided by the number of samples n. so, si=tn the fundamental frequency, f0, which is 1t. the fundamental frequency is the frequency of the repeating pattern or how long the wavelength is. in the previous waves, the fundamental frequency was 12π. the goalkicker.com – r notes for professionals  299  frequencies of the wave components must be integer multiples of the fundamental frequency. f0 is called the ﬁrst harmonic, the second harmonic is 2∗f0, the third is 3∗f0, etc. repeat.xs <- seq(-2*pi,0,pi/100) wave.3.repeat <- 0.5*sin(3*repeat.xs) + 0.25*sin(10*repeat.xs) plot(xs,wave.3,type=""l"") title(""repeating pattern"") points(repeat.xs,wave.3.repeat,type=""l"",col=""red""); abline(h=0,v=c(-2*pi,0),lty=3)  here’s a r function for plotting trajectories given a fourier series: plot.fourier <- function(fourier.series, f.0, ts) {  goalkicker.com – r notes for professionals  300  w <- 2*pi*f.0 trajectory <- sapply(ts, function(t) fourier.series(t,w)) plot(ts, trajectory, type=""l"", xlab=""time"", ylab=""f(t)""); abline(h=0,lty=3)}  goalkicker.com – r notes for professionals  301",t_59bf60f88801,t_59bf60f88801,7
c_2e1a52e7c0a6,"chapter 84 of the book on r.chapter 84: gpu-accelerated computing section 84.1: gpur gpumatrix objects library(gpur) # gpumatrix objects x <- gpumatrix(rnorm(100), 10, 10) y <- gpumatrix(rnorm(100), 10, 10) # transfer data to gpu when operation called # automatically copied back to cpu z <- x %*% y  section 84.2: gpur vclmatrix objects library(gpur) # vclmatrix objects x <- vclmatrix(rnorm(100), 10, 10) y <- vclmatrix(rnorm(100), 10, 10) # data always on gpu # no data transfer z <- x %*% y  goalkicker.com – r notes for professionals  326",t_59bf60f88801,t_59bf60f88801,7
c_36446e0a093c,"chapter 116 of the book on r.chapter 116: non-standard evaluation and standard evaluation dplyr and many modern libraries in r use non-standard evaluation (nse) for interactive programming and standard evaluation (se) for programming1. for instance, the summarise() function use non-standard evaluation but relies on the summarise_() which uses standard evaluation. the lazyeval library makes it easy to turn standard evaluation function into nse functions.  section 116.1: examples with standard dplyr verbs nse functions should be used in interactive programming. however, when developping new functions in a new package, it's better to use se version. load dplyr and lazyeval : library(dplyr) library(lazyeval)  filtering nse version filter(mtcars, cyl == 8) filter(mtcars, cyl < 6) filter(mtcars, cyl < 6 & vs == 1)  se version (to be use when programming functions in a new package) filter_(mtcars, .dots = list(~ cyl == 8)) filter_(mtcars, .dots = list(~ cyl < 6)) filter_(mtcars, .dots = list(~ cyl < 6, ~ vs == 1))  summarise nse version summarise(mtcars, summarise(mtcars,  mean(disp)) mean_disp = mean(disp))  se version summarise_(mtcars, .dots = lazyeval::interp(~ mean(x), x = quote(disp))) summarise_(mtcars, .dots = setnames(list(lazyeval::interp(~ mean(x), x = quote(disp))), ""mean_disp"")) summarise_(mtcars, .dots = list(""mean_disp"" = lazyeval::interp(~ mean(x), x = quote(disp))))  mutate nse version mutate(mtcars, displ_l = disp / 61.0237)  goalkicker.com – r notes for professionals  423  se version mutate_( .data = mtcars, .dots = list( ""displ_l"" = lazyeval::interp( ~ x / 61.0237, x = quote(disp) ) ) )  goalkicker.com – r notes for professionals  424",t_59bf60f88801,t_59bf60f88801,7
c_3c30aeecadc3,"chapter 47 of the book on r.chapter 47: shiny section 47.1: create an app shiny is an r package developed by rstudio that allows the creation of web pages to interactively display the results of an analysis in r. there are two simple ways to create a shiny app: in one .r ﬁle, or in two ﬁles: ui.r and server.r. a shiny app is divided into two parts: ui: a user interface script, controlling the layout and appearance of the application. server: a server script which contains code to allow the application to react. one ﬁle library(shiny) # create the ui ui <- shinyui(fluidpage( # application title titlepanel(""hello world!"") )) # create the server function server <- shinyserver(function(input, output){}) # run the app shinyapp(ui = ui, server = server)  two ﬁles create ui.r ﬁle library(shiny) # define ui for application shinyui(fluidpage( # application title titlepanel(""hello world!"") ))  create server.r ﬁle library(shiny) # define server logic shinyserver(function(input, output){})  section 47.2: checkbox group create a group of checkboxes that can be used to toggle multiple choices independently. the server will receive the input as a character vector of the selected values. library(shiny) ui <- fluidpage(  goalkicker.com – r notes for professionals  214  checkboxgroupinput(""checkgroup1"", label = h3(""this is a checkbox group""), choices = list(""1"" = 1, ""2"" = 2, ""3"" = 3), selected = 1), fluidrow(column(3, verbatimtextoutput(""text_choice""))) )  server <- function(input, output){ output$text_choice <- renderprint({ return(paste0(""you have chosen the choice "",input$checkgroup1))}) } shinyapp(ui = ui, server = server)  it's possible to change the settings : label : title choices : selected values selected : the initially selected value (null for no selection) inline : horizontal or vertical width it is also possible to add html.  section 47.3: radio button you can create a set of radio buttons used to select an item from a list. it's possible to change the settings : selected : the initially selected value (character(0) for no selection) inline : horizontal or vertical width it is also possible to add html. library(shiny) ui <- fluidpage( radiobuttons(""radio"", label = html('<font color=""red""><font size=""5pt"">welcome</font></font><br> <b>your favorite color is red ?</b>'), choices = list(""true"" = 1, ""false"" = 2), selected = 1, inline = t, width = ""100%""),  goalkicker.com – r notes for professionals  215  fluidrow(column(3, textoutput(""value""))))  server <- function(input, output){ output$value <- renderprint({ if(input$radio == 1){return('great !')} else{return(""sorry !"")}})} shinyapp(ui = ui, server = server)  section 47.4: debugging debug() and debugonce() won't work well in the context of most shiny debugging. however, browser() statements  inserted in critical places can give you a lot of insight into how your shiny code is (not) working. see also: debugging using browser() showcase mode showcase mode displays your app alongside the code that generates it and highlights lines of code in server.r as it runs them. there are two ways to enable showcase mode: launch shiny app with the argument display.mode = ""showcase"", e.g., runapp(""myapp"", display.mode = ""showcase"").  create ﬁle called description in your shiny app folder and add this line in it: displaymode: showcase. reactive log visualizer reactive log visualizer provides an interactive browser-based tool for visualizing reactive dependencies and execution in your application. to enable reactive log visualizer, execute options(shiny.reactlog=true) in r console and or add that line of code in your server.r ﬁle. to start reactive log visualizer, hit ctrl+f3 on windows or command+f3 on mac when your app is running. use left and right arrow keys to navigate in reactive log visualizer.  section 47.5: select box create a select list that can be used to choose a single or multiple items from a list of values. library(shiny) ui <- fluidpage( selectinput(""id_selectinput"", label = html('<b><font size=""3"">what is your favorite color ?</font></b>'), multiple = true, choices = list(""red"" = ""red"", ""green"" = ""green"", ""blue"" = ""blue"", ""yellow"" = ""yellow""), selected = null), br(), br(), fluidrow(column(3, textoutput(""text_choice""))))  goalkicker.com – r notes for professionals  216  server <- function(input, output){ output$text_choice <- renderprint({ return(input$id_selectinput)}) } shinyapp(ui = ui, server = server)  it's possible to change the settings : label : title choices : selected values selected : the initially selected value (null for no selection) multiple : true or false width size selectize: true or false (for use or not selectize.js, change the display) it is also possible to add html.  section 47.6: launch a shiny app you can launch an application in several ways, depending on how you create you app. if your app is divided in two ﬁles ui.r and server.r or if all of your app is in one ﬁle. 1. two ﬁles app your two ﬁles ui.r and server.rhave to be in the same folder. you could then launch your app by running in the console the shinyapp() function and by passing the path of the directory that contains the shiny app. shinyapp(""path_to_the_folder_containing_the_files"")  you can also launch the app directly from rstudio by pressing the run app button that appear on rstudio when you an ui.r or server.r ﬁle open.  or you can simply write runapp() on the console if your working directory is shiny app directory. 2. one ﬁle app if you create your in one r ﬁle you can also launch it with the shinyapp() function. inside of your code : goalkicker.com – r notes for professionals  217  library(shiny) ui <- fluidpage() #create the ui server <- function(input, output){} #create the server shinyapp(ui = ui, server = server) #run the app  in the console by adding path to a .r ﬁle containing the shiny application with the parameter appfile: shinyapp(appfile=""path_to_my_r_file_containig_the_app"")  section 47.7: control widgets function actionbutton  widget action button  checkboxgroupinput a group of check boxes checkboxinput  a single check box  dateinput  a calendar to aid date selection  daterangeinput  a pair of calendars for selecting a date range  ﬁleinput  a ﬁle upload control wizard  helptext  help text that can be added to an input form  numericinput  a ﬁeld to enter numbers  radiobuttons  a set of radio buttons  selectinput  a box with choices to select from  sliderinput  a slider bar  submitbutton  a submit button  textinput  a ﬁeld to enter text  library(shiny) # create the ui ui <- shinyui(fluidpage( titlepanel(""basic widgets""), fluidrow( column(3, h3(""buttons""), actionbutton(""action"", label = ""action""), br(), br(), submitbutton(""submit"")), column(3, h3(""single checkbox""), checkboxinput(""checkbox"", label = ""choice a"", value = true)), column(3, checkboxgroupinput(""checkgroup"", label = h3(""checkbox group""), choices = list(""choice 1"" = 1, ""choice 2"" = 2, ""choice 3"" = 3), selected = 1)), column(3, dateinput(""date"", label = h3(""date input""),  goalkicker.com – r notes for professionals  218  value = ""2014-01-01"")) ), fluidrow( column(3, daterangeinput(""dates"", label = h3(""date range""))), column(3, fileinput(""file"", label = h3(""file input""))), column(3, h3(""help text""), helptext(""note: help text isn't a true widget,"", ""but it provides an easy way to add text to"", ""accompany other widgets."")), column(3, numericinput(""num"", label = h3(""numeric input""), value = 1)) ), fluidrow( column(3, radiobuttons(""radio"", label = h3(""radio buttons""), choices = list(""choice 1"" = 1, ""choice 2"" = 2, ""choice 3"" = 3),selected = 1)), column(3, selectinput(""select"", label = h3(""select box""), choices = list(""choice 1"" = 1, ""choice 2"" = 2, ""choice 3"" = 3), selected = 1)), column(3, sliderinput(""slider1"", label = h3(""sliders""), min = 0, max = 100, value = 50), sliderinput(""slider2"", """", min = 0, max = 100, value = c(25, 75)) ), column(3, textinput(""text"", label = h3(""text input""), value = ""enter text..."")) ) )) # create the server function server <- shinyserver(function(input, output){}) # run the app shinyapp(ui = ui, server = server)  goalkicker.com – r notes for professionals  219",t_59bf60f88801,t_59bf60f88801,7
c_c977ba054be8,"chapter 97 of the book on microsoft sql server.chapter 97: delimiting special characters and reserved words section 97.1: basic method the basic method to escape reserved words for sql server is the use of the square brackets ([ and ]). for example, description and name are reserved words; however, if there is an object using both as names, the syntax used is: select [description] from dbo.tablename where [name] = 'foo'  the only special character for sql server is the single quote ' and it is escaped by doubling its usage. for example, to ﬁnd the name o'shea in the same table, the following syntax would be used: select [description] from dbo.tablename where [name] = 'o''shea'  goalkicker.com – microsoft® sql server® notes for professionals  241",t_66676e6f7fd5,t_66676e6f7fd5,8
c_948ebb4159ba,"chapter 12 of the book on microsoft sql server.chapter 12: coalesce section 12.1: using coalesce to build comma-delimited string we can get a comma delimited string from multiple rows using coalesce as shown below. since table variable is used, we need to execute whole query once. so to make easy to understand, i have added begin and end block. begin --table variable declaration to store sample records declare @table table (firstname varchar(256), lastname varchar(256)) --inserting sample records into table variable @table insert into @table (firstname, lastname) values ('john','smith'), ('jane','doe') --creating variable to store result declare @names varchar(4000) --used colesce function, so it will concatenate comma separated firstname into @names varible select @names = coalesce(@names + ',', '') + firstname from @table --now selecting actual result select @names end  section 12.2: getting the ﬁrst not null from a list of column values select coalesce(null, null, 'techonthenet.com', null, 'checkyourmath.com'); result: 'techonthenet.com' select coalesce(null, 'techonthenet.com', 'checkyourmath.com'); result: 'techonthenet.com' select coalesce(null, null, 1, 2, 3, null, 4); result: 1  section 12.3: coalesce basic example coalesce() returns the ﬁrst non null value in a list of arguments. suppose we had a table containing phone  numbers, and cell phone numbers and wanted to return only one for each user. in order to only obtain one, we can get the ﬁrst non null value. declare @table table (userid int, phonenumber varchar(12), cellnumber varchar(12)) insert into @table (userid, phonenumber, cellnumber) values (1,'555-869-1123',null), (2,'555-123-7415','555-846-7786'), (3,null,'555-456-8521')  goalkicker.com – microsoft® sql server® notes for professionals  41  select userid, coalesce(phonenumber, cellnumber) from @table  goalkicker.com – microsoft® sql server® notes for professionals  42",t_66676e6f7fd5,t_66676e6f7fd5,8
c_3a78786db583,"section ""content list"" of the book on microsoft sql server.microsoft sql server microsoft sql server notes for professionals  ®  ®  notes for professionals  200+ pages  of professional hints and tricks  goalkicker.com  free programming books  disclaimer this is an unocial free book created for educational purposes and is not aliated with ocial microsoft® sql server® group(s) or company(s). all trademarks and registered trademarks are the property of their respective owners  contents about ................................................................................................................................................................................... 1 chapter 1: getting started with microsoft sql server .............................................................................. 2 section 1.1: insert / select / update / delete: the basics of data manipulation language ......................... 2 section 1.2: select all rows and columns from a table ............................................................................................ 6 section 1.3: update speciﬁc row ................................................................................................................................ 6 section 1.4: delete all rows ........................................................................................................................................ 7 section 1.5: comments in code .................................................................................................................................... 7 section 1.6: print .......................................................................................................................................................... 8 section 1.7: select rows that match a condition ......................................................................................................... 8 section 1.8: update all rows ....................................................................................................................................... 8 section 1.9: truncate table ..................................................................................................................................... 9 section 1.10: retrieve basic server information ......................................................................................................... 9 section 1.11: create new table and insert records from old table ............................................................................. 9 section 1.12: using transactions to change data safely ......................................................................................... 10 section 1.13: getting table row count ...................................................................................................................... 11  chapter 2: data types ............................................................................................................................................. 12 section 2.1: exact numerics ........................................................................................................................................ 12 section 2.2: approximate numerics .......................................................................................................................... 13 section 2.3: date and time ........................................................................................................................................ 13 section 2.4: character strings .................................................................................................................................... 14 section 2.5: unicode character strings .................................................................................................................... 14 section 2.6: binary strings .......................................................................................................................................... 14 section 2.7: other data types ................................................................................................................................... 14  chapter 3: converting data types ..................................................................................................................... 15 section 3.1: try parse ............................................................................................................................................... 15 section 3.2: try convert ......................................................................................................................................... 15 section 3.3: try cast ................................................................................................................................................. 16 section 3.4: cast .......................................................................................................................................................... 16 section 3.5: convert .................................................................................................................................................... 16  chapter 4: user deﬁned table types ............................................................................................................. 18 section 4.1: creating a udt with a single int column that is also a primary key .................................................. 18 section 4.2: creating a udt with multiple columns ................................................................................................. 18 section 4.3: creating a udt with a unique constraint: ............................................................................................ 18 section 4.4: creating a udt with a primary key and a column with a default value: ......................................... 18  chapter 5: select statement .............................................................................................................................. 19 section 5.1: basic select from table ........................................................................................................................ 19 section 5.2: filter rows using where clause ........................................................................................................... 19 section 5.3: sort results using order by ................................................................................................................. 19 section 5.4: group result using group by ............................................................................................................... 19 section 5.5: filter groups using having clause ....................................................................................................... 20 section 5.6: returning only ﬁrst n rows .................................................................................................................... 20 section 5.7: pagination using offset fetch .......................................................................................................... 20 section 5.8: select without from (no data souce) ............................................................................................... 20  chapter 6: alias names in sql server ............................................................................................................. 21 section 6.1: giving alias after derived table name .................................................................................................. 21 section 6.2: using as ................................................................................................................................................... 21 section 6.3: using = ..................................................................................................................................................... 21  section 6.4: without using as ..................................................................................................................................... 21  chapter 7: nulls ........................................................................................................................................................ 22 section 7.1: coalesce () ............................................................................................................................................ 22 section 7.2: ansi nulls ............................................................................................................................................. 22 section 7.3: isnull() ................................................................................................................................................... 23 section 7.4: is null / is not null .................................................................................................................................... 23 section 7.5: null comparison ................................................................................................................................... 23 section 7.6: null with not in subquery ................................................................................................................. 24  chapter 8: variables ................................................................................................................................................. 26 section 8.1: declare a table variable ........................................................................................................................ 26 section 8.2: updating variables using select ......................................................................................................... 26 section 8.3: declare multiple variables at once, with initial values ........................................................................ 27 section 8.4: updating a variable using set .............................................................................................................. 27 section 8.5: updating variables by selecting from a table ..................................................................................... 28 section 8.6: compound assignment operators ........................................................................................................ 28  chapter 9: dates ......................................................................................................................................................... 29 section 9.1: date & time formatting using convert ............................................................................................ 29 section 9.2: date & time formatting using format ............................................................................................. 30 section 9.3: dateadd for adding and subtracting time periods ........................................................................... 31 section 9.4: create function to calculate a person's age on a speciﬁc date ........................................................ 32 section 9.5: get the current datetime ...................................................................................................................... 32 section 9.6: getting the last day of a month ............................................................................................................ 33 section 9.7: cross platform date object ....................................................................................................... 33 section 9.8: return just date from a datetime ....................................................................................................... 33 section 9.9: datediff for calculating time period dierences ............................................................................. 34 section 9.10: datepart & datename ..................................................................................................................... 34 section 9.11: date parts reference ............................................................................................................................. 35 section 9.12: date format extended ......................................................................................................................... 35  chapter 10: generating a range of dates ...................................................................................................... 39 section 10.1: generating date range with recursive cte ...................................................................................... 39 section 10.2: generating a date range with a tally table .................................................................................... 39  chapter 11: database snapshots ........................................................................................................................ 40 section 11.1: create a database snapshot ................................................................................................................. 40 section 11.2: restore a database snapshot .............................................................................................................. 40 section 11.3: delete snapshot ................................................................................................................................... 40  chapter 12: coalesce .............................................................................................................................................. 41 section 12.1: using coalesce to build comma-delimited string .......................................................................... 41 section 12.2: getting the ﬁrst not null from a list of column values ....................................................................... 41 section 12.3: coalesce basic example ....................................................................................................................... 41  chapter 13: if...else ................................................................................................................................................... 43 section 13.1: single if statement ................................................................................................................................ 43 section 13.2: multiple if statements .......................................................................................................................... 43 section 13.3: single if..else statement ...................................................................................................................... 43 section 13.4: multiple if... else with ﬁnal else statements ..................................................................................... 44 section 13.5: multiple if...else statements ................................................................................................................ 44  chapter 14: case statement ................................................................................................................................ 45 section 14.1: simple case statement ......................................................................................................................... 45 section 14.2: searched case statement ................................................................................................................... 45  chapter 15: insert into ........................................................................................................................................ 46  section 15.1: insert multiple rows of data ............................................................................................................... 46 section 15.2: use output to get the new id ............................................................................................................ 46 section 15.3: insert from select query results ................................................................................................... 47 section 15.4: insert a single row of data ................................................................................................................ 47 section 15.5: insert on speciﬁc columns ................................................................................................................. 47 section 15.6: insert hello world into table ........................................................................................................... 47  chapter 16: merge ..................................................................................................................................................... 48 section 16.1: merge to insert / update / delete ...................................................................................................... 48 section 16.2: merge using cte source ...................................................................................................................... 49 section 16.3: merge example - synchronize source and target table ................................................................. 49 section 16.4: merge using derived source table .................................................................................................... 50 section 16.5: merge using except ............................................................................................................................. 50  chapter 17: create view ....................................................................................................................................... 52 section 17.1: create indexed view ........................................................................................................................... 52 section 17.2: create view ......................................................................................................................................... 52 section 17.3: create view with encryption ............................................................................................................ 53 section 17.4: create view with inner join .......................................................................................................... 53 section 17.5: grouped views ...................................................................................................................................... 53 section 17.6: union-ed views ................................................................................................................................... 54  chapter 18: views ........................................................................................................................................................ 55 section 18.1: create a view with schema binding ..................................................................................................... 55 section 18.2: create a view ......................................................................................................................................... 55 section 18.3: create or replace view .......................................................................................................................... 55  chapter 19: union ...................................................................................................................................................... 56 section 19.1: union and union all ................................................................................................................................ 56  chapter 20: try/catch ......................................................................................................................................... 59 section 20.1: transaction in a try/catch .............................................................................................................. 59 section 20.2: raising errors in try-catch block ........................................................................................................ 59 section 20.3: raising info messages in try catch block .......................................................................................... 60 section 20.4: re-throwing exception generated by raiserror ........................................................................... 60 section 20.5: throwing exception in try/catch blocks ....................................................................................... 60  chapter 21: while loop ............................................................................................................................................ 62 section 21.1: using while loop .................................................................................................................................... 62 section 21.2: while loop with min aggregate function usage ................................................................................. 62  chapter 22: over clause ........................................................................................................................................ 63 section 22.1: cumulative sum .................................................................................................................................... 63 section 22.2: using aggregation functions with over ........................................................................................... 63 section 22.3: dividing data into equally-partitioned buckets using ntile ........................................................... 64 section 22.4: using aggregation funtions to ﬁnd the most recent records .......................................................... 64  chapter 23: group by ............................................................................................................................................. 66 section 23.1: simple grouping .................................................................................................................................... 66 section 23.2: group by multiple columns ............................................................................................................... 66 section 23.3: group by with rollup and cube .................................................................................................... 67 section 23.4: group by with multiple tables, multiple columns .............................................................................. 68 section 23.5: having .................................................................................................................................................. 69  chapter 24: order by ............................................................................................................................................ 71 section 24.1: simple order by clause ...................................................................................................................... 71 section 24.2: order by multiple ﬁelds .................................................................................................................... 71 section 24.3: custom ordering .................................................................................................................................. 71  section 24.4: order by with complex logic ............................................................................................................ 72  chapter 25: the stuff function ........................................................................................................................ 73 section 25.1: using for xml to concatenate values from multiple rows ........................................................... 73 section 25.2: basic character replacement with stuff() ..................................................................................... 73 section 25.3: basic example of stuff() function .................................................................................................... 74 section 25.4: stu for comma separated in sql server ........................................................................................... 74 section 25.5: obtain column names separated with comma (not a list) .............................................................. 74  chapter 26: json in sql server ......................................................................................................................... 76 section 26.1: index on json properties by using computed columns .................................................................. 76 section 26.2: join parent and child json entities using cross apply openjson ........................................... 77 section 26.3: format query results as json with for json .............................................................................. 78 section 26.4: parse json text .................................................................................................................................... 78 section 26.5: format one table row as a single json object using for json .................................................. 78 section 26.6: parse json text using openjson function ..................................................................................... 79  chapter 27: openjson ........................................................................................................................................... 80 section 27.1: transform json array into set of rows ............................................................................................. 80 section 27.2: get key:value pairs from json text ................................................................................................... 80 section 27.3: transform nested json ﬁelds into set of rows ................................................................................ 80 section 27.4: extracting inner json sub-objects ..................................................................................................... 81 section 27.5: working with nested json sub-arrays .............................................................................................. 81  chapter 28: for json ............................................................................................................................................. 83 section 28.1: for json path ................................................................................................................................... 83 section 28.2: for json path with column aliases ................................................................................................ 83 section 28.3: for json clause without array wrapper (single object in output) ............................................... 83 section 28.4: include_null_values .................................................................................................................... 84 section 28.5: wrapping results with root object ................................................................................................... 84 section 28.6: for json auto .................................................................................................................................. 84 section 28.7: creating custom nested json structure ........................................................................................... 85  chapter 29: queries with json data ................................................................................................................ 86 section 29.1: using values from json in query ....................................................................................................... 86 section 29.2: using json values in reports ............................................................................................................. 86 section 29.3: filter-out bad json text from query results ..................................................................................... 86 section 29.4: update value in json column ............................................................................................................ 86 section 29.5: append new value into json array ................................................................................................... 87 section 29.6: join table with inner json collection ............................................................................................... 87 section 29.7: finding rows that contain value in the json array .......................................................................... 87  chapter 30: storing json in sql tables ......................................................................................................... 88 section 30.1: json stored as text column ................................................................................................................ 88 section 30.2: ensure that json is properly formatted using isjson ................................................................... 88 section 30.3: expose values from json text as computed columns .................................................................... 88 section 30.4: adding index on json path ................................................................................................................ 88 section 30.5: json stored in in-memory tables ...................................................................................................... 89  chapter 31: modify json text ............................................................................................................................... 90 section 31.1: modify value in json text on the speciﬁed path ................................................................................ 90 section 31.2: append a scalar value into a json array .......................................................................................... 90 section 31.3: insert new json object in json text ................................................................................................. 90 section 31.4: insert new json array generated with for json query ................................................................ 91 section 31.5: insert single json object generated with for json clause ........................................................... 91  chapter 32: for xml path ................................................................................................................................... 93  section 32.1: using for xml path to concatenate values .................................................................................... 93 section 32.2: specifying namespaces ....................................................................................................................... 93 section 32.3: specifying structure using xpath expressions ................................................................................... 94 section 32.4: hello world xml ................................................................................................................................... 95  chapter 33: join ........................................................................................................................................................... 96 section 33.1: inner join ................................................................................................................................................ 96 section 33.2: outer join .............................................................................................................................................. 97 section 33.3: using join in an update ....................................................................................................................... 99 section 33.4: join on a subquery .............................................................................................................................. 99 section 33.5: cross join ............................................................................................................................................ 100 section 33.6: self join ............................................................................................................................................... 101 section 33.7: accidentally turning an outer join into an inner join ....................................................................... 101 section 33.8: delete using join ................................................................................................................................ 102  chapter 34: cross apply ........................................................................................................................................ 104 section 34.1: join table rows with dynamically generated rows from a cell ...................................................... 104 section 34.2: join table rows with json array stored in cell ............................................................................... 104 section 34.3: filter rows by array values ................................................................................................................ 104  chapter 35: computed columns ....................................................................................................................... 106 section 35.1: a column is computed from an expression ...................................................................................... 106 section 35.2: simple example we normally use in log tables ............................................................................... 106  chapter 36: common table expressions ...................................................................................................... 107 section 36.1: generate a table of dates using cte ................................................................................................ 107 section 36.2: employee hierarchy ........................................................................................................................... 107 section 36.3: recursive cte ..................................................................................................................................... 108 section 36.4: delete duplicate rows using cte ...................................................................................................... 109 section 36.5: cte with multiple as statements ...................................................................................................... 110 section 36.6: find nth highest salary using cte .................................................................................................... 110  chapter 37: move and copy data around tables ..................................................................................... 111 section 37.1: copy data from one table to another ............................................................................................... 111 section 37.2: copy data into a table, creating that table on the ﬂy .................................................................... 111 section 37.3: move data into a table (assuming unique keys method) .............................................................. 111  chapter 38: limit result set ............................................................................................................................... 113 section 38.1: limiting with percent ....................................................................................................................... 113 section 38.2: limiting with fetch ........................................................................................................................... 113 section 38.3: limiting with top ............................................................................................................................... 113  chapter 39: retrieve information about your instance ....................................................................... 114 section 39.1: general information about databases, tables, stored procedures and how to search them ............................................................................................................................................................................. 114 section 39.2: get information on current sessions and query executions .......................................................... 115 section 39.3: information about sql server version ............................................................................................. 116 section 39.4: retrieve edition and version of instance ......................................................................................... 116 section 39.5: retrieve instance uptime in days .................................................................................................... 116 section 39.6: retrieve local and remote servers ................................................................................................. 116  chapter 40: with ties option ............................................................................................................................ 117 section 40.1: test data ............................................................................................................................................. 117  chapter 41: string functions .............................................................................................................................. 119 section 41.1: quotename ........................................................................................................................................... 119 section 41.2: replace ................................................................................................................................................ 119 section 41.3: substring .............................................................................................................................................. 120  section 41.4: string_split ........................................................................................................................................... 120 section 41.5: left ........................................................................................................................................................ 121 section 41.6: right ..................................................................................................................................................... 121 section 41.7: soundex ................................................................................................................................................ 122 section 41.8: format .................................................................................................................................................. 122 section 41.9: string_escape ..................................................................................................................................... 124 section 41.10: ascii .................................................................................................................................................... 124 section 41.11: char ...................................................................................................................................................... 125 section 41.12: concat ................................................................................................................................................. 125 section 41.13: ltrim ................................................................................................................................................... 125 section 41.14: rtrim ................................................................................................................................................... 126 section 41.15: patindex .............................................................................................................................................. 126 section 41.16: space ................................................................................................................................................... 126 section 41.17: dierence ........................................................................................................................................... 127 section 41.18: len ....................................................................................................................................................... 127 section 41.19: lower ................................................................................................................................................... 128 section 41.20: upper ................................................................................................................................................. 128 section 41.21: unicode ............................................................................................................................................... 128 section 41.22: nchar ................................................................................................................................................. 129 section 41.23: str ........................................................................................................................................................ 129 section 41.24: reverse .............................................................................................................................................. 129 section 41.25: replicate ............................................................................................................................................ 129 section 41.26: charindex ........................................................................................................................................... 130  chapter 42: logical functions ........................................................................................................................... 131 section 42.1: choose ............................................................................................................................................... 131 section 42.2: iif .......................................................................................................................................................... 131  chapter 43: aggregate functions ................................................................................................................... 132 section 43.1: sum() .................................................................................................................................................... 132 section 43.2: avg() ................................................................................................................................................... 132 section 43.3: max() ................................................................................................................................................... 133 section 43.4: min() .................................................................................................................................................... 133 section 43.5: count() .............................................................................................................................................. 133 section 43.6: count(column_name) with group by column_name ............................................................. 134  chapter 44: string aggregate functions in sql server ...................................................................... 135 section 44.1: using stuff for string aggregation ................................................................................................. 135 section 44.2: string_agg for string aggregation .................................................................................................. 135  chapter 45: ranking functions ......................................................................................................................... 136 section 45.1: dense_rank () .................................................................................................................................. 136 section 45.2: rank() ................................................................................................................................................. 136  chapter 46: window functions .......................................................................................................................... 137 section 46.1: centered moving average ................................................................................................................. 137 section 46.2: find the single most recent item in a list of timestamped events ................................................ 137 section 46.3: moving average of last 30 items ...................................................................................................... 137  chapter 47: pivot / unpivot .......................................................................................................................... 138 section 47.1: dynamic pivot ................................................................................................................................... 138 section 47.2: simple pivot & unpivot (t-sql) ................................................................................................... 139 section 47.3: simple pivot - static columns ............................................................................................................ 141  chapter 48: dynamic sql pivot ....................................................................................................................... 142 section 48.1: basic dynamic sql pivot ................................................................................................................... 142  chapter 49: partitioning ....................................................................................................................................... 143 section 49.1: retrieve partition boundary values .................................................................................................. 143 section 49.2: switching partitions ............................................................................................................................ 143 section 49.3: retrieve partition table,column, scheme, function, total and min-max boundry values using single query ....................................................................................................................................................... 143  chapter 50: stored procedures ........................................................................................................................ 145 section 50.1: creating and executing a basic stored procedure .......................................................................... 145 section 50.2: stored procedure with if...else and insert into operation ............................................................... 146 section 50.3: dynamic sql in stored procedure ................................................................................................... 147 section 50.4: stored procedure with out parameters ................................................................................. 148 section 50.5: simple looping ................................................................................................................................... 149 section 50.6: simple looping ................................................................................................................................... 150  chapter 51: retrieve information about the database ........................................................................ 151 section 51.1: retrieve a list of all stored procedures ............................................................................................ 151 section 51.2: get the list of all databases on a server ........................................................................................... 151 section 51.3: count the number of tables in a database .................................................................................... 152 section 51.4: database files ..................................................................................................................................... 152 section 51.5: see if enterprise-speciﬁc features are being used .......................................................................... 153 section 51.6: determine a windows login's permission path ............................................................................... 153 section 51.7: search and return all tables and columns containing a speciﬁed column value .................... 153 section 51.8: get all schemas, tables, columns and indexes ................................................................................. 154 section 51.9: return a list of sql agent jobs, with schedule information ........................................................... 155 section 51.10: retrieve tables containing known column ................................................................................... 157 section 51.11: show size of all tables in current database ................................................................................... 158 section 51.12: retrieve database options ............................................................................................................... 158 section 51.13: find every mention of a ﬁeld in the database ................................................................................ 158 section 51.14: retrieve information on backup and restore operations .............................................................. 158  chapter 52: split string function in sql server ....................................................................................... 160 section 52.1: split string in sql server 2008/2012/2014 using xml ...................................................................... 160 section 52.2: split a string in sql server 2016 ......................................................................................................... 160 section 52.3: t-sql table variable and xml ......................................................................................................... 161  chapter 53: insert ..................................................................................................................................................... 162 section 53.1: add a row to a table named invoices ............................................................................................... 162  chapter 54: primary keys ................................................................................................................................... 163 section 54.1: create table w/ identity column as primary key ............................................................................. 163 section 54.2: create table w/ guid primary key .................................................................................................. 163 section 54.3: create table w/ natural key .............................................................................................................. 163 section 54.4: create table w/ composite key ........................................................................................................ 163 section 54.5: add primary key to existing table .................................................................................................... 163 section 54.6: delete primary key ............................................................................................................................. 164  chapter 55: foreign keys ..................................................................................................................................... 165 section 55.1: foreign key relationship/constraint .................................................................................................. 165 section 55.2: maintaining relationship between parent/child rows ..................................................................... 165 section 55.3: adding foreign key relationship on existing table .......................................................................... 166 section 55.4: add foreign key on existing table ..................................................................................................... 166 section 55.5: getting information about foreign key constraints ........................................................................ 166  chapter 56: last inserted identity ................................................................................................................... 167 section 56.1: @@identity and max(id) ................................................................................................................ 167 section 56.2: scope_identity() ............................................................................................................................ 167  section 56.3: @@identity ...................................................................................................................................... 167 section 56.4: ident_current('tablename') ........................................................................................................ 168  chapter 57: scope_identity() ........................................................................................................................ 169 section 57.1: introduction with simple example ..................................................................................................... 169  chapter 58: sequences .......................................................................................................................................... 170 section 58.1: create sequence ................................................................................................................................. 170 section 58.2: use sequence in table ...................................................................................................................... 170 section 58.3: insert into table with sequence ........................................................................................................ 170 section 58.4: delete from & insert new ................................................................................................................. 170  chapter 59: index ...................................................................................................................................................... 171 section 59.1: create clustered index ....................................................................................................................... 171 section 59.2: drop index ........................................................................................................................................... 171 section 59.3: create non-clustered index .............................................................................................................. 171 section 59.4: show index info ................................................................................................................................... 171 section 59.5: returns size and fragmentation indexes ......................................................................................... 171 section 59.6: reorganize and rebuild index ........................................................................................................... 172 section 59.7: rebuild or reorganize all indexes on a table ................................................................................... 172 section 59.8: rebuild all index database ................................................................................................................ 172 section 59.9: index on view ...................................................................................................................................... 172 section 59.10: index investigations .......................................................................................................................... 173  chapter 60: full-text indexing ........................................................................................................................... 174 section 60.1: a. creating a unique index, a full-text catalog, and a full-text index ............................................. 174 section 60.2: creating a full-text index on several table columns ....................................................................... 174 section 60.3: creating a full-text index with a search property list without populating it ................................. 174 section 60.4: full-text search .................................................................................................................................. 175  chapter 61: trigger .................................................................................................................................................. 176 section 61.1: dml triggers ........................................................................................................................................ 176 section 61.2: types and classiﬁcations of trigger ................................................................................................. 177  chapter 62: cursors ................................................................................................................................................. 178 section 62.1: basic forward only cursor ................................................................................................................ 178 section 62.2: rudimentary cursor syntax ............................................................................................................... 178  chapter 63: transaction isolation levels ...................................................................................................... 180 section 63.1: read committed ................................................................................................................................. 180 section 63.2: what are ""dirty reads""? ..................................................................................................................... 180 section 63.3: read uncommitted ............................................................................................................................ 181 section 63.4: repeatable read ................................................................................................................................ 181 section 63.5: snapshot .............................................................................................................................................. 181 section 63.6: serializable .......................................................................................................................................... 181  chapter 64: advanced options .......................................................................................................................... 183 section 64.1: enable and show advanced options ................................................................................................. 183 section 64.2: enable backup compression default ................................................................................................ 183 section 64.3: enable cmd permission ...................................................................................................................... 183 section 64.4: set default ﬁll factor percent ............................................................................................................ 183 section 64.5: set system recovery interval ............................................................................................................ 183 section 64.6: set max server memory size ............................................................................................................. 183 section 64.7: set number of checkpoint tasks ....................................................................................................... 183  chapter 65: migration ............................................................................................................................................ 184 section 65.1: how to generate migration scripts ................................................................................................... 184  chapter 66: table valued parameters .......................................................................................................... 186  section 66.1: using a table valued parameter to insert multiple rows to a table ............................................... 186  chapter 67: dbmail ................................................................................................................................................. 187 section 67.1: send simple email ............................................................................................................................... 187 section 67.2: send results of a query ...................................................................................................................... 187 section 67.3: send html email ................................................................................................................................ 187  chapter 68: in-memory oltp (hekaton) ...................................................................................................... 188 section 68.1: declare memory-optimized table variables ................................................................................... 188 section 68.2: create memory optimized table ..................................................................................................... 188 section 68.3: show created .dll ﬁles and tables for memory optimized tables ................................................. 189 section 68.4: create memory optimized system-versioned temporal table ................................................... 190 section 68.5: memory-optimized table types and temp tables ........................................................................ 190  chapter 69: temporal tables ............................................................................................................................ 192 section 69.1: create temporal tables .................................................................................................................. 192 section 69.2: for system_time all ..................................................................................................................... 192 section 69.3: creating a memory-optimized system-versioned temporal table and cleaning up the sql server history table ........................................................................................................................................... 192 section 69.4: for system_time between <start_date_time> and <end_date_time> ............................... 194 section 69.5: for system_time from <start_date_time> to <end_date_time> ......................................... 194 section 69.6: for system_time contained in (<start_date_time> , <end_date_time>) ........................... 194 section 69.7: how do i query temporal data? ........................................................................................................ 194 section 69.8: return actual value speciﬁed point in time(for system_time as of <date_time>) .............. 195  chapter 70: use of temp table ........................................................................................................................ 196 section 70.1: dropping temp tables ......................................................................................................................... 196 section 70.2: local temp table .............................................................................................................................. 196 section 70.3: global temp table ............................................................................................................................. 196  chapter 71: scheduled task or job ................................................................................................................. 198 section 71.1: create a scheduled job ...................................................................................................................... 198  chapter 72: isolation levels and locking ....................................................................................................... 200 section 72.1: examples of setting the isolation level .............................................................................................. 200  chapter 73: sorting/ordering rows ................................................................................................................. 201 section 73.1: basics .................................................................................................................................................... 201 section 73.2: order by case ..................................................................................................................................... 203  chapter 74: privileges or permissions ........................................................................................................... 205 section 74.1: simple rules .......................................................................................................................................... 205  chapter 75: sqlcmd ............................................................................................................................................... 206 section 75.1: sqlcmd.exe called from a batch ﬁle or command line ................................................................. 206  chapter 76: resource governor ....................................................................................................................... 207 section 76.1: reading the statistics ......................................................................................................................... 207  chapter 77: file group ........................................................................................................................................... 208 section 77.1: create ﬁlegroup in database ............................................................................................................. 208  chapter 78: basic ddl operations in ms sql server ............................................................................ 210 section 78.1: getting started ..................................................................................................................................... 210  chapter 79: subqueries ......................................................................................................................................... 212 section 79.1: subqueries ............................................................................................................................................ 212  chapter 80: pagination ......................................................................................................................................... 214 section 80.1: pagination with offset fetch ........................................................................................................ 214 section 80.2: paginaton with inner query ............................................................................................................... 214 section 80.3: paging in various versions of sql server ....................................................................................... 214  section 80.4: sql server 2012/2014 using order by offset and fetch next ............................................. 215 section 80.5: pagination using row_number with a common table expression .......................................... 215  chapter 81: clustered columnstore ...................................................................................................... 217 section 81.1: adding clustered columnstore index on existing table .................................................................... 217 section 81.2: rebuild clustered columnstore index .................................................................................... 217 section 81.3: table with clustered columnstore index ................................................................................ 217  chapter 82: parsename ......................................................................................................................................... 218 section 82.1: parsename ......................................................................................................................................... 218  chapter 83: installing sql server on windows ......................................................................................... 219 section 83.1: introduction .......................................................................................................................................... 219  chapter 84: analyzing a query ......................................................................................................................... 220 section 84.1: scan vs seek ........................................................................................................................................ 220  chapter 85: query hints ....................................................................................................................................... 221 section 85.1: join hints ............................................................................................................................................ 221 section 85.2: group by hints ................................................................................................................................. 221 section 85.3: fast rows hint .................................................................................................................................... 222 section 85.4: union hints ........................................................................................................................................ 222 section 85.5: maxdop option ................................................................................................................................. 222 section 85.6: index hints ......................................................................................................................................... 222  chapter 86: query store ....................................................................................................................................... 224 section 86.1: enable query store on database ....................................................................................................... 224 section 86.2: get execution statistics for sql queries/plans ............................................................................... 224 section 86.3: remove data from query store ........................................................................................................ 224 section 86.4: forcing plan for query ....................................................................................................................... 224  chapter 87: querying results by page .......................................................................................................... 226 section 87.1: row_number() .................................................................................................................................... 226  chapter 88: schemas ............................................................................................................................................. 227 section 88.1: purpose ................................................................................................................................................ 227 section 88.2: creating a schema ............................................................................................................................ 227 section 88.3: alter schema ....................................................................................................................................... 227 section 88.4: dropping schemas ............................................................................................................................. 227  chapter 89: backup and restore database ............................................................................................... 228 section 89.1: basic backup to disk with no options ............................................................................................... 228 section 89.2: basic restore from disk with no options ......................................................................................... 228 section 89.3: restore database with replace .................................................................................................. 228  chapter 90: transaction handling ................................................................................................................... 229 section 90.1: basic transaction skeleton with error handling ............................................................................... 229  chapter 91: natively compiled modules (hekaton) ................................................................................ 230 section 91.1: natively compiled stored procedure ................................................................................................. 230 section 91.2: natively compiled scalar function ..................................................................................................... 230 section 91.3: native inline table value function ...................................................................................................... 231  chapter 92: spatial data ...................................................................................................................................... 233 section 92.1: point ................................................................................................................................................... 233  chapter 93: dynamic sql ..................................................................................................................................... 234 section 93.1: execute sql statement provided as string ...................................................................................... 234 section 93.2: dynamic sql executed as dierent user ........................................................................................ 234 section 93.3: sql injection with dynamic sql ....................................................................................................... 234 section 93.4: dynamic sql with parameters ......................................................................................................... 235  chapter 94: dynamic data masking ............................................................................................................... 236 section 94.1: adding default mask on the column ................................................................................................. 236 section 94.2: mask email address using dynamic data masking ........................................................................ 236 section 94.3: add partial mask on column ............................................................................................................. 236 section 94.4: showing random value from the range using random() mask .................................................... 236 section 94.5: controlling who can see unmasked data ........................................................................................ 237  chapter 95: export data in txt ﬁle by using sqlcmd ............................................................................ 238 section 95.1: by using sqlcmd on command prompt ......................................................................................... 238  chapter 96: common language runtime integration .......................................................................... 239 section 96.1: enable clr on database .................................................................................................................... 239 section 96.2: adding .dll that contains sql clr modules ...................................................................................... 239 section 96.3: create clr function in sql server .................................................................................................. 239 section 96.4: create clr user-deﬁned type in sql server .................................................................................. 240 section 96.5: create clr procedure in sql server ............................................................................................... 240  chapter 97: delimiting special characters and reserved words ...................................................... 241 section 97.1: basic method ....................................................................................................................................... 241  chapter 98: dbcc ..................................................................................................................................................... 242 section 98.1: dbcc statement .................................................................................................................................. 242 section 98.2: dbcc maintenance commands ....................................................................................................... 242 section 98.3: dbcc validation statements ............................................................................................................. 243 section 98.4: dbcc informational statements ....................................................................................................... 243 section 98.5: dbcc trace commands .................................................................................................................... 243  chapter 99: bulk import ...................................................................................................................................... 245 section 99.1: bulk insert ....................................................................................................................................... 245 section 99.2: bulk insert with options ................................................................................................................ 245 section 99.3: reading entire content of ﬁle using openrowset(bulk) .......................................................... 245 section 99.4: read ﬁle using openrowset(bulk) and format ﬁle .................................................................. 245 section 99.5: read json ﬁle using openrowset(bulk) ..................................................................................... 246  chapter 100: service broker ............................................................................................................................... 247 section 100.1: basics .................................................................................................................................................. 247 section 100.2: enable service broker on database ................................................................................................ 247 section 100.3: create basic service broker construction on database (single database communication) ............................................................................................................................................................................. 247 section 100.4: how to send basic communication through service broker ........................................................ 248 section 100.5: how to receive conversation from targetqueue automatically ................................................. 248  chapter 101: permissions and security .......................................................................................................... 250 section 101.1: assign object permissions to a user ................................................................................................ 250  chapter 102: database permissions ............................................................................................................... 251 section 102.1: changing permissions ....................................................................................................................... 251 section 102.2: create user .................................................................................................................................... 251 section 102.3: create role .................................................................................................................................... 251 section 102.4: changing role membership ............................................................................................................. 251  chapter 103: row-level security ........................................................................................................................ 252 section 103.1: rls ﬁlter predicate ............................................................................................................................ 252 section 103.2: altering rls security policy ............................................................................................................. 252 section 103.3: preventing updated using rls block predicate ............................................................................. 253  chapter 104: encryption ....................................................................................................................................... 254 section 104.1: encryption by certiﬁcate ................................................................................................................... 254 section 104.2: encryption of database .................................................................................................................... 254  section 104.3: encryption by symmetric key .......................................................................................................... 254 section 104.4: encryption by passphrase ............................................................................................................... 255  chapter 105: phantom read .............................................................................................................................. 256 section 105.1: isolation level read uncommitted .............................................................................................. 256  chapter 106: filestream ........................................................................................................................................ 257 section 106.1: example .............................................................................................................................................. 257  chapter 107: bcp (bulk copy program) utility ........................................................................................... 258 section 107.1: example to import data without a format file(using native format ) ....................................... 258  chapter 108: sql server evolution through dierent versions (2000 - 2016) .......................... 259 section 108.1: sql server version 2000 - 2016 ....................................................................................................... 259  chapter 109: sql server management studio (ssms) .......................................................................... 262 section 109.1: refreshing the intellisense cache .................................................................................................... 262  chapter 110: managing azure sql database ............................................................................................. 263 section 110.1: find service tier information for azure sql database ................................................................... 263 section 110.2: change service tier of azure sql database .................................................................................. 263 section 110.3: replication of azure sql database ................................................................................................ 263 section 110.4: create azure sql database in elastic pool .................................................................................... 264  chapter 111: system database - tempdb .................................................................................................... 265 section 111.1: identify tempdb usage ...................................................................................................................... 265 section 111.2: tempdb database details ................................................................................................................. 265  appendix a: microsoft sql server management studio shortcut keys ...................................... 266 section a.1: shortcut examples ................................................................................................................................ 266 section a.2: menu activation keyboard shortcuts ................................................................................................ 266 section a.3: custom keyboard shortcuts ............................................................................................................... 266  credits ............................................................................................................................................................................ 269 you may also like ...................................................................................................................................................... 273",t_66676e6f7fd5,t_66676e6f7fd5,8
c_3c161bb4552c,"chapter 53 of the book on microsoft sql server.chapter 53: insert section 53.1: add a row to a table named invoices insert into invoices [ /* column names may go here */ ] values (123, '1234abc', '2016-08-05 20:18:25.770', 321, 5, '2016-08-04');  column names are required if the table you are inserting into contains a column with the identity attribute. insert into invoices ([id], [num], [datetime], [total], [term], [duedate]) values (123, '1234abc', '2016-08-05 20:18:25.770', 321, 5, '2016-08-25');  goalkicker.com – microsoft® sql server® notes for professionals  162",t_66676e6f7fd5,t_66676e6f7fd5,8
c_c6dc592c9e01,"chapter 82 of the book on microsoft sql server.chapter 82: parsename 'object_name' is the name of the object for which to retrieve the speciﬁed object part. object_name is sysname. this parameter is an optionally-qualiﬁed object name. if all parts of the object name are qualiﬁed, this name can have four parts: the server name, the database name, the owner name, and the object name.  object_piece is the object part to return. object_piece is of type int, and can have these values:1 = object name 2 = schema name 3 = database name 4 = server name  section 82.1: parsename declare @objectname nvarchar(1000) set @objectname = 'headofficesql1.northwind.dbo.authors' select parsename(@objectname, ,parsename(@objectname, ,parsename(@objectname, ,parsename(@objectname,  4) 3) 2) 1)  as as as as  server db owner object  returns: server db headoﬃcesql1 northwind owner object dbo authors  goalkicker.com – microsoft® sql server® notes for professionals  218",t_66676e6f7fd5,t_66676e6f7fd5,8
c_d067e64421e5,"chapter 105 of the book on microsoft sql server.chapter 105: phantom read in database systems, isolation determines how transaction integrity is visible to other users and systems, so it deﬁnes how/when the changes made by one operation become visible to other. the phantom read may occurs when you getting data not yet commited to database.  section 105.1: isolation level read uncommitted create a sample table on a sample database create table [dbo].[table_1]( [id] [int] identity(1,1) not null, [title] [varchar](50) null, constraint [pk_table_1] primary key clustered ( [id] asc )with (pad_index = off, statistics_norecompute = off, ignore_dup_key = off, allow_row_locks = on, allow_page_locks = on) on [primary] ) on [primary]  now open a first query editor (on the database) insert the code below, and execute (do not touch the --rollback) in this case you insert a row on db but do not commit changes. begin tran insert into table_1 values('title 1') select * from [test].[dbo].[table_1] --rollback  now open a second query editor (on the database), insert the code below and execute begin tran set transaction isolation level read uncommitted select * from [test].[dbo].[table_1]  you may notice that on second editor you can see the newly created row (but not committed) from ﬁrst transaction. on ﬁrst editor execute the rollback (select the rollback word and execute). -- rollback the first transaction rollback  execute the query on second editor and you see that the record disappear (phantom read), this occurs because you tell, to the 2nd transaction to get all rows, also the uncommitteds. this occurs when you change the isolation level with set transaction isolation level read uncommitted  goalkicker.com – microsoft® sql server® notes for professionals  256",t_66676e6f7fd5,t_66676e6f7fd5,8
c_a2122a57ab58,"chapter 118 of the book on c#.chapter 118: making a variable thread safe section 118.1: controlling access to a variable in a parallel.for loop using system; using system.threading; using system.threading.tasks; class program { static void main( string[] args ) { object sync = new object(); int sum = 0; parallel.for( 1, 1000, ( i ) => { lock( sync ) sum = sum + i; // lock is necessary // as a practical matter, ensure this `parallel for` executes // on multiple threads by simulating a lengthy operation. thread.sleep( 1 ); } ); console.writeline( ""correct answer should be 499500. sum is: {0}"", sum ); } }  it is not suﬃcient to just do sum = sum + i without the lock because the read-modify-write operation is not atomic. a thread will overwrite any external modiﬁcations to sum that occur after it has read the current value of sum, but before it stores the modiﬁed value of sum + i back into sum.  goalkicker.com – c# notes for professionals  598",t_689e6562417a,t_689e6562417a,9
c_3986e69c6199,"chapter 26 of the book on c#.chapter 26: collection initializers section 26.1: collection initializers initialize a collection type with values: var stringlist = new list<string> { ""foo"", ""bar"", };  collection initializers are syntactic sugar for add() calls. above code is equivalent to: var temp = new list<string>(); temp.add(""foo""); temp.add(""bar""); var stringlist = temp;  note that the intialization is done atomically using a temporary variable, to avoid race conditions. for types that oﬀer multiple parameters in their add() method, enclose the comma-separated arguments in curly braces: var numberdictionary = new dictionary<int, string> { { 1, ""one"" }, { 2, ""two"" }, };  this is equivalent to: var temp = new dictionary<int, string>(); temp.add(1, ""one""); temp.add(2, ""two""); var numberdictionarynumberdictionary = temp;  section 26.2: c# 6 index initializers starting with c# 6, collections with indexers can be initialized by specifying the index to assign in square brackets, followed by an equals sign, followed by the value to assign. dictionary initialization an example of this syntax using a dictionary: var dict = new dictionary<string, int> { [""key1""] = 1, [""key2""] = 50 };  this is equivalent to: var dict = new dictionary<string, int>();  goalkicker.com – c# notes for professionals  111  dict[""key1""] = 1; dict[""key2""] = 50  the collection initializer syntax to do this before c# 6 was: var dict = new dictionary<string, int> { { ""key1"", 1 }, { ""key2"", 50 } };  which would correspond to: var dict = new dictionary<string, int>(); dict.add(""key1"", 1); dict.add(""key2"", 50);  so there is a signiﬁcant diﬀerence in functionality, as the new syntax uses the indexer of the initialized object to assign values instead of using its add() method. this means the new syntax only requires a publicly available indexer, and works for any object that has one. public class indexableclass { public int this[int index] { set { console.writeline(""{0} was assigned to index {1}"", value, index); } } } var foo = new indexableclass { [0] = 10, [1] = 20 }  this would output: 10 was assigned to index 0 20 was assigned to index 1  section 26.3: collection initializers in custom classes to make a class support collection initializers, it must implement ienumerable interface and have at least one add method. since c# 6, any collection implementing ienumerable can be extended with custom add methods using extension methods. class program { static void main() { var col = new mycollection { ""foo"", { ""bar"", 3 },  goalkicker.com – c# notes for professionals  112  ""baz"", 123.45d, }; } } class mycollection : ienumerable { private ilist list = new arraylist(); public void add(string item) { list.add(item) } public void add(string item, int count) { for(int i=0;i< count;i++) { list.add(item); } } public ienumerator getenumerator() { return list.getenumerator(); } } static class mycollectionextensions { public static void add(this mycollection @this, double value) => @this.add(value.tostring()); }  section 26.4: using collection initializer inside object initializer public class tag { public ilist<string> synonyms { get; set; } } synonyms is a collection-type property. when the tag object is created using object initializer syntax, synonyms can  also be initialized with collection initializer syntax: tag t = new tag { synonyms = new list<string> {""c#"", ""c-sharp""} };  the collection property can be readonly and still support collection initializer syntax. consider this modiﬁed example (synonyms property now has a private setter): public class tag { public tag() { synonyms = new list<string>(); }  goalkicker.com – c# notes for professionals  113  public ilist<string> synonyms { get; private set; } }  a new tag object can be created like this: tag t = new tag { synonyms = {""c#"", ""c-sharp""} };  this works because collection initializers are just syntatic sugar over calls to add(). there's no new list being created here, the compiler is just generating calls to add() on the exiting object.  section 26.5: collection initializers with parameter arrays you can mix normal parameters and parameter arrays: public class lotteryticket : ienumerable{ public int[] luckynumbers; public string username; public void add(string username, params int[] luckynumbers){ username = username; lottery = luckynumbers; } }  this syntax is now possible: var tickets = new {""mr cool"" , {""bruce"" , {""john cena"", }  list<lotteryticket>{ 35663, 35732, 12312, 75685}, 26874, 66677, 24546, 36483, 46768, 24632, 24527}, 25446, 83356, 65536, 23783, 24567, 89337}  goalkicker.com – c# notes for professionals  114",t_689e6562417a,t_689e6562417a,9
c_c982c1057350,"chapter 12 of the book on c#.chapter 12: string.format parameter details format a composite format string, which deﬁnes the way args should be combined into a string. args  a sequence of objects to be combined into a string. since this uses a params argument, you can either use a comma-separated list of arguments or an actual object array.  provider  a collection of ways of formatting objects to strings. typical values include cultureinfo.invariantculture and cultureinfo.currentculture.  the format methods are a set of overloads in the system.string class used to create strings that combine objects into speciﬁc string representations. this information can be applied to string.format, various writeline methods as well as other methods in the .net framework.  section 12.1: since c# 6.0 version ≥ 6.0  since c# 6.0 it is possible to use string interpolation in place of string.format. string name = ""john""; string lastname = ""doe""; console.writeline($""hello {name} {lastname}!"");  hello john doe! more examples for this under the topic c# 6.0 features: string interpolation.  section 12.2: places where string.format is 'embedded' in the framework there are several places where you can use string.format indirectly: the secret is to look for the overload with the signature string format, params object[] args, e.g.: console.writeline(string.format(""{0} - {1}"", name, value));  can be replaced with shorter version: console.writeline(""{0} - {1}"", name, value);  there are other methods which also use string.formate.g.: debug.writeline(); // and print() stringbuilder.appendformat();  section 12.3: create a custom format provider public class customformat : iformatprovider, icustomformatter { public string format(string format, object arg, iformatprovider formatprovider) { if (!this.equals(formatprovider))  goalkicker.com – c# notes for professionals  62  { return null; } if (format == ""reverse"") { return string.join("""", arg.tostring().reverse()); } return arg.tostring(); } public object getformat(type formattype) { return formattype==typeof(icustomformatter) ? this:null; } }  usage: string.format(new customformat(), ""-> {0:reverse} <-"", ""hello world"");  output: -> dlrow olleh <-  section 12.4: date formatting datetime date = new datetime(2016, 07, 06, 18, 30, 14); // format: year, month, day hours, minutes, seconds console.write(string.format(""{0:dd}"",date)); //format by culture info string.format(new system.globalization.cultureinfo(""mn-mn""),""{0:dddd}"",date); version ≥ 6.0  console.write($""{date:ddd}"");  output : 06 лхагва 06  speciﬁer d date  meaning  sample  result  {0:d}  7/6/2016 06  dd  day, zero-padded  {0:dd}  ddd  short day name  {0:ddd} wed  dddd  full day name  {0:dddd} wednesday  d  long date  {0:d}  wednesday, july 6, 2016  f  full date and time, short  {0:f}  wednesday, july 6, 2016 6:30 pm  ﬀ  second fractions, 2 digits  {0:ff}  20  ﬀf  second fractions, 3 digits  {0:fff} 201  ﬀﬀ  second fractions, 4 digits  {0:ffff} 2016  f  full date and time, long  {0:f}  goalkicker.com – c# notes for professionals  wednesday, july 6, 2016 6:30:14 pm 63  g  default date and time  {0:g}  7/6/2016 6:30 pm  gg  era  {0:gg}  a.d  hh  hour (2 digits, 12h)  {0:hh}  06  hh  hour (2 digits, 24h)  {0:hh}  18  m  month and day  {0:m}  july 6  mm  minutes, zero-padded  {0:mm}  30  mm  month, zero-padded  {0:mm}  07  mmm  3-letter month name  {0:mmm} jul  mmmm full month name  {0:mmmm} july  ss  seconds  {0:ss}  14  r  rfc1123 date  {0:r}  wed, 06 jul 2016 18:30:14 gmt  s  sortable date string  {0:s}  2016-07-06t18:30:14  t  short time  {0:t}  6:30 pm  t  long time  {0:t}  6:30:14 pm  tt  am/pm  {0:tt}  pm  u  universal sortable local time {0:u}  2016-07-06 18:30:14z  u  universal gmt  {0:u}  wednesday, july 6, 2016 9:30:14 am  y  month and year  {0:y}  july 2016  yy  2 digit year  {0:yy}  16  yyyy  4 digit year  {0:yyyy} 2016  zz  2 digit timezone oﬀset  {0:zz}  zzz  full time zone oﬀset  {0:zzz} +09:00  +09  section 12.5: currency formatting the ""c"" (or currency) format speciﬁer converts a number to a string that represents a currency amount. string.format(""{0:c}"", 112.236677) // $112.23 - defaults to system  precision default is 2. use c1, c2, c3 and so on to control precision. string.format(""{0:c1}"", string.format(""{0:c3}"", string.format(""{0:c4}"", string.format(""{0:c9}"",  112.236677) 112.236677) 112.236677) 112.236677)  //$112.2 //$112.237 //$112.2367 //$112.236677000  currency symbol 1. pass cultureinfo instance to use custom culture symbol. string.format(new cultureinfo(""en-us""), ""{0:c}"", 112.236677); //$112.24 string.format(new cultureinfo(""de-de""), ""{0:c}"", 112.236677); //112,24 € string.format(new cultureinfo(""hi-in""), ""{0:c}"", 112.236677); //  112.24  2. use any string as currency symbol. use numberformatinfo as to customize currency symbol. numberformatinfo nfi = new cultureinfo( ""en-us"", false ).numberformat; nfi = (numberformatinfo) nfi.clone(); nfi.currencysymbol = ""?"";  goalkicker.com – c# notes for professionals  64  string.format(nfi, ""{0:c}"", 112.236677); //?112.24 nfi.currencysymbol = ""?%^&""; string.format(nfi, ""{0:c}"", 112.236677); //?%^&112.24  position of currency symbol use currencypositivepattern for positive values and currencynegativepattern for negative values. numberformatinfo nfi = new cultureinfo( ""en-us"", false ).numberformat; nfi.currencypositivepattern = 0; string.format(nfi, ""{0:c}"", 112.236677); //$112.24 - default nfi.currencypositivepattern = 1; string.format(nfi, ""{0:c}"", 112.236677); //112.24$ nfi.currencypositivepattern = 2; string.format(nfi, ""{0:c}"", 112.236677); //$ 112.24 nfi.currencypositivepattern = 3; string.format(nfi, ""{0:c}"", 112.236677); //112.24 $  negative pattern usage is the same as positive pattern. a lot more use cases please refer to original link. custom decimal separator numberformatinfo nfi = new cultureinfo( ""en-us"", false ).numberformat; nfi.currencypositivepattern = 0; nfi.currencydecimalseparator = ""..""; string.format(nfi, ""{0:c}"", 112.236677); //$112..24  section 12.6: using custom number format numberformatinfo can be used for formatting both integer and ﬂoat numbers. // invariantresult is ""1,234,567.89"" var invarianresult = string.format(cultureinfo.invariantculture, ""{0:#,###,##}"", 1234567.89); // numberformatinfo is one of classes that implement iformatprovider var customprovider = new numberformatinfo { numberdecimalseparator = ""_ns_"", // will be used instead of ',' numbergroupseparator = ""_gs_"", // will be used instead of '.' }; // customresult is ""1_gs_234_gs_567_ns_89"" var customresult = string.format(customprovider, ""{0:#,###.##}"", 1234567.89);  section 12.7: align left/ right, pad with spaces the second value in the curly braces dictates the length of the replacement string. by adjusting the second value to be positive or negative, the alignment of the string can be changed. string.format(""left: string: ->{0,-5}<- int: ->{1,-5}<-"", ""abc"", 123); string.format(""right: string: ->{0,5}<- int: ->{1,5}<-"", ""abc"", 123);  output: left: string: ->abc <- int: ->123 <right: string: -> abc<- int: -> 123<-  goalkicker.com – c# notes for professionals  65  section 12.8: numeric formats // integral types as hex string.format(""hexadecimal: byte2: {0:x2}; byte4: {0:x4}; char: {1:x2}"", 123, (int)'a'); // integers with thousand separators string.format(""integer, thousand sep.: {0:#,#}; fixed length: >{0,10:#,#}<"", 1234567); // integer with leading zeroes string.format(""integer, leading zeroes: {0:00}; "", 1); // decimals string.format(""decimal, fixed precision: {0:0.000}; as percents: {0:0.00%}"", 0.12);  output: hexadecimal: byte2: 7b; byte4: 007b; char: 41 integer, thousand sep.: 1,234,567; fixed length: > 1,234,567< integer, leading zeroes: 01; decimal, fixed precision: 0.120; as percents: 12.00%  section 12.9: tostring() the tostring() method is present on all reference object types. this is due to all reference types being derived from object which has the tostring() method on it. the tostring() method on the object base class returns the type name. the fragment below will print out ""user"" to the console. public class user { public string name { get; set; } public int id { get; set; } } ... var user = new user {name = ""user1"", id = 5}; console.writeline(user.tostring());  however, the class user can also override tostring() in order to alter the string it returns. the code fragment below prints out ""id: 5, name: user1"" to the console. public class user { public string name { get; set; } public int id { get; set; } public override tostring() { return string.format(""id: {0}, name: {1}"", id, name); } } ... var user = new user {name = ""user1"", id = 5}; console.writeline(user.tostring());  goalkicker.com – c# notes for professionals  66  section 12.10: escaping curly brackets inside a string.format() expression string outsidetext = ""i am outside of bracket""; string.format(""{{i am in brackets!}} {0}"", outsidetext); //outputs ""{i am in brackets!} i am outside of bracket""  section 12.11: relationship with tostring() while the string.format() method is certainly useful in formatting data as strings, it may often be a bit overkill, especially when dealing with a single object as seen below : string.format(""{0:c}"", money);  // yields ""$42.00""  an easier approach might be to simply use the tostring() method available on all objects within c#. it supports all of the same standard and custom formatting strings, but doesn't require the necessary parameter mapping as there will only be a single argument : money.tostring(""c"");  // yields ""$42.00""  caveats & formatting restrictions while this approach may be simpler in some scenarios, the tostring() approach is limited with regards to adding left or right padding like you might do within the string.format() method : string.format(""{0,10:c}"", money);  // yields ""  $42.00""  in order to accomplish this same behavior with the tostring() method, you would need to use another method like padleft() or padright() respectively : money.tostring(""c"").padleft(10);  // yields ""  goalkicker.com – c# notes for professionals  $42.00""  67",t_689e6562417a,t_689e6562417a,9
c_cff8214e4e76,"chapter 119 of the book on c#.chapter 119: lock statement section 119.1: throwing exception in a lock statement following code will release the lock. there will be no problem. behind the scenes lock statement works as try finally lock(locker) { throw new exception(); }  more can be seen in the c# 5.0 speciﬁcation: a lock statement of the form lock (x) ...  where x is an expression of a reference-type, is precisely equivalent to bool __lockwastaken = false; try { system.threading.monitor.enter(x, ref __lockwastaken); ... } finally { if (__lockwastaken) system.threading.monitor.exit(x); }  except that x is only evaluated once.  section 119.2: simple usage common usage of lock is a critical section. in the following example reserveroom is supposed to be called from diﬀerent threads. synchronization with lock is the simplest way to prevent race condition here. method body is surrounded with lock which ensures that two or more threads cannot execute it simultaneously. public class hotel { private readonly object _roomlock = new object(); public void reserveroom(int roomnumber) { // lock keyword ensures that only one thread executes critical section at once // in this case, reserves a hotel room of given number // preventing double bookings lock (_roomlock) { // reserve room logic goes here } } }  if a thread reaches lock-ed block while another thread is running within it, the former will wait another to exit the goalkicker.com – c# notes for professionals  599  block. best practice is to deﬁne a private object to lock on, or a private static object variable to protect data common to all instances.  section 119.3: return in a lock statement following code will release lock. lock(locker) { return 5; }  for a detailed explanation, this so answer is recommended.  section 119.4: anti-patterns and gotchas locking on an stack-allocated / local variable one of the fallacies while using lock is the usage of local objects as locker in a function. since these local object instances will diﬀer on each call of the function, lock will not perform as expected. list<string> stringlist = new list<string>(); public void addtolistnotthreadsafe(string something) { // do not do this, as each call to this method // will lock on a different instance of an object. // this provides no thread safety, it only degrades performance. var locallock = new object(); lock(locallock) { stringlist.add(something); } } // define object that can be used for thread safety in the addtolist method readonly object classlock = new object(); public void addtolist(list<string> stringlist, string something) { // use the classlock instance field to achieve a // thread-safe lock before adding to stringlist lock(classlock) { stringlist.add(something); } }  assuming that locking restricts access to the synchronizing object itself if one thread calls: lock(obj) and another thread calls obj.tostring() second thread is not going to be blocked. object obj = new object(); public void somemethod()  goalkicker.com – c# notes for professionals  600  { lock(obj) { //do dangerous stuff } } //meanwhile on other tread public void someothermethod() { var objinstring = obj.tostring(); //this does not block }  expecting subclasses to know when to lock sometimes base classes are designed such that their subclasses are required to use a lock when accessing certain protected ﬁelds: public abstract class base { protected readonly object padlock; protected readonly list<string> list; public base() { this.padlock = new object(); this.list = new list<string>(); } public abstract void do(); } public class derived1 : base { public override void do() { lock (this.padlock) { this.list.add(""derived1""); } } } public class derived2 : base { public override void do() { this.list.add(""derived2""); // oops! i forgot to lock! } }  it is much safer to encapsulate locking by using a template method: public abstract class base { private readonly object padlock; // this is now private protected readonly list<string> list; public base() { this.padlock = new object();  goalkicker.com – c# notes for professionals  601  this.list = new list<string>(); } public void do() { lock (this.padlock) { this.dointernal(); } } protected abstract void dointernal(); } public class derived1 : base { protected override void dointernal() { this.list.add(""derived1""); // yay! no need to lock } }  locking on a boxed valuetype variable does not synchronize in the following example, a private variable is implicitly boxed as it's supplied as an object argument to a function, expecting a monitor resource to lock at. the boxing occurs just prior to calling the incinsync function, so the boxed instance corresponds to a diﬀerent heap object each time the function is called. public int count { get; private set; } private readonly int counterlock = 1; public void inc() { incinsync(counterlock); } private void incinsync(object monitorresource) { lock (monitorresource) { count++; } }  boxing occurs in the inc function: bulemiccounter.inc: il_0000: nop il_0001: ldarg.0 il_0002: ldarg.0 il_0003: ldfld il_0008: box il_000d: call il_0012: nop il_0013: ret  userquery+bulemiccounter.counterlock system.int32** userquery+bulemiccounter.incinsync  it does not mean that a boxed valuetype can't be used for monitor locking at all: private readonly object counterlock = 1;  goalkicker.com – c# notes for professionals  602  now boxing occurs in constructor, which is ﬁne for locking: il_0001: il_0002: il_0007:  ldc.i4.1 box stfld  system.int32 userquery+bulemiccounter.counterlock  using locks unnecessarily when a safer alternative exists a very common pattern is to use a private list or dictionary in a thread safe class and lock every time it is accessed: public class cache { private readonly object padlock; private readonly dictionary<string, object> values; public wordstats() { this.padlock = new object(); this.values = new dictionary<string, object>(); } public void add(string key, object value) { lock (this.padlock) { this.values.add(key, value); } } /* rest of class omitted */ }  if there are multiple methods accessing the values dictionary, the code can get very long and, more importantly, locking all the time obscures its intent. locking is also very easy to forget and lack of proper locking can cause very hard to ﬁnd bugs. by using a concurrentdictionary, we can avoid locking completely: public class cache { private readonly concurrentdictionary<string, object> values; public wordstats() { this.values = new concurrentdictionary<string, object>(); } public void add(string key, object value) { this.values.add(key, value); } /* rest of class omitted */ }  using concurrent collections also improves performance because all of them employ lock-free techniques to some extent.  goalkicker.com – c# notes for professionals  603  section 119.5: using instances of object for lock when using c#'s inbuilt lock statement an instance of some type is needed, but its state does not matter. an instance of object is perfect for this: public class threadsafe { private static readonly object locker = new object();  public void somethreadsafemethod() { lock (locker) { // only one thread can be here at a time. } } }  nb. instances of type should not be used for this (in the code above typeof(threadsafe)) because instances of type are shared across appdomains and thus the extent of the lock can expectedly include code it shouldn't (eg. if threadsafe is loaded into two appdomains in the same process then locking on its type instance would mutually  lock).  goalkicker.com – c# notes for professionals  604",t_689e6562417a,t_689e6562417a,9
c_51200cf25975,"chapter 4 of the book on c#.chapter 4: conditional statements section 4.1: if-else statement programming in general often requires a decision or a branch within the code to account for how the code operates under diﬀerent inputs or conditions. within the c# programming language (and most programming languages for this matter), the simplest and sometimes the most useful way of creating a branch within your program is through an if-else statement. lets assume we have method (a.k.a. a function) which takes an int parameter which will represent a score up to 100, and the method will print out a message saying whether we pass or fail. static void printpassorfail(int score) { if (score >= 50) // if score is greater or equal to 50 { console.writeline(""pass!""); } else // if score is not greater or equal to 50 { console.writeline(""fail!""); } }  when looking at this method, you may notice this line of code (score >= 50) inside the if statement. this can be seen as a boolean condition, where if the condition is evaluated to equal true, then the code that is in between the if { } is ran.  for example, if this method was called like this: printpassorfail(60);, the output of the method would be a console print saying pass! since the parameter value of 60 is greater or equal to 50. however, if the method was called like: printpassorfail(30);, the output of the method would print out saying fail!. this is because the value 30 is not greater or equal to 50, thus the code in between the else { } is ran instead of the if statement. in this example, we've said that score should go up to 100, which hasn't been accounted for at all. to account for score not going past 100 or possibly dropping below 0, see the if-else if-else statement example.  section 4.2: if statement conditions are standard boolean expressions and values the following statement if (conditiona && conditionb && conditionc) //...  is exactly equivalent to bool conditions = conditiona && conditionb && conditionc; if (conditions) // ...  in other words, the conditions inside the ""if"" statement just form an ordinary boolean expression. a common mistake when writing conditional statements is to explicitly compare to true and false:  goalkicker.com – c# notes for professionals  34  if (conditiona == true && conditionb == false && conditionc == true) // ...  this can be rewritten as if (conditiona && !conditionb && conditionc)  section 4.3: if-else if-else statement following on from the if-else statement example, it is now time to introduce the else if statement. the else if statement follows directly after the if statement in the if-else if-else structure, but intrinsically has has a similar syntax as the if statement. it is used to add more branches to the code than what a simple if-else statement can. in the example from if-else statement, the example speciﬁed that the score goes up to 100; however there were never any checks against this. to ﬁx this, lets modify the method from if-else statement to look like this: static void printpassorfail(int score) { if (score > 100) // if score is greater than 100 { console.writeline(""error: score is greater than 100!""); } else if (score < 0) // else if score is less than 0 { console.writeline(""error: score is less than 0!""); } else if (score >= 50) // else if score is greater or equal to 50 { console.writeline(""pass!""); } else // if none above, then score must be between 0 and 49 { console.writeline(""fail!""); } }  all these statements will run in order from the top all the way to the bottom until a condition has been met. in this new update of the method, we've added two new branches to now accommodate for the score going out of bounds. for example, if we now called the method in our code as printpassofail(110);, the output would be a console print saying error: score is greater than 100!; and if we called the method in our code like printpassorfail(-20);, the output would say error: score is less than 0!.  goalkicker.com – c# notes for professionals  35",t_689e6562417a,t_689e6562417a,9
c_07de5f527945,"chapter 146 of the book on c#.chapter 146: clscompliantattribute constructor  parameter initializes an instance of the clscompliantattribute class with a boolean value clscompliantattribute(boolean) indicating whether the indicated program element is cls-compliant.  section 146.1: access modiﬁer to which cls rules apply using system; [assembly:clscompliant(true)] namespace clsdoc { public class cat { internal uint16 _age = 0; private uint16 _daystillvacination = 0; //warning cs3003 type of 'cat.daystillvacination' is not cls-compliant protected uint16 daystillvacination { get { return _daystillvacination; } } //warning cs3003 type of 'cat.age' is not cls-compliant public uint16 age { get { return _age; } } //valid behaviour by cls-compliant rules public int increaseage() { int increasedage = (int)_age + 1; return increasedage; } } }  the rules for cls compliance apply only to a public/protected components.  section 146.2: violation of cls rule: unsigned types / sbyte using system; [assembly:clscompliant(true)] namespace clsdoc { public class car { internal uint16 _yearofcreation = 0; //warning cs3008 identifier '_numberofdoors' is not cls-compliant //warning cs3003 type of 'car._numberofdoors' is not cls-compliant public uint32 _numberofdoors = 0;  goalkicker.com – c# notes for professionals  703  //warning cs3003 type of 'car.yearofcreation' is not cls-compliant public uint16 yearofcreation { get { return _yearofcreation; } }  //warning cs3002 return type of 'car.calculatedistance()' is not cls-compliant public uint64 calculatedistance() { return 0; }  //warning cs3002 return type of 'car.testdummyunsignedpointermethod()' is not cls-compliant public uintptr testdummyunsignedpointermethod() { int[] arr = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }; uintptr ptr = (uintptr)arr[0];  return ptr; } //warning cs3003 type of 'car.age' is not cls-compliant public sbyte age = 120;  } }  section 146.3: violation of cls rule: same naming using system; [assembly:clscompliant(true)] namespace clsdoc { public class car { //warning cs3005 identifier 'car.calculateage()' differing only in case is not clscompliant public int calculateage() { return 0; } public int calculateage() { return 0; } } }  visual basic is not case sensitive  goalkicker.com – c# notes for professionals  704  section 146.4: violation of cls rule: identiﬁer _ using system; [assembly:clscompliant(true)] namespace clsdoc { public class car { //warning cs3008 identifier '_age' is not cls-complian public int _age = 0; } }  you can not start variable with _  section 146.5: violation of cls rule: inherit from non clscomplaint class using system; [assembly:clscompliant(true)] namespace clsdoc { [clscompliant(false)] public class animal { public int age = 0; } //warning cs3009 'dog': base type 'animal' is not cls-compliant public class dog : animal { } }  goalkicker.com – c# notes for professionals  705",t_689e6562417a,t_689e6562417a,9
c_9c453174d65f,"chapter 91 of the book on c#.chapter 91: overload resolution section 91.1: basic overloading example this code contains an overloaded method named hello: class example { public static void hello(int arg) { console.writeline(""int""); } public static void hello(double arg) { console.writeline(""double""); } public static void main(string[] args) { hello(0); hello(0.0); } }  when the main method is called, it will print int double  at compile-time, when the compiler ﬁnds the method call hello(0), it ﬁnds all methods with the name hello. in this case, it ﬁnds two of them. it then tries to determine which of the methods is better. the algorithm for determining which method is better is complex, but it usually boils down to ""make as few implicit conversions as possible"". thus, in the case of hello(0), no conversion is needed for the method hello(int) but an implicit numeric conversion is needed for the method hello(double). thus, the ﬁrst method is chosen by the compiler. in the case of hello(0.0), there is no way to convert 0.0 to an int implicitly, so the method hello(int) is not even considered for overload resolution. only method remains and so it is chosen by the compiler.  section 91.2: ""params"" is not expanded, unless necessary the following program: class program { static void method(params object[] objects) { system.console.writeline(objects.length); } static void method(object a, object b) { system.console.writeline(""two""); } static void main(string[] args)  goalkicker.com – c# notes for professionals  505  { object[] objectarray = new object[5]; method(objectarray); method(objectarray, objectarray); method(objectarray, objectarray, objectarray); } }  will print: 5 two 3  the call expression method(objectarray) could be interpreted in two ways: a single object argument that happens to be an array (so the program would output 1 because that would be the number of arguments, or as an array of arguments, given in the normal form, as though the method method did not have the keyword params. in these situations, the normal, non-expanded form always takes precedence. so, the program outputs 5. in the second expression, method(objectarray, objectarray), both the expanded form of the ﬁrst method and the traditional second method are applicable. in this case also, non-expanded forms take precedence, so the program prints two. in the third expression, method(objectarray, objectarray, objectarray), the only option is to use the expanded form of the ﬁrst method, and so the program prints 3.  section 91.3: passing null as one of the arguments if you have void f1(mytype1 x) { // do something } void f1(mytype2 x) { // do something else }  and for some reason you need to call the ﬁrst overload of f1 but with x = null, then doing simply f1(null);  will not compile as the call is ambiguous. to counter this you can do f1(null as mytype1);  goalkicker.com – c# notes for professionals  506",t_689e6562417a,t_689e6562417a,9
c_f3724edf0eed,"chapter 11 of the book on c#.chapter 11: common string operations section 11.1: formatting a string use the string.format() method to replace one or more items in the string with the string representation of a speciﬁed object: string.format(""hello {0} foo {1}"", ""world"", ""bar"") //hello world foo bar  section 11.2: correctly reversing a string most times when people have to reverse a string, they do it more or less like this: char[] a = s.tochararray(); system.array.reverse(a); string r = new string(a);  however, what these people don't realize is that this is actually wrong. and i don't mean because of the missing null check. it is actually wrong because a glyph/graphemecluster can consist out of several codepoints (aka. characters). to see why this is so, we ﬁrst have to be aware of the fact what the term ""character"" actually means. reference: character is an overloaded term than can mean many things. a code point is the atomic unit of information. text is a sequence of code points. each code point is a number which is given meaning by the unicode standard. a grapheme is a sequence of one or more code points that are displayed as a single, graphical unit that a reader recognizes as a single element of the writing system. for example, both a and ä are graphemes, but they may consist of multiple code points (e.g. ä may be two code points, one for the base character a followed by one for the diaresis; but there's also an alternative, legacy, single code point representing this grapheme). some code points are never part of any grapheme (e.g. the zero-width non-joiner, or directional overrides). a glyph is an image, usually stored in a font (which is a collection of glyphs), used to represent graphemes or parts thereof. fonts may compose multiple glyphs into a single representation, for example, if the above ä is a single code point, a font may chose to render that as two separate, spatially overlaid glyphs. for otf, the font's gsub and gpos tables contain substitution and positioning information to make this work. a font may contain multiple alternative glyphs for the same grapheme, too. so in c#, a character is actually a codepoint. which means, if you just reverse a valid string like les misérables, which can look like this string s = ""les mise\u0301rables"";  as a sequence of characters, you will get:  goalkicker.com – c# notes for professionals  53  selbaŕesim sel as you can see, the accent is on the r character, instead of the e character. although string.reverse.reverse will yield the original string if you both times reverse the char array, this kind of reversal is deﬁnitely not the reverse of the original string. you'll need to reverse each graphemecluster only. so, if done correctly, you reverse a string like this: private static system.collections.generic.list<string> graphemeclusters(string s) { system.collections.generic.list<string> ls = new system.collections.generic.list<string>(); system.globalization.textelementenumerator enumerator = system.globalization.stringinfo.gettextelementenumerator(s); while (enumerator.movenext()) { ls.add((string)enumerator.current); } return ls; }  // this private static string reversegraphemeclusters(string s) { if(string.isnullorempty(s) || s.length == 1) return s; system.collections.generic.list<string> ls = graphemeclusters(s); ls.reverse(); return string.join("""", ls.toarray()); } public static void testme() { string s = ""les mise\u0301rables""; // s = ""noël""; string r = reversegraphemeclusters(s); // // // //  this would be wrong: char[] a = s.tochararray(); system.array.reverse(a); string r = new string(a);  system.console.writeline(r); }  and - oh joy - you'll realize if you do it correctly like this, it will also work for asian/south-asian/east-asian languages (and french/swedish/norwegian, etc.)...  section 11.3: padding a string to a ﬁxed length string s = ""foo""; string paddedleft = s.padleft(5); // paddedleft = "" foo"" (pads with spaces by default) string paddedright = s.padright(6, '+'); // paddedright = ""foo+++""  goalkicker.com – c# notes for professionals  54  string nopadded = s.padleft(2);  // nopadded = ""foo"" (original string is never shortened)  section 11.4: getting x characters from the right side of a string visual basic has left, right, and mid functions that returns characters from the left, right, and middle of a string. these methods does not exist in c#, but can be implemented with substring(). they can be implemented as an extension methods like the following: public static class stringextensions { /// <summary> /// vb left function /// </summary> /// <param name=""stringparam""></param> /// <param name=""numchars""></param> /// <returns>left-most numchars characters</returns> public static string left( this string stringparam, int numchars ) { // handle possible null or numeric stringparam being passed stringparam += string.empty; // handle possible negative numchars being passed numchars = math.abs( numchars ); // validate numchars parameter if (numchars > stringparam.length) numchars = stringparam.length; return stringparam.substring( 0, numchars ); } /// <summary> /// vb right function /// </summary> /// <param name=""stringparam""></param> /// <param name=""numchars""></param> /// <returns>right-most numchars characters</returns> public static string right( this string stringparam, int numchars ) { // handle possible null or numeric stringparam being passed stringparam += string.empty; // handle possible negative numchars being passed numchars = math.abs( numchars ); // validate numchars parameter if (numchars > stringparam.length) numchars = stringparam.length; return stringparam.substring( stringparam.length - numchars ); } /// <summary> /// vb mid function - to end of string /// </summary> /// <param name=""stringparam""></param> /// <param name=""startindex"">vb-style startindex, 1st char startindex = 1</param> /// <returns>balance of string beginning at startindex character</returns> public static string mid( this string stringparam, int startindex )  goalkicker.com – c# notes for professionals  55  { // handle possible null or numeric stringparam being passed stringparam += string.empty; // handle possible negative startindex being passed startindex = math.abs( startindex ); // validate numchars parameter if (startindex > stringparam.length) startindex = stringparam.length; // c# strings are zero-based, convert passed startindex return stringparam.substring( startindex - 1 ); } /// <summary> /// vb mid function - for number of characters /// </summary> /// <param name=""stringparam""></param> /// <param name=""startindex"">vb-style startindex, 1st char startindex = 1</param> /// <param name=""numchars"">number of characters to return</param> /// <returns>balance of string beginning at startindex character</returns> public static string mid( this string stringparam, int startindex, int numchars) { // handle possible null or numeric stringparam being passed stringparam += string.empty; // handle possible negative startindex being passed startindex = math.abs( startindex ); // handle possible negative numchars being passed numchars = math.abs( numchars ); // validate numchars parameter if (startindex > stringparam.length) startindex = stringparam.length; // c# strings are zero-based, convert passed startindex return stringparam.substring( startindex - 1, numchars ); } }  this extension method can be used as follows: string string string string string  mylongstring = ""hello world!""; myshortstring = mylongstring.right(6); myleftstring = mylongstring.left(5); mymidstring1 = mylongstring.left(4); mymidstring2 = mylongstring.left(2,3);  // ""world!"" // ""hello"" // ""lo world"" // ""ell""  section 11.5: checking for empty string using string.isnullorempty() and string.isnullorwhitespace() string string string string string string  nullstring = null; emptystring = """"; whitespacestring = "" ""; tabstring = ""\t""; newlinestring = ""\n""; nonemptystring = ""abc123"";  goalkicker.com – c# notes for professionals  56  bool result; result result result result result result  = = = = = =  string.isnullorempty(nullstring); string.isnullorempty(emptystring); string.isnullorempty(whitespacestring); string.isnullorempty(tabstring); string.isnullorempty(newlinestring); string.isnullorempty(nonemptystring);  // // // // // //  true true false false false false  result result result result result result  = = = = = =  string.isnullorwhitespace(nullstring); string.isnullorwhitespace(emptystring); string.isnullorwhitespace(tabstring); string.isnullorwhitespace(newlinestring); string.isnullorwhitespace(whitespacestring); string.isnullorwhitespace(nonemptystring);  // // // // // //  true true true true true false  section 11.6: trimming unwanted characters o the start and/or end of strings string.trim() string x = "" hello world! ""; string y = x.trim(); // ""hello world!"" string q = ""{(hi!*""; string r = q.trim( '(', '*', '{' ); // ""hi!"" string.trimstart() and string.trimend() string q = ""{(hi*""; string r = q.trimstart( '{' ); // ""(hi*"" string s = q.trimend( '*' ); // ""{(hi""  section 11.7: convert decimal number to binary,octal and hexadecimal format 1. to convert decimal number to binary format use base 2 int32 number = 15; console.writeline(convert.tostring(number, 2));  //output : 1111  2. to convert decimal number to octal format use base 8 int number = 15; console.writeline(convert.tostring(number, 8));  //output : 17  3. to convert decimal number to hexadecimal format use base 16 var number = 15; console.writeline(convert.tostring(number, 16));  //output : f  section 11.8: construct a string from array the string.join method will help us to construct a string from array/list of characters or string. this method accepts two parameters. the ﬁrst one is the delimiter or the separator which will help you to separate each element in the array. and the second parameter is the array itself. goalkicker.com – c# notes for professionals  57  string from char array: string delimiter="",""; char[] chararray = new[] { 'a', 'b', 'c' }; string inputstring = string.join(delimiter, chararray);  output : a,b,c if we change the delimiter as """" then the output will become abc. string from list of char: string delimiter = ""|""; list<char> charlist = new list<char>() { 'a', 'b', 'c' }; string inputstring = string.join(delimiter, charlist);  output : a|b|c string from list of strings: string delimiter = "" ""; list<string> stringlist = new list<string>() { ""ram"", ""is"", ""a"",""boy"" }; string inputstring = string.join(delimiter, stringlist);  output : ram is a boy string from array of strings: string delimiter = ""_""; string[] stringarray = new [] { ""ram"", ""is"", ""a"",""boy"" }; string inputstring = string.join(delimiter, stringarray);  output : ram_is_a_boy  section 11.9: formatting using tostring usually we are using string.format method for formatting purpose, the.tostring is usually used for converting other types to string. we can specify the format along with the tostring method while conversion is taking place, so we can avoid an additional formatting. let me explain how it works with diﬀerent types; integer to formatted string: int intvalue = 10; string zeropaddedinteger = intvalue.tostring(""000""); // output will be ""010"" string customformat = intvalue.tostring(""input value is 0""); // output will be 10""  ""input value is  double to formatted string: double string string string  doublevalue = 10.456; roundeddouble = doublevalue.tostring(""0.00""); // output 10.46 integerpart = doublevalue.tostring(""00""); // output 10 customformat = doublevalue.tostring(""input value is 0.0""); // input value is 10.5  formatting datetime using tostring datetime currentdate = datetime.now; // {7/21/2016 7:23:15 pm} string datetimestring = currentdate.tostring(""dd-mm-yyyy hh:mm:ss""); // ""21-07-2016 19:23:15""  goalkicker.com – c# notes for professionals  58  string dateonlystring = currentdate.tostring(""dd-mm-yyyy""); // ""21-07-2016"" string datewithmonthinwords = currentdate.tostring(""dd-mmmm-yyyy hh:mm:ss""); // ""21-july-2016 19:23:15""  section 11.10: splitting a string by another string string str = ""this--is--a--complete--sentence""; string[] tokens = str.split(new[] { ""--"" }, stringsplitoptions.none);  result: [ ""this"", ""is"", ""a"", ""complete"", ""sentence"" ]  section 11.11: splitting a string by speciﬁc character string helloworld = ""hello world, how is it going?""; string[] parts1 = helloworld.split(','); //parts1: [""hello world"", "" how is it going?""] string[] parts2 = helloworld.split(' '); //parts2: [""hello"", ""world,"", ""how"", ""is"", ""it"", ""going?""]  section 11.12: getting substrings of a given string string helloworld = ""hello world!""; string world = helloworld.substring(6); //world = ""world!"" string hello = helloworld.substring(0,5); // hello = ""hello"" substring returns the string up from a given index, or between two indexes (both inclusive).  section 11.13: determine whether a string begins with a given sequence string helloworld = ""hello world""; helloworld.startswith(""hello""); // true helloworld.startswith(""foo""); // false  finding a string within a string using the system.string.contains you can ﬁnd out if a particular string exists within a string. the method returns a boolean, true if the string exists else false. string s = ""hello world""; bool stringexists = s.contains(""ello"");  //stringexists =true as the string contains the substring  section 11.14: getting a char at speciﬁc index and enumerating the string you can use the substring method to get any number of characters from a string at any given location. however, if you only want a single character, you can use the string indexer to get a single character at any given index like you goalkicker.com – c# notes for professionals  59  do with an array: string s = ""hello""; char c = s[1]; //returns 'e'  notice that the return type is char, unlike the substring method which returns a string type. you can also use the indexer to iterate through the characters of the string: string s = ""hello""; foreach (char c in s) console.writeline(c); /********* this will print each character on a new line: h e l l o **********/  section 11.15: joining an array of strings into a new one var parts = new[] { ""foo"", ""bar"", ""fizz"", ""buzz""}; var joined = string.join("", "", parts); //joined = ""foo, bar, fizz, buzz""  section 11.16: replacing a string within a string using the system.string.replace method, you can replace part of a string with another string. string s = ""hello world""; s = s.replace(""world"", ""universe""); // s = ""hello universe""  all the occurrences of the search string are replaced. this method can also be used to remove part of a string, using the string.empty ﬁeld: string s = ""hello world""; s = s.replace(""ell"", string.empty); // s = ""ho world""  section 11.17: changing the case of characters within a string the system.string class supports a number of methods to convert between uppercase and lowercase characters in a string. system.string.tolowerinvariant is used to return a string object converted to lowercase. system.string.toupperinvariant is used to return a string object converted to uppercase.  note: the reason to use the invariant versions of these methods is to prevent producing unexpected culturespeciﬁc letters. this is explained here in detail. example: string s = ""my string"";  goalkicker.com – c# notes for professionals  60  s = s.tolowerinvariant(); // ""my string"" s = s.toupperinvariant(); // ""my string""  note that you can choose to specify a speciﬁc culture when converting to lowercase and uppercase by using the string.tolower(cultureinfo) and string.toupper(cultureinfo) methods accordingly.  section 11.18: concatenate an array of strings into a single string the system.string.join method allows to concatenate all elements in a string array, using a speciﬁed separator between each element: string[] words = {""one"", ""two"", ""three"", ""four""}; string singlestring = string.join("","", words); // singlestring = ""one,two,three,four""  section 11.19: string concatenation string concatenation can be done by using the system.string.concat method, or (much easier) using the + operator: string first = ""hello ""; string second = ""world""; string concat = first + second; // concat = ""hello world"" concat = string.concat(first, second); // concat = ""hello world""  in c# 6 this can be done as follows: string concat = $""{first},{second}"";  goalkicker.com – c# notes for professionals  61",t_689e6562417a,t_689e6562417a,9
c_cb0efb39e924,"pause and reflect on your reading or learning.jump to navigation  performing a stop 'n' write  performing a stop 'n' write  one of the best ways to activate your learning is to stop and write. in this activity, you pause in the middle of your reading or listening to write a brief reflection about what has happened in the text or lesson so far.  your goal is to get your ideas down in a way that is most natural to you. you could, perhaps, combine words, pictures, and/or graphic organizers.  when you reflect, answer questions such as these:  what is the most important thing i learned so far?  what parts didn’t i understand?  what parts do i want to know more about?  how does the writing/topic make me feel?  what will happen next?  what does this story, topic, or concept remind me of?  your turn stop halfway through your next reading assignment and write an answer to one or more of the questions from above. try writing non-stop for 5 to 8 minutes. don't worry about spelling or punctuation. if you get stuck, draw a picture or create a diagram about the topic.  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_82dad323a28d,t_82dad323a28d,10
c_86748dcc57b2,"correct capitalization.jump to navigation  correcting capitalization 1  correcting capitalization 1  everett historical/shutterstock.com  your turn read the capitalization rules. then read this paragraph, which has errors in capitalization. write any incorrect word but correct the capitalization, or print the lesson to mark your corrections.  capitalization rules:  capitalize the first word in a sentence.  capitalize proper nouns (the names of people, places, or things): george washington, valley forge, ford falcon.  capitalize proper adjectives (modifiers formed from proper nouns): american general, pennsylvanian camp, ford automobile.  leave common nouns lowercased unless they appear at the beginning of a sentence. a common noun is not a name: general, camp, or automobile.  the real mccoy  the real mccoy (corrected)  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_82dad323a28d,t_82dad323a28d,10
c_7333bf63f58e,"inspire students to write family stories.jump to navigation  writing a family story and historical marker  writing a family story and historical marker  all families have stories about their past and present. some of these stories are interesting or important; others may be funny or sad. the people in your family and their stories are part of your story, too. the following family story tells about the writer’s great-great grandfather:  the first kascinski in america  joseph was the first kascinski in my family to come to america from poland. he arrived by ship in 1914 in new york. he next traveled by train to milwaukee. joseph fought in world war i and then in 1919 started his own business, a hot dog stand along north beach. he was the first food vendor there, and his success allowed him later to start two restaurants. joseph’s hard work helped our family get started in america.  it can be fun to honor a family member with a historical marker, too. (a historical marker honors a person or event and can be posted at an important site.) here is a historical marker honoring joseph kascinski.  your turn write a family story and create a historical marker based on it.  identify a family story you would like to share. this could be a story from the past or present. if needed, ask a family member for help.  gather details about the story.  write your story. answer the 5 w’s (who? what? when? where? and why?) about the person or event.  create a historical marker based on the story. combine graphics and words on your marker. be creative.  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_82dad323a28d,t_82dad323a28d,10
c_0a851f1ffce7,"closely read with sq3r.jump to navigation  closely read with sq3r  closely read with sq3r  thoughtful learning  how can you actively read a text rather than passively letting your eyes gloss over it? try the sq3r strategy:  survey the text to get a first impression, reading headings, first and last paragraphs, bits of dialogue, captions, and graphics.  question the work, asking yourself what you will learn by reading.  read the work carefully, taking notes as you go along and annotating the text (if the copy belongs to you).  recite the thesis or theme of the text, any main supporting points, and the answers to any questions you posed.  review the selection and your notes one final time to help you remember the material.  your turn use sq3r to closely read the following text. you can download a copy of the text to read and annotate.  captain stormfield’s visit to heaven  by mark twain  chapter i [excerpt]  well, when i had been dead about thirty years i begun to get a little anxious. mind you, had been whizzing through space all that time, like a comet. like a comet! why, peters, i laid over the lot of them! of course there warn't any of them going my way, as a steady thing, you know, because they travel in a long circle like the loop of a lasso, whereas i was pointed as straight as a dart for the hereafter; but i happened on one every now and then that was going my way for an hour or so, and then we had a bit of a brush together. but it was generally pretty one-sided, because i sailed by them the same as if they were standing still. an ordinary comet don't make more than about 200,000 miles a minute. of course when i came across one of that sort--like encke's and halley's comets, for instance--it warn't anything but just a flash and a vanish, you see. you couldn't rightly call it a race. it was as if the comet was a gravel-train and i was a telegraph despatch. but after i got outside of our astronomical system, i used to flush a comet occasionally that was something like. we haven't got any such comets--ours don't begin. one night i was swinging along at a good round gait, everything taut and trim, and the wind in my favor--i judged i was going about a million miles a minute--it might have been more, it couldn't have been less--when i flushed a most uncommonly big one about three points off my starboard bow. by his stern lights i judged he was bearing about northeast-and-by-north-half-east. well, it was so near my course that i wouldn't throw away the chance; so i fell off a point, steadied my helm, and went for him. you should have heard me whiz, and seen the electric fur fly! in about a minute and a half i was fringed out with an electrical nimbus that flamed around for miles and miles and lit up all space like broad day. the comet was burning blue in the distance, like a sickly torch, when i first sighted him, but he begun to grow bigger and bigger as i crept up on him. i slipped up on him so fast that when i had gone about 150,000,000 miles i was close enough to be swallowed up in the phosphorescent glory of his wake, and i couldn't see anything for the glare. thinks i, it won't do to run into him, so i shunted to one side and tore along. by and by i closed up abreast of his tail. do you know what it was like? it was like a gnat closing up on the continent of america. i forged along. by and by i had sailed along his coast for a little upwards of a hundred and fifty million miles, and then i could see by the shape of him that i hadn't even got up to his waistband yet. why, peters, we don't know anything about comets, down here. if you want to see comets that are comets, you've got to go outside of our solar system-- where there's room for them, you understand. my friend, i've seen comets out there that couldn't even lay down inside the orbits of our noblest comets without their tails hanging over.  vadim sadovski/shutterstock.com  well, i boomed along another hundred and fifty million miles, and got up abreast his shoulder, as you may say. i was feeling pretty fine, i tell you; but just then i noticed the officer of the deck come to the side and hoist his glass in my direction. straight off i heard him sing out--""below there, ahoy! shake her up, shake her up! heave on a hundred million billion tons of brimstone!""  ""ay-ay, sir!""  ""pipe the stabboard watch! all hands on deck!""  ""ay-ay, sir!""  ""send two hundred thousand million men aloft to shake out royals and sky-scrapers!""  ""ay-ay, sir!""  ""hand the stuns'ls! hang out every rag you've got! clothe her from stem to rudder-post!""  ""ay-ay, sir!""  in about a second i begun to see i'd woke up a pretty ugly customer, peters. in less than ten seconds that comet was just a blazing cloud of red-hot canvas. it was piled up into the heavens clean out of sight--the old thing seemed to swell out and occupy all space; the sulphur smoke from the furnaces--oh, well, nobody can describe the way it rolled and tumbled up into the skies, and nobody can half describe the way it smelt. neither can anybody begin to describe the way that monstrous craft begun to crash along. and such another powwow--thousands of bo's'n's whistles screaming at once, and a crew like the populations of a hundred thousand worlds like ours all swearing at once. well, i never heard the like of it before.  we roared and thundered along side by side, both doing our level best, because i'd never struck a comet before that could lay over me, and so i was bound to beat this one or break something. i judged i had some reputation in space, and i calculated to keep it. i noticed i wasn't gaining as fast, now, as i was before, but still i was gaining. there was a power of excitement on board the comet. upwards of a hundred billion passengers swarmed up from below and rushed to the side and begun to bet on the race. of course this careened her and damaged her speed. my, but wasn't the mate mad! he jumped at that crowd, with his trumpet in his hand, and sung out--  ""amidships! amidships, you—! or i'll brain the last idiot of you!""  well, sir, i gained and gained, little by little, till at last i went skimming sweetly by the magnificent old conflagration's nose. by this time the captain of the comet had been rousted out, and he stood there in the red glare for'ard, by the mate, in his shirt- sleeves and slippers, his hair all rats' nests and one suspender hanging, and how sick those two men did look! i just simply couldn't help putting my thumb to my nose as i glided away and singing out:  ""ta-ta! ta-ta! any word to send to your family?""  peters, it was a mistake. yes, sir, i've often regretted that--it was a mistake. you see, the captain had given up the race, but that remark was too tedious for him--he couldn't stand it. he turned to the mate, and says he--  ""have we got brimstone enough of our own to make the trip?""  ""yes, sir.""  ""sure?""  ""yes, sir--more than enough.""  ""how much have we got in cargo for satan?""  ""eighteen hundred thousand billion quintillions of kazarks.""  ""very well, then, let his boarders freeze till the next comet comes. lighten ship! lively, now, lively, men! heave the whole cargo overboard!""  peters, look me in the eye, and be calm. i found out, over there, that a kazark is exactly the bulk of a hundred and sixty-nine worlds like ours! they hove all that load overboard. when it fell it wiped out a considerable raft of stars just as clean as if they'd been candles and somebody blowed them out. as for the race, that was at an end. the minute she was lightened the comet swung along by me the same as if i was anchored. the captain stood on the stern, by the after-davits, and put his thumb to his nose and sung out--  ""ta-ta! ta-ta! maybe you've got some message to send your friends in the everlasting tropics!""  then he hove up his other suspender and started for'ard, and inside of three-quarters of an hour his craft was only a pale torch again in the distance. yes, it was a mistake, peters--that remark of mine. i don't reckon i'll ever get over being sorry about it. i'd 'a' beat the bully of the firmament if i'd kept my mouth shut. . . . .  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_82dad323a28d,t_82dad323a28d,10
c_fcf68c3679fa,"use commas in series.jump to navigation  using commas in a series  using commas in a series  luciano queiroz/shutterstock.com  your turn read the rules about commas in a series. then read the paragraph, which needs commas.  write each series showing where the commas go, or print the lesson to mark your corrections.  comma rules:  when three or more words or phrases are joined with the word and or or, a comma should follow each item except the very last: bacon, lettuce, and tomato.  include a comma before the and or or.  if you're an anteater  if you're an anteater (corrected)  © 2019 thoughtful learning. copying is permitted.  k12.thoughtfullearning.com",t_82dad323a28d,t_82dad323a28d,10
c_c7b1483e973d,"example of transforming a discrete random variable  - [instructor] anush is playing a carnival game that involves two free throws. the table below displays the probability distribution of x, the number of shots that anush makes in a set of two attempts, along with some summary statistics. so here's the random variable x it's a discrete random variable. it only takes on a finite number of value, sometimes you can say it takes on a countable number of values. we see we can either make zero free throws, one, or two of the two. and the probability that he makes zero is here, one is here, two is here. and then they also give us the mean of x and the standard deviation of x. then they tell us if the game costs anush $15 to play and he wins $10 per shot he makes, what are the mean and standard deviation of his net gain from playing the game n? all right, so let's define a new random variable n. which is equal to his net gain. net gain. we can define n in terms of x. what is his net gain going to be? well let's see, n, it's going to be equal to 10 times however many shots he makes. so it's gonna be 10 times x. and then no matter what, he has to pay $15 to play. minus 15. in fact, we can set up a little table here for the probability distribution of n. so, let me make it right over here. so i'll make it look just like this one. n is equal to net gain. and here we'll have the probability of n. and there's three outcomes here. the outcome that corresponds to him making zero shots, well that would be 10 times zero minus 15. that would be a net gain of negative 15. and would have the same probability, 0.16. when he makes one shot, the net gain is gonna be 10 times one minus 15 which is, negative five. which is going to have the same probability. he has a 48% chance of making one shot. and so it's a 48% chance of losing five dollars. and then last, but not least, when x is two his net gain is gonna be positive five. plus five. and so this is a 0.36 chance. so what they want us to figure out are, what are the mean and standard deviation of his net gain? so let's first figure out the mean of n. well, if you scale a random variable the corresponding mean is going to be scaled by the same amount. and if you shift a random variable the corresponding mean is gonna be shifted by the same amount. so the mean of n is gonna be 10 times the mean of x minus 15. which is equal to 10 times 1.2 minus 15. 1.2. so there's 12 minus 15 which is equal to negative three. now the standard deviation of n is gonna be slightly different. for the standard deviation, scaling matters. if you scale a random variable by a certain value you would also scale the standard deviation by the same value. so this is going to be equal to 10 times the standard deviation of x. now you might say, what about the shift over here? well, the shift should not affect the spread of the random variable. if you're scaling the random variable, well, your spread should grow by the amount that you're scaling it. but by shifting it, it doesn't affect how much you disperse from the mean. so standard deviation is only affected by the scaling, but not by the shifting. so this is going to be 10 times 0.69 which is going to. this was an approximation. so i'll say this is approximately to 6.9. so this is our new distribution for our net gain. this is the mean of our net gain. and this is roughly the standard deviation of our net gain.",t_92cf4e58f786,t_92cf4e58f786,11
c_9f1ced514fd3,"our friend and cleveland cavalier, lebron james, asks sal how to determine the probability of making 10 free throws in a row. hint: the answer is surprising!  hey everybody, it's lebron here. i got a quick brain teaser for you. what are the odds of making 10 free throws in a row? here's my good friend sal with the answer. that's a great question, lebron, and i think the answer might surprise you. so, i looked up your career free-throw percentage and you are right at around, 75%, which is a little bit higher than my free-throw percentage. and one way to interpret that: if we have a million lebron james, and you can imagine any large number of lebron james is taking a free throw. let's say, this line represents all of the lebron james' that take that first free-throw. let's call that free throw number 1. we would expect, on average, that 75% of them would make that first free-throw. so, let me draw 75%, so this is about halfway. so this would be 25, this would get us for 75. so we would expect 75% of them would make that first free throw. 75%, and then the other 25% we would expect on average would miss that first free-throw. now, what we care about are the ones that keep making the free-throws. we want ten in a row! so, let's just focus on the 75% that made the first one. some of these 25% might make some free-throws going forward. but we don't care about them anymore. they are kind of out-of-the-game! so, let's go to free-throw number two. free throw ... number two. what percentage of the folks who made of the lebron james-es, that made the first free-throw, what percentage would we expect to make the second one? and we're going to assume, whether or not you made the first one, has no bearing on the probability of you on making the second, that this continues to be the probability of a lebron james making a given free throw. so we would expect 75% of these lebron james' to also make the second one. we are going to take 75% of 75%. so this is about half of that 75%; this would be a quarter, this would be three-fourths, which is about 75%, which is exactly 75%. so right over here. this represents the ones that made the first one, how many also made the second one. so you could say that the percentage of the lebron james-s that we would expect on average to make the first two free-throws. this is... this is the length right over here is 75 percent of 75%. 75% of this 75% right over there. and i think you might begin to see a pattern emerging. let's go to the 3rd free-throw: free throw number 3. so what percentage of these folks are going to make the third one? well, 75% of them are going to make the 3rd one. so, 75% of them are going to make the 3rd one. what is this going to be? this is going to be 75%, 75% of this number, of this length, which is 75% of 75%. and if you would go all the way to free throw #10, and i think you see the pattern here, (if we are going all the way to free throw #10), so i am just skipping a bunch, we are going to get some very, very, very small fraction that had made all ten, is essentially going to be 75% times 75% times 75%... 10 times: 75% being multiplied repeatedly 10 times. so this is going to be what we have left off with, this is going to be 75%, times 75% (and let me copy and paste this) (so it doesn't take forever.) (so... copy, and then paste it. so times out) (i will put the multiplication signs on later) (that's four... that's six... that's eight...) (...and then: that is ten. right over there,) (let me throw the multiplication signs in there, so) (times, times, times, times...) so this little fraction that made all ten of them is going to be equaled to this value right over here. 75 of... let's see: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10: 75% being repeatedly multiplied 10 times. now, this would obviously have taken me forever to do it by hand. and even on a calculator, if i would have punched all of these in, i might have made mistakes. but lucky for us: there is a mathematical operator that is essentially repeated multiplications. and that's taking an exponent. so another way - another way of writing that, (right over there), we could write that as: 75% to the... tenth power, repeated multiplying 75% ten times- these are the same expressions. and 75%, the word ""per-cent"", literally means ""per hundred"". you might recognize the root work, ""cent"", from things like ""century"", 100 years in a century, 100 cents in a dollar, so this literally means ""per hundred"". so we could write this a ""75 over 100 to the 10th power"", which is the same thing as 0.75 to the 10th power. and let's get our calculator out and see what this evaluates to. so, 0.75 to the... 10th power, gets us to: .056, and i'll just round to the nearest hundreds, so if we'd round to the nearest hundreds, that gets us to .06. so this is roughly equaled to (if we round to the nearest hundreds): 0.06 which is equaled to, roughly when we round, a 6% probability of making ten free throws in a row! which even though you have quite a high free throw percentage, this is not that high of a probability. it's a little bit better than a one-in-twenty chance. now: what i want to throw out there for everyone else watching this, is to think about how we can make a general statement about anybody, if that anybody has some free throw percentages, and wants to say: what's the probability of making 10 in a row? how can we say that? well, i think we saw the pattern right over here. the probability... of making, let's call it ""n"", where ""n"" is the number of free-throws we care about, n free-throws in a row, for somebody, and we are not just talking about lebron here, is going to be their free throw percentage, and in this case, lebron's in 75%, to the number of free throws we want to get in a row. so to the n-th power. for example: you might want to play around with your own free throw percentages. if your free-throw percentage is, let's say, 60%, which is the same thing as .6. so let's say you have a 60% free-throw percentage, and you want to see the probability of getting 5 in a row, you would take that to the fifth power. and you'd get - what looks like, if you round it to the nearest hundredth, would be about 8%. so i encourage you to try this with different free-throw percentages, and different numbers of free throws that you are attempting to get in a row",t_92cf4e58f786,t_92cf4e58f786,11
c_987887a2366f,"learn to choose the ""preferred"" measures of center and spread when outliers are present in a set of data.  - [narrator] so we have nine students who recently graduated from a small school that has a class size of nine, and they wanna figure out what is the central tendency for salaries one year after graduation? and they also wanna have a sense of the spread around that central tendency one year after graduation. so they all agree to put in their salaries into a computer, and so these are their salaries. they're measured in thousands. so one makes 35,000, 50,000, 50,000, 50,000, 56,000, two make 60,000, one makes 75,000, and one makes 250,000. so she's doing very well for herself, and the computer it spits out a bunch of parameters based on this data here. so it spits out two typical measures of central tendency. the mean is roughly 76.2. the computer would calculate it by adding up all of these numbers, these nine numbers, and then dividing by nine, and the median is 56, and median is quite easy to calculate. you just order the numbers and you take the middle number here which is 56. now what i want you to do is pause this video and think about for this data set, for this population of salaries, which measure, which measure of central tendency is a better measure? all right, so let's think about this a little bit. i'm gonna plot it on a line here. i'm gonna plot my data so we get a better sense and we just don't see them, so we just don't see things as numbers, but we see where those numbers sit relative to each other. so let's say this is zero. let's say this is, let's see, one, two, three, four, five. so this would be 250, this is 50, 100, 150, 200, 200, and let's see. let's say if this is 50 than this would be roughly 40 right here, and i just wanna get rough. so this would be about 60, 70, 80, 90, close enough. i'm, i could draw this a little bit neater, but, 60, 70, 80, 90. actually, let me just clean this up a little bit more too. this one right over here would be a little bit closer to this one. let me just put it right around here. so that's 40, and then this would be 30, 20, 10. okay, that's pretty good. so let's plot this data. so, one student makes 35,000, so that is right over there. two make 50,000, or three make 50,000, so one, two, and three. i'll put it like that. one makes 56,000 which would put them right over here. one makes 60,000, or actually, two make 60,000, so it's like that. one makes 75,000, so that's 60, 70, 75,000. so it's gonna be right around there, and then one makes 250,000. so one's salary is all the way around there, and then when we calculate the mean as 76.2 as our measure of central tendency, 76.2 is right over there. so is this a good measure of central tendency? well to me it doesn't feel that good, because our measure of central tendency is higher than all of the data points except for one, and the reason is is that you have this one that the, that our, our data is skewed significantly by this data point at $250,000. it is so far from the rest of the distribution from the rest of the data that it has skewed the mean, and this is something that you see in general. if you have data that is skewed, and especially things like salary data where someone might make, most people are making 50, 60, $70,000, but someone might make two million dollars, and so that will skew the average or skew the mean i should say, when you add them all up and divide by the number of data points you have. in this case, especially when you have data points that would skew the mean, median is much more robust. the median at 56 sits right over here, which seems to be much more indicative for central tendency. and think about it. even if you made this instead of 250,000 if you made this 250,000 thousand, which would be 250 million dollars, which is a ginormous amount of money to make, it wouldn't, it would skew the mean incredibly, but it actually would not even change the median, because the median, it doesn't matter how high this number gets. this could be a trillion dollars. this could be a quadrillion dollars. the median is going to stay the same. so the median is much more robust if you have a skewed data set. mean makes a little bit more sense if you have a symmetric data set or if you have things that are, you know, where, where things are roughly above and below the mean, or things aren't skewed incredibly in one direction, especially by a handful of data points like we have right over here. so in this example, the median is a much better measure of central tendency. and so what about spread? well you might say, well, sal you already told us that the mean is not so good and the standard deviation is based on the mean. you take each of these data points, find their distance from the mean, square that number, add up those squared distances, divide by the number of data points if we're taking the population standard deviation, and then you, and then you, you take the square root of the whole thing. and so since this is based on the mean, which isn't a good measure of central tendency in this situation, and this, this is also going to skew that standard deviation. this is going to be, this is a lot larger than if you look at the, the actual, if you wanted an indication of the spread. yes, you have this one data point that's way far away from either the mean or the median depending on how you wanna think about it, but most of the data points seem much closer, and so for that situation, not only are we using the median, but the interquartile range is once again more robust. how do we calculate the interquartile range? well, you take the median and then you take the bottom group of numbers and calculate the median of those. so that's 50 right over here and then you take the top group of numbers, the upper group of numbers, and the median there is 60 and 75, it's 67.5. if this looks unfamiliar we have many videos on interquartile range and calculating standard deviation and median and mean. this is just a little bit of a review, and then the difference between these two is 17.5, and notice, this distance between these two, this 17.5, this isn't going to change, even if this is 250 billion dollars. so once again, it is both of these measures are more robust when you have a skewed data set. so the big take away here is mean and standard deviation, they're not bad if you have a roughly symmetric data set, if you don't have any significant outliers, things that really skew the data set, mean and standard deviation can be quite solid. but if you're looking at something that could get really skewed by a handful of data points median might be, median and interquartile range, median for central tendency, interquartile range for spread around that central tendency, and that's why you'll see when people talk about salaries they'll often talk about median, because you can have some skewed salaries, especially on the up side. when we talk about things like home prices you'll see median often measured more typically than mean, because home prices in a neighborhood, a lot of, or in a city, a lot of the houses might be in the 200,000, $300,000 range, but maybe there's one ginormous mansion that is 100 million dollars, and if you calculated mean that would skew and give a false impression of the average or the central tendency of prices in that city.",t_92cf4e58f786,t_92cf4e58f786,11
c_87179e8004bc,"introduction to sampling distributions  - [instructor] what we're gonna do in this video is talk about the idea of a sampling distribution. now, just to make things a little bit concrete, let's imagine that we have a population of some kind. let's say it's a bunch of balls, each of them have a number written on it. for that population, we could calculate parameters. so, a parameter you could view as a truth about that population. we've covered this in other videos. so for example, you could have the population mean, the mean of the numbers written on top of that ball. you could have the population standard deviation. you could have the proportion of balls that are even, whatever, these are all population parameters. now we know from many other videos that you might not know the population parameter or might not even be easy to find, and so the way that we try to estimate a population parameter is by taking a sample, so this right over here is a sample size of size n. sample of size n. and then we can calculate a statistic from that sample, based on that sample, maybe we picked n balls from there. and so from that, we can calculate a statistic that is used to estimate this parameter. but we know that this is a random sample right over here, so every time we take a sample, the statistic that we calculate for that sample is not necessarily going to be the same as the population parameter. in fact, if we were to take a random sample of size n again and then we were to calculate the statistic again, we could very well get a different value. so, these are all going to be estimates of this parameter. and so an interesting question is what is the distribution of the values that i could get for the statistics? what is the frequency with which i can get different values for the statistic that is trying to estimate this parameter? and that distribution is what a sampling distribution is. so let's make this even a little bit more concrete. let's imagine where our population, i'm gonna make this a very simple example. let's say our population has three balls in it. one, two, three, and they're numbered, one, two, and three. and it's very easy to calculate. let's say the parameter that we care about right over here is the population mean, and that of course is gonna be one plus two plus three, all of that over three, which is six divided by three which is two. so, that is our population parameter. but let's say that we wanted to take samples, let's say samples of two balls at a time and every time we take a ball, we'll replace it. so each ball we take, it is an independent pick. and we're gonna use those samples of two balls at a time in order to estimate the population mean. so for example, this could be our first sample of size two and let's say in that first sample, i pick a one and let's say i pick a two. well then i can calculate the sample statistic here. in this case, it would be the sample mean which is used to estimate the population mean. and for this sample of two, it's going to be 1.5. then i can do it again. and let's say i get a one and i get a three. well now, when i calculate the sample mean, the average of one and three or the mean of one and three is going to be equal to two. let's think about all of the different scenarios of samples we can get and what the associated sample means are going to be. and then we can see the frequency of getting those sample means. and so, let me draw a little bit of a table here. so, make a table right over here. and let's see, these are the numbers that we pick and remember, when we pick one ball, we'll record that number, then we'll put it back in, and then we'll pick another ball. so these are going to be independent events and it's gonna be with replacement. and so, let's say we could pick a one and then a one. we could pick a one, then a two, a one and a three. we could pick a two and then a one. we could pick a two and a two, a two and a three. we could pick a three and a one, a three and a two or a three and a three. there's three possible balls for the first pick and three possible balls for the second 'cause we're doing it with replacement. and so, what is the sample mean in each of these for all of these combinations? so for this one, the sample mean is one. here, it is 1.5. here, it is two. here, it is 1.5. here, it is two. here, it is 2.5. here, it is two. here, it is 2.5. and then here, it is three. and so, we can now plot the frequencies of these possible sample means that we can get and that plot will be a sampling distribution of the sample means. so let's do that. so, we make a little chart right over, a little graph right over here. so these are the possible sample means. we can get a one, we can get a 1.5, we can get a two, we can get a 2.5 or we can get a three. and now let's see the frequency of it. i will put that over here. and so let's see, how many ones out of our nine possibilities we have, how many were one? well, only one of the sample means was one, and so the relative frequency, if we just set the number, we could make this line go up one or we could just say, ""hey, this is going to be one ""out of the nine possibilities."" and so let me just make that. i'll call this right over here. this is 1/9. now, what about 1.5? let's see, there's one, two of these possibilities out of nine. so, 1.5, it would look like this. this right over here is two over nine. and now, what about two? well, we can see there's one, two, three. so three out of the nine possibilities, we got a two. so we could say this is two or we could say this is 3/9, which is the same thing of course as 1/3. so this right over here is three over nine. and then what about 2.5? well, there's two 2.5's, so two out of the nine times. another way you can interpret this is when you take a random sample with replacement of two balls, you have a 2/9 chance of having a sample mean of 2.5. and then last but not least, right over here, there's one scenario out of the nine where you get two three's or 1/9. and so this right over here, this is the sampling distribution, sampling distribution, for the sample mean for n equals two or for sample size of two.",t_92cf4e58f786,t_92cf4e58f786,11
c_785d12633ada,"example showing how to use a standard normal table to estimate a p-value.  - [instructor] fay read an article that said 26% of americans can speak more than one language. she was curious if this figure was higher in her city, so she tested her null hypothesis that the proportion in her city is the same as all americans, 26%. her alternative hypothesis is it's actually greater than 26%, where p represents the proportion of people in her city that can speak more than one language. she found that 40 of 120 people sampled could speak more than one language. so what's going on is here's the population of her city, she took a sample, her sample size is 120. and then she calculates her sample proportion which is 40 out of 120 and this is going to be equal to one-third, which is approximately equal to 0.33. and then she calculates the test statistic for these results was z is approximately equal to 1.83. we do this in other videos, but just as a reminder of how she gets this, she's really trying to say well how many standard deviations above the assumed proportion, remember when we're doing these significance tests we're assuming that the null hypothesis is true and then we figure out well what's the probability of getting something at least this extreme or this extreme or more? and then if it's below a threshold, then we would reject the null hypothesis which would suggest the alternative. but that's what this z statistic is, is how many standard deviations above the assumed proportion is that? so the z statistic, and we did this in previous videos, you would find the difference between this, what we got for our sample, our sample proportion, and the assumed true proportion. so 0.33 minus 0.26, all of that over the standard deviation of the sampling distribution of the sample proportions. and we've seen that in previous videos. that is just going to be the assumed proportion, so it would be just this. it would be the assumed population proportion times one, minus the assumed population proportion over n. in this particular situation, that would be 0.26 times one, minus 0.26, all of that over our n, that's our sample size, 120. and if you calculate this, this should give us approximately 1.83. so they did all of that for us. and they say assuming that the necessary conditions are met, they're talking about the necessary conditions to assume that the sampling distribution of the sample proportions is roughly normal and that's the random condition, the normal condition, the independence condition that we have talk about in the past. what is the approximate p value? well this p value, this is the p value would be equal to the probability of in a normal distribution, we're assuming that the sampling distribution is normal 'cause we met the necessary conditions, so in a normal distribution, what is the probability of getting a z greater than or equal to 1.83? so to help us visualize this, let's visualize what the sampling distribution would look like. we're assuming it is roughly normal. the mean of the sampling distribution right over here would be the assumed population proportion, so that would be p not. when we put that little zero there that means the assumed population proportion from the null hypothesis, and that's 0.26, and this result that we got from our sample is 1.83 standard deviations above the mean of the sampling distribution. so 1.83. so that would be 1.83 standard deviations. and so what we wanna do, this probability is this area under our normal curve right here. so now let's get our z table. so notice this z table gives us the area to the left of a certain z value. we wanted it to the right of a certain z value. but a normal distribution is symmetric. so instead of saying anything greater than or equal to 1.83 standard deviations above the mean, we could say anything less than or equal to 1.83 standard deviations below the means. so this is negative 1.83. and so we could look at that on this z table right over here, negative 1.8, negative 1.83 is this right over here. so 0.0336. so there we have it. so this is approximately 0.0336 or a little over 3% or a little less than 4%. and so what fay would then do is compare that to the significance level that she should have set before conducting this significance test. and so if her significance level was say 5%, well then that situation since this is lower that that significance level, she would be able to reject the null hypothesis. she would say hey the probability of getting this result assuming that the null hypothesis is true, is below my threshold. it's quite low. and so i will reject it and it would suggest the alternative. however, if her significance level was lower than this for whatever reason, if she has say a 1% significance level, then she would fail to reject the null hypothesis.",t_92cf4e58f786,t_92cf4e58f786,11
c_a2bcc87c6d09,"hypothesis test for difference of means  in the last video, we came up with a 95% confidence interval for the mean weight loss between the low-fat group and the control group. in this video, i actually want to do a hypothesis test, really to test if this data makes us believe that the low-fat diet actually does anything at all. and to do that let's set up our null and alternative hypotheses. so our null hypothesis should be that this low-fat diet does nothing. and if the low-fat diet does nothing, that means that the population mean on our low-fat diet minus the population mean on our control should be equal to zero. and this is a completely equivalent statement to saying that the mean of the sampling distribution of our low-fat diet minus the mean of the sampling distribution of our control should be equal to zero. and that's because we've seen this multiple times. the mean of your sampling distribution is going to be the same thing as your population mean. so this is the same thing is that. that is the same thing is that. or, another way of saying it is, if we think about the mean of the distribution of the difference of the sample means, and we focused on this in the last video, that that should be equal to zero. because this thing right over here is the same thing as that right over there. so that is our null hypothesis. and our alternative hypothesis, i'll write over here. it's just that it actually does do something. and let's say that it actually has an improvement. so that would mean that we have more weight loss. so if we have the mean of group one, the population mean of group one minus the population mean of group two should be greater then zero. so this is going to be a one tailed distribution. or another way we can view it, is that the mean of the difference of the distributions, x1 minus x2 is going to be greater then zero. these are equivalent statements. because we know that this is the same thing as this, which is the same thing as this, which is what i wrote right over here. now, to do any type of hypothesis test, we have to decide on a level of significance. what we're going to do is, we're going to assume that our null hypothesis is correct. and then with that assumption that the null hypothesis is correct, we're going to see what is the probability of getting this sample data right over here. and if that probability is below some threshold, we will reject the null hypothesis in favor of the alternative hypothesis. now, that probability threshold, and we've seen this before, is called the significance level, sometimes called alpha. and here, we're going to decide for a significance level of 95%. or another way to think about it, assuming that the null hypothesis is correct, we want there to be no more than a 5% chance of getting this result here. or no more than a 5% chance of incorrectly rejecting the null hypothesis when it is actually true. or that would be a type one error. so if there's less than a 5% probability of this happening, we're going to reject the null hypothesis. less than a 5% probability given the null hypothesis is true, then we're going to reject the null hypothesis in favor of the alternative. so let's think about this. so we have the null hypothesis. let me draw a distribution over here. the null hypothesis says that the mean of the differences of the sampling distributions should be equal to zero. now, in that situation, what is going to be our critical region here? well, we need a result, so we're going to need some critical value here. because this isn't a normalized normal distribution. but there's some critical value here. the hardest thing is statistics is getting the wording right. there's some critical value here that the probability of getting a sample from this distribution above that value is only 5%. so we just need to figure out what this critical value is. and if our value is larger than that critical value, then we can reject the null hypothesis. because that means the probability of getting this is less than 5%. we could reject the null hypothesis and go with the alternative hypothesis. remember, once again, we can use z-scores, and we can assume this is a normal distribution because our sample size is large for either of those samples. we have a sample size of 100. and to figure that out, the first step, if we just look at a normalized normal distribution like this, what is your critical z value? we're getting a result above that z value, only has a 5% chance. so this is actually cumulative. so this whole area right over here is going to be 95% chance. we can just look at the z table. we're looking for 95% percent. we're looking at the one tailed case. so let's look for 95%. this is the closest thing. we want to err on the side of being a little bit maybe to the right of this. so let's say 95.05 is pretty good. so that's 1.65. so this critical z value is equal to 1.65. or another way to view it is, this distance right here is going to be 1.65 standard deviations. i know my writing is really small. i'm just saying the standard deviation of that distribution. so what is the standard deviation of that distribution? we actually calculated it in the last video, and i'll recalculate it here. the standard deviation of our distribution of the difference of the sample means is going to be equal to the square root of the variance of our first population. now, the variance of our first population, we don't know it. but we could estimate it with our sample standard deviation. if you take your sample standard deviation, 4.67 and you square it, you get your sample variance. and so this is the variance. this is our best estimate of the variance of the population. and we want to divide that by the sample size. and then plus our best estimate of the variance of the population of group two, which is 4.04 squared. the sample standard deviation of group two squared. that gives us variance divided by 100. i did before in the last. maybe it's still sitting on my calculator. yes, it's still sitting on the calculator. it's this quantity right up here. 4.67 squared divided by 100 plus 4.04 squared divided by 100. so it's 0.617. so this right here is going to be 0.617. so this distance right here, is going to be 1.65 times 0.617. so let's figure out what that is. so let's take 0.617 times 1.65. so it's 1.02. this distance right here is 1.02. so what this tells us is, if we assume that the diet actually does nothing, there's a only a 5% chance of having a difference between the means of these two samples to have a difference of more than 1.02. there's only a 5% chance of that. well, the mean that we actually got is 1.91. so that's sitting out here someplace. so it definitely falls in this critical region. the probability of getting this, assuming that the null hypothesis is correct, is less than 5%. so it's smaller probability than our significance level. actually, let me be very clear. the significance level, this alpha right here, needs to be 5%. not the 95%. i think i might have said here. but i wrote down the wrong number there. i subtracted it from one by accident. probably in my head. but anyway, the significance level is 5%. the probability given that the null hypothesis is true, the probability of getting the result that we got, the probability of getting that difference, is less than our significance level. it is less than 5%. so based on the rules that we set out for ourselves of having a significance level of 5%, we will reject the null hypothesis in favor of the alternative that the diet actually does make you lose more weight.",t_92cf4e58f786,t_92cf4e58f786,11
c_b1b49106a88c,"thinking about the different ways we can pick officers in order to find the probability of one situation in particular.  a club of nine people wants to choose a board of three officers, president, vice president, and secretary. assuming the officers are chosen at random, what is the probability that the officers are marcia for president, sabita for vice president, and robert for secretary? so to think about the probability of marcia-- so let me write this-- president is equal to marcia, or vice president is equal to sabita, and secretary is equal to robert. this, right here, is one possible outcome, one specific outcome. so it's one outcome out of the total number of outcomes, over the total number of possibilities. now what is the total number of possibilities? well to think about that, let's just think about the three positions. you have president, you have vice president, and you have secretary. now let's just assume that we're going to fill the slot of president first. we don't have to do president first, but we're just going to pick here. so if we're just picking president first, we haven't assigned anyone to any officers just yet, so we have nine people to choose from. so there are nine possibilities here. now, when we go to selecting our vice president, we would have already assigned one person to the president. so we only have eight people to pick from. and when we assign our secretary, we would've already assigned our president and vice president, so we're only going to have seven people to pick from. so the total permutations here or the total number of possibilities, or the total number of ways, to pick president, vice president, and secretary from nine people, is going to be 9 times 8 times 7. which is, let's see, 9 times 8 is 72. 72 times 7, 2 times 7 is 14, 7 times 7 is 49 plus 1 is 50. so there's 504 possibilities. so to answer the question, the probability of marcia being president, sabita being vice president, and robert being secretary is 1 over the total number of possibilities, which is 1 over 504. that's the probability.",t_92cf4e58f786,t_92cf4e58f786,11
c_8a1f96d1258e,"probability for a geometric random variable being greater than a certain value.  - [instructor] emelia registers vehicles for the department of transportation. sports utility vehicles, also known as suvs, make up 12% of the vehicles she registers. let v be the number of vehicles emelia registers in a day until she first registers an suv. assume the type of each vehicle is independent. find the probability that emelia registers more than four, more than four, vehicles before she registers an suv. so, let's just first think about what this random variable v is. so, it's the number of vehicles emelia registers in a day, until she registers an suv. so, for example if the first person who walks in the line or through the door, has an suv and they're trying to register it, then v would be equal to one. if the first person isn't an suv, but the second person is, then v would be equal to two, so forth and so on. so, this right over here is a classic geometric random variable, right over here. so, geometric random variable. we have a very clear success metric for each trial. do we have a suv or not? each trial is independent, they tell us that. they are independent. the probability of success in each trial is constant. we have a 12% success for each new person who comes through the line. now the reason this is not a binomial random variable, is that we do not have a finite number of trials. here, we're gonna keep performing trials. we're gonna keep serving people in the line, until we get an suv. and so, what we have over here, when they say find the probability that emelia registers more than four vehicles before she registers an suv. this is the probability that v is greater than four. so, i encourage you like always, pause this video and see if you can work through it. and we're gonna assume, she's not just gonna leave her, i guess her desk, or wherever the things are being registered. she's not going to leave the counter until someone shows up registering an suv. so, we will just keep looking at people, i guess we could say over multiple days, forever. she'll work for an infinite number of years, just for the sake of this problem, until an suv actually shows up. so, try to figure this out. alright, i'm assuming you've had a go and some of you might said, well, isn't this going to be equal to the probability that v is equal to five, plus the probability that v is equal to six, plus the probability that v is equal to seven, and it just goes on and on and on forever. and this is actually true. and you say, well, how do i calculate this? i'm just summing up an infinite number of things. now the key realization here, is that one way to think about the probability that v is greater than four, is this is the same thing as the probability that v is not less than or equal to four, these two things are equivalent. so, what's the probability that v is not less than or equal to four? this might be a slightly easier thing for you to calculate. once again, pause the video and see if you can figure it out. well what's the probability that v is not less than or equal to four? well that's the same thing as the probability of first four customers, or first four, i guess people. first four, i'll say customers, or i'll say first four cars. the customer's cars, not suvs. so, this one is feeling pretty straightforward. what's the probability that for each customer she goes to, that they're not an suv? well that's one minus 12%, or 88%, or 0.88. and if we want to know the probability of the first four cars are not suvs. well that's 0.88 to the fourth power. and so that's all we have to calculate. and so let's get our calculator out. and say i'm going to get, oops. i'm going to get 0.88 and i'm going to raise it to the fourth power and i get, and i'm just going to round it to, the nearest, let's see, do they tell me to round it? okay, i'll just round it to the nearest, i guess 100th, well, i'll just write it as 0.5997. is approximately equal to, 0.5997. if you wanted to write this as a percentage it would be approximately 59.97%. so a little bit better than half, than a 50% shot, a little less than a two-thirds shot, that she is going to have to see more than four customers until she sees an suv.",t_92cf4e58f786,t_92cf4e58f786,11
c_e196531ffd1e,"sal introduces the magic behind the law of large numbers.  let's learn a little bit about the law of large numbers, which is on many levels, one of the most intuitive laws in mathematics and in probability theory. but because it's so applicable to so many things, it's often a misused law or sometimes, slightly misunderstood. so just to be a little bit formal in our mathematics, let me just define it for you first and then we'll talk a little bit about the intuition. so let's say i have a random variable, x. and we know its expected value or its population mean. the law of large numbers just says that if we take a sample of n observations of our random variable, and if we were to average all of those observations-- and let me define another variable. let's call that x sub n with a line on top of it. this is the mean of n observations of our random variable. so it's literally this is my first observation. so you can kind of say i run the experiment once and i get this observation and i run it again, i get that observation. and i keep running it n times and then i divide by my number of observations. so this is my sample mean. this is the mean of all the observations i've made. the law of large numbers just tells us that my sample mean will approach my expected value of the random variable. or i could also write it as my sample mean will approach my population mean for n approaching infinity. and i'll be a little informal with what does approach or what does convergence mean? but i think you have the general intuitive sense that if i take a large enough sample here that i'm going to end up getting the expected value of the population as a whole. and i think to a lot of us that's kind of intuitive. that if i do enough trials that over large samples, the trials would kind of give me the numbers that i would expect given the expected value and the probability and all that. but i think it's often a little bit misunderstood in terms of why that happens. and before i go into that let me give you a particular example. the law of large numbers will just tell us that-- let's say i have a random variable-- x is equal to the number of heads after 100 tosses of a fair coin-- tosses or flips of a fair coin. first of all, we know what the expected value of this random variable is. it's the number of tosses, the number of trials times the probabilities of success of any trial. so that's equal to 50. so the law of large numbers just says if i were to take a sample or if i were to average the sample of a bunch of these trials, so you know, i get-- my first time i run this trial i flip 100 coins or have 100 coins in a shoe box and i shake the shoe box and i count the number of heads, and i get 55. so that would be x1. then i shake the box again and i get 65. then i shake the box again and i get 45. and i do this n times and then i divide it by the number of times i did it. the law of large numbers just tells us that this the average-- the average of all of my observations, is going to converge to 50 as n approaches infinity. or for n approaching 50. i'm sorry, n approaching infinity. and i want to talk a little bit about why this happens or intuitively why this is. a lot of people kind of feel that oh, this means that if after 100 trials that if i'm above the average that somehow the laws of probability are going to give me more heads or fewer heads to kind of make up the difference. that's not quite what's going to happen. that's often called the gambler's fallacy. let me differentiate. and i'll use this example. so let's say-- let me make a graph. and i'll switch colors. this is n, my x-axis is n. this is the number of trials i take. and my y-axis, let me make that the sample mean. and we know what the expected value is, we know the expected value of this random variable is 50. let me draw that here. this is 50. so just going to the example i did. so when n is equal to-- let me just [inaudible] here. so my first trial i got 55 and so that was my average. i only had one data point. then after two trials, let's see, then i have 65. and so my average is going to be 65 plus 55 divided by 2. which is 60. so then my average went up a little bit. then i had a 45, which will bring my average down a little bit. i won't plot a 45 here. now i have to average all of these out. what's 45 plus 65? let me actually just get the number just so you get the point. so it's 55 plus 65. it's 120 plus 45 is 165. divided by 3. 3 goes into 165 5-- 5 times 3 is 15. it's 53. no, no, no. 55. so the average goes down back down to 55. and we could keep doing these trials. so you might say that the law of large numbers tell this, ok, after we've done 3 trials and our average is there. so a lot of people think that somehow the gods of probability are going to make it more likely that we get fewer heads in the future. that somehow the next couple of trials are going to have to be down here in order to bring our average down. and that's not necessarily the case. going forward the probabilities are always the same. the probabilities are always 50% that i'm going to get heads. it's not like if i had a bunch of heads to start off with or more than i would have expected to start off with, that all of a sudden things would be made up and i would get more tails. that would the gambler's fallacy. that if you have a long streak of heads or you have a disproportionate number of heads, that at some point you're going to have-- you have a higher likelihood of having a disproportionate number of tails. and that's not quite true. what the law of large numbers tells us is that it doesn't care-- let's say after some finite number of trials your average actually-- it's a low probability of this happening, but let's say your average is actually up here. is actually at 70. you're like, wow, we really diverged a good bit from the expected value. but what the law of large numbers says, well, i don't care how many trials this is. we have an infinite number of trials left. and the expected value for that infinite number of trials, especially in this type of situation is going to be this. so when you average a finite number that averages out to some high number, and then an infinite number that's going to converge to this, you're going to over time, converge back to the expected value. and that was a very informal way of describing it, but that's what the law or large numbers tells you. and it's an important thing. it's not telling you that if you get a bunch of heads that somehow the probability of getting tails is going to increase to kind of make up for the heads. what it's telling you is, is that no matter what happened over a finite number of trials, no matter what the average is over a finite number of trials, you have an infinite number of trials left. and if you do enough of them it's going to converge back to your expected value. and this is an important thing to think about. but this isn't used in practice every day with the lottery and with casinos because they know that if you do large enough samples-- and we could even calculate-- if you do large enough samples, what's the probability that things deviate significantly? but casinos and the lottery every day operate on this principle that if you take enough people-- sure, in the short-term or with a few samples, a couple people might beat the house. but over the long-term the house is always going to win because of the parameters of the games that they're making you play. anyway, this is an important thing in probability and i think it's fairly intuitive. although, sometimes when you see it formally explained like this with the random variables and that it's a little bit confusing. all it's saying is that as you take more and more samples, the average of that sample is going to approximate the true average. or i should be a little bit more particular. the mean of your sample is going to converge to the true mean of the population or to the expected value of the random variable. anyway, see you in the next video.",t_92cf4e58f786,t_92cf4e58f786,11
c_9b23845a36a3,"sal breaks down how to create the probability distribution of the number of ""heads"" after 3 flips of a fair coin.  voiceover:let's say we define the random variable capital x as the number of heads we get after three flips of a fair coin. so given that definition of a random variable, what we're going to try and do in this video is think about the probability distributions. so what is the probability of the different possible outcomes or the different possible values for this random variable. we'll plot them to see how that distribution is spread out amongst those possible outcomes. so let's think about all of the different values that you could get when you flip a fair coin three times. so you could get all heads, heads, heads, heads. you could get heads, heads, tails. you could get heads, tails, heads. you could get heads, tails, tails. you could have tails, heads, heads. you could have tails, head, tails. you could have tails, tails, heads. and then you could have all tails. so there's eight equally, when you do the actual experiment there's eight equally likely outcomes here. but which of them, how would these relate to the value of this random variable? so let's think about, what's the probability, there is a situation where you have zero heads. so what's the probably that our random variable x is equal to zero? well, that's this situation right over here where you have zero heads. it's one out of the eight equally likely outcomes. so that is going to be 1/8. what's the probability that our random variable capital x is equal to one? well, let's see. which of these outcomes gets us exactly one head? we have this one right over here. we have that one right over there. we have this one right over there. and i think that's all of them. so three out of the eight equally likely outcomes provide us, get us to one head, which is the same thing as saying that our random variable equals one. so this has a 3/8 probability. so what's the probability, i think you're getting, maybe getting the hang of it at this point. what's the probability that the random variable x is going to be equal to two? well, for x to be equal to two, we must, that means we have two heads when we flip the coins three times. so that's this outcome meets this constraint. this outcome would get our random variable to be equal to two. and this outcome would make our random variable equal to two. and this is three out of the eight equally likely outcomes. so this has a 3/8 probability. and then finally we could say what is the probability that our random variable x is equal to three? well, how does our random variable x equal three? well we have to get three heads when we flip the coin. so there's only one out of the eight equally likely outcomes that meets that constraint. so it's a 1/8 probability. so now we just have to think about how we plot this, to see how this is distributed. so let me draw... so over here on the vertical axis this will be the probability. probability. and it's going to be between zero and one. you can't have a probability larger than one. so just like this. so let's see, if this is one right over here, and let's see everything here looks like it's in eighths so let's put everything in terms of eighths. so that's half. this is a fourth. that's a fourth. that's not quite a fourth. this is a fourth right over here. and then we can do it in terms of eighths. so that's a pretty good approximation. and then over here we can have the outcomes. outcomes. and so outcomes, i'll say outcomes for alright let's write this so value for x so x could be zero actually let me do those same colors, x could be zero. x could be one. x could be two. x could be equal to two. x could be equal to three. x could be equal to three. so these are the possible values for x. and now we're just going to plot the probability. the probability that x has a value of zero is 1/8. that's, i'll make a little bit of a bar right over here that goes up to 1/8. so let draw it like this. so goes up to, so this is 1/8 right over here. the probability that x equals one is 3/8. so 2/8, 3/8 gets us right over let me do that in the purple color so probability of one, that's 3/8. that's right over there. that's 3/8. so let me draw that bar, draw that bar. and just like that. the probability that x equals two. the probability that x equals two is also 3/8. so that's going to be on the same level. just like that. and then, the probability that x equals three well that's 1/8. so it's going to the same height as this thing over here. i'm using the wrong color. so it's going to look like this. it's going to look like this. and actually let me just write this a little bit neater. i can write that three. cut and paste. move that three a little closer in so that it looks a little bit neater. and i can actually move that two in actually as well. so cut and paste. so i can move that two. and there you have it! we have made a probability distribution for the random variable x. and the random variable x can only take on these discrete values. it can't take on the value half or the value pi or anything like that. so this, what we've just done here is constructed a discrete probability distribution. let me write that down. so this is a discrete, it only, the random variable only takes on discrete values. it can't take on any values in between these things. so discrete probability. probability distribution. distribution for our random variable x.",t_92cf4e58f786,t_92cf4e58f786,11
c_c0abe8099953,"sal determines if the results of an experiment about advertising are statistically significant.  voiceover:in an experiment aimed at studying the effect of advertising on eating behavior in children, a group of 500 children, seven to 11 years old were randomly assigned to two different groups. after randomization, each child was asked to watch a cartoon in a private room, containing a large bowl of goldfish crackers. the cartoon included two commercial breaks. the first group watched food commercials, mostly snacks while the second group watched non-food commercials, games and entertainment products. once the child finished watching the cartoon, the conductors of the experiment weighed the cracker bowls to measure how many grams of crackers the child ate. they found that the mean amount of crackers eaten by the children who watched food commercials is 10 grams greater than the mean amount of crackers eaten by the children who watched non-food commercials. let's just think about what happens up to this point. they took 500 children and then they randomly assigned them to two different groups. you have group one over here and you have group two. let's say that this right over here is the first group. the first group watched food commercials. this is group number one. they watched food commercials. we could call this the treatment group. we're trying to see what's the effect of watching food commercials and then they tell us. the second group watched non-food commercials, so this is the control group. number two, this is non-food commercials. this is the control right over here. once the child finished watching the cartoon, for each child they weighed how much of the crackers they ate and then they took the mean of it and they found that the mean here that the kids ate 10 grams greater on average than this group right over here which just looking at that data makes you believe that okay, well something maybe happened over here. that maybe the treatment from watching the food commercials made the students eat more of the goldfish crackers but the question that you always have to ask yourself in a situation like this. well, isn't there some probability that this would have happened by chance that even if you didn't make them watch the commercials. if these were just two random groups and you didn't make either group watch a commercial, you made them all watch the same commercials. there's some chance that the mean of one group could be dramatically different than the other one. it just happened to be in this experiment that the mean here that it looks like the kids ate 10 grams more. how do you figure out, what's the probability that this could have happened, that the 10 grams greater in mean amount eaten here that that could have just happened by chance. well the way you do it is what they do right over here. using a simulator, they re-randomize the results into two new groups and measure the difference between the means of the new groups. they repeated the simulation 150 times and plotted the differences given. the resulting difference is as given below. what they did is they said, okay, they have 500 kids and each kid, they had 500 children. number one, two, three, all the way up to 500. for each child they measured how much was the weight of the crackers that they ate? maybe child one ate two grams and child two ate four grams and child three ate, i don't know, ate 12 grams all the way to child number 500 ate, i don't know, maybe they didn't eat anything at all, ate zero grams. we already know, let's say the first time around. the first half was in the treatment group when we're just ranking them like this and then the second, they're randomly assigned into these groups and at the second half was in the control group. what they're doing now is they're taking the same results and they're re-randomizing it. now they're saying, okay, let's maybe put this person in group number two and this person in group number two and this person stays in group number two and this person stays in group number one and this person stays in group number one. now they're completely mixing up all of the results that they had. it's completely random of whether the student had watched the food commercial or the non-food commercial and then they're testing what's the mean of the new number one group and the new number two group. they're saying well, what is the distribution of the differences in means. they see when they did this way when they're essentially just completely randomly taking these results and putting them into two new buckets. you have a bunch of cases where you get no difference in the means. out of the 150 times that they repeated the simulation doing this little exercise here. one, two, three, four, five, six, seven, eight, nine, 10, 11, 12, 13, 14, 15. i'm having trouble counting this let's see. one, two, three, four, five, six, seven, eight, nine, 10, 11, 12. it's so small, i'm aging but it looks like there's about, i don't know. high teens about 20 times when there's actually no noticeable difference in the means of the groups where you just randomly allocate the results amongst the two groups. when you look at this, if it was just, if you just randomly put people into two groups, the probability or the situations where you get a 10 gram difference are actually very unlikely. let's see, is this the difference? the difference between the means of the new groups. it's not clear whether this is group one minus group two or group two minus group one but in either case the situations where you have a 10 gram difference in mean. it's only two out of the 150 times. when you do it randomly, when you just randomly put these results into two groups, the probability of the means being this different, it only happens two out of the 150 times. there's a 150 dots here. that is on the order of 2% or actually it's less than 2%, it's between one and 2%. let's say the situation we're talking about. let's say that this is group one minus group two in terms of how much was eaten and so you're looking at this situation right over here that that's only one out of a 150 times. it happened less frequently than one in a 100 times. it happened only one in a 150 times. if you look at that, you say well, the probability this was just random. the probability of getting the results that you got is less than 1%. to me and then to most statisticians, that tells us that our experiment was significant, that the probability of getting the results that you got. the children who watched food commercials being 10 grams greater than the mean amount of crackers eaten by the children who watched non-food commercials. if you just randomly put 500 kids into two different buckets based on the simulation results it looks like there's only, if you'd run the simulation a 150 times, that only happened one out of the 150 times. it seems like this was very, it's very unlikely that this was purely due to chance. if this was just a chance event, this would only happen roughly one in 150 times but the fact that this happened in your experiment, it makes you feel pretty confident that your experiment is significant. in most studies, in most experiments, the threshold that they think about is the probability of something statistically significant. if the probability of that happening by chance is less than 5%, this is less than 1%. i would definitely say that the experiment is significant.",t_92cf4e58f786,t_92cf4e58f786,11
c_ac2c43847012,"the central limit theorem and the sampling distribution of the sample mean  in the last video, we learned about what is quite possibly the most profound idea in statistics, and that's the central limit theorem. and the reason why it's so neat is, we could start with any distribution that has a well defined mean and variance-- actually, i wrote the standard deviation here in the last video, that should be the mean, and let's say it has some variance. i could write it like that, or i could write the standard deviation there. but as long as it has a well defined mean and standard deviation, i don't care what the distribution looks like. what i can do is take samples-- in the last video of say, size four-- that means i take literally four instances of this random variable, this is one example. i take their mean, and i consider this the sample mean from my first trial, or you could almost say for my first sample. i know it's very confusing, because you can consider that a sample, the set to be a sample, or you could consider each member of the set is a sample. so that can be a little bit confusing there. but i have this first sample mean, and then i keep doing that over and over. in my second sample, my sample size is four. i got four instances of this random variable, i average them, i have another sample mean. and the cool thing about the central limit theorem, is as i keep plotting the frequency distribution of my sample means, it starts to approach something that approximates the normal distribution. and it's going to do a better job of approximating that normal distribution as n gets larger. and just so we have a little terminology on our belt, this frequency distribution right here that i've plotted out, or here, or up here that i started plotting out, that is called-- and it's kind of confusing, because we use the word sample so much-- that is called the sampling distribution of the sample mean. and let's dissect this a little bit, just so that this long description of this distribution starts to make a little bit of sense. when we say it's the sampling distribution, that's telling us that it's being derived from-- it's a distribution of some statistic, which in this case happens to be the sample mean-- and we're deriving it from samples of an original distribution. so each of these. so this is my first sample, my sample size is four. i'm using the statistic, the mean. i actually could have done it with other things, i could have done the mode or the range or other statistics. but sampling distribution of the sample mean is the most common one. it's probably, in my mind, the best place to start learning about the central limit theorem, and even frankly, sampling distribution. so that's what it's called. and just as a little bit of background-- and i'll prove this to you experimentally, not mathematically, but i think the experimental is on some levels more satisfying with statistics-- that this will have the same mean as your original distribution. as your original distribution right here. so it has the same mean, but we'll see in the next video that this is actually going to start approximating a normal distribution, even though my original distribution that this is kind of generated from, is completely non-normal. so let's do that with this app right here. and just to give proper credit where credit is due, this is-- i think was developed at rice university-- this is from onlinestatbook.com. this is their app, which i think is a really neat app, because it really helps you to visualize what a sampling distribution of the sample mean is. so i can literally create my own custom distribution here. so let me make something kind of crazy. so you could do this, in theory, with a discrete or a continuous probability density function. but what they have here, we could take on one of 32 values, and i'm just going to set the different probabilities of getting any of those 32 values. so clearly, this right here is not a normal distribution. it looks a little bit bimodal, but it doesn't have long tails. but what i want to do is, first just use a simulation to understand, or to better understand, what the sampling distribution is all about. so what i'm going to do is, i'm going to take-- we'll start with-- five at a time. so my sample size is going to be five. and so when i click animated, what it's going to do, is it's going to take five samples from this probability distribution function. it's going to take five samples, and you're going to see them when i click animated, it's going to average them and plot the average down here. and then i'm going to click it again, and it's going to do it again. so there you go, it got five samples from there, it averaged them, and it hit there. so what i just do? i clicked-- oh, i wanted to clear that. let me make this bottom one none. so let me do that over again. so i'm going to take five at time. so i took five samples from up here, and then it took its mean and plotted the mean there. let me do it again. five samples from this probability distribution function, plotted it right there. i could keep doing it. it'll take some time. but you can see i plotted it right there. now i could do this 1,000 times, it's going to take forever. let's say i just wanted to do it 1,000 times. so this program, just to be clear, it's actually generating the random numbers. this isn't like a rigged program. it's actually going to generate the random numbers according to this probability distribution function. it's going to take five at a time, find their means, and plot the means. so if i click 10,000, it's going to do that 10,000 times. so it's going to take five numbers from here 10,000 times and find their means 10,000 times and then plot the 10,000 means here. so let's do that. so there you go. and notice it's already looking a lot like a normal distribution. and like i said, the original mean of my crazy distribution here was 14.45, and after doing 10,000 samples-- or 10,000 trials-- my mean here is 14.42. so i'm already getting pretty close to the mean there. my standard deviation, you might notice, is less than that. we'll talk about that in a future video. and the skew and kurtosis, these are things that help us measure how normal a distribution is. and i've talked a little bit about it in the past, and let me actually just diverge a little bit, it's interesting. and they're fairly straightforward concepts. skew literally tells-- so if this is-- let me do it in a different color-- if this is a perfect normal distribution-- and clearly my drawing is very far from perfect-- if that's a perfect distribution, this would have a skew of zero. if you have a positive skew, that means you have a larger right tail than you would otherwise expect. so something with a positive skew might look like this. it would have a large tail to the right. so this would be a positive skew, which makes it a little less than ideal for normal distribution. and a negative skew would look like this, it has a long tail to the left. so negative skew might look like that. so that is a negative skew. if you have trouble remembering it, just remember which direction the tail is going. this tail is going towards a negative direction, this tail is going to the positive direction. so if something has no skew, that means that it's nice and symmetrical around its mean. now kurtosis, which sounds like a very fancy word, is similarly not that fancy of an idea. so once again, if i were to draw a perfect normal distribution. remember, there is no one normal distribution, you could have different means and different standard deviations. let's say that's a perfect normal distribution. if i have positive kurtosis, what's going to happen is, i'm going to have fatter tails-- let me draw it a little nicer than that-- i'm going to have fatter tails, but i'm going to have a more pointy peak. i didn't have to draw it that pointy, let me draw it like this. i'm going to have fatter tails, and i'm going to have a more pointy peak than a normal distribution. so this right here is positive kurtosis. so something that has positive kurtosis-- depending on how positive it is-- it tells you it's a little bit more pointy than a real normal distribution. and negative kurtosis has smaller tails, but it's smoother near the middle. so it's like this. so something like this would have negative kurtosis. and maybe in future videos we'll explore that in more detail, but in the context of the simulation, it's just telling us how normal this distribution is. so when our sample size was n equal 5 and we did 10,000 trials, we got pretty close to a normal distribution. let's do another 10,000 trials, just to see what happens. it looks even more like a normal distribution. our mean is now the exact same number, but we still have a little bit of skew, and a little bit of kurtosis. now let's see what happens if we do the same thing with a larger sample size. and we could actually do them simultaneously. so here's n equal 5. let's do here, n equals 25. just let me clear them. i'm going to do the sampling distribution of the sample mean. and i'm going to run 10,000 trials-- i'll do one animated trial, just so you remember what's going on. so i'm literally taking first five samples from up here, find their mean. now i'm taking 25 samples from up here, find its mean, and then plotting it down here. so here the sample size is 25, here it's five. i'll do it one more time. i take five, get the mean, plot it. take 25, get the mean, and then plot it down there. this is a larger sample size. now that thing that i just did, i'm going to do 10,000 times. and remember, our first distribution was just this really crazy very non-normal distribution, but once we did it-- whoops, i didn't want to make it that big. scroll up a little bit. so here, what's interesting? i mean they both look a little normal, but if you look at the skew and the kurtosis, when our sample size is larger, it's more normal. this has a lower skew than when our sample size was only five. and it has a less negative kurtosis than when our sample size was five. so this is a more normal distribution. and one thing that we're going to explore further in a future video, is not only is it more normal in its shape, but it's also tighter fit around the mean. and you can even think about why that kind of makes sense. when your sample size is larger, your odds of getting really far away from the mean is lower. because it's very low likelihood, if you're taking 25 samples, or 100 samples, that you're just going to get a bunch of stuff way out here, or a bunch of stuff way out here. you're very likely to get a reasonable spread of things. so it makes sense that your mean-- your sample mean-- is less likely to be far away from the mean. we're going to talk a little bit more about in the future. but hopefully this kind of satisfies you that-- at least experimentally, i haven't proven it to you with mathematical rigor, which hopefully we'll do in the future. but hopefully this satisfies you, at least experimentally, that the central limit theorem really does apply to any distribution. i mean, this is a crazy distribution. and i encourage you to use this applet at onlinestatbook.com and experiment with other crazy distributions to believe it for yourself. but the interesting things are that we're approaching a normal distribution, but as my sample size got larger, it's a better fit for a normal distribution.",t_92cf4e58f786,t_92cf4e58f786,11
c_18093c2d076a,"find the number of ways you can put four types of flowers into three types of pots.  - [voiceover] you're at a florist store and you're interested in buying some type of a potted flower. and you ask the florist, ""what type of flowers do you sell?"" and he says, ""well we sell four types of flowers, we sell ""roses, tulips, sunflowers, and lilies."" and you say, ""what type of pots could i put them in?"" and he says, ""well you could pick any flower, and then you ""could pick any of our three pots, we have brown pots, ""we have yellow pots, and we have green pots."" so, the question that i ask to you is, how many types of, i guess, flower and pots put together can you walk out of this florist store with? for example, you could get a rose and a brown pot, you could get a rose and a green pot. or you could get a yellow pot that has a sunflower in it. or a yellow pot that has a lily in it. so, how many scenarios could you walk out of that store with? and like always, i'll encourage you to pause the video and try to figure it out on your own. let's think through it. i'll just write the first letters, just to visualize or just so i don't have to write down everything. so, you could have a brown pot, you could have a yellow pot, or you could have a green pot. you difinitely have to pick a pot, so you're going to have one of those. and then for each of these three, there's four possible flowers you could have. you could have a rose with the brown pot, you could have a rose with the yellow pot, you could have a rose with the green pot. you could have a tulip with the brown pot, a tulip with the yellow pot, a tulip with the green pot. you could have a sunflower with each of the three pots, or you could have a lily with the brown pot, a lily with the yellow pot, and a lily with a green pot. so, how many scenarios are we talking about? well, we had three pots, so we have three pots right over here, and we have four possible flowers to put in the pots, and so we see that we have four possible flowers for each of the three pots. it's going to be three times four possibilites, or 12. you see them right over here. this is brown with rose, brown with tulip, brown with sunflower, brown with lily. yellow with rose, yellow with tulip, yellow with sunflower, yellow with lily. so, if we count these, one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve. twelve possible pot, flower scenarios to walk out of that florist store with.",t_92cf4e58f786,t_92cf4e58f786,11
c_4aeb1dd1f982,"a kenn borek basler (turbo dc-3) taxis, takes-off, and flies low back over the field at williams airfield outside mcmurdo station, antarctica",t_a6554500a6df,t_a6554500a6df,12
c_5cbcd90c9885,"in this webcast, we speak with ice stories correspondent howie koss, a member of the offshore new harbor expedition.",t_a6554500a6df,t_a6554500a6df,12
c_55e69337d8a8,"landings and take-offs of helicopters, a twin otter airplane, a lc-130 hercules transport plane; and a shot of a hagglund tracked vehicle. transportation used in greenland to do scientific research.",t_a6554500a6df,t_a6554500a6df,12
c_55307d1bd087,join exploratorium senior scientist paul doherty once more as he serves up hands-on activities related to antarctic science.,t_a6554500a6df,t_a6554500a6df,12
c_7517e0c08f20,"in this live webcast, we look deeper into the film 'ice people.'  we speak with noted geologists allan ashworth and adam lewis, and filmmaker anne aghion in our san francisco studio.",t_a6554500a6df,t_a6554500a6df,12
c_d74a93b7d34f,"chapter 55 of the book on javascript.chapter 55: fetch method  options  details the http method to use for the request. ex: get, post, put, delete, head. defaults to get.  headers  a headers object containing additional http headers to include in the request.  body  the request payload, can be a string or a formdata object. defaults to undefined  cache  the caching mode. default, reload, no-cache  referrer  the referrer of the request.  mode  cors, no-cors, same-origin. defaults to no-cors.  credentials omit, same-origin, include. defaults to omit. redirect  follow, error, manual. defaults to follow.  integrity  associated integrity metadata. defaults to empty string.  section 55.1: getting json data // get some data from stackoverflow fetch(""https://api.stackexchange.com/2.2/questions/featured?order=desc&sort=activity&site=stackover flow"") .then(resp => resp.json()) .then(json => console.log(json)) .catch(err => console.log(err));  section 55.2: set request headers fetch('/example.json', { headers: new headers({ 'accept': 'text/plain', 'x-your-custom-header': 'example value' }) });  section 55.3: post data posting form data fetch(`/example/submit`, { method: 'post', body: new formdata(document.getelementbyid('example-form')) });  posting json data fetch(`/example/submit.json`, { method: 'post', body: json.stringify({ email: document.getelementbyid('example-email').value, comment: document.getelementbyid('example-comment').value }) });  goalkicker.com – javascript® notes for professionals  309  section 55.4: send cookies the fetch function does not send cookies by default. there are two possible ways to send cookies: 1. only send cookies if the url is on the same origin as the calling script. fetch('/login', { credentials: 'same-origin' })  2. always send cookies, even for cross-origin calls. fetch('https://otherdomain.com/login', { credentials: 'include' })  section 55.5: globalfetch the globalfetch interface exposes the fetch function, which can be used to request resources. fetch('/path/to/resource.json') .then(response => { if (!response.ok()) { throw new error(""request failed!""); } return response.json(); }) .then(json => { console.log(json); });  the resolved value is a response object. this object contains the body of the response, as well as its status and headers.  section 55.6: using fetch to display questions from the stack overﬂow api const url = 'http://api.stackexchange.com/2.2/questions?site=stackoverflow&tagged=javascript'; const questionlist = document.createelement('ul'); document.body.appendchild(questionlist); const responsedata = fetch(url).then(response => response.json()); responsedata.then(({items, has_more, quota_max, quota_remaining}) => { for (const {title, score, owner, link, answer_count} of items) { const listitem = document.createelement('li'); questionlist.appendchild(listitem); const a = document.createelement('a'); listitem.appendchild(a); a.href = link; a.textcontent = `[${score}] ${title} (by ${owner.display_name || 'somebody'})` } });  goalkicker.com – javascript® notes for professionals  310",t_a765d0035891,t_a765d0035891,13
c_0bf89cca1306,"chapter 56 of the book on javascript.chapter 56: scope section 56.1: closures when a function is declared, variables in the context of its declaration are captured in its scope. for example, in the code below, the variable x is bound to a value in the outer scope, and then the reference to x is captured in the context of bar: var x = 4; // declaration in outer scope function bar() { console.log(x); // outer scope is captured on declaration } bar(); // prints 4 to console  sample output: 4 this concept of ""capturing"" scope is interesting because we can use and modify variables from an outer scope even after the outer scope exits. for example, consider the following: function foo() { var x = 4; // declaration in outer scope function bar() { console.log(x); // outer scope is captured on declaration } return bar; // x goes out of scope after foo returns } var barwithx = foo(); barwithx(); // we can still access x  sample output: 4 in the above example, when foo is called, its context is captured in the function bar. so even after it returns, bar can still access and modify the variable x. the function foo, whose context is captured in another function, is said to be a closure. private data this lets us do some interesting things, such as deﬁning ""private"" variables that are visible only to a speciﬁc function or set of functions. a contrived (but popular) example: function makecounter() { var counter = 0; return { value: function () { return counter;  goalkicker.com – javascript® notes for professionals  311  }, increment: function () { counter++; } }; } var a = makecounter(); var b = makecounter(); a.increment(); console.log(a.value()); console.log(b.value());  sample output: 10 when makecounter() is called, a snapshot of the context of that function is saved. all code inside makecounter() will use that snapshot in their execution. two calls of makecounter() will thus create two diﬀerent snapshots, with their own copy of counter. immediately-invoked function expressions (iife) closures are also used to prevent global namespace pollution, often through the use of immediately-invoked function expressions. immediately-invoked function expressions (or, perhaps more intuitively, self-executing anonymous functions) are essentially closures that are called right after declaration. the general idea with iife's is to invoke the side-eﬀect of creating a separate context that is accessible only to the code within the iife. suppose we want to be able to reference jquery with $. consider the naive method, without using an iife: var $ = jquery; // we've just polluted the global namespace by assigning window.$ to jquery  in the following example, an iife is used to ensure that the $ is bound to jquery only in the context created by the closure: (function ($) { // $ is assigned to jquery here })(jquery); // but window.$ binding doesn't exist, so no pollution  see the canonical answer on stackoverﬂow for more information on closures.  section 56.2: hoisting what is hoisting? hoisting is a mechanism which moves all variable and function declarations to the top of their scope. however, variable assignments still happen where they originally were. for example, consider the following code:  goalkicker.com – javascript® notes for professionals  312  console.log(foo); var foo = 42; console.log(foo);  // → undefined // → 42  the above code is the same as: var foo;  // → hoisted variable declaration  console.log(foo);  // → undefined  foo = 42;  // → variable assignment remains in the same place  console.log(foo);  // → 42  note that due to hoisting the above undefined is not the same as the not defined resulting from running: console.log(foo);  // → foo is not defined  a similar principle applies to functions. when functions are assigned to a variable (i.e. a function expression), the variable declaration is hoisted while the assignment remains in the same place. the following two code snippets are equivalent. // → foo is not a function  console.log(foo(2, 3)); var foo = function(a, b) { return a * b; } var foo; console.log(foo(2, 3)); foo = function(a, b) { return a * b; }  // → foo is not a function  when declaring function statements, a diﬀerent scenario occurs. unlike function statements, function declarations are hoisted to the top of their scope. consider the following code: console.log(foo(2, 3)); function foo(a, b) { return a * b; }  // → 6  the above code is the same as the next code snippet due to hoisting: function foo(a, b) { return a * b; } console.log(foo(2, 3));  // → 6  here are some examples of what is and what isn't hoisting: // valid code: foo(); function foo() {} // invalid code: bar();  // → typeerror: bar is not a function  goalkicker.com – javascript® notes for professionals  313  var bar = function () {};  // valid code: foo(); function foo() { bar(); } function bar() {}  // invalid code: foo(); function foo() { bar(); // → typeerror: bar is not a function } var bar = function () {};  // (e) valid: function foo() { bar(); } var bar = function(){}; foo();  limitations of hoisting initializing a variable can not be hoisted or in simple javascript hoists declarations not initialization. for example: the below scripts will give diﬀerent outputs. var x = 2; var y = 4; alert(x + y);  this will give you an output of 6. but this... var x = 2; alert(x + y); var y = 4;  this will give you an output of nan. since we are initializing the value of y, the javascript hoisting is not happening, so the y value will be undeﬁned. the javascript will consider that y is not yet declared. so the second example is same as of below. var x = 2; var y; alert(x + y); y = 4;  this will give you an output of nan.  goalkicker.com – javascript® notes for professionals  314  section 56.3: dierence between var and let (note: all examples using let are also valid for const) var is available in all versions of javascript, while let and const are part of ecmascript 6 and only available in some  newer browsers. var is scoped to the containing function or the global space, depending when it is declared: var x = 4; // global scope function dothings() { var x = 7; // function scope console.log(x); } console.log(x); // >> 4 dothings(); // >> 7 console.log(x); // >> 4  that means it ""escapes"" if statements and all similar block constructs: var x = 4; if (true) { var x = 7; } console.log(x); // >> 7 for (var i = 0; i < 4; i++) { var j = 10; } console.log(i); // >> 4 console.log(j); // >> 10  by comparison, let is block scoped: let x = 4; if (true) { let x = 7; console.log(x); // >> 7 } console.log(x); // >> 4 for (let i = 0; i < 4; i++) {  goalkicker.com – javascript® notes for professionals  315  let j = 10; } console.log(i); // >> ""referenceerror: i is not defined"" console.log(j); // >> ""referenceerror: j is not defined""  note that i and j are only declared in the for loop and are therefore undeclared outside of it. there are several other crucial diﬀerences: global variable declaration in the top scope (outside any functions and blocks), var declarations put an element in the global object. let does not: var x = 4; let y = 7; console.log(this.x); // >> 4 console.log(this.y); // >> undefined  re-declaration declaring a variable twice using var doesn't produce an error (even though it's equivalent to declaring it once): var x = 4; var x = 7;  with let, this produces an error: let x = 4; let x = 7;  typeerror: identiﬁer x has already been declared the same is true when y is declared with var: var y = 4; let y = 7;  typeerror: identiﬁer y has already been declared however variables declared with let can be reused (not re-declared) in a nested block let i = 5; { let i = 6; console.log(i); // >> 6 } console.log(i); // >> 5  within the block the outer i can be accessed, but if the within block has a let declaration for i, the outer i can not be accessed and will throw a referenceerror if used before the second is declared. let i = 5;  goalkicker.com – javascript® notes for professionals  316  { i = 6; let i;  // outer i is unavailable within the temporal dead zone  }  referenceerror: i is not deﬁned hoisting variables declared both with var and let are hoisted. the diﬀerence is that a variable declared with var can be referenced before its own assignment, since it gets automatically assigned (with undefined as its value), but let cannot–it speciﬁcally requires the variable to be declared before being invoked: console.log(x); // >> undefined console.log(y); // >> ""referenceerror: `y` is not defined"" //or >> ""referenceerror: can't access lexical declaration `y` before initialization"" var x = 4; let y = 7;  the area between the start of a block and a let or const declaration is known as the temporal dead zone, and any references to the variable in this area will cause a referenceerror. this happens even if the variable is assigned before being declared: y=7; // >> ""referenceerror: `y` is not defined"" let y;  in non-strict-mode, assigning a value to a variable without any declaration, automatically declares the variable in the global scope. in this case, instead of y being automatically declared in the global scope, let reserves the variable's name (y) and does not allow any access or assignment to it before the line where it is declared/initialized.  section 56.4: apply and call syntax and invocation the apply and call methods in every function allow it to provide a custom value for this. function print() { console.log(this.toprint); } print.apply({ toprint: ""foo"" }); // >> ""foo"" print.call({ toprint: ""foo"" }); // >> ""foo""  you might notice that the syntax for both the invocations used above are the same. i.e. the signature looks similar. but there is a small diﬀerence in their usage, since we are dealing with functions and changing their scopes, we still need to maintain the original arguments passed to the function. both apply and call support passing arguments to the target function as follows: function speak() { var sentences = array.prototype.slice.call(arguments); console.log(this.name+"": ""+sentences); } var person = { name: ""sunny"" }; speak.apply(person, [""i"", ""code"", ""startups""]); // >> ""sunny: i code startups"" speak.call(person, ""i"", ""<3"", ""javascript""); // >> ""sunny: i <3 javascript""  goalkicker.com – javascript® notes for professionals  317  notice that apply allows you to pass an array or the arguments object (array-like) as the list of arguments, whereas, call needs you to pass each argument separately.  these two methods give you the freedom to get as fancy as you want, like implementing a poor version of the ecmascript's native bind to create a function that will always be called as a method of an object from an original function. function bind (func, obj) { return function () { return func.apply(obj, array.prototype.slice.call(arguments, 1)); } } var obj = { name: ""foo"" }; function print() { console.log(this.name); } printobj = bind(print, obj); printobj();  this will log ""foo""  the bind function has a lot going on 1. obj will be used as the value of this 2. forward the arguments to the function 3. and then return the value  section 56.5: arrow function invocation version ≥ 6  when using arrow functions this takes the value from the enclosing execution context's this (that is, this in arrow functions has lexical scope rather than the usual dynamic scope). in global code (code that doesn't belong to any function) it would be the global object. and it keeps that way, even if you invoke the function declared with the arrow notation from any of the others methods here described. var globalthis = this; //""window"" in a browser, or ""global"" in node.js var foo = (() => this); console.log(foo() === globalthis);  //true  var obj = { name: ""foo"" }; console.log(foo.call(obj) === globalthis);  //true  see how this inherits the context rather than referring to the object the method was called on. var globalthis = this;  goalkicker.com – javascript® notes for professionals  318  var obj = { withoutarrow: function() { return this; }, witharrow: () => this }; console.log(obj.withoutarrow() === obj); console.log(obj.witharrow() === globalthis);  //true //true  var fn = obj.withoutarrow; //no longer calling withoutarrow as a method var fn2 = obj.witharrow; console.log(fn() === globalthis); //true console.log(fn2() === globalthis); //true  section 56.6: bound invocation the bind method of every function allows you to create new version of that function with the context strictly bound to a speciﬁc object. it is especially useful to force a function to be called as a method of an object. var obj = { foo: 'bar' }; function foo() { return this.foo; } fooobj = foo.bind(obj); fooobj();  this will log: bar  section 56.7: method invocation invoking a function as a method of an object the value of this will be that object. var obj = { name: ""foo"", print: function () { console.log(this.name) } }  we can now invoke print as a method of obj. this will be obj obj.print();  this will thus log: foo  goalkicker.com – javascript® notes for professionals  319  section 56.8: anonymous invocation invoking a function as an anonymous function, this will be the global object (self in the browser). function func() { return this; } func() === window; // true version = 5  in ecmascript 5's strict mode, this will be undefined if the function is invoked anonymously. (function () { ""use strict""; func(); }())  this will output undefined  section 56.9: constructor invocation when a function is invoked as a constructor with the new keyword this takes the value of the object being constructed function obj(name) { this.name = name; } var obj = new obj(""foo""); console.log(obj);  this will log { name: ""foo"" }  section 56.10: using let in loops instead of var (click handlers example) let's say we need to add a button for each piece of loadeddata array (for instance, each button should be a slider showing the data; for the sake of simplicity, we'll just alert a message). one may try something like this: for(var i = 0; i < loadeddata.length; i++) jquery(""#container"").append(""<a class='button'>""+loadeddata[i].label+""</a>"") .children().last() // now let's attach a handler to the button which is a child .on(""click"",function() { alert(loadeddata[i].content); });  but instead of alerting, each button will cause the  goalkicker.com – javascript® notes for professionals  320  typeerror: loadeddata[i] is undeﬁned error. this is because the scope of i is the global scope (or a function scope) and after the loop, i == 3. what we need is not to ""remember the state of i"". this can be done using let: for(let i = 0; i < loadeddata.length; i++) jquery(""#container"").append(""<a class='button'>""+loadeddata[i].label+""</a>"") .children().last() // now let's attach a handler to the button which is a child .on(""click"",function() { alert(loadeddata[i].content); });  an example of loadeddata to be tested with this code: var loadeddata = [ { label:""apple"", content:""green and round"" }, { label:""blackberry"", content:""small black or blue"" }, { label:""pineapple"", content:""weird stuff.. difficult to explain the shape"" } ];  a ﬁddle to illustrate this  goalkicker.com – javascript® notes for professionals  321",t_a765d0035891,t_a765d0035891,13
c_01bc25f78d87,"chapter 19 of the book on javascript.chapter 19: functions functions in javascript provide organized, reusable code to perform a set of actions. functions simplify the coding process, prevent redundant logic, and make code easier to follow. this topic describes the declaration and utilization of functions, arguments, parameters, return statements and scope in javascript.  section 19.1: function scoping when you deﬁne a function, it creates a scope. everything deﬁned within the function is not accessible by code outside the function. only code within this scope can see the entities deﬁned inside the scope. function foo() { var a = 'hello'; console.log(a); // => 'hello' } console.log(a);  // reference error  nested functions are possible in javascript and the same rules apply. function foo() { var a = 'hello'; function bar() { var b = 'world'; console.log(a); // => 'hello' console.log(b); // => 'world' } console.log(a); console.log(b);  // => 'hello' // reference error  } console.log(a); console.log(b);  // reference error // reference error  when javascript tries to resolve a reference or variable, it starts looking for it in the current scope. if it cannot ﬁnd that declaration in the current scope, it climbs up one scope to look for it. this process repeats until the declaration has been found. if the javascript parser reaches the global scope and still cannot ﬁnd the reference, a reference error will be thrown. var a = 'hello'; function foo() { var b = 'world'; function bar() { var c = '!!'; console.log(a); console.log(b); console.log(c); console.log(d);  // // // //  => 'hello' => 'world' => '!!' reference error  }  goalkicker.com – javascript® notes for professionals  163  }  this climbing behavior can also mean that one reference may ""shadow"" over a similarly named reference in the outer scope since it gets seen ﬁrst. var a = 'hello'; function foo() { var a = 'world'; function bar() { console.log(a); }  // => 'world'  } version ≥ 6  the way javascript resolves scoping also applies to the const keyword. declaring a variable with the const keyword implies that you are not allowed to reassign the value, but declaring it in a function will create a new scope and with that a new variable. function foo() { const a = true; function bar() { const a = false; console.log(a); }  // different variable // false  const a = false; a = false; console.log(a);  // syntaxerror // typeerror // true  }  however, functions are not the only blocks that create a scope (if you are using let or const). let and const declarations have a scope of the nearest block statement. see here for a more detailed description.  section 19.2: currying currying is the transformation of a function of n arity or arguments into a sequence of n functions taking only one argument. use cases: when the values of some arguments are available before others, you can use currying to decompose a function into a series of functions that complete the work in stages, as each value arrives. this can be useful: when the value of an argument almost never changes (e.g., a conversion factor), but you need to maintain the ﬂexibility of setting that value (rather than hard-coding it as a constant). when the result of a curried function is useful before the other curried functions have run. to validate the arrival of the functions in a speciﬁc sequence. for example, the volume of a rectangular prism can be explained by a function of three factors: length (l), width (w), and height (h): var prism = function(l, w, h) { return l * w * h; }  goalkicker.com – javascript® notes for professionals  164  a curried version of this function would look like: function prism(l) { return function(w) { return function(h) { return l * w * h; } } } version ≥ 6  // alternatively, with concise ecmascript 6+ syntax: var prism = l => w => h => l * w * h;  you can call these sequence of functions with prism(2)(3)(5), which should evaluate to 30. without some extra machinery (like with libraries), currying is of limited syntactical ﬂexibility in javascript (es 5/6) due to the lack of placeholder values; thus, while you can use var a = prism(2)(3) to create a partially applied function, you cannot use prism()(3)(5).  section 19.3: immediately invoked function expressions sometimes you don't want to have your function accessible/stored as a variable. you can create an immediately invoked function expression (iife for short). these are essentially self-executing anonymous functions. they have access to the surrounding scope, but the function itself and any internal variables will be inaccessible from outside. an important thing to note about iife is that even if you name your function, iife are not hoisted like standard functions are and cannot be called by the function name they are declared with. (function() { alert(""i've run - but can't be run again because i'm immediately invoked at runtime, leaving behind only the result i generate""); }());  this is another way to write iife. notice that the closing parenthesis before the semicolon was moved and placed right after the closing curly bracket: (function() { alert(""this is iife too.""); })();  you can easily pass parameters into an iife: (function(message) { alert(message); }(""hello world!""));  additionally, you can return values to the surrounding scope: var example = (function() { return 42; }()); console.log(example); // => 42  if required it is possible to name an iife. while less often seen, this pattern has several advantages, such as providing a reference which can be used for a recursion and can make debugging simpler as the name is included in the callstack. goalkicker.com – javascript® notes for professionals  165  (function namediife() { throw error; // we can now see the error thrown in 'namediife()' }());  while wrapping a function in parenthesis is the most common way to denote to the javascript parser to expect an expression, in places where an expression is already expected, the notation can be made more concise: var a = function() { return 42 }(); console.log(a) // => 42  arrow version of immediately invoked function: version ≥ 6  (() => console.log(""hello!""))(); // => hello!  section 19.4: named functions functions can either be named or unnamed (anonymous functions): var namedsum = function sum (a, b) { // named return a + b; } var anonsum = function (a, b) { // anonymous return a + b; } namedsum(1, 3); anonsum(1, 3);  4 4 but their names are private to their own scope: var sumtwonumbers = function sum (a, b) { return a + b; } sum(1, 3);  uncaught referenceerror: sum is not deﬁned named functions diﬀer from the anonymous functions in multiple scenarios: when you are debugging, the name of the function will appear in the error/stack trace named functions are hoisted while anonymous functions are not named functions and anonymous functions behave diﬀerently when handling recursion depending on ecmascript version, named and anonymous functions may treat the function name property diﬀerently  named functions are hoisted goalkicker.com – javascript® notes for professionals  166  when using an anonymous function, the function can only be called after the line of declaration, whereas a named function can be called before declaration. consider foo(); var foo = function () { // using an anonymous function console.log('bar'); }  uncaught typeerror: foo is not a function  foo(); function foo () { // using a named function console.log('bar'); }  bar  named functions in a recursive scenario a recursive function can be deﬁned as: var say = function (times) { if (times > 0) { console.log('hello!'); say(times - 1); } } //you could call 'say' directly, //but this way just illustrates the example var sayhellotimes = say; sayhellotimes(2);  hello! hello! what if somewhere in your code the original function binding gets redeﬁned? var say = function (times) { if (times > 0) { console.log('hello!'); say(times - 1); } } var sayhellotimes = say; say = ""oops""; sayhellotimes(2);  goalkicker.com – javascript® notes for professionals  167  hello! uncaught typeerror: say is not a function this can be solved using a named function // the outer variable can even have the same name as the function // as they are contained in different scopes var say = function say (times) { if (times > 0) { console.log('hello!'); // this time, 'say' doesn't use the outer variable // it uses the named function say(times - 1); } } var sayhellotimes = say; say = ""oops""; sayhellotimes(2);  hello! hello! and as bonus, the named function can't be set to undefined, even from inside: var say = function say (times) { // this does nothing say = undefined; if (times > 0) { console.log('hello!'); // this time, 'say' doesn't use the outer variable // it's using the named function say(times - 1); } } var sayhellotimes = say; say = ""oops""; sayhellotimes(2);  hello! hello!  the name property of functions before es6, named functions had their name properties set to their function names, and anonymous functions had their name properties set to the empty string.  goalkicker.com – javascript® notes for professionals  168  version ≤ 5  var foo = function () {} console.log(foo.name); // outputs '' function foo () {} console.log(foo.name); // outputs 'foo'  post es6, named and unnamed functions both set their name properties: version ≥ 6  var foo = function () {} console.log(foo.name); // outputs 'foo' function foo () {} console.log(foo.name); // outputs 'foo' var foo = function bar () {} console.log(foo.name); // outputs 'bar'  section 19.5: binding `this` and arguments version ≥ 5.1  when you take a reference to a method (a property which is a function) in javascript, it usually doesn't remember the object it was originally attached to. if the method needs to refer to that object as this it won't be able to, and calling it will probably cause a crash. you can use the .bind() method on a function to create a wrapper that includes the value of this and any number of leading arguments. var monitor = { threshold: 5, check: function(value) { if (value > this.threshold) { this.display(""value is too high!""); } }, display(message) { alert(message); } }; monitor.check(7); // the value of `this` is implied by the method call syntax.  var badcheck = monitor.check; badcheck(15); // the value of `this` is window object and this.threshold is undefined, so value > this.threshold is false var check = monitor.check.bind(monitor); check(15); // this value of `this` was explicitly bound, the function works. var check8 = monitor.check.bind(monitor, 8); check8(); // we also bound the argument to `8` here. it can't be re-specified.  when not in strict mode, a function uses the global object (window in the browser) as this, unless the function is called as a method, bound, or called with the method .call syntax. window.x = 12;  goalkicker.com – javascript® notes for professionals  169  function example() { return this.x; } console.log(example()); // 12  in strict mode this is undefined by default window.x = 12; function example() { ""use strict""; return this.x; } console.log(example()); // uncaught typeerror: cannot read property 'x' of undefined(…) version ≥ 7  bind operator the double colon bind operator can be used as a shortened syntax for the concept explained above: var log = console.log.bind(console); // long version const log = ::console.log; // short version foo.bar.call(foo); // long version foo::bar(); // short version foo.bar.call(foo, arg1, arg2, arg3); // long version foo::bar(arg1, arg2, arg3); // short version foo.bar.apply(foo, args); // long version foo::bar(...args); // short version  this syntax allows you to write normally, without worrying about binding this everywhere. binding console functions to variables var log = console.log.bind(console);  usage: log('one', '2', 3, [4], {5: 5});  output: one 2 3 [4] object {5: 5}  why would you do that? one use case can be when you have custom logger and you want to decide on runtime which one to use. var logger = require('applogger'); var log = logtoserver ? logger.log : console.log.bind(console);  goalkicker.com – javascript® notes for professionals  170  section 19.6: functions with an unknown number of arguments (variadic functions) to create a function which accepts an undetermined number of arguments, there are two methods depending on your environment. version ≤ 5  whenever a function is called, it has an array-like arguments object in its scope, containing all the arguments passed to the function. indexing into or iterating over this will give access to the arguments, for example function logsomethings() { for (var i = 0; i < arguments.length; ++i) { console.log(arguments[i]); } } logsomethings('hello', 'world'); // logs ""hello"" // logs ""world""  note that you can convert arguments to an actual array if need-be; see: converting array-like objects to arrays version ≥ 6  from es6, the function can be declared with its last parameter using the rest operator (...). this creates an array which holds the arguments from that point onwards function personlogssomethings(person, ...msg) { msg.foreach(arg => { console.log(person, 'says', arg); }); } personlogssomethings('john', 'hello', 'world'); // logs ""john says hello"" // logs ""john says world""  functions can also be called with similar way, the spread syntax const logarguments = (...args) => console.log(args) const list = [1, 2, 3] logarguments('a', 'b', 'c', ...list) // output: array [ ""a"", ""b"", ""c"", 1, 2, 3 ]  this syntax can be used to insert arbitrary number of arguments to any position, and can be used with any iterable(apply accepts only array-like objects). const logarguments = (...args) => console.log(args) function* generatenumbers() { yield 6 yield 5 yield 4 } logarguments('a', ...generatenumbers(), ...'pqr', 'b') // output: array [ ""a"", 6, 5, 4, ""p"", ""q"", ""r"", ""b"" ]  goalkicker.com – javascript® notes for professionals  171  section 19.7: anonymous function deﬁning an anonymous function when a function is deﬁned, you often give it a name and then invoke it using that name, like so: foo(); function foo(){ // ... }  when you deﬁne a function this way, the javascript runtime stores your function in memory and then creates a reference to that function, using the name you've assigned it. that name is then accessible within the current scope. this can be a very convenient way to create a function, but javascript does not require you to assign a name to a function. the following is also perfectly legal: function() { // ... }  when a function is deﬁned without a name, it's known as an anonymous function. the function is stored in memory, but the runtime doesn't automatically create a reference to it for you. at ﬁrst glance, it may appear as if such a thing would have no use, but there are several scenarios where anonymous functions are very convenient. assigning an anonymous function to a variable a very common use of anonymous functions is to assign them to a variable: var foo = function(){ /*...*/ }; foo();  this use of anonymous functions is covered in more detail in functions as a variable supplying an anonymous function as a parameter to another function some functions may accept a reference to a function as a parameter. these are sometimes referred to as ""dependency injections"" or ""callbacks"", because it allows the function your calling to ""call back"" to your code, giving you an opportunity to change the way the called function behaves. for example, the array object's map function allows you to iterate over each element of an array, then build a new array by applying a transform function to each element. var nums = [0,1,2]; var doublednums = nums.map( function(element){ return element * 2; } ); // [0,2,4]  it would be tedious, sloppy and unnecessary to create a named function, which would clutter your scope with a function only needed in this one place and break the natural ﬂow and reading of your code (a colleague would have to leave this code to ﬁnd your function to understand what's going on). returning an anonymous function from another function sometimes it's useful to return a function as the result of another function. for example: var hash = gethashfunction( 'sha1' );  goalkicker.com – javascript® notes for professionals  172  var hashvalue = hash( 'secret value' ); function gethashfunction( algorithm ){ if ( algorithm === 'sha1' ) return function( value ){ /*...*/ }; else if ( algorithm === 'md5' ) return function( value ){ /*...*/ }; }  immediately invoking an anonymous function unlike many other languages, scoping in javascript is function-level, not block-level. (see function scoping ). in some cases, however, it's necessary to create a new scope. for example, it's common to create a new scope when adding code via a <script> tag, rather than allowing variable names to be deﬁned in the global scope (which runs the risk of other scripts colliding with your variable names). a common method to handle this situation is to deﬁne a new anonymous function and then immediately invoke it, safely hiding you variables within the scope of the anonymous function and without making your code accessible to third-parties via a leaked function name. for example: <!-- my script --> <script> function initialize(){ // foo is safely hidden within initialize, but... var foo = ''; } // ...my initialize function is now accessible from global scope. // there is a risk someone could call it again, probably by accident. initialize(); </script> <script> // using an anonymous function, and then immediately // invoking it, hides my foo variable and guarantees // no one else can call it a second time. (function(){ var foo = ''; }()) // <--- the parentheses invokes the function immediately </script>  self-referential anonymous functions sometimes it's useful for an anonymous function to be able to refer to itself. for example, the function may need to recursively call itself or add properties to itself. if the function is anonymous, though, this can be very diﬃcult as it requires knowledge of the variable that the function has been assigned to. this is the less than ideal solution: var foo = function(callagain){ console.log( 'whassup?' ); // less than ideal... we're dependent on a variable reference... if (callagain === true) foo(false); }; foo(true); // console output: // whassup? // whassup? // assign bar to the original function, and assign foo to another function. var bar = foo; foo = function(){  goalkicker.com – javascript® notes for professionals  173  console.log('bad.') }; bar(true); // console output: // whassup? // bad.  the intent here was for the anonymous function to recursively call itself, but when the value of foo changes, you end up with a potentially diﬃcult to trace bug. instead, we can give the anonymous function a reference to itself by giving it a private name, like so: var foo = function myself(callagain){ console.log( 'whassup?' ); // less than ideal... we're dependent on a variable reference... if (callagain === true) myself(false); }; foo(true); // console output: // whassup? // whassup? // assign bar to the original function, and assign foo to another function. var bar = foo; foo = function(){ console.log('bad.') }; bar(true); // console output: // whassup? // whassup?  note that the function name is scoped to itself. the name has not leaked into the outer scope: myself(false); // referenceerror: myself is not defined  this technique is especially useful when dealing with recursive anonymous functions as callback parameters: version ≥ 5  // calculate the fibonacci value for each number in an array: var fib = false, result = [1,2,3,4,5,6,7,8].map( function fib(n){ return ( n <= 2 ) ? 1 : fib( n - 1 ) + fib( n - 2 ); }); // result = [1, 1, 2, 3, 5, 8, 13, 21] // fib = false (the anonymous function name did not overwrite our fib variable)  section 19.8: default parameters before ecmascript 2015 (es6), a parameter's default value could be assigned in the following way: function printmsg(msg) {  goalkicker.com – javascript® notes for professionals  174  msg = typeof msg !== 'undefined' ? // if a value was provided msg : // then, use that value in the reassignment 'default value for msg.'; // else, assign a default value console.log(msg); }  es6 provided a new syntax where the condition and reassignment depicted above is no longer necessary: version ≥ 6  function printmsg(msg='default value for msg.') { console.log(msg); } printmsg(); // -> ""default value for msg."" printmsg(undefined); // -> ""default value for msg."" printmsg('now my msg in different!'); // -> ""now my msg in different!""  this also shows that if a parameter is missing when the function is invoked, its value is kept as undefined, as it can be conﬁrmed by explicitly providing it in the following example (using an arrow function): version ≥ 6  let param_check = (p = 'str') => console.log(p + ' is of type: ' + typeof p); param_check(); // -> ""str is of type: string"" param_check(undefined); // -> ""str is of type: string"" param_check(1); // -> ""1 is of type: number"" param_check(this); // -> ""[object window] is of type: object""  functions/variables as default values and reusing parameters the default parameters' values are not restricted to numbers, strings or simple objects. a function can also be set as the default value callback = function(){}: version ≥ 6  function foo(callback = function(){ console.log('default'); }) { callback(); } foo(function (){ console.log('custom'); }); // custom foo(); //default  there are certain characteristics of the operations that can be performed through default values: a previously declared parameter can be reused as a default value for the upcoming parameters' values. inline operations are allowed when assigning a default value to a parameter. variables existing in the same scope of the function being declared can be used in its default values. functions can be invoked in order to provide their return value into a default value. version ≥ 6  let zero = 0; function multiply(x) { return x * 2;} function add(a = 1 + zero, b = a, c = b + a, d = multiply(c)) { console.log((a + b + c), d);  goalkicker.com – javascript® notes for professionals  175  } add(1); add(3); add(2, 7); add(1, 2, 5); add(1, 2, 5, 10);  // // // // //  4, 4 12, 12 18, 18 8, 10 8, 20  reusing the function's return value in a new invocation's default value: version ≥ 6  let array = [1]; // meaningless: this will be overshadowed in the function's scope function add(value, array = []) { array.push(value); return array; } add(5); // [5] add(6); // [6], not [5, 6] add(6, add(5)); // [5, 6] arguments value and length when lacking parameters in invocation  the arguments array object only retains the parameters whose values are not default, i.e. those that are explicitly provided when the function is invoked: version ≥ 6  function foo(a = 1, b = a + 1) { console.info(arguments.length, arguments); console.log(a,b); } foo(); foo(4); foo(5, 6);  // info: 0 >> [] | log: 1, 2 // info: 1 >> [4] | log: 4, 5 // info: 2 >> [5, 6] | log: 5, 6  section 19.9: call and apply functions have two built-in methods that allow the programmer to supply arguments and the this variable diﬀerently: call and apply. this is useful, because functions that operate on one object (the object that they are a property of) can be repurposed to operate on another, compatible object. additionally, arguments can be given in one shot as arrays, similar to the spread (...) operator in es6. let obj = { a: 1, b: 2, set: function (a, b) { this.a = a; this.b = b; } }; obj.set(3, 7); // normal syntax obj.set.call(obj, 3, 7); // equivalent to the above obj.set.apply(obj, [3, 7]); // equivalent to the above; note that an array is used console.log(obj); // prints { a: 3, b: 5 } let myobj = {}; myobj.set(5, 4); // fails; myobj has no `set` property  goalkicker.com – javascript® notes for professionals  176  obj.set.call(myobj, 5, 4); // success; `this` in set() is re-routed to myobj instead of obj obj.set.apply(myobj, [5, 4]); // same as above; note the array console.log(myobj); // prints { a: 3, b: 5 } version ≥ 5  ecmascript 5 introduced another method called bind() in addition to call() and apply() to explicitly set this value of the function to speciﬁc object. it behaves quite diﬀerently than the other two. the ﬁrst argument to bind() is the this value for the new function. all other arguments represent named parameters that should be permanently set in the new function. function showname(label) { console.log(label + "":"" + this.name); } var student1 = { name: ""ravi"" }; var student2 = { name: ""vinod"" }; // create a function just for student1 var shownamestudent1 = showname.bind(student1); shownamestudent1(""student1""); // outputs ""student1:ravi"" // create a function just for student2 var shownamestudent2 = showname.bind(student2, ""student2""); shownamestudent2(); // outputs ""student2:vinod"" // attaching a method to an object doesn't change `this` value of that method. student2.sayname = shownamestudent1; student2.sayname(""student2""); // outputs ""student2:ravi""  section 19.10: partial application similar to currying, partial application is used to reduce the number of arguments passed to a function. unlike currying, the number need not go down by one. example: this function ... function multiplythenadd(a, b, c) { return a * b + c; }  ... can be used to create another function that will always multiply by 2 and then add 10 to the passed value; function reversedmultiplythenadd(c, b, a) { return a * b + c; } function factory(b, c) { return reversedmultiplythenadd.bind(null, c, b); } var multiplytwothenaddten = factory(2, 10);  goalkicker.com – javascript® notes for professionals  177  multiplytwothenaddten(10); // 30  the ""application"" part of partial application simply means ﬁxing parameters of a function.  section 19.11: passing arguments by reference or value in javascript all arguments are passed by value. when a function assigns a new value to an argument variable, that change will not be visible to the caller: var obj = {a: 2}; function myfunc(arg){ arg = {a: 5}; // note the assignment is to the parameter variable itself } myfunc(obj); console.log(obj.a); // 2  however, changes made to (nested) properties of such arguments, will be visible to the caller: var obj = {a: 2}; function myfunc(arg){ arg.a = 5; // assignment to a property of the argument } myfunc(obj); console.log(obj.a); // 5  this can be seen as a call by reference: although a function cannot change the caller's object by assigning a new value to it, it could mutate the caller's object. as primitive valued arguments, like numbers or strings, are immutable, there is no way for a function to mutate them: var s = 'say'; function myfunc(arg){ arg += ' hello'; // assignment to the parameter variable itself } myfunc(s); console.log(s); // 'say'  when a function wants to mutate an object passed as argument, but does not want to actually mutate the caller's object, the argument variable should be reassigned: version ≥ 6  var obj = {a: 2, b: 3}; function myfunc(arg){ arg = object.assign({}, arg); // assignment to argument variable, shallow copy arg.a = 5; } myfunc(obj); console.log(obj.a); // 2  as an alternative to in-place mutation of an argument, functions can create a new value, based on the argument, and return it. the caller can then assign it, even to the original variable that was passed as argument: var a = 2; function myfunc(arg){ arg++; return arg;  goalkicker.com – javascript® notes for professionals  178  } a = myfunc(a); console.log(obj.a); // 3  section 19.12: function arguments, ""arguments"" object, rest and spread parameters functions can take inputs in form of variables that can be used and assigned inside their own scope. the following function takes two numeric values and returns their sum: function addition (argument1, argument2){ return argument1 + argument2; } console.log(addition(2, 3)); // -> 5 arguments object  the arguments object contains all the function's parameters that contain a non-default value. it can also be used even if the parameters are not explicitly declared: (function() { console.log(arguments) })(0,'str', [2,{3}]) // -> [0, ""str"", array[2]]  although when printing arguments the output resembles an array, it is in fact an object: (function() { console.log(typeof arguments) })(); // -> object  rest parameters: function (...parm) {} in es6, the ... syntax when used in the declaration of a function's parameters transforms the variable to its right into a single object containing all the remaining parameters provided after the declared ones. this allows the function to be invoked with an unlimited number of arguments, which will become part of this variable: (function(a, ...b){console.log(typeof b+': '+b[0]+b[1]+b[2]) })(0,1,'2',[3],{i:4}); // -> object: 123  spread parameters: function_name(...varb); in es6, the ... syntax can also be used when invoking a function by placing an object/variable to its right. this allows that object's elements to be passed into that function as a single object: let nums = [2,42,-1]; console.log(...['a','b','c'], math.max(...nums)); // -> a b c 42  section 19.13: function composition composing multiple functions into one is a functional programming common practice; composition makes a pipeline through which our data will transit and get modiﬁed simply working on the functioncomposition (just like snapping pieces of a track together)... you start out with some single responsibility functions: version ≥ 6  const capitalize = x => x.replace(/^\w/, m => m.touppercase()); const sign = x => x + ',\nmade with love';  goalkicker.com – javascript® notes for professionals  179  and easily create a transformation track: version ≥ 6  const formattext = compose(capitalize, sign); formattext('this is an example') //this is an example, //made with love  n.b. composition is achieved through a utility function usually called compose as in our example. implementation of compose are present in many javascript utility libraries (lodash, rambda, etc.) but you can also start out with a simple implementation such as: version ≥ 6  const compose = (...funs) => x => funs.reduce((ac, f) => f(ac), x);  section 19.14: get the name of a function object version ≥ 6  es6: myfunction.name  explanation on mdn. as of 2015 works in node.js and all major browsers except ie.  version ≥ 5  es5: if you have a reference to the function, you can do: function functionname( func ) { // match: // - ^ the beginning of the string // - function the word 'function' // - \s+ at least some white space // - ([\w\$]+) capture one or more valid javascript identifier characters // - \( followed by an opening brace // var result = /^function\s+([\w\$]+)\(/.exec( func.tostring() ) return result ? result[1] : '' }  section 19.15: recursive function a recursive function is simply a function, that would call itself. function factorial (n) { if (n <= 1) { return 1; }  goalkicker.com – javascript® notes for professionals  180  return n * factorial(n - 1); }  the above function shows a basic example of how to perform a recursive function to return a factorial. another example, would be to retrieve the sum of even numbers in an array. function countevennumbers (arr) { // sentinel value. recursion stops on empty array. if (arr.length < 1) { return 0; } // the shift() method removes the first element from an array // and returns that element. this method changes the length of the array. var value = arr.shift(); // `value % 2 === 0` tests if the number is even or odd // if it's even we add one to the result of counting the remainder of // the array. if it's odd, we add zero to it. return ((value % 2 === 0) ? 1 : 0) + countevens(arr); }  it is important that such functions make some sort of sentinel value check to avoid inﬁnite loops. in the ﬁrst example above, when n is less than or equal to 1, the recursion stops, allowing the result of each call to be returned back up the call stack.  section 19.16: using the return statement the return statement can be a useful way to create output for a function. the return statement is especially useful if you do not know in which context the function will be used yet. //an example function that will take a string as input and return //the first character of the string. function firstchar (stringin){ return stringin.charat(0); }  now to use this function, you need to put it in place of a variable somewhere else in your code: using the function result as an argument for another function: console.log(firstchar(""hello world""));  console output will be: > h  the return statement ends the function if we modify the function in the beginning, we can demonstrate that the return statement ends the function. function firstchar (stringin){ console.log(""the first action of the first char function""); return stringin.charat(0); console.log(""the last action of the first char function"");  goalkicker.com – javascript® notes for professionals  181  }  running this function like so will look like this: console.log(firstchar(""js""));  console output: > the first action of the first char function > j  it will not print the message after the return statement, as the function has now been ended. return statement spanning multiple lines: in javascript, you can normally split up a line of code into many lines for readability purposes or organization. this is valid javascript: var name = ""bob"", age = 18;  when javascript sees an incomplete statement like var it looks to the next line to complete itself. however, if you make the same mistake with the return statement, you will not get what you expected. return ""hi, my name is ""+ name + "". "" + ""i'm ""+ age + "" years old."";  this code will return undefined because return by itself is a complete statement in javascript, so it will not look to the next line to complete itself. if you need to split up a return statement into multiple lines, put a value next to return before you split it up, like so. return ""hi, my name is "" + name + "". "" + ""i'm "" + age + "" years old."";  section 19.17: functions as a variable a normal function declaration looks like this: function foo(){ }  a function deﬁned like this is accessible from anywhere within its context by its name. but sometimes it can be useful to treat function references like object references. for example, you can assign an object to a variable based on some set of conditions and then later retrieve a property from one or the other object: var name = 'cameron'; var spouse; if ( name === 'taylor' ) spouse = { name: 'jordan' }; else if ( name === 'cameron' ) spouse = { name: 'casey' }; var spousename = spouse.name;  goalkicker.com – javascript® notes for professionals  182  in javascript, you can do the same thing with functions: // example 1 var hashalgorithm = 'sha1'; var hash; if ( hashalgorithm === 'sha1' ) hash = function(value){ /*...*/ }; else if ( hashalgorithm === 'md5' ) hash = function(value){ /*...*/ }; hash('fred');  in the example above, hash is a normal variable. it is assigned a reference to a function, after which the function it references can be invoked using parentheses, just like a normal function declaration. the example above references anonymous functions... functions that do not have their own name. you can also use variables to refer to named functions. the example above could be rewritten like so: // example 2 var hashalgorithm = 'sha1'; var hash; if ( hashalgorithm === 'sha1' ) hash = sha1hash; else if ( hashalgorithm === 'md5' ) hash = md5hash; hash('fred'); function md5hash(value){ // ... } function sha1hash(value){ // ... }  or, you can assign function references from object properties: // example 3 var hashalgorithms = { sha1: function(value) { /**/ }, md5: function(value) { /**/ } }; var hashalgorithm = 'sha1'; var hash; if ( hashalgorithm === 'sha1' ) hash = hashalgorithms.sha1; else if ( hashalgorithm === 'md5' ) hash = hashalgorithms.md5; hash('fred');  you can assign the reference to a function held by one variable to another by omitting the parentheses. this can result in an easy-to-make mistake: attempting to assign the return value of a function to another variable, but accidentally assigning the reference to the function. // example 4 var a = getvalue; var b = a; // b is now a reference to getvalue. var c = b(); // b is invoked, so c now holds the value returned by getvalue (41)  goalkicker.com – javascript® notes for professionals  183  function getvalue(){ return 41; }  a reference to a function is like any other value. as you've seen, a reference can be assigned to a variable, and that variable's reference value can be subsequently assigned to other variables. you can pass around references to functions like any other value, including passing a reference to a function as the return value of another function. for example: // example 5 // gethashingfunction returns a function, which is assigned // to hash for later use: var hash = gethashingfunction( 'sha1' ); // ... hash('fred');  // return the function corresponding to the given algorithmname function gethashingfunction( algorithmname ){ // return a reference to an anonymous function if (algorithmname === 'sha1') return function(value){ /**/ }; // return a reference to a declared function else if (algorithmname === 'md5') return md5; } function md5hash(value){ // ... }  you don't need to assign a function reference to a variable in order to invoke it. this example, building oﬀ example 5, will call gethashingfunction and then immediately invoke the returned function and pass its return value to hashedvalue. // example 6 var hashedvalue = gethashingfunction( 'sha1' )( 'fred' );  a note on hoisting keep in mind that, unlike normal function declarations, variables that reference functions are not ""hoisted"". in example 2, the md5hash and sha1hash functions are deﬁned at the bottom of the script, but are available everywhere immediately. no matter where you deﬁne a function, the interpreter ""hoists"" it to the top of its scope, making it immediately available. this is not the case for variable deﬁnitions, so code like the following will break: var functionvariable; hoistedfunction(); // works, because the function is ""hoisted"" to the top of its scope functionvariable(); // error: undefined is not a function. function hoistedfunction(){} functionvariable = function(){};  goalkicker.com – javascript® notes for professionals  184",t_a765d0035891,t_a765d0035891,13
c_4de8cbc6dddc,"chapter 22 of the book on javascript.chapter 22: classes section 22.1: class constructor the fundamental part of most classes is its constructor, which sets up each instance's initial state and handles any parameters that were passed when calling new. it's deﬁned in a class block as though you're deﬁning a method named constructor, though it's actually handled as a special case. class myclass { constructor(option) { console.log(`creating instance using ${option} option.`); this.option = option; } }  example usage: const foo = new myclass('speedy'); // logs: ""creating instance using speedy option""  a small thing to note is that a class constructor cannot be made static via the static keyword, as described below for other methods.  section 22.2: class inheritance inheritance works just like it does in other object-oriented languages: methods deﬁned on the superclass are accessible in the extending subclass. if the subclass declares its own constructor then it must invoke the parents constructor via super() before it can access this. class superclass { constructor() { this.logger = console.log; } log() { this.logger(`hello ${this.name}`); } } class subclass extends superclass { constructor() { super(); this.name = 'subclass'; } } const subclass = new subclass(); subclass.log(); // logs: ""hello subclass""  goalkicker.com – javascript® notes for professionals  192  section 22.3: static methods static methods and properties are deﬁned on the class/constructor itself, not on instance objects. these are speciﬁed in a class deﬁnition by using the static keyword. class myclass { static mystaticmethod() { return 'hello'; } static get mystaticproperty() { return 'goodbye'; } } console.log(myclass.mystaticmethod()); // logs: ""hello"" console.log(myclass.mystaticproperty); // logs: ""goodbye""  we can see that static properties are not deﬁned on object instances: const myclassinstance = new myclass(); console.log(myclassinstance.mystaticproperty); // logs: undefined  however, they are deﬁned on subclasses: class mysubclass extends myclass {}; console.log(mysubclass.mystaticmethod()); // logs: ""hello"" console.log(mysubclass.mystaticproperty); // logs: ""goodbye""  section 22.4: getters and setters getters and setters allow you to deﬁne custom behaviour for reading and writing a given property on your class. to the user, they appear the same as any typical property. however, internally a custom function you provide is used to determine the value when the property is accessed (the getter), and to perform any necessary changes when the property is assigned (the setter). in a class deﬁnition, a getter is written like a no-argument method preﬁxed by the get keyword. a setter is similar, except that it accepts one argument (the new value being assigned) and the set keyword is used instead. here's an example class which provides a getter and setter for its .name property. each time it's assigned, we'll record the new name in an internal .names_ array. each time it's accessed, we'll return the latest name. class myclass { constructor() { this.names_ = []; } set name(value) { this.names_.push(value); } get name() { return this.names_[this.names_.length - 1]; } }  goalkicker.com – javascript® notes for professionals  193  const myclassinstance = new myclass(); myclassinstance.name = 'joe'; myclassinstance.name = 'bob'; console.log(myclassinstance.name); // logs: ""bob"" console.log(myclassinstance.names_); // logs: [""joe"", ""bob""]  if you only deﬁne a setter, attempting to access the property will always return undefined. const classinstance = new class { set prop(value) { console.log('setting', value); } }; classinstance.prop = 10; // logs: ""setting"", 10 console.log(classinstance.prop); // logs: undefined  if you only deﬁne a getter, attempting to assign the property will have no eﬀect. const classinstance = new class { get prop() { return 5; } }; classinstance.prop = 10; console.log(classinstance.prop); // logs: 5  section 22.5: private members javascript does not technically support private members as a language feature. privacy - described by douglas crockford - gets emulated instead via closures (preserved function scope) that will be generated each with every instantiation call of a constructor function. the queue example demonstrates how, with constructor functions, local state can be preserved and made accessible too via privileged methods. class queue { constructor () {  // - does generate a closure with each instantiation.  const list = [];  // - local state (""private member"").  this.enqueue = function (type) {  // - privileged public method // accessing the local state // ""writing"" alike.  list.push(type); return type; }; this.dequeue = function () { return list.shift();  // - privileged public method // accessing the local state // ""reading / writing"" alike.  }; } }  goalkicker.com – javascript® notes for professionals  194  var q = new queue; q.enqueue(9); q.enqueue(8); q.enqueue(7); console.log(q.dequeue()); console.log(q.dequeue()); console.log(q.dequeue()); console.log(q); console.log(object.keys(q));  // // // // // // // // // // //  ... first in ...  9 ... first out. 8 7 {} [""enqueue"",""dequeue""]  with every instantiation of a queue type the constructor generates a closure. thus both of a queue type's own methods enqueue and dequeue (see object.keys(q)) still do have access to list that continues to live in its enclosing scope that, at construction time, has been preserved. making use of this pattern - emulating private members via privileged public methods - one should keep in mind that, with every instance, additional memory will be consumed for every own property method (for it is code that can't be shared/reused). the same is true for the amount/size of state that is going to be stored within such a closure.  section 22.6: methods methods can be deﬁned in classes to perform a function and optionally return a result. they can receive arguments from the caller. class something { constructor(data) { this.data = data } dosomething(text) { return { data: this.data, text } } } var s = new something({}) s.dosomething(""hi"") // returns: { data: {}, text: ""hi"" }  section 22.7: dynamic method names there is also the ability to evaluate expressions when naming methods similar to how you can access an objects' properties with []. this can be useful for having dynamic property names, however is often used in conjunction with symbols. let metadata = symbol('metadata'); class car { constructor(make, model) { this.make = make; this.model = model; } // example using symbols  goalkicker.com – javascript® notes for professionals  195  [metadata]() { return { make: this.make, model: this.model }; } // you can also use any javascript expression // this one is just a string, and could also be defined with simply add() [""add""](a, b) { return a + b; } // this one is dynamically evaluated [1 + 2]() { return ""three""; } } let mazdampv = new car(""mazda"", ""mpv""); mazdampv.add(4, 5); // 9 mazdampv[3](); // ""three"" mazdampv[metadata](); // { make: ""mazda"", model: ""mpv"" }  section 22.8: managing private data with classes one of the most common obstacles using classes is ﬁnding the proper approach to handle private states. there are 4 common solutions for handling private states: using symbols symbols are new primitive type introduced on in es2015, as deﬁned at mdn a symbol is a unique and immutable data type that may be used as an identiﬁer for object properties. when using symbol as a property key, it is not enumerable. as such, they won't be revealed using for var in or object.keys. thus we can use symbols to store private data. const topsecret = symbol('topsecret'); // our private key; will only be accessible on the scope of the module file export class secretagent{ constructor(secret){ this[topsecret] = secret; // we have access to the symbol key (closure) this.coverstory = 'just a simple gardner'; this.domission = () => { figurewhattodo(topsecret[topsecret]); // we have access to topsecret }; } }  because symbols are unique, we must have reference to the original symbol to access the private property. import {secretagent} from 'secretagent.js'  goalkicker.com – javascript® notes for professionals  196  const agent = new secretagent('steal all the ice cream'); // ok let's try to get the secret out of him! object.keys(agent); // ['coverstory'] only cover story is public, our secret is kept. agent[symbol('topsecret')]; // undefined, as we said, symbols are always unique, so only the original symbol will help us to get the data.  but it's not 100% private; let's break that agent down! we can use the object.getownpropertysymbols method to get the object symbols. const secretkeys = object.getownpropertysymbols(agent); agent[secretkeys[0]] // 'steal all the ice cream' , we got the secret.  using weakmaps weakmap is a new type of object that have been added for es6.  as deﬁned on mdn the weakmap object is a collection of key/value pairs in which the keys are weakly referenced. the keys must be objects and the values can be arbitrary values. another important feature of weakmap is, as deﬁned on mdn. the key in a weakmap is held weakly. what this means is that, if there are no other strong references to the key, the entire entry will be removed from the weakmap by the garbage collector. the idea is to use the weakmap, as a static map for the whole class, to hold each instance as key and keep the private data as a value for that instance key. thus only inside the class will we have access to the weakmap collection. let's give our agent a try, with weakmap: const topsecret = new weakmap(); // will hold all private data of all instances. export class secretagent{ constructor(secret){ topsecret.set(this,secret); // we use this, as the key, to set it on our instance private data this.coverstory = 'just a simple gardner'; this.domission = () => { figurewhattodo(topsecret.get(this)); // we have access to topsecret }; } }  because the const topsecret is deﬁned inside our module closure, and since we didn't bind it to our instance properties, this approach is totally private, and we can't reach the agent topsecret. deﬁne all methods inside the constructor the idea here is simply to deﬁne all our methods and members inside the constructor and use the closure to access private members without assigning them to this. export class secretagent{  goalkicker.com – javascript® notes for professionals  197  constructor(secret){ const topsecret = secret; this.coverstory = 'just a simple gardner'; this.domission = () => { figurewhattodo(topsecret); // we have access to topsecret }; } }  in this example as well the data is 100% private and can't be reached outside the class, so our agent is safe. using naming conventions we will decide that any property who is private will be preﬁxed with _. note that for this approach the data isn't really private. export class secretagent{ constructor(secret){ this._topsecret = secret; // it private by convention this.coverstory = 'just a simple gardner'; this.domission = () => { figurewhattodo(this_topsecret); }; } }  section 22.9: class name binding classdeclaration's name is bound in diﬀerent ways in diﬀerent scopes 1. the scope in which the class is deﬁned - let binding 2. the scope of the class itself - within { and } in class {} - const binding class foo { // foo inside this block is a const binding } // foo here is a let binding  for example, class a { foo() { a = null; // will throw at runtime as a inside the class is a `const` binding } } a = null; // will not throw as a here is a `let` binding  this is not the same for a function function a() { a = null; // works } a.prototype.foo = function foo() { a = null; // works } a = null; // works  goalkicker.com – javascript® notes for professionals  198",t_a765d0035891,t_a765d0035891,13
c_a12d5fefdf39,"chapter 96 of the book on javascript.chapter 96: same origin policy & crossorigin communication same-origin policy is used by web browsers to prevent scripts to be able to access remote content if the remote address has not the same origin of the script. this prevents malicious scripts from performing requests to other websites to obtain sensitive data. the origin of two addresses is considered the same if both urls have the same protocol, hostname and port.  section 96.1: safe cross-origin communication with messages the window.postmessage() method together with its relative event handler window.onmessage can be safely used to enable cross-origin communication. the postmessage() method of the target window can be called to send a message to another window, which will be able to intercept it with its onmessage event handler, elaborate it, and, if necessary, send a response back to the sender window using postmessage() again. example of window communicating with a children frame content of http://main-site.com/index.html: <!-- ... --> <iframe id=""frame-id"" src=""http://other-site.com/index.html""></iframe> <script src=""main_site_script.js""></script> <!-- ... -->  content of http://other-site.com/index.html: <!-- ... --> <script src=""other_site_script.js""></src> <!-- ... -->  content of main_site_script.js: // get the <iframe>'s window var framewindow = document.getelementbyid('frame-id').contentwindow; // add a listener for a response window.addeventlistener('message', function(evt) { // important: check the origin of the data! if (event.origin.indexof('http://other-site.com') == 0) { // check the response console.log(evt.data); /* ... */ } }); // send a message to the frame's window framewindow.postmessage(/* any obj or var */, '*');  content of other_site_script.js:  goalkicker.com – javascript® notes for professionals  426  window.addeventlistener('message', function(evt) { // important: check the origin of the data! if (event.origin.indexof('http://main-site.com') == 0) { // read and elaborate the received data console.log(evt.data); /* ... */ // send a response back to the main window window.parent.postmessage(/* any obj or var */, '*'); } });  section 96.2: ways to circumvent same-origin policy as far as client-side javascript engines are concerned (those running inside a browser), there is no straightforward solution available for requesting content from sources other than the current domain. (by the way, this limitation does not exist in javascript-server tools such as node js.) however, it is (in some situations) indeed possible to retrieve data from other sources using the following methods. please do note that some of them may present hacks or workarounds instead of solutions production system should rely on. method 1: cors most public apis today allow developers to send data bidirectionally between client and server by enabling a feature called cors (cross-origin resource sharing). the browser will check if a certain http header (accesscontrol-allow-origin) is set and that the requesting site's domain is listed in the header's value. if it is, then the  browser will allow establishing ajax connections. however, because developers cannot change other servers' response headers, this method can't always be relied on. method 2: jsonp json with padding is commonly blamed to be a workaround. it is not the most straightforward method, but it still gets the job done. this method takes advantage of the fact that script ﬁles can be loaded from any domain. still, it is crucial to mention that requesting javascript code from external sources is always a potential security risk and this should generally be avoided if there's a better solution available. the data requested using jsonp is typically json, which happens to ﬁt the syntax used for object deﬁnition in javascript, making this method of transport very simple. a common way to let websites use the external data obtained via jsonp is to wrap it inside a callback function, which is set via a get parameter in the url. once the external script ﬁle loads, the function will be called with the data as its ﬁrst parameter. <script> function myfunc(obj){ console.log(obj.example_field); } </script> <script src=""http://example.com/api/endpoint.js?callback=myfunc""></script>  the contents of http://example.com/api/endpoint.js?callback=myfunc might look like this:  goalkicker.com – javascript® notes for professionals  427  myfunc({""example_field"":true})  the function always has to be deﬁned ﬁrst, otherwise it won't be deﬁned when the external script loads.  goalkicker.com – javascript® notes for professionals  428",t_a765d0035891,t_a765d0035891,13
c_5fc963c0fa9b,"chapter 87 of the book on javascript.chapter 87: using javascript to get/set css custom variables section 87.1: how to get and set css variable property values to get a value use the .getpropertyvalue() method element.style.getpropertyvalue(""--var"")  to set a value use the .setproperty() method. element.style.setproperty(""--var"", ""new_value"")  goalkicker.com – javascript® notes for professionals  406",t_a765d0035891,t_a765d0035891,13
c_332051bd2260,"sal evaluates the definite integral of f(x)=|x+2| between -4 and 0.  - [voiceover] so we have f of x being equal to the absolute value of x plus two. and we wanna evaluate the definite integral from negative four to zero of f of x, dx. and like always, pause this video and see if you can work through this. now when you first do this you might stumble around a little bit, because how do you take the anti-derivative of an absolute value function? and the key here is to, one way to approach it is to rewrite f of x without the absolute value and we can do that by rewriting it as a piecewise function. and the way i'm gonna do it, i'm gonna think about intervals where whatever we take inside the absolute value's going to be positive and other intervals where everything that we take inside the absolute value is going to be negative. and the point at which we change is where x plus two is equal to zero or x is equal to negative two. so let's just think about the intervals x is less than negative two and x is greater than or equal to negative two. and this could have been less than or equal, in which case this would have been greater than, either way it would have been equal to this absolute vale, this is a continuous function here. and so when, let's do the easier case. when x is greater than or equal to negative two then x plus two is going to be positive, or it's going to be greater than or equal to zero, and so the absolute value of it is just going to be x plus two. so it's going to be x plus two when x is greater than or equal to negative two. and what about when x is less than negative two? well when x is less than negative two, x plus two is going to be negative, and then if you take the absolute value of a negative number you're gonna take the opposite of it. so this is going to be negative x plus two. and to really help grok this, 'cause frankly this is the hardest part of what we're doing, and really this is more algebra than calculus. let me draw the absolute value function to make this clear. so that is my x-axis, that is my y-axis and let's say we're here at negative two. and so when we are less than the negative two, when x is less than negative two my graph is going to look like this. it is going to look something, it's gonna look like that. and when we are greater than negative two, do that in a different color, when we are greater than negative two it's going to look like this. it's going to look like that. and so notice this is in blue we have, this is the graph x plus two, we can say this is a graph of y equals x plus two. and what we have in magenta right over here, this is the graph of negative x minus two. it has a negative slope and we intercept the y-axis at negative two. so it makes sense. there's multiple ways that you could reason through this. now once we break it up then we can break up the integral. we could say that what we wrote here, this is equal to the integral from negative four to two, sorry negative four to negative two of f of x, which is in that case it's going to be negative x minus two, i just distributed the negative sign there. dx, and then plus the definite integral going from negative two to zero of x plus two, dx. and just to make sure we know what we're doin' here, if this is negative four right over here, this is zero, that first integral is gonna give us this area right over here. what's the area under the curve negative x minus two, under that curve or under that line and above the x-axis. and the second integral is gonna give us this area right over here between x plus two and the x-axis going from negative two to zero. and so let's evaluate each of these and you might even be able to just evaluate these with a little bit of triangle areas, but let's just do this analytically or algebraically. and so what's the anti-derivative of negative x? well that's negative x-squared over two, and then we have the negative two, so this is gonna be the anti-derivative is negative two x, we're gonna evaluate that at negative two and negative four. and so that part is going to be what? negative two squared, so it's the negative of negative two squared. so it's negative four over two minus two times negative two. so plus four. so that's it evaluated at negative two. and then minus, if we evaluate it at negative four. so we're gonna have minus negative four squared is 16 over two, minus two times negative four. so that is plus eight. so what is that going to give us? so this is negative two, this right over here is negative eight, so the second term right over here is just going to be equal to zero. did i do that right? yeah, the 16 over two, it's negative and this is positive. okay, so this is just going to be zero. and this is negative two plus four which is going to be equal to two. so what we have here in magenta is equal to two. and what we have here in the blue, well let's see, this is the anti-derivative of x-squared over two, plus two x, gonna evaluate it at zero and negative two. you evaluate this thing at zero, it's just gonna be zero and from that you're going to subtract negative two squared over two. that is positive four over two which is positive two. and then plus two times negative two. so minus four. and so this is going to be the negative of negative two, or positive two. so it's two plus two. and that makes sense that what we have in magenta here is two and what we have over here is two, there's the symmetry here. there is a symmetry here. and so you add 'em all together and you get our integral is going to be equal to four. and once again, just as a reality check you could say, look, the height here is two, the width, the base here is two. two times two times one-half is indeed equal to two. same thing over here. so that's the more geometric argument for why that area's two, that area is two, add 'em together you get positive four.",t_aab1bc41d83c,t_aab1bc41d83c,14
c_6a2017bdca35,"finding the appropriate expression to use when looking for the total distance traveled over a certain time interval.  - [instructor] alexey received the following problem: a particle moves in a straight line with velocity v of t is equal to negative t squared plus eight meters per second, where t is time in seconds. at t is equal to two, the particle's distance from the starting point was five meters. what is the total distance the particle has traveled between t equals two and t equals six seconds? which expression should alexey use to solve the problem? so we don't actually have to figure the actual answer out, we just have to figure out what is the appropriate expression. so like always, pause this video and see if you can work through it on your own. so now let's tackle this together. so the key question is what is the total distance the particle has traveled between t equals two and t equals six? so we just care what happens between those points, we don't care that the particle's distance from the starting point was five meters at t equals two. so this right over here is actually unnecessary information. so the first thing that you might wanna think about is well maybe distance is just the integral of the velocity function; we've seen that multiple times. if you want to find the change in a quantity, you just say the starting time and the ending time and then you integrate the rate function. so wouldn't it just be that? now we have to be very very careful. if the question was what is the displacement for the particle between time equals two and time equals six, this would have been the correct answer. so this would be displacement. displacement from t equals two to t is equal to six. but they're not saying displacement. they're saying total distance the particle has traveled. so this is the total path length for the particle. so one way to think about it, you would integrate not the velocity function, if you integrate velocity, you get displacement, instead, you would integrate the speed function. now what is speed? it is the magnitude of velocity and in one dimension, it would just be the absolute value of your velocity function. and so the absolute value of the velocity function, this would give you, integrating the speed, this would give you the distance. distance from t equals two to t is equal to six, and let's see, we have that choice right over here. the displacement one here, this is an interesting distracter but that is not going to be the choice. this one right over here, v prime of six, that gives you the acceleration. if you're taking the derivative of the velocity function, the acceleration at six seconds, that's not what we're interested in. and this gives you the absolute difference in velocity, when in between time six and time two, that's not what we're trying to figure out either.",t_aab1bc41d83c,t_aab1bc41d83c,14
c_82e58dd487b9,"here we find the average value of x^2+1 on the interval between 0 and 3.  - let's say that we have the function f of x is equal to x squared plus one and what we want to do is we want to figure out the average value of our function f on the interval, on the closed interval between zero and let's say between zero and three. i encourage you to pause this video especially if you've seen the other videos on introducing the idea of an average value of a function and figure out what this is. what is the average value of our function f over this interval? so, i'm assuming you've had a go at it. let's just visualize what's going on and then we can actually find the average. so that's my y axis. this is my x axis. now over the interval between zero and three, so let's say this is the zero, this is one, two, three. it's a closed interval. when x is zero f of zero is going to be one. so, we're going to be right over here. f of one is two. so it's one, two, three. actually, let me make my scale a little bit smaller on that. i have to go all the way up to 10. so this is going to be 10. this is going to be five. and then one, two, three. this is the hardest part is making this even. so see this is going to be in the middle. pretty good, and then let's see in the middle. then we have that. good enough. all right. so, we're going to be there. we're going to be there. i have obviously different scales for x and y axis. two squared plus one is five. three squared plus one is 10. three squared plus one is 10. so it's going to look something like this. this is what our function is going to look like. so, that's the graph of y is equal to f of x. and we care about the average value on the closed interval between zero and three. between zero and three. so, one way to think about it, you could apply the formula, but it's very important to think about what does that formula actually mean? once again, you shouldn't memorize this formula because it actually kind of falls out out of what it actually means. so the average of our function is going to be equal to the definite integral over this interval. so, essentially the area under this curve. so, it's going to be the definite intergral from zero to three of f of x which is x squared plus one dx. then we're going to take this area. we're going to take this area right over here and we're going to divide it by the width of our interval to essentially come up with the average height, or the average value of our function. so, we're going to divide it by b minus a, or three minus zero, which is just going to be three. and so now we just have to evaluate this. so, this is going to be equal to one third times -- let's see the antiderivative of x squared is x to the third over three. antiderivative of one is x, and we're going to evaluate it from zero to three. so, this is going to be equal to one third times when we evaluate it at three. let me use another color here. when we evaluate it at three it's going to be three to the third divided by three. well, that's just going to be 27 divided by three. that's nine plus three and then when we evaluated zero, minus zero minus zero. so, it's just minus. when you evaluated zero it's just going to be zero. and so, we are left with -- i'm going to make the brackets that same color. this is going to be one third times 12. one third times 12, which is equal to four. which is equal to four. so this is the average value of our function. the average value of our function over this interval is equal to four. notice, our function actually hits that value at some point in the interval. at some point in the interval, something lower than two but greater than one. we can maybe call that c. it looks like our function hits that value. this is actually a generally true thing. this is a mean value theorem for integrals and we'll go into more depth there. but you can see this kind of does look like it's average value. that if you imagine the box, if you multiplied this height, this average value times this width you would have this area right over here, and this area right over here is the same, this area that i'm highlighting in yellow right over here is the same as the area under the curve because we have the average height times the width is the same thing as the area under the curve. so, anyway hopefully you found that interesting.",t_aab1bc41d83c,t_aab1bc41d83c,14
c_0ba642656c76,"approximating area under a curve using rectangle where the heights are the value of the function at the midpoint of each interval.  - [instructor] what we wanna do in this video is get an understanding of how we can approximate the area under a curve. and for the sake of an example, we'll use the curve y is equal to x squared plus one. and let's think about the area under this curve, above the x-axis, from x equals negative one to x equals two. so that would be this area right over here. and there's many ways that i could tackle this, but what i'm going to do is i'm gonna break up this interval into three equal sections that are really the bases of rectangles. and then we're gonna think about the different ways to define the heights of those rectangles. so once again, i'm going to approximate using three rectangles of equal width. and then we'll think about the different ways that we can define the heights of the rectangles. so let's first define the heights of each rectangle by the value of the function at the midpoint. so we see that right over here. so let's just make sure that it actually makes sense to us. so if we look at our first rectangle right over here, actually let's just first appreciate, we have split up this x, we have split up the interval from x equals negative one to x equals two into three equal sections, and then each of them have a width of one. if we wanted a better approximation we could do more sections or more rectangles, but let's just see how we would compute this. well the width of each of these is one, the height is based on the value of the function at the midpoint. the midpoint here is negative 1/2, the midpoint here is 1/2, the midpoint here is 3/2. and so this height is going to be negative 1/2 squared plus one. so negative 1/2 squared is 1/4 plus one, so that's 5/4. so the height here is 5/4. so you take 5/4 times one. this area is 5/4, let me write that down. so if we're doing the midpoint to define the height of each rectangle, this first one has an area of 5/4. do it in a color you can see, five over four. the second one, same idea, 1/2 squared plus one is 5/4 times a width of one. so 5/4 there. so let me add that. plus 5/4. and then this third rectangle, what's its height? well we're gonna take the height at the midpoint, so 3/2 squared is 9/4 plus one, which is the same thing as 13/4. so it has a height of 13/4, and then a width of one, so times one, which would just give us 13/4. so plus 13/4, which would give us 23 over four which is the same thing as 5 3/4. and so this is often known as a midpoint approximation where we're using the midpoint of each interval to define the height of our rectangle. but this isn't the only way to do it. we could look at the left endpoint or the right endpoint, and we do that in other videos. and if we wanna do it just for kicks here, let's just do that really fast. so if we wanna look at the left endpoints of our interval, well here our left endpoint is negative one, negative one squared plus one is two, two times one gives us two. and then here the left part of this interval is x equals zero, zero squared plus one is one, one times one is one. and now here our left endpoint is one, one squared plus one is equal to two, times one, our base, is equal to two. so here we have a situation where we take our left endpoints, where it is equal to two plus one plus two or five. well we can also look at the right endpoints of our intervals. so this first rectangle here, clearly under approximating the area over this first interval. its right endpoint is zero, zero squared plus one is one, so a height of one, width of one, has an area of one. second rectangle here, it has a height of, look at our right endpoint, one squared plus one is two, times our width of one, well that's just gonna give us two. and then here our right endpoint is two, squared plus one is five, times our width of one, gives us five. so in this case we get, when we look at our right endpoints of our intervals, we get one plus two plus five is equal to eight. and eyeballing this, it looks like we're definitely over counting more than under counting, and so this looks like an over approximation. so the whole idea here's just to appreciate how we can compute these approximations using rectangles. and as you can imagine, if we added more rectangles that had skinnier and skinnier bases but still covered the interval from x equals negative one to x equals two, we would get better and better approximations of the true area.",t_aab1bc41d83c,t_aab1bc41d83c,14
c_4ca470860b5d,"based on the fundamental theorem of calculus, we can use antiderivatives to compute integrals.  so we've got the function, f of x is equal to x squared. and what i'm concerned with, is finding the area under the curve, y is equal to f of x, so that's my y axis. this is my, my, x axis. then let me draw my function. my function looks like this. at least in the, in the first quadrant. that's where i'll graph it for now. i could also graph it, obviously in the second quadrant. but, what i care about is the area under this curve and above the positive x axis, between, between x equals 1 and x equals 4, x equals 4. and i'm tired of approximating areas. i wanna find the exact area under this curve above the x axis. and the way we denote the exact area under the curve, this little brown shaded area, is using the definite integral. the definite integral from 1 to 4 of f of x, dx. and the way that, or the way i conceptualize where this notation comes from, is we imagine a bunch of infinite, an infinite number of infinitely thin rectangles that we sum up to find this area. let me draw one of those infinitely thin rectangles, maybe not so infinitely thin. so, let me draw it like this. so, that would be one of the rectangles, that would be another rectangle. this should be reminiscent of a riemann sum. in fact, that's where the riemann integral comes from. think of a riemann sum where you have an infinite number of these rectangles, where the width of each of the rectangles. this is how i conceptualize it, is dx, and the height of this rectangle is the function evaluated at an x that's within this interval right over here. and so, this part right over here is the area of one of those rectangles, and we were summing them all up. and this kind of an elongated s, reminiscent of a sigma for summing. we're summing up the infinite number, of those infinitely thin rectangles, or the areas of those infinitely thin rectangles between 1 and 4. so that's where the notation of the definite integral comes from. but we still haven't done anything. we've just written some notation that says the exact area of the un- between 1 and 4, under the curve f of x, and above the x axis. in order to actually do anything really productive with this, we have to turn to the second fundamental theorem of calculus, sometimes called part two of the fundamental theorem of calculus. &gt;&gt; which tells us, that if f has an antiderivative, so if we have the antiderivative of f, so f of x is derivative, derivative of some function capital f of x, or another way of saying it is, f, capital f of x is the antiderivative, antiderivative of lower case f of x. then i can evaluate this thing, and we do a whole video on conceptually understanding why this makes sense. we could evaluate this, by evaluating the antiderivative of f, or an antiderivative of f, at 4. and from that, subtract the antiderivative evaluated at 1. so, let's do it for this particular case right over here. so we are taking, i'll just rewrite this statement. instead of writing f of x, i'll write x squared. so, the definite integral from 1 to 4 of x squared dx. well, we're just gonna have to figure out what the antiderivative is. so if f of x is equal to x squared, what is capital f of x equal to? what is the antiderivative? well, you might remember from your power rule, that if you take the derivative with respect to x of x to the third, you are going to get 3x squared, which is pretty darn close to x squared except for this factor of 3. so, let's divide both sides by 3. let's divide both sides by 3, and you get the derivative of x to the third divided by 3 is indeed x squared. or, you can say this is the same thing as the derivative with respect to x of, x to the third over 3. take the derivative of this. it'll be 3 times one third. and then you'll decrement the power, it'll just be x squared. so, this right over here, once again, is x squared. it's just equal to, just equal to x squared. so, in this case, our capital f of x, our antiderivative, is x to the third, x to the third over 3. and so we just have to evaluate that at 4 and at 1, and sometimes the way we would, the, the notation we would use is, we'll say that the antiderivative is x to the third over 3, and we're going to evaluate it, the one i, i always just like to write the numbers up here, at 4 and from that subtracted, evaluated at 1. sometimes you'll see people write a little line here too, we'll say we're evaluate it at 4 and then at 1. but i'll just do it without the line. if we're gonna evaluate this thing at 4 and from that subtract it, subtract it evaluated at 1, so this going to be equal to 4 to the third power is 64, so it's going to be 64 over 3. let me color code it, this is, this right over here, is this, right over there and then from that, we're going to subtract this business evaluated at one. well, when you evaluate it at 1, you get 1 to the third is one over 3. you get one third. so just to be clear, this is this right over there. and then we are ready to just subtract these fractions. 64 over 3, minus one third, is equal to 63 over 3. and 3 goes into 63 exactly, exactly 21 times. so, whatever the units are, the area of this brown area is 21 square units.",t_aab1bc41d83c,t_aab1bc41d83c,14
c_2224856ef342,"chapter 50 of the book on java.chapter 50: nested and inner classes using java, developers have the ability to deﬁne a class within another class. such a class is called a nested class. nested classes are called inner classes if they were declared as non-static, if not, they are simply called static nested classes. this page is to document and provide details with examples on how to use java nested and inner classes.  section 50.1: a simple stack using a nested class public class intstack { private intstacknode head; // intstacknode is the inner class of the class intstack // each instance of this inner class functions as one link in the // overall stack that it helps to represent private static class intstacknode { private int val; private intstacknode next; private intstacknode(int v, intstacknode n) { val = v; next = n; } } public intstack push(int v) { head = new intstacknode(v, head); return this; } public int pop() { int x = head.val; head = head.next; return x; } }  and the use thereof, which (notably) does not at all acknowledge the existence of the nested class. public class main { public static void main(string[] args) { intstack s = new intstack(); s.push(4).push(3).push(2).push(1).push(0); //prints: 0, 1, 2, 3, 4, for(int i = 0; i < 5; i++) { system.out.print(s.pop() + "", ""); } } }  section 50.2: static vs non static nested classes when creating a nested class, you face a choice of having that nested class static: goalkicker.com – java® notes for professionals  290  public class outerclass1 { private static class staticnestedclass { } }  or non-static: public class outerclass2 { private class nestedclass { } }  at its core, static nested classes do not have a surrounding instance of the outer class, whereas non-static nested classes do. this aﬀects both where/when one is allowed to instantiate a nested class, and what instances of those nested classes are allowed to access. adding to the above example: public class outerclass1 { private int afield; public void amethod(){} private static class staticnestedclass { private int innerfield; private staticnestedclass() { innerfield = afield; //illegal, can't access afield from static context amethod(); //illegal, can't call amethod from static context } private staticnestedclass(outerclass1 instance) { innerfield = instance.afield; //legal } } public static void astaticmethod() { staticnestedclass s = new staticnestedclass(); //legal, able to construct in static context //do stuff involving s... } } public class outerclass2 { private int afield; public void amethod() {} private class nestedclass { private int innerfield; private nestedclass() { innerfield = afield; //legal amethod(); //legal  goalkicker.com – java® notes for professionals  291  } } public void anonstaticmethod() { nestedclass s = new nestedclass(); //legal } public static void astaticmethod() { nestedclass s = new nestedclass(); //illegal. can't construct without surrounding outerclass2 instance. //as this is a static context, there is no surrounding outerclass2 instance } }  thus, your decision of static vs non-static mainly depends on whether or not you need to be able to directly access ﬁelds and methods of the outer class, though it also has consequences for when and where you can construct the nested class. as a rule of thumb, make your nested classes static unless you need to access ﬁelds and methods of the outer class. similar to making your ﬁelds private unless you need them public, this decreases the visibility available to the nested class (by not allowing access to an outer instance), reducing the likelihood of error.  section 50.3: access modiﬁers for inner classes a full explanation of access modiﬁers in java can be found here. but how do they interact with inner classes? public, as usual, gives unrestricted access to any scope able to access the type. public class outerclass { public class innerclass { public int x = 5; } public innerclass createinner() { return new innerclass(); } } public class someotherclass { public static void main(string[] args) { int x = new outerclass().createinner().x; //direct field access is legal } }  both protected and the default modiﬁer (of nothing) behave as expected as well, the same as they do for nonnested classes. private, interestingly enough, does not restrict to the class it belongs to. rather, it restricts to the compilation unit -  the .java ﬁle. this means that outer classes have full access to inner class ﬁelds and methods, even if they are marked private. public class outerclass {  goalkicker.com – java® notes for professionals  292  public class innerclass { private int x; private void aninnermethod() {} } public innerclass amethod() { innerclass a = new innerclass(); a.x = 5; //legal a.aninnermethod(); //legal return a; } }  the inner class itself can have a visibility other than public. by marking it private or another restricted access modiﬁer, other (external) classes will not be allowed to import and assign the type. they can still get references to objects of that type, however. public class outerclass { private class innerclass{} public innerclass makeinnerclass() { return new innerclass(); } } public class anotherclass { public static void main(string[] args) { outerclass o = new outerclass(); innerclass x = o.makeinnerclass(); //illegal, can't find type outerclass.innerclass x = o.makeinnerclass(); //illegal, innerclass has visibility private object x = o.makeinnerclass(); //legal } }  section 50.4: anonymous inner classes an anonymous inner class is a form of inner class that is declared and instantiated with a single statement. as a consequence, there is no name for the class that can be used elsewhere in the program; i.e. it is anonymous. anonymous classes are typically used in situations where you need to be able to create a light-weight class to be passed as a parameter. this is typically done with an interface. for example: public static comparator<string> case_insensitive = new comparator<string>() { @override public int compare(string string1, string string2) { return string1.touppercase().compareto(string2.touppercase()); } };  this anonymous class deﬁnes a comparator<string> object (case_insensitive) that compares two strings ignoring diﬀerences in case. other interfaces that are frequently implemented and instantiated using anonymous classes are runnable and goalkicker.com – java® notes for professionals  293  callable. for example: // an anonymous runnable class is used to provide an instance that the thread // will run when started. thread t = new thread(new runnable() { @override public void run() { system.out.println(""hello world""); } }); t.start(); // prints ""hello world""  anonymous inner classes can also be based on classes. in this case, the anonymous class implicitly extends the existing class. if the class being extended is abstract, then the anonymous class must implement all abstract methods. it may also override non-abstract methods. constructors an anonymous class cannot have an explicit constructor. instead, an implicit constructor is deﬁned that uses super(...) to pass any parameters to a constructor in the class that is being extended. for example: someclass anon = new someclass(1, ""happiness"") { @override public int somemethod(int arg) { // do something } };  the implicit constructor for our anonymous subclass of someclass will call a constructor of someclass that matches the call signature someclass(int, string). if no constructor is available, you will get a compilation error. any exceptions that are thrown by the matched constructor are also thrown by the implicit constructor. naturally, this does not work when extending an interface. when you create an anonymous class from an interface, the classes superclass is java.lang.object which only has a no-args constructor.  section 50.5: create instance of non-static inner class from outside an inner class which is visible to any outside class can be created from this class as well. the inner class depends on the outside class and requires a reference to an instance of it. to create an instance of the inner class, the new operator only needs to be called on an instance of the outer class. class outerclass { class innerclass { } } class outsideclass { outerclass outer = new outerclass(); outerclass.innerclass createinner() { return outer.new innerclass(); } }  goalkicker.com – java® notes for professionals  294  note the usage as outer.new.  section 50.6: method local inner classes a class written within a method called method local inner class. in that case the scope of the inner class is restricted within the method. a method-local inner class can be instantiated only within the method where the inner class is deﬁned. the example of using method local inner class: public class outerclass { private void outermethod() { final int outerint = 1; // method local inner class class methodlocalinnerclass { private void print() { system.out.println(""method local inner class "" + outerint); } } // accessing the inner class methodlocalinnerclass inner = new methodlocalinnerclass(); inner.print(); } public static void main(string args[]) { outerclass outer = new outerclass(); outer.outermethod(); } }  executing will give an output: method local inner class 1 .  section 50.7: accessing the outer class from a non-static inner class the reference to the outer class uses the class name and this public class outerclass { public class innerclass { public void method() { system.out.println(""i can access my enclosing class: "" + outerclass.this); } } }  you can access ﬁelds and methods of the outer class directly. public class outerclass { private int counter; public class innerclass { public void method() { system.out.println(""i can access "" + counter);  goalkicker.com – java® notes for professionals  295  } } }  but in case of name collision you can use the outer class reference. public class outerclass { private int counter; public class innerclass { private int counter; public void method() { system.out.println(""my counter: "" + counter); system.out.println(""outer counter: "" + outerclass.this.counter); // updating my counter counter = outerclass.this.counter; } } }  goalkicker.com – java® notes for professionals  296",t_afb9306e5f18,t_afb9306e5f18,15
c_2986c35edc5a,"section ""about"" of the book on java.about  please feel free to share this pdf with anyone for free, latest version of this book can be downloaded from: https://goalkicker.com/javabook  this java® notes for professionals book is compiled from stack overﬂow documentation, the content is written by the beautiful people at stack overﬂow. text content is released under creative commons by-sa, see credits at the end of this book whom contributed to the various chapters. images may be copyright of their respective owners unless otherwise speciﬁed this is an unoﬃcial free book created for educational purposes and is not aﬃliated with oﬃcial java® group(s) or company(s) nor stack overﬂow. all trademarks and registered trademarks are the property of their respective company owners the information presented in this book is not guaranteed to be correct nor accurate, use at your own risk please send feedback and corrections to web@petercv.com  goalkicker.com – java® notes for professionals  1",t_afb9306e5f18,t_afb9306e5f18,15
c_d01e74684567,"chapter 43 of the book on java.chapter 43: annotations in java, an annotation is a form of syntactic metadata that can be added to java source code. it provides data about a program that is not part of the program itself. annotations have no direct eﬀect on the operation of the code they annotate. classes, methods, variables, parameters and packages are allowed to be annotated.  section 43.1: the idea behind annotations the java language speciﬁcation describes annotations as follows: an annotation is a marker which associates information with a program construct, but has no eﬀect at run time. annotations may appear before types or declarations. it is possible for them to appear in a place where they could apply to both a type or a declaration. what exactly an annotation applies to is governed by the ""meta-annotation"" @target. see ""deﬁning annotation types"" for more information. annotations are used for a multitude of purposes. frameworks like spring and spring-mvc make use of annotations to deﬁne where dependencies should be injected or where requests should be routed. other frameworks use annotations for code-generation. lombok and jpa are prime examples, that use annotations to generate java (and sql) code. this topic aims to provide a comprehensive overview of: how to deﬁne your own annotations? what annotations does the java language provide? how are annotations used in practice?  section 43.2: deﬁning annotation types annotation types are deﬁned with @interface. parameters are deﬁned similar to methods of a regular interface. @interface myannotation { string param1(); boolean param2(); int[] param3(); // array parameter }  default values @interface myannotation { string param1() default ""somevalue""; boolean param2() default true; int[] param3() default {}; }  meta-annotations meta-annotations are annotations that can be applied to annotation types. special predeﬁned meta-annotation deﬁne how annotation types can be used. goalkicker.com – java® notes for professionals  241  @target the @target meta-annotation restricts the types the annotation can be applied to. @target(elementtype.method) @interface myannotation { // this annotation can only be applied to methods }  multiple values can be added using array notation, e.g. @target({elementtype.field, elementtype.type}) available values elementtype  target  annotation_type annotation types  example usage on target element @retention(retentionpolicy.runtime) terface  myannotation  constructor  constructors  @myannotationlic myclass() {}  field  ﬁelds, enum constants  @xmlattributevate int count;  local_variable  variable declarations inside methods  package  package (in packageinfo.java)  @deprecatedkage very.old;  method  methods  @xmlelementlic int getcount() {...}  parameter  method/constructor parameters  type  classes, interfaces, enums  for (@loopvariable int i = 0; i < 100; i++) {  @unused string resultvariable; }  public rectangle( @namedarg(""width"") double width,  @namedarg(""height"") double height) { ... } @xmlrootelementlic class report {}  version ≥ java se 8  elementtype target example usage on target element type_parameter type parameter declarations public <@myannotation t> void f(t t) {} type_use  use of a type  object o = ""42"";ing s = (@myannotation string) o;  @retention the @retention meta-annotation deﬁnes the annotation visibility during the applications compilation process or execution. by default, annotations are included in .class ﬁles, but are not visible at runtime. to make an annotation accessible at runtime, retentionpolicy.runtime has to be set on that annotation. @retention(retentionpolicy.runtime) @interface myannotation { // this annotation can be accessed with reflections at runtime }  available values retentionpolicy eﬀect the annotation is available in the .class ﬁle, but not at runtime class runtime  the annotation is available at runtime and can be accessed via reﬂection  source  the annotation is available at compile time, but not added to the .class ﬁles. the annotation can be used e.g. by an annotation processor.  @documented the @documented meta-annotation is used to mark annotations whose usage should be documented by api documentation generators like javadoc. it has no values. with @documented, all classes that use the annotation will list it on their generated documentation page. without @documented, it's not possible to see which classes use the goalkicker.com – java® notes for professionals  242  annotation in the documentation. @inherited the @inherited meta-annotation is relevant to annotations that are applied to classes. it has no values. marking an annotation as @inherited alters the way that annotation querying works. for a non-inherited annotation, the query only examines the class being examined. for an inherited annotation, the query will also check the super-class chain (recursively) until an instance of the annotation is found. note that only the super-classes are queried: any annotations attached to interfaces in the classes hierarchy will be ignored. @repeatable the @repeatable meta-annotation was added in java 8. it indicates that multiple instances of the annotation can be attached to the annotation's target. this meta-annotation has no values.  section 43.3: runtime annotation checks via reﬂection java's reﬂection api allows the programmer to perform various checks and operations on class ﬁelds, methods and annotations during runtime. however, in order for an annotation to be at all visible at runtime, the retentionpolicy must be changed to runtime, as demonstrated in the example below: @interface mydefaultannotation { } @retention(retentionpolicy.runtime) @interface myruntimevisibleannotation { } public class annotationatruntimetest { @mydefaultannotation static class runtimecheck1 { } @myruntimevisibleannotation static class runtimecheck2 { } public static void main(string[] args) { annotation[] annotationsbytype = runtimecheck1.class.getannotations(); annotation[] annotationsbytype2 = runtimecheck2.class.getannotations(); system.out.println(""default retention: "" + arrays.tostring(annotationsbytype)); system.out.println(""runtime retention: "" + arrays.tostring(annotationsbytype2)); } }  section 43.4: built-in annotations the standard edition of java comes with some annotations predeﬁned. you do not need to deﬁne them by yourself and you can use them immediately. they allow the compiler to enable some fundamental checking of methods, goalkicker.com – java® notes for professionals  243  classes and code. @override this annotation applies to a method and says that this method must override a superclass' method or implement an abstract superclass' method deﬁnition. if this annotation is used with any other kind of method, the compiler will throw an error. concrete superclass public class vehicle { public void drive() { system.out.println(""i am driving""); } } class car extends vehicle { // fine @override public void drive() { system.out.prinln(""brrrm, brrm""); } }  abstract class abstract class animal { public abstract void makenoise(); } class dog extends animal { // fine @override public void makenoise() { system.out.prinln(""woof""); } }  does not work class logger1 { public void log(string logstring) { system.out.prinln(logstring); } } class logger2 { // this will throw compile-time error. logger2 is not a subclass of logger1. // log method is not overriding anything @override public void log(string logstring) { system.out.println(""log 2"" + logstring); } }  the main purpose is to catch mistyping, where you think you are overriding a method, but are actually deﬁning a new one. class vehicle {  goalkicker.com – java® notes for professionals  244  public void drive() { system.out.println(""i am driving""); } } class car extends vehicle { // compiler error. ""dirve"" is not the correct method name to override. @override public void dirve() { system.out.prinln(""brrrm, brrm""); } }  note that the meaning of @override has changed over time: in java 5, it meant that the annotated method had to override a non-abstract method declared in the superclass chain. from java 6 onward, it is also satisﬁed if the annotated method implements an abstract method declared in the classes superclass / interface hierarchy. (this can occasionally cause problems when back-porting code to java 5.) @deprecated this marks the method as deprecated. there can be several reasons for this: the api is ﬂawed and is impractical to ﬁx, usage of the api is likely to lead to errors, the api has been superseded by another api, the api is obsolete, the api is experimental and is subject to incompatible changes, or any combination of the above. the speciﬁc reason for deprecation can usually be found in the documentation of the api. the annotation will cause the compiler to emit an error if you use it. ides may also highlight this method somehow as deprecated class complexalgorithm { @deprecated public void oldslowunthreadsafemethod() { // stuff here } public void quickthreadsafemethod() { // client code should use this instead } }  @suppresswarnings in almost all cases, when the compiler emits a warning, the most appropriate action is to ﬁx the cause. in some instances (generics code using untype-safe pre-generics code, for example) this may not be possible and it's better to suppress those warnings that you expect and cannot ﬁx, so you can more clearly see unexpected warnings. goalkicker.com – java® notes for professionals  245  this annotation can be applied to a whole class, method or line. it takes the category of warning as a parameter. @suppresswarnings(""deprecation"") public class riddledwithwarnings { // several methods calling deprecated code here } @suppresswarning(""finally"") public boolean checkdata() { // method calling return from within finally block }  it is better to limit the scope of the annotation as much as possible, to prevent unexpected warnings also being suppressed. for example, conﬁning the scope of the annotation to a single-line: complexalgorithm algorithm = new complexalgorithm(); @suppresswarnings(""deprecation"") algoritm.slowunthreadsafemethod(); // we marked this method deprecated in an example above @suppresswarnings(""unsafe"") list<integer> list = getuntypesafelist(); // old library returns, non-generic list containing only integers  the warnings supported by this annotation may vary from compiler to compiler. only the unchecked and deprecation warnings are speciﬁcally mentioned in the jls. unrecognized warning types will be ignored.  @safevarargs because of type erasure, void method(t... t) will be converted to void method(object[] t) meaning that the compiler is not always able to verify that the use of varargs is type-safe. for instance: private static <t> void generatesvarargswarning(t... lists) {  there are instances where the use is safe, in which case you can annotate the method with the safevarargs annotation to suppress the warning. this obviously hides the warning if your use is unsafe too. @functionalinterface this is an optional annotation used to mark a functionalinterface. it will cause the compiler to complain if it does not conform to the functionalinterface spec (has a single abstract method) @functionalinterface public interface itrade { public boolean check(trade t); } @functionalinterface public interface predicate<t> { boolean test(t t); }  section 43.5: compile time processing using annotation processor this example demonstrates how to do compile time checking of an annotated element. the annotation goalkicker.com – java® notes for professionals  246  the @setter annotation is a marker can be applied to methods. the annotation will be discarded during compilation not be available afterwards. package annotation; import import import import  java.lang.annotation.elementtype; java.lang.annotation.retention; java.lang.annotation.retentionpolicy; java.lang.annotation.target;  @retention(retentionpolicy.source) @target(elementtype.method) public @interface setter { }  the annotation processor the setterprocessor class is used by the compiler to process the annotations. it checks, if the methods annotated with the @setter annotation are public, non-static methods with a name starting with set and having a uppercase letter as 4th letter. if one of these conditions isn't met, a error is written to the messager. the compiler writes this to stderr, but other tools could use this information diﬀerently. e.g. the netbeans ide allows the user specify annotation processors that are used to display error messages in the editor. package annotation.processor; import import import import import import import import import import import import import import import  annotation.setter; java.util.set; javax.annotation.processing.abstractprocessor; javax.annotation.processing.messager; javax.annotation.processing.processingenvironment; javax.annotation.processing.roundenvironment; javax.annotation.processing.supportedannotationtypes; javax.annotation.processing.supportedsourceversion; javax.lang.model.sourceversion; javax.lang.model.element.element; javax.lang.model.element.elementkind; javax.lang.model.element.executableelement; javax.lang.model.element.modifier; javax.lang.model.element.typeelement; javax.tools.diagnostic;  @supportedannotationtypes({""annotation.setter""}) @supportedsourceversion(sourceversion.release_8) public class setterprocessor extends abstractprocessor { private messager messager; @override public boolean process(set<? extends typeelement> annotations, roundenvironment roundenv) { // get elements annotated with the @setter annotation set<? extends element> annotatedelements = roundenv.getelementsannotatedwith(setter.class); for (element element : annotatedelements) { if (element.getkind() == elementkind.method) { // only handle methods as targets checkmethod((executableelement) element); } } // don't claim annotations to allow other processors to process them return false;  goalkicker.com – java® notes for professionals  247  } private void checkmethod(executableelement method) { // check for valid name string name = method.getsimplename().tostring(); if (!name.startswith(""set"")) { printerror(method, ""setter name must start with \""set\""""); } else if (name.length() == 3) { printerror(method, ""the method name must contain more than just \""set\""""); } else if (character.islowercase(name.charat(3))) { if (method.getparameters().size() != 1) { printerror(method, ""character following \""set\"" must be upper case""); } } // check, if setter is public if (!method.getmodifiers().contains(modifier.public)) { printerror(method, ""setter must be public""); } // check, if method is static if (method.getmodifiers().contains(modifier.static)) { printerror(method, ""setter must not be static""); } } private void printerror(element element, string message) { messager.printmessage(diagnostic.kind.error, message, element); } @override public void init(processingenvironment processingenvironment) { super.init(processingenvironment); // get messager for printing errors messager = processingenvironment.getmessager(); } }  packaging to be applied by the compiler, the annotation processor needs to be made available to the spi (see serviceloader). to do this a text ﬁle meta-inf/services/javax.annotation.processing.processor needs to be added to the jar ﬁle containing the annotation processor and the annotation in addition to the other ﬁles. the ﬁle needs to include the fully qualiﬁed name of the annotation processor, i.e. it should look like this annotation.processor.setterprocessor  we'll assume the jar ﬁle is called annotationprocessor.jar below. example annotated class the following class is example class in the default package with the annotations being applied to the correct elements according to the retention policy. however only the annotation processor only considers the second method a valid annotation target. import annotation.setter;  goalkicker.com – java® notes for professionals  248  public class annotationprocessortest { @setter private void setvalue(string value) {} @setter public void setstring(string value) {} @setter public static void main(string[] args) {} }  using the annotation processor with javac if the annotation processor is discovered using the spi, it is automatically used to process annotated elements. e.g. compiling the annotationprocessortest class using javac -cp annotationprocessor.jar annotationprocessortest.java  yields the following output annotationprocessortest.java:6: error: setter must be public private void setvalue(string value) {} ^ annotationprocessortest.java:12: error: setter name must start with ""set"" public static void main(string[] args) {} ^ 2 errors  instead of compiling normally. no .class ﬁle is created. this could be prevented by specifying the -proc:none option for javac. you could also forgo the usual compilation by specifying -proc:only instead. ide integration netbeans annotation processors can be used in the netbeans editor. to do this the annotation processor needs to be speciﬁed in the project settings: 1. go to project properties > build > compiling 2. add check marks for enable annotation processing and enable annotation processing in editor 3. click add next to the annotation processor list 4. in the popup that appears enter the fully qualiﬁed class name of the annotation processor and click ok. result  goalkicker.com – java® notes for professionals  249  section 43.6: repeating annotations until java 8, two instances of the same annotation could not be applied to a single element. the standard workaround was to use a container annotation holding an array of some other annotation: // author.java @retention(retentionpolicy.runtime) public @interface author { string value(); } // authors.java @retention(retentionpolicy.runtime) public @interface authors { author[] value(); } // test.java @authors({ @author(""mary""), @author(""sam"") }) public class test { public static void main(string[] args) { author[] authors = test.class.getannotation(authors.class).value(); for (author author : authors) { system.out.println(author.value()); // output: // mary // sam } } } version ≥ java se 8  java 8 provides a cleaner, more transparent way of using container annotations, using the @repeatable annotation. first we add this to the author class: @repeatable(authors.class)  this tells java to treat multiple @author annotations as though they were surrounded by the @authors container. we can also use class.getannotationsbytype() to access the @author array by its own class, instead of through its goalkicker.com – java® notes for professionals  250  container: @author(""mary"") @author(""sam"") public class test { public static void main(string[] args) { author[] authors = test.class.getannotationsbytype(author.class); for (author author : authors) { system.out.println(author.value()); // output: // mary // sam } } }  section 43.7: inherited annotations by default class annotations do not apply to types extending them. this can be changed by adding the @inherited annotation to the annotation deﬁnition example consider the following 2 annotations: @inherited @target(elementtype.type) @retention(retentionpolicy.runtime) public @interface inheritedannotationtype { }  and @target(elementtype.type) @retention(retentionpolicy.runtime) public @interface uninheritedannotationtype { }  if three classes are annotated like this: @uninheritedannotationtype class a { } @inheritedannotationtype class b extends a { } class c extends b { }  running this code system.out.println(new a().getclass().getannotation(inheritedannotationtype.class)); system.out.println(new b().getclass().getannotation(inheritedannotationtype.class)); system.out.println(new c().getclass().getannotation(inheritedannotationtype.class)); system.out.println(""_________________________________""); system.out.println(new a().getclass().getannotation(uninheritedannotationtype.class));  goalkicker.com – java® notes for professionals  251  system.out.println(new b().getclass().getannotation(uninheritedannotationtype.class)); system.out.println(new c().getclass().getannotation(uninheritedannotationtype.class));  will print a result similar to this (depending on the packages of the annotation): null @inheritedannotationtype() @inheritedannotationtype() _________________________________ @uninheritedannotationtype() null null  note that annotations can only be inherited from classes, not interfaces.  section 43.8: getting annotation values at run-time you can fetch the current properties of the annotation by using reﬂection to fetch the method or field or class which has an annotation applied to it, and then fetching the desired properties. @retention(retentionpolicy.runtime) @interface myannotation { string key() default ""foo""; string value() default ""bar""; }  class annotationexample { // put the annotation on the method, but leave the defaults @myannotation public void testdefaults() throws exception { // using reflection, get the public method ""testdefaults"", which is this method with no args method method = annotationexample.class.getmethod(""testdefaults"", null); // fetch the annotation that is of type myannotation from the method myannotation annotation = (myannotation)method.getannotation(myannotation.class); // print out the settings of the annotation print(annotation); } //put the annotation on the method, but override the settings @myannotation(key=""baz"", value=""buzz"") public void testvalues() throws exception { // using reflection, get the public method ""testvalues"", which is this method with no args method method = annotationexample.class.getmethod(""testvalues"", null); // fetch the annotation that is of type myannotation from the method myannotation annotation = (myannotation)method.getannotation(myannotation.class); // print out the settings of the annotation print(annotation); } public void print(myannotation annotation) { // fetch the myannotation 'key' & 'value' properties, and print them out system.out.println(annotation.key() + "" = "" + annotation.value()); } public static void main(string[] args) {  goalkicker.com – java® notes for professionals  252  annotationexample example = new annotationexample(); try { example.testdefaults(); example.testvalues(); } catch( exception e ) { // shouldn't throw any exceptions system.err.println(""exception ["" + e.getclass().getname() + ""] - "" + e.getmessage()); e.printstacktrace(system.err); } } }  the output will be foo = bar baz = buzz  section 43.9: annotations for 'this' and receiver parameters when java annotations were ﬁrst introduced there was no provision for annotating the target of an instance method or the hidden constructor parameter for an inner classes constructor. this was remedied in java 8 with addition of receiver parameter declarations; see jls 8.4.1. the receiver parameter is an optional syntactic device for an instance method or an inner class's constructor. for an instance method, the receiver parameter represents the object for which the method is invoked. for an inner class's constructor, the receiver parameter represents the immediately enclosing instance of the newly constructed object. either way, the receiver parameter exists solely to allow the type of the represented object to be denoted in source code, so that the type may be annotated. the receiver parameter is not a formal parameter; more precisely, it is not a declaration of any kind of variable (§4.12.3), it is never bound to any value passed as an argument in a method invocation expression or qualiﬁed class instance creation expression, and it has no eﬀect whatsoever at run time. the following example illustrates the syntax for both kinds of receiver parameter: public class outer { public class inner { public inner (outer this) { // ... } public void doit(inner this) { // ... } } }  the sole purpose of receiver parameters is to allow you to add annotations. for example, you might have a custom annotation @isopen whose purpose is to assert that a closeable object has not been closed when a method is called. for example: public class myresource extends closeable { public void update(@isopen myresource this, int value) { // ... }  goalkicker.com – java® notes for professionals  253  public void close() { // ... } }  at one level, the @isopen annotation on this could simply serve as documentation. however, we could potentially do more. for example: an annotation processor could insert a runtime check that this is not in closed state when update is called. a code checker could perform a static code analysis to ﬁnd cases where this could be closed when update is called.  section 43.10: add multiple annotation values an annotation parameter can accept multiple values if it is deﬁned as an array. for example the standard annotation @suppresswarnings is deﬁned like this: public @interface suppresswarnings { string[] value(); }  the value parameter is an array of strings. you can set multiple values by using a notation similar to array initializers: @suppresswarnings({""unused""}) @suppresswarnings({""unused"", ""javadoc""})  if you only need to set a single value, the brackets can be omitted: @suppresswarnings(""unused"")  goalkicker.com – java® notes for professionals  254",t_afb9306e5f18,t_afb9306e5f18,15
c_5a8cf1010b6e,"chapter 142 of the book on java.chapter 142: security & cryptography section 142.1: compute cryptographic hashes to compute the hashes of relatively small blocks of data using diﬀerent algorithms: final messagedigest md5 = messagedigest.getinstance(""md5""); final messagedigest sha1 = messagedigest.getinstance(""sha-1""); final messagedigest sha256 = messagedigest.getinstance(""sha-256""); final byte[] data = ""foo bar"".getbytes(); system.out.println(""md5 hash: "" + datatypeconverter.printhexbinary(md5.digest(data))); system.out.println(""sha1 hash: "" + datatypeconverter.printhexbinary(sha1.digest(data))); system.out.println(""sha256 hash: "" + datatypeconverter.printhexbinary(sha256.digest(data)));  produces this output: md5 hash: e99e768582f6dd5a3ba2d9c849df736e sha1 hash: 0135faa6323685ba8a8ff8d3f955f0c36949d8fb sha256 hash: 8d35c97bcd902b96d1b551741bbe8a7f50bb5a690b4d0225482eaa63dbfb9ded  additional algorithms may be available depending on your implementation of the java platform.  section 142.2: encrypt and decrypt data with public / private keys to encrypt data with a public key: final cipher rsa = cipher.getinstance(""rsa""); rsa.init(cipher.encrypt_mode, keypair.getpublic()); rsa.update(message.getbytes()); final byte[] result = rsa.dofinal(); system.out.println(""message: "" + message); system.out.println(""encrypted: "" + datatypeconverter.printhexbinary(result));  produces output similar to: message: hello encrypted: 5641fbb9558ecfa9ed...  note that when creating the cipher object, you have to specify a transformation that is compatible with the type of key being used. (see jca standard algorithm names for a list of supported transformations.). for rsa encryption data message.getbytes() length must be smaller than the key size. see this so answer for detail. to decrypt the data: final cipher rsa = cipher.getinstance(""rsa""); rsa.init(cipher.decrypt_mode, keypair.getprivate()); rsa.update(ciphertext); final string result = new string(rsa.dofinal());  goalkicker.com – java® notes for professionals  790  system.out.println(""decrypted: "" + result);  produces the following output: decrypted: hello  section 142.3: generate cryptographically random data to generate samples of cryptographically random data: final byte[] sample = new byte[16]; new securerandom().nextbytes(sample); system.out.println(""sample: "" + datatypeconverter.printhexbinary(sample));  produces output similar to: sample: e4f14cea2384f70b706b53a6df8c5efe  note that the call to nextbytes() may block while entropy is gathered depending on the algorithm being used. to specify the algorithm and provider: final byte[] sample = new byte[16]; final securerandom randomness = securerandom.getinstance(""sha1prng"", ""sun""); randomness.nextbytes(sample); system.out.println(""provider: "" + randomness.getprovider()); system.out.println(""algorithm: "" + randomness.getalgorithm()); system.out.println(""sample: "" + datatypeconverter.printhexbinary(sample));  produces output similar to: provider: sun version 1.8 algorithm: sha1prng sample: c80c44baeb352fd29fbbe20489e4c0b9  section 142.4: generate public / private key pairs to generate key pairs using diﬀerent algorithms and key sizes: final keypairgenerator dhgenerator = keypairgenerator.getinstance(""diffiehellman""); final keypairgenerator dsagenerator = keypairgenerator.getinstance(""dsa""); final keypairgenerator rsagenerator = keypairgenerator.getinstance(""rsa""); dhgenerator.initialize(1024); dsagenerator.initialize(1024); rsagenerator.initialize(2048); final keypair dhpair = dhgenerator.generatekeypair(); final keypair dsapair = dsagenerator.generatekeypair(); final keypair rsapair = rsagenerator.generatekeypair();  goalkicker.com – java® notes for professionals  791  additional algorithms and key sizes may be available on your implementation of the java platform. to specify a source of randomness to use when generating the keys: final keypairgenerator generator = keypairgenerator.getinstance(""rsa""); generator.initialize(2048, securerandom.getinstance(""sha1prng"", ""sun"")); final keypair pair = generator.generatekeypair();  section 142.5: compute and verify digital signatures to compute a signature: final privatekey privatekey = keypair.getprivate(); final byte[] data = ""foo bar"".getbytes(); final signature signer = signature.getinstance(""sha1withrsa""); signer.initsign(privatekey); signer.update(data); final byte[] signature = signer.sign();  note that the signature algorithm must be compatible with the algorithm used to generate the key pair. to verify a signature: final publickey publickey = keypair.getpublic(); final signature verifier = signature.getinstance(""sha1withrsa""); verifier.initverify(publickey); verifier.update(data); system.out.println(""signature: "" + verifier.verify(signature));  produces this output: signature: true  goalkicker.com – java® notes for professionals  792",t_afb9306e5f18,t_afb9306e5f18,15
c_689c247a5cfb,"chapter 181 of the book on java.chapter 181: appdynamics and tibco businessworks instrumentation for easy integration as appdynamics aims to provide a way to measure application performance, speed of development, delivery (deployment) of applications is an essential factor in making devops eﬀorts a true success. monitoring a tibco bw application with appd is generally simple and not time consuming but when deploying large sets of applications rapid instrumentation is key. this guide shows how to instrument all of your bw applications in a single step without modifying each application before deploying.  section 181.1: example of instrumentation of all bw applications in a single step for appdynamics 1. locate and open your tibco bw bwengine.tra ﬁle typlically under tibco_home/bw/5.12/bin/bwengine.tra (linux environment) 2. look for the line that states: *** common variables. modify these only. *** 3. add the following line right after that section tibco.deployment=%tibco.deployment% 4. go to the end of the ﬁle and add (replace ? with your own values as needed or remove the ﬂag that does not apply): java.extended.properties=-javaagent:/opt/appd/current/appagent/javaagent.jar dappdynamics.http.proxyhost=? -dappdynamics.http.proxyport=? -dappdynamics.agent.applicationname=? -dappdynamics.agent.tiername=? -dappdynamics.agent.nodename=%tibco.deployment% dappdynamics.controller.ssl.enabled=? -dappdynamics.controller.sslport=? -dappdynamics.agent.logs.dir=? dappdynamics.agent.runtime.dir=? -dappdynamics.controller.hostname=? -dappdynamics.controller.port=? -dappdynamics.agent.accountname=? -dappdynamics.agent.accountaccesskey=? 5. save ﬁle and redeploy. all your applications should now be instrumented automatically at deployment time.  goalkicker.com – java® notes for professionals  921",t_afb9306e5f18,t_afb9306e5f18,15
c_b8407acb7186,"chapter 25 of the book on java.chapter 25: lists a list is an ordered collection of values. in java, lists are part of the java collections framework. lists implement the java.util.list interface, which extends java.util.collection.  section 25.1: sorting a generic list the collections class oﬀers two standard static methods to sort a list: sort(list<t> list) applicable to lists where t extends comparable<? super t>, and sort(list<t> list, comparator<? super t> c) applicable to lists of any type.  applying the former requires amending the class of list elements being sorted, which is not always possible. it might also be undesirable as although it provides the default sorting, other sorting orders may be required in diﬀerent circumstances, or sorting is just a one oﬀ task. consider we have a task of sorting objects that are instances of the following class: public class user { public final long id; public final string username; public user(long id, string username) { this.id = id; this.username = username; } @override public string tostring() { return string.format(""%s:%d"", username, id); } }  in order to use collections.sort(list<user> list) we need to modify the user class to implement the comparable interface. for example public class user implements comparable<user> { public final long id; public final string username; public user(long id, string username) { this.id = id; this.username = username; } @override public string tostring() { return string.format(""%s:%d"", username, id); } @override /** the natural ordering for 'user' objects is by the 'id' field. */ public int compareto(user o) { return id.compareto(o.id); } }  goalkicker.com – java® notes for professionals  146  (aside: many standard java classes such as string, long, integer implement the comparable interface. this makes lists of those elements sortable by default, and simpliﬁes implementation of compare or compareto in other classes.) with the modiﬁcation above, the we can easily sort a list of user objects based on the classes natural ordering. (in this case, we have deﬁned that to be ordering based on id values). for example: list<user> users = lists.newarraylist( new user(33l, ""a""), new user(25l, ""b""), new user(28l, """")); collections.sort(users); system.out.print(users); // [b:25, c:28, a:33]  however, suppose that we wanted to sort user objects by name rather than by id. alternatively, suppose that we had not been able to change the class to make it implement comparable. this is where the sort method with the comparator argument is useful: collections.sort(users, new comparator<user>() { @override /* order two 'user' objects based on their names. */ public int compare(user left, user right) { return left.username.compareto(right.username); } }); system.out.print(users); // [a:33, b:25, c:28] version ≥ java se 8  in java 8 you can use a lambda instead of an anonymous class. the latter reduces to a one-liner: collections.sort(users, (l, r) -> l.username.compareto(r.username));  further, there java 8 adds a default sort method on the list interface, which simpliﬁes sorting even more. users.sort((l, r) -> l.username.compareto(r.username))  section 25.2: convert a list of integers to a list of strings list<integer> nums = arrays.aslist(1, 2, 3); list<string> strings = nums.stream() .map(object::tostring) .collect(collectors.tolist());  that is: 1. create a stream from the list 2. map each element using object::tostring 3. collect the string values into a list using collectors.tolist()  section 25.3: classes implementing list - pros and cons the list interface is implemented by diﬀerent classes. each of them has its own way for implementing it with diﬀerent strategies and providing diﬀerent pros and cons. goalkicker.com – java® notes for professionals  147  classes implementing list these are all of the public classes in java se 8 that implement the java.util.list interface: 1. abstract classes: abstractlist abstractsequentiallist 2. concrete classes: arraylist attributelist copyonwritearraylist linkedlist rolelist roleunresolvedlist stack vector  pros and cons of each implementation in term of time complexity arraylist public class arraylist<e> extends abstractlist<e> implements list<e>, randomaccess, cloneable, serializable  arraylist is a resizable-array implementation of the list interface. storing the list into an array, arraylist provides methods (in addition to the methods implementing the list interface) for manipulating the size of the array. initialize arraylist of integer with size 100 list<integer> mylist = new arraylist<integer>(100); // constructs an empty list with the specified initial capacity.  - pros: the size, isempty, get, set, iterator, and listiterator operations run in constant time. so getting and setting each element of the list has the same time cost: int e1 = mylist.get(0); // int e2 = mylist.get(10); // mylist.set(2,10); //  \ | => all the same constant cost => o(1) /  - cons: being implemented with an array (static structure) adding elements over the size of the array has a big cost due to the fact that a new allocation need to be done for all the array. however, from documentation: the add operation runs in amortized constant time, that is, adding n elements requires o(n) time removing an element requires o(n) time.  attributelist  goalkicker.com – java® notes for professionals  148  on coming  copyonwritearraylist on coming  linkedlist public class linkedlist<e> extends abstractsequentiallist<e> implements list<e>, deque<e>, cloneable, serializable  linkedlist is implemented by a doubly-linked list a linked data structure that consists of a set of sequentially linked records called nodes. iitialize linkedlist of integer list<integer> mylist = new linkedlist<integer>(); // constructs an empty list.  - pros: adding or removing an element to the front of the list or to the end has constant time. mylist.add(10); // \ mylist.add(0,2); // | => constant time => o(1) mylist.remove(); // /  - cons: from documentation: operations that index into the list will traverse the list from the beginning or the end, whichever is closer to the speciﬁed index. operations such as: mylist.get(10); // \ mylist.add(11,25); // | => worst case done in o(n/2) mylist.set(15,35); // /  rolelist on coming  roleunresolvedlist on coming  stack on coming  goalkicker.com – java® notes for professionals  149  vector on coming  section 25.4: finding common elements between 2 lists suppose you have two lists: a and b, and you need to ﬁnd the elements that exist in both lists. you can do it by just invoking the method list.retainall(). example: public static void main(string[] args) { list<integer> numbersa = new arraylist<>(); list<integer> numbersb = new arraylist<>(); numbersa.addall(arrays.aslist(new integer[] { 1, 3, 4, 7, 5, 2 })); numbersb.addall(arrays.aslist(new integer[] { 13, 32, 533, 3, 4, 2 })); system.out.println(""a: "" + numbersa); system.out.println(""b: "" + numbersb); list<integer> numbersc = new arraylist<>(); numbersc.addall(numbersa); numbersc.retainall(numbersb); system.out.println(""list a : "" + numbersa); system.out.println(""list b : "" + numbersb); system.out.println(""common elements between a and b: "" + numbersc); }  section 25.5: in-place replacement of a list element this example is about replacing a list element while ensuring that the replacement element is at the same position as the element that is replaced. this can be done using these methods: set(int index, t type) int indexof(t type) consider an arraylist containing the elements ""program starting!"", ""hello world!"" and ""goodbye world!"" list<string> strings = new arraylist<string>(); strings.add(""program starting!""); strings.add(""hello world!""); strings.add(""goodbye world!"");  if we know the index of the element we want to replace, we can simply use set as follows: strings.set(1, ""hi world"");  if we don't know the index, we can search for it ﬁrst. for example: int pos = strings.indexof(""goodbye world!""); if (pos >= 0) {  goalkicker.com – java® notes for professionals  150  strings.set(pos, ""goodbye cruel world!""); }  notes: 1. the set operation will not cause a concurrentmodificationexception. 2. the set operation is fast ( o(1) ) for arraylist but slow ( o(n) ) for a linkedlist. 3. an indexof search on an arraylist or linkedlist is slow ( o(n) ).  section 25.6: making a list unmodiﬁable the collections class provides a way to make a list unmodiﬁable: list<string> ls = new arraylist<string>(); list<string> unmodifiablelist = collections.unmodifiablelist(ls);  if you want an unmodiﬁable list with one item you can use: list<string> unmodifiablelist = collections.singletonlist(""only string in the list"");  section 25.7: moving objects around in the list the collections class allows for you to move objects around in the list using various methods (ls is the list): reversing a list: collections.reverse(ls);  rotating positions of elements in a list the rotate method requires an integer argument. this is how many spots to move it along the line by. an example of this is below: list<string> ls = new arraylist<string>(); ls.add("" how""); ls.add("" are""); ls.add("" you?""); ls.add(""hello,""); collections.rotate(ls, 1); for(string line : ls) system.out.print(line); system.out.println();  this will print ""hello, how are you?"" shuﬄing elements around in a list using the same list above, we can shuﬄe the elements in a list: collections.shuffle(ls);  we can also give it a java.util.random object that it uses to randomly place objects in spots: random random = new random(12); collections.shuffle(ls, random);  goalkicker.com – java® notes for professionals  151  section 25.8: creating, adding and removing element from an arraylist arraylist is one of the inbuilt data structures in java. it is a dynamic array (where the size of the data structure not  needed to be declared ﬁrst) for storing elements (objects). it extends abstractlist class and implements list interface. an arraylist can contain duplicate elements where it maintains insertion order. it should be noted that the class arraylist is non-synchronized, so care should be taken when handling concurrency with arraylist. arraylist allows random access because array works at the index basis. manipulation is slow in arraylist because of shifting that often occurs when an element is removed from the array list. an arraylist can be created as follows: list<t> myarraylist = new arraylist<>();  where t ( generics ) is the type that will be stored inside arraylist. the type of the arraylist can be any object. the type can't be a primitive type (use their wrapper classes instead). to add an element to the arraylist, use add() method: myarraylist.add(element);  or to add item to a certain index: myarraylist.add(index, element); //index of the element should be an int (starting from 0)  to remove an item from the arraylist, use the remove() method: myarraylist.remove(element);  or to remove an item from a certain index: myarraylist.remove(index); //index of the element should be an int (starting from 0)  section 25.9: creating a list giving your list a type to create a list you need a type (any class, e.g. string). this is the type of your list. the list will only store objects of the speciﬁed type. for example: list<string> strings;  can store ""string1"", ""hello world!"", ""goodbye"", etc, but it can't store 9.2, however: list<double> doubles;  can store 9.2, but not ""hello world!"". initialising your list if you try to add something to the lists above you will get a nullpointerexception, because strings and doubles goalkicker.com – java® notes for professionals  152  both equal null! there are two ways to initialise a list: option 1: use a class that implements list list is an interface, which means that does not have a constructor, rather methods that a class must override. arraylist is the most commonly used list, though linkedlist is also common. so we initialise our list like this: list<string> strings = new arraylist<string>();  or list<string> strings = new linkedlist<string>(); version ≥ java se 7  starting from java se 7, you can use a diamond operator: list<string> strings = new arraylist<>();  or list<string> strings = new linkedlist<>();  option 2: use the collections class the collections class provides two useful methods for creating lists without a list variable: emptylist(): returns an empty list. singletonlist(t): creates a list of type t and adds the element speciﬁed.  and a method which uses an existing list to ﬁll data in: addall(l, t...): adds all the speciﬁed elements to the list passed as the ﬁrst parameter.  examples: import java.util.list; import java.util.collections; list<integer> l = collections.emptylist(); list<integer> l1 = collections.singletonlist(42); collections.addall(l1, 1, 2, 3);  section 25.10: positional access operations the list api has eight methods for positional access operations: add(t type) add(int index, t type) remove(object o) remove(int index) get(int index) set(int index, e element) int indexof(object o) int lastindexof(object o)  so, if we have a list:  goalkicker.com – java® notes for professionals  153  list<string> strings = new arraylist<string>();  and we wanted to add the strings ""hello world!"" and ""goodbye world!"" to it, we would do it as such: strings.add(""hello world!""); strings.add(""goodbye world!"");  and our list would contain the two elements. now lets say we wanted to add ""program starting!"" at the front of the list. we would do this like this: strings.add(0, ""program starting!"");  note: the ﬁrst element is 0. now, if we wanted to remove the ""goodbye world!"" line, we could do it like this: strings.remove(""goodbye world!"");  and if we wanted to remove the ﬁrst line (which in this case would be ""program starting!"", we could do it like this: strings.remove(0);  note: 1. adding and removing list elements modify the list, and this can lead to a concurrentmodificationexception if the list is being iterated concurrently. 2. adding and removing elements can be o(1) or o(n) depending on the list class, the method used, and whether you are adding / removing an element at the start, the end, or in the middle of the list. in order to retrieve an element of the list at a speciﬁed position you can use the e get(int index); method of the list api. for example: strings.get(0);  will return the ﬁrst element of the list. you can replace any element at a speciﬁed position by using the set(int index, e element);. for example: strings.set(0,""this is a replacement"");  this will set the string ""this is a replacement"" as the ﬁrst element of the list. note: the set method will overwrite the element at the position 0. it will not add the new string at the position 0 and push the old one to the position 1. the int indexof(object o); returns the position of the ﬁrst occurrence of the object passed as argument. if there are no occurrences of the object in the list then the -1 value is returned. in continuation of the previous example if you call: strings.indexof(""this is a replacement"")  the 0 is expected to be returned as we set the string ""this is a replacement"" in the position 0 of our list. in case where there are more than one occurrence in the list when int indexof(object o); is called then as mentioned goalkicker.com – java® notes for professionals  154  the index of the ﬁrst occurrence will be returned. by calling the int lastindexof(object o) you can retrieve the index of the last occurrence in the list. so if we add another ""this is a replacement"": strings.add(""this is a replacement""); strings.lastindexof(""this is a replacement"");  this time the 1 will be returned and not the 0;  section 25.11: iterating over elements in a list for the example, lets say that we have a list of type string that contains four elements: ""hello, "", ""how "", ""are "", ""you?"" the best way to iterate over each element is by using a for-each loop: public void printeachelement(list<string> list){ for(string s : list){ system.out.println(s); } }  which would print: hello, how are you?  to print them all in the same line, you can use a stringbuilder: public void printasline(list<string> list){ stringbuilder builder = new stringbuilder(); for(string s : list){ builder.append(s); } system.out.println(builder.tostring()); }  will print: hello, how are you?  alternatively, you can use element indexing ( as described in accessing element at ith index from arraylist ) to iterate a list. warning: this approach is ineﬃcient for linked lists.  section 25.12: removing elements from list b that are present in the list a lets suppose you have 2 lists a and b, and you want to remove from b all the elements that you have in a the method in this case is list.removeall(collection c);  #example:  goalkicker.com – java® notes for professionals  155  public static void main(string[] args) { list<integer> numbersa = new arraylist<>(); list<integer> numbersb = new arraylist<>(); numbersa.addall(arrays.aslist(new integer[] { 1, 3, 4, 7, 5, 2 })); numbersb.addall(arrays.aslist(new integer[] { 13, 32, 533, 3, 4, 2 })); system.out.println(""a: "" + numbersa); system.out.println(""b: "" + numbersb); numbersb.removeall(numbersa); system.out.println(""b cleared: "" + numbersb); }  this will print a: [1, 3, 4, 7, 5, 2] b: [13, 32, 533, 3, 4, 2] b cleared: [13, 32, 533]  goalkicker.com – java® notes for professionals  156",t_afb9306e5f18,t_afb9306e5f18,15
c_bb648f2d5277,"chapter 37 of the book on java.chapter 37: enumset class java enumset class is the specialized set implementation for use with enum types. it inherits abstractset class and implements the set interface.  section 37.1: enum set example import java.util.*; enum days { sunday, monday, tuesday, wednesday, thursday, friday, saturday } public class enumsetexample { public static void main(string[] args) { set<days> set = enumset.of(days.tuesday, days.wednesday); // traversing elements iterator<days> iter = set.iterator(); while (iter.hasnext()) system.out.println(iter.next()); } }  goalkicker.com – java® notes for professionals  206",t_afb9306e5f18,t_afb9306e5f18,15
c_0166d1150098,"chapter 87 of the book on java.chapter 87: random number generation section 87.1: pseudo random numbers java provides, as part of the utils package, a basic pseudo-random number generator, appropriately named random. this object can be used to generate a pseudo-random value as any of the built-in numerical datatypes (int, float, etc). you can also use it to generate a random boolean value, or a random array of bytes. an example usage  is as follows: import java.util.random; ... random random = new random(); int randint = random.nextint(); long randlong = random.nextlong(); double randdouble = random.nextdouble(); //this returns a value between 0.0 and 1.0 float randfloat = random.nextfloat(); //same as nextdouble byte[] randbytes = new byte[16]; random.nextbytes(randbytes); //nextbytes takes a user-supplied byte array, and fills it with random bytes. it returns nothing.  note: this class only produces fairly low-quality pseudo-random numbers, and should never be used to generate random numbers for cryptographic operations or other situations where higher-quality randomness is critical (for that, you would want to use the securerandom class, as noted below). an explanation for the distinction between ""secure"" and ""insecure"" randomness is beyond the scope of this example.  section 87.2: pseudo random numbers in speciﬁc range the method nextint(int bound) of random accepts an upper exclusive boundary, i.e. a number that the returned random value must be less than. however, only the nextint method accepts a bound; nextlong, nextdouble etc. do not. random random = new random(); random.nextint(1000); // 0 - 999 int number = 10 + random.nextint(100); // number is in the range of 10 to 109  starting in java 1.7, you may also use threadlocalrandom (source). this class provides a thread-safe prng (pseudorandom number generator). note that the nextint method of this class accepts both an upper and lower bound. import java.util.concurrent.threadlocalrandom; // nextint is normally exclusive of the top value, // so add 1 to make it inclusive threadlocalrandom.current().nextint(min, max + 1);  note that the oﬃcial documentation states that nextint(int bound) can do weird things when bound is near 230+1 (emphasis added): the algorithm is slightly tricky. it rejects values that would result in an uneven distribution (due to the fact that 2^31 is not divisible by n). the probability of a value being rejected depends on n. the worst goalkicker.com – java® notes for professionals  512  case is n=2^30+1, for which the probability of a reject is 1/2, and the expected number of iterations before the loop terminates is 2. in other words, specifying a bound will (slightly) decrease the performance of the nextint method, and this performance decrease will become more pronounced as the bound approaches half the max int value.  section 87.3: generating cryptographically secure pseudorandom numbers random and threadlocalrandom are good enough for everyday use, but they have a big problem: they are based on  a linear congruential generator, an algorithm whose output can be predicted rather easily. thus, these two classes are not suitable for cryptographic uses (such as key generation). one can use java.security.securerandom in situations where a prng with an output that is very hard to predict is required. predicting the random numbers created by instances of this class is hard enough to label the class as cryptographically secure. import java.security.securerandom; import java.util.arrays; public class foo { public static void main(string[] args) { securerandom rng = new securerandom(); byte[] randombytes = new byte[64]; rng.nextbytes(randombytes); // fills randombytes with random bytes (duh) system.out.println(arrays.tostring(randombytes)); } }  besides being cryptographically secure, securerandom has a gigantic period of 2160, compared to randoms period of 248. it has one drawback of being considerably slower than random and other linear prngs such as mersenne twister and xorshift, however. note that securerandom implementation is both platform and provider dependent. the default securerandom (given by sun provider in sun.security.provider.securerandom): on unix-like systems, seeded with data from /dev/random and/or /dev/urandom. on windows, seeded with calls to cryptgenrandom() in cryptoapi.  section 87.4: generating random numbers with a speciﬁed seed //creates a random instance with a seed of 12345. random random = new random(12345l); //gets a threadlocalrandom instance threadlocalrandom tlr = threadlocalrandom.current(); //set the instance's seed. tlr.setseed(12345l);  using the same seed to generate random numbers will return the same numbers every time, so setting a diﬀerent seed for every random instance is a good idea if you don't want to end up with duplicate numbers.  goalkicker.com – java® notes for professionals  513  a good method to get a long that is diﬀerent for every call is system.currenttimemillis(): random random = new random(system.currenttimemillis()); threadlocalrandom.current().setseed(system.currenttimemillis());  section 87.5: select random numbers without duplicates /** * returns a array of random numbers with no duplicates * @param range the range of possible numbers for ex. if 100 then it can be anywhere from 1-100 * @param length the length of the array of random numbers * @return array of random numbers with no duplicates. */ public static int[] getrandomnumberswithnoduplicates(int range, int length){ if (length<range){ // this is where all the random numbers int[] randomnumbers = new int[length]; // loop through all the random numbers to set them for (int q = 0; q < randomnumbers.length; q++){ // get the remaining possible numbers int remainingnumbers = range-q; // get a new random number from the remainingnumbers int newrandspot = (int) (math.random()*remainingnumbers); newrandspot++; // loop through all the possible numbers for (int t = 1; t < range+1; t++){ // check to see if this number has already been taken boolean taken = false; for (int number : randomnumbers){ if (t==number){ taken = true; break; } } // if it hasnt been taken then remove one from the spots if (!taken){ newrandspot--; // if we have gone though all the spots then set the value if (newrandspot==0){ randomnumbers[q] = t; } } } } return randomnumbers; } else { // invalid can't have a length larger then the range of possible numbers } return null; }  the method works by looping though an array that has the size of the requested length and ﬁnds the remaining goalkicker.com – java® notes for professionals  514  length of possible numbers. it sets a random number of those possible numbers newrandspot and ﬁnds that number within the non taken number left. it does this by looping through the range and checking to see if that number has already been taken. for example if the range is 5 and the length is 3 and we have already chosen the number 2. then we have 4 remaining numbers so we get a random number between 1 and 4 and we loop through the range(5) skipping over any numbers that we have already used(2). now let's say the next number chosen between 1 & 4 is 3. on the ﬁrst loop we get 1 which has not yet been taken so we can remove 1 from 3 making it 2. now on the second loop we get 2 which has been taken so we do nothing. we follow this pattern until we get to 4 where once we remove 1 it becomes 0 so we set the new randomnumber to 4.  section 87.6: generating random number using apachecommon lang3 we can use org.apache.commons.lang3.randomutils to generate random numbers using a single line. int x = randomutils.nextint(1, 1000);  the method nextint(int startinclusive, int endexclusive) takes a range. apart from int, we can generate random long, double, float and bytes using this class. randomutils class contains the following methodsstatic byte[] nextbytes(int count) //creates an array of random bytes. static double nextdouble() //returns a random double within 0 - double.max_value static double nextdouble(double startinclusive, double endinclusive) //returns a random double within the specified range. static float nextfloat() //returns a random float within 0 - float.max_value static float nextfloat(float startinclusive, float endinclusive) //returns a random float within the specified range. static int nextint() //returns a random int within 0 - integer.max_value static int nextint(int startinclusive, int endexclusive) //returns a random integer within the specified range. static long nextlong() //returns a random long within 0 - long.max_value static long nextlong(long startinclusive, long endexclusive) //returns a random long within the specified range.  goalkicker.com – java® notes for professionals  515",t_afb9306e5f18,t_afb9306e5f18,15
c_0abc27076951,"chapter 65 of the book on java.chapter 65: super keyword section 65.1: super keyword use with examples super keyword performs important role in three places 1. constructor level 2. method level 3. variable level constructor level super keyword is used to call parent class constructor. this constructor can be default constructor or  parameterized constructor. default constructor : super(); parameterized constructor : super(int no, double amount, string name); class parentclass { parentclass(){ system.out.println(""constructor of superclass""); } } class subclass extends parentclass { subclass(){ /* compile adds super() here at the first line * of this constructor implicitly */ system.out.println(""constructor of subclass""); } subclass(int n1){ /* compile adds super() here at the first line * of this constructor implicitly */ system.out.println(""constructor with arg""); } void display(){ system.out.println(""hello""); } public static void main(string args[]){ // creating object using default constructor subclass obj= new subclass(); //calling sub class method obj.display(); //creating object 2 using arg constructor subclass obj2= new subclass(10); obj2.display(); } }  note: super() must be the ﬁrst statement in constructor otherwise we will get the compilation error message. method level  goalkicker.com – java® notes for professionals  375  super keyword can also be used in case of method overriding. super keyword can be used to invoke or call parent  class method. class parentclass { //overridden method void display(){ system.out.println(""parent class method""); } } class subclass extends parentclass { //overriding method void display(){ system.out.println(""child class method""); } void printmsg(){ //this would call overriding method display(); //this would call overridden method super.display(); } public static void main(string args[]){ subclass obj= new subclass(); obj.printmsg(); } }  note:if there is not method overriding then we do not need to use super keyword to call parent class method. variable level super is used to refer immediate parent class instance variable. in case of inheritance, there may be possibility of  base class and derived class may have similar data members.in order to diﬀerentiate between the data member of base/parent class and derived/child class, in the context of derived class the base class data members must be preceded by super keyword. //parent class or superclass class parentclass { int num=100; } //child class or subclass class subclass extends parentclass { /* i am declaring the same variable * num in child class too. */ int num=110; void printnumber(){ system.out.println(num); //it will print value 110 system.out.println(super.num); //it will print value 100 } public static void main(string args[]){ subclass obj= new subclass(); obj.printnumber(); } }  goalkicker.com – java® notes for professionals  376  note: if we are not writing super keyword before the base class data member name then it will be referred as current class data member and base class data member are hidden in the context of derived class.  goalkicker.com – java® notes for professionals  377",t_afb9306e5f18,t_afb9306e5f18,15
c_736329b2803d,"what is multicystic dysplastic kidney (mcdk)? well, mcdk is a non-inherited congenital disorder where the ureteric bud fails to develop properly, which means urine isn't allowed to drain and fluid filled cysts form. multicystic dysplastic kidney or mcdk is a congenital disease where one or both kidneys don’t form quite right, specifically causing them to not drain urine properly, which results in urine building up in the kidneys and forming multiple fluid-filled sacs called cysts. alright so during fetal development, first off you’ve got this structure called the mesonephric duct which is involved in development of urinary and reproductive organs, and during the 5th week of gestation, a little guy called the ureteric bud starts pushing its way into another structure called the metanephric blastema, and together, these two little embryologic structures go on to develop into a kidney. at about the 7th week, nephrogenesis, or formation of the kidneys, starts under the influence of that ureteric bud. by about 20 weeks, the ureteric bud has formed the ureters, the renal calyces, collecting ducts, and collecting tubules, while the metanephric blastema develops into the nephron itself, which includes the epithelial cells and the podocytes of bowman’s capsule. in the third trimester and throughout infancy, the kidneys continue to grow and mature. although not completely known, it’s thought that mcdk is a result of some sort of abnormal induction of the metanephric blastema by the ureteric bud. this failure might be the fault of the mesonephric duct not forming right, or the ureteric bud not forming right, or both. regardless of the cause of failure, the ureteric bud is supposed to go on to form the ureters as well as the rest of the tubules that branch out to collect urine. so as blood starts coming in to be filtered, and urine starts getting produced, a failure to properly develop into these urine-collecting tubules means that the urine has nowhere to go, and so it builds up in the kidneys and forms these fluid-filled cysts that are composed of abnormal connective tissue—especially cartilage—that actually replaces normal kidney tissue and decreases the kidney’s ability to function. most cases are actually unilateral, meaning they affect only one kidney, although sometimes it might be bilateral, where both are affected. mcdk is usually a sporadic condition that happens during development, and does not follow a clear inheritance pattern; which is an important distinction from polycystic kidney disease, a similar cystic kidney disease that’s familial, meaning inherited and in this case it’s typically passed through autosomal dominant inheritance. having said that, there are some genetic syndromes, like papillorenal syndrome, that have been associated with mcdk, as well as some genes that may play a role like eya1, six1, and the pax2 gene. certain prescription drugs taken for maternal hypertension like ace inhibitors, as well as illicit drugs like cocaine have also been implicated as potentially causing mcdk in the developing fetus. if only one kidney’s been affected and the other’s functioning normally, the remaining kidney might be able to preserve overall kidney function. if it’s bilateral and mild, the newborn may need dialysis and/or a kidney transplant, but newborns with severe bilateral mcdk usually don’t survive. alright, so as a quick recap, multicystic dysplastic kidney is a type of non-inherited congenital kidney disease where the ureteric bud fails to develop properly, resulting in a buildup of urine, and formation of cysts. thanks for watching, you can help support us by donating on patreon, or subscribing to our channel, or telling your friends about us on social media.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_2357aa82f193,"what is wilson's disease (wilson disease)? you usually take in more copper than your body needs every day, and any excess is excreted. one essential mineral that our body needs to get through the diet is copper, and typically we take in about 1 to 2 mg per day from the food we eat, things like whole grains, beans, nuts and potatoes; but really our body only needs about 0.75 mg / day, so that extra copper is excreted. about 90% of the excess copper is excreted into the bile, where it eventually ends up as fecal copper, and the other 10% is excreted in the urine. in wilson disease, there’s genetic defect that results in the excess copper being kept in the body and deposited in various tissues...where it’s not supposed to be, and just like iron, free copper reacts with hydrogen peroxide in the body to form the hydroxyl radical, a reactive oxygen species that’s pretty good at damaging tissue, so over time those tissues are seriously damaged by free radical generation. now your liver cells, or hepatocytes, play a really important role in helping the body get rid of excess copper. so usually the copper from the diet is absorbed in the stomach and small intestine via enterocytes, and passed off into the portal vein to the liver. once it’s in the liver it’s sent to a special transport protein called atp7b, which has a couple super important jobs. the first job, is that it binds copper to apoceruloplasmin, which is the major copper-carrying protein in the blood and is responsible for carrying 95% of the copper in blood. after it binds copper it’s then just called ceruloplasmin, and this guy can haul 6 molecules of copper at once. atp7b’s other job is to gather up the rest of the copper into vesicles to be exocytosed into into the bile canaliculi, where it goes into the bile and is eventually excreted. with wilson disease, there’s an autosomal recessive defect in this atp7b transport protein. as you could probably guess, that means it can’t incorporate the copper into ceruloplasmin or excrete it into the bile. since it’s not doing either of these things anymore, the copper builds up inside the hepatocyte and starts to produce free radicals. eventually, all this built up copper and free-radical damage injures or destroys the hepatocyte, causing free copper to spill out into the interstitial space and from there into the blood supply, where it’s circulated to and deposited in other tissues, where it also causes free radical damage over time. one organ in particular is the brain, and for this reason wilson disease can have serious neurological symptoms and complications. depending on where it deposits, it can cause different disorders, if it deposits in the basal ganglia, it can cause a movement disorder that’s a lot like parkinsonism. if it gets to the cerebral cortex it can be toxic to neurons, and can lead to neuronal cell death and dementia. one place that it can deposit that can be helpful for diagnosis, is in descemet’s membrane of the cornea, which is this membrane between the stroma and the endothelial layer of the cornea, so you’ll look for something called kayser-fleischer rings, which are visible copper deposits in the cornea. since it starts in the liver though, liver damage is usually seen first, and often progresses from acute hepatitis to cirrhosis and liver failure. symptoms usually present in late childhood. typically when you look at someone’s blood with wilson’s disease, you’ll note a couple pretty key things. one is that there’ll be an overall decreased level of ceruloplasmin in the blood, because remember that you need apoceruloplasmin to bind to copper for it to be ceruloplasmin, so without atp7b binding copper to apoceruloplasmin, all you have is apoceruloplasmin which is relatively unstable and doesn’t last very long in the plasma. this can be important for diagnosing wilson’s disease early on. another key feature to note, as hepatocytes are damaged and release free or unbound copper, there’ll be increased levels of free copper in the blood, which will also lead to increased free copper in the urine. other common complications from deposited copper in other tissues include an enlarged liver and spleen, hepatosplenomegaly, renal disease due to damage to the proximal tubules of the kidney, and hemolytic anemia due to direct damage that circulating free copper causes to red blood cells. penicillamine will usually be used to treat wilson’s disease, penicillamine is an alpha amino acid metabolite of penicillin, but doesn’t share the same antibiotic properties as penicillin. instead, though, it’s a copper chelating agent, meaning it binds the free copper in the serum and makes it easier to excrete. also though, patients can be given zinc or ammonium tetrathiomolybdate, both which reduce copper reabsorption in the urine and therefore increase the amount of copper that’s ultimately excreted in the urine. finally, if the liver’s been damaged to the point of cirrhosis and liver failure, a liver transplant may be needed.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_397a9e1e9870,"what is diabetes mellitus? diabetes mellitus is when there's too much glucose, a type of sugar, in the blood. diabetes mellitus can be split into type 1, type 2, as well as a couple other subtypes, including gestational diabetes and drug-induced diabetes. diabetes mellitus author: tanner marshall, ms editor: rishi desai, md, mph in diabetes mellitus, your body has trouble moving glucose, which is a type of sugar, from your blood into your cells. this leads to high levels of glucose in your blood and not enough of it in your cells, and remember that your cells need glucose as a source of energy, so not letting the glucose enter means that the cells starve for energy despite having glucose right on their doorstep. in general, the body controls how much glucose is in the blood relative to how much gets into the cells with two hormones: insulin and glucagon. insulin is used to reduce blood glucose levels, and glucagon is used to increase blood glucose levels. both of these hormones are produced by clusters of cells in the pancreas called islets of langerhans. insulin is secreted by beta cells in the center of the islets, and glucagon is secreted by alpha cells in the periphery of the islets. insulin reduces the amount of glucose in the blood by binding to insulin receptors embedded in the cell membrane of various insulin-responsive tissues like muscle cells and adipose tissue. when activated, the insulin receptors cause vesicles containing glucose transporter that are inside the cell to fuse with the cell membrane, allowing glucose to be transported into the cell. glucagon does exactly the opposite, it raises the blood glucose levels by getting the liver to generate new molecules of glucose from other molecules and also break down glycogen into glucose so that it can all get dumped into the blood. diabetes mellitus is diagnosed when the blood glucose levels get too high, and this is seen among 10% of the world population. there are two types of diabetes - type 1 and type 2, and the main difference between them is the underlying mechanism that causes the blood glucose levels to rise. about 10% of people with diabetes having type 1, and the remaining 90% of people with diabetes having type 2. let’s start with type 1 diabetes mellitus, sometimes just called type 1 diabetes. in this situation, the body doesn’t make enough insulin. the reason this happens is that in type 1 diabetes there is a type 4 hypersensitivity response or a cell-mediated immune response where a person’s own t cells attack the pancreas. as a quick review, remember that the immune system has t cells that react to all sorts of antigens, which are usually small peptides, polysaccharides, or lipids, and that some of these antigens are part of our own body’s cells. it doesn’t make sense to allow t cells that will attack our own cells to hang around, and so there’s this process to eliminate them called “self-tolerance”. in type 1 diabetes, there is a genetic abnormality causes a loss of self-tolerance among t cells that specifically target the beta cell antigens. losing self-tolerance means that these t cells are allowed to recruit other immune cells and coordinate an attack on these beta cells. losing beta cells means less insulin, and less insulin means that glucose piles up in the blood, because it can’t enter the body’s cells. one really important genes involved in regulation of the immune response is the human leukocyte antigen system, or hla system. although it’s called a system, it’s basically this group of genes on chromosome six that encode the major histocompatibility complex, or mhc, which is a protein that’s extremely important in helping the immune system recognize foreign molecules, as well as maintaining self-tolerance. mhc is like the serving platter that antigens are presented to the immune cells. interestingly, people with type 1 diabetes often have specific hla genes in common with each another, one called hla-dr3 and another called hla-dr4. but this is just a genetic clue right? because not everyone with hla-dr3 and hla-dr4 develop diabetes. in diabetes mellitus type 1, destruction of beta cells usually starts early in life, but sometimes up to 90% of the beta cells are destroyed before symptoms crop up. four clinical symptoms of uncontrolled diabetes, that all sound similar, are polyphagia, glycosuria, polyuria, and polydipsia. let’s go through them one by one. even though there’s a lot of glucose in the blood, it can’t get into cells, which leaves cells starved for energy, so in response, adipose tissue starts breaking down fat, called lipolysis, and muscle tissue starts breaking down proteins, both of which results in weight loss for someone with uncontrolled diabetes. this catabolic state leaves people feeling hungry, also known as polyphagia. “phagia” means eating, and “poly” means a lot. now with high glucose levels, that means that when blood gets filtered through the kidneys, some of it starts to spill into the urine, called glycosuria. “glycos” refers to glucose, “uria” the urine. since glucose is osmotically active, water tends to follow it, resulting in an increase in urination, or polyuria. “poly” again refers to a lot, and “uria” again refers to urine again. finally, because there is so much urination, people with uncontrolled diabetes become dehydrated and thirsty, or polydipsia. “poly” means a lot, and “dipsia” means thirst. even though people with diabetes aren’t able to produce their own insulin, they can still respond to insulin, so treatment involves lifelong insulin therapy to regulate their blood glucose levels and basically enable their cells to use glucose. one really serious complication with type 1 diabetes is called diabetic ketoacidosis, or dka. to understand it, let’s go back to the process of lipolysis, where fat is broken down into free fatty acids. after that happens, the liver turns the fatty acids into ketone bodies, like acetoacetic acid and beta hydroxybutyric acid, acetoacetic acid is a ketoacid because it has a ketone group and a carboxylic acid group. beta hydroxybutyric acid on the other hand, even though it’s still one of the ketone bodies, isn’t technically a ketoacid since its ketone group has been reduced to a hydroxyl group. these ketone bodies are important because they can be used by cells for energy, but they also increase the acidity of the blood, which is why it’s called keto-acid-osis. if the blood becoming really acidic can have major effects throughout the body. patients can develop kussmaul respiration, which is a deep and labored breathing as the body tries to move carbon dioxide out of the blood, in an effort to reduce its acidity. cells also have a transporter that exchanges hydrogen ions (or protons—h+) for potassium. when the blood gets acidic, it is by definition loaded with protons that get sent into cells while potassium gets sent into the fluid outside cells. another thing to keep in mind is that in addition to helping glucose enter cells, insulin stimulates the sodium-potassium atpases which help potassium get into cells, and so without insulin, more potassium stays in the fluid outside cells. both of these mechanisms lead to increased potassium in the fluid outside of cells which quickly makes it into the blood and causes hyperkalemia. the potassium is then excreted, so over time, even though the blood potassium levels remain high, overall stores of potassium in the body—which includes potassium inside cells—starts to run low. patients will also have a high anion gap, which reflects a large difference in the unmeasured negative and positive ions in the serum, largely due to this build up of ketoacids. diabetic ketoacidosis can happen even in people who’ve already been diagnosed with diabetes and currently have some sort of insulin therapy. in states of stress, like an infection, the body releases epinephrine, which in turn stimulates the release of glucagon. too much glucagon can tip the delicate hormonal balance of glucagon and insulin in favor of elevating blood sugars and can lead to a cascade of events we just described—increased glucose in the blood, loss of glucose in the urine, loss of water, dehydration, and in parallel a need for alternate energy, generation of ketone bodies, and ketoacidosis. interestingly, both ketone bodies break down into acetone and escape as a gas by getting breathed out the lungs which gives a sweet fruity smell to a person’s breath. in general though, that’s the only sweet thing about this illness, which also causes nausea, vomiting, and if severe, mental status changes and acute cerebral edema. treatment of a dka episode involves giving plenty of fluids, which helps with dehydration, insulin which helps lower blood glucose levels, and replacement of electrolytes, like potassium; all of which help to reverse the acidosis. now, let’s switch gears and talk about type 2 diabetes, which is where the body makes insulin, but the tissues don’t respond as well to it. the exact reason why cells don’t “respond” isn’t fully understood, essentially the body’s providing the normal amount of insulin, but the cells don’t move their glucose transporters to their membrane in response, which remember is needed for glucose to get into the cell, these cells therefore they have insulin resistance. some risk factors for insulin resistance are obesity, lack of exercise, and hypertension, and the exact mechanisms are still being explored. for example, an excess of adipose tissue—or fat—is thought to cause the release of free fatty acids and so-called “adipokines”, which are signaling molecules that can cause inflammation, which seems related to insulin resistance. however, many people that are obese are not diabetic, so genetic factors probably play a major role as well. we see this when we look at twin studies as well, where having a twin with type 2 diabetes increases the risk of developing type 2 diabetes, completely independent of other environmental risk factors. in type 2 diabetes, since tissues don’t respond as well to normal levels of insulin, the body ends up producing more insulin in order to get the same effect and move glucose out of the blood. they do this through beta cell hyperplasia, an increased number of beta cells, and beta cell hypertrophy, where they actually grow in size, all in this attempt to to pump out more insulin. this works for a while, and by keeping insulin levels higher than normal, blood glucose levels can be kept normal, called normoglycemia. now, along with insulin, beta cells also secrete islet amyloid polypeptide, or amylin, so while beta cells are cranking out insulin they also secrete an increased amount of amylin. over time, amylin builds up and aggregates in the islets. this beta cell compensation, though, isn’t sustainable, and over time those maxed out beta cells get exhausted, and they become dysfunctional, and undergo hypotrophy and get smaller, as well as hypoplasia and die off. as beta cells are lost and insulin levels decrease, glucose levels in the blood start to increase, and patients develop hyperglycemia, which leads to similar clinical signs that i mentioned before, like polyphagia, glycosuria, polyuria, and polydipsia. but unlike type 1 diabetes, there is generally some circulating insulin in type 2 diabetes from the beta cells that are trying to compensate for the insulin resistance. this means that the insulin/glucagon balance is such that diabetic ketoacidosis doesn’t usually develop. having said that, a complication called hyperosmolar hyperglycemic state (or hhs) is much more common in type 2 diabetes than type 1 diabetes - and it causes increased plasma osmolarity due to extreme dehydration and concentration of the blood. to help understand this, remember that glucose is a polar molecule that cannot passively diffuse across cell membranes, which means that it acts as a solute. so when levels of glucose are super high in the blood (meaning it’s a hyperosmolar state), water begins to leave the body’s cells and enter the blood vessels, leaving the cells relatively dry and shriveled rather than plump and juicy. blood vessels that are full of water lead to increased urination and total body dehydration. and this is a very serious situation because the dehydration of the body’s cells and in particular the brain can cause a number of symptoms including mental status changes. in hhs, you can sometimes see mild ketonemia and acidosis, but not to the extent that it’s seen in dka, and in dka you can see some hyperosmolarity, so there is definitely overlap between these two syndromes. besides type 1 and type 2 diabetes, there are also a couple other subtypes of diabetes mellitus. gestational diabetes is when pregnant women have increased blood glucose which is particularly during the third trimester. although ultimately unknown, the cause is thought to be related to pregnancy hormones that interfere with insulin’s action on insulin receptors. also, sometimes people can develop drug-induced diabetes, which is where medications have side effects that tend to increase blood glucose levels. the mechanism for both of these is thought to be related to insulin resistance (like type 2 diabetes), rather than an autoimmune destruction process (like in type 1 diabetes). diagnosing type 1 or type 2 diabetes is done by getting a sense for how much glucose is floating around in the blood and has specific standards that the world health organization uses. very commonly, a fasting glucose test is taken where the person doesn’t eat or drink (except water, that’s okay) for 8 hours and has their blood tested for glucose levels. levels of 110 milligrams per deciliter to 125 milligrams per deciliter indicates prediabetes and 126 milligrams per deciliter or higher indicates diabetes. a non-fasting or random glucose test can be done at any time, with 200 milligrams per deciliter or higher being a red flag for diabetes. another test is called an oral glucose tolerance test, where a person is given glucose, and then a blood samples are taken at time intervals to figure out how well it’s being cleared from the blood, the most important interval being 2 hours later. levels of 140 milligrams per deciliter to 199 milligrams per deciliter indicate prediabetes and 200 or above indicates diabetes. another thing to know is that when blood glucose levels get high, the glucose can also stick to proteins that are floating around in the blood or in cells. so that brings us to another type of test that can be done which is the hba1c test, which tests for the proportion of hemoglobin in red blood cells that has glucose stuck to it - called glycated hemoglobin. hba1c levels of 5.7% to 6.4% indicates prediabetes, and 6.5% or higher indicates diabetes. this proportion of glycated hemoglobin doesn’t change day to day, so it gives a sense for whether the blood glucose levels have been high over the past 2 to 3 months. over time, high glucose levels can cause damage to tiny blood vessels, called the microvasculature. in arterioles, a process called hyaline arteriolosclerosis where the walls of arterioles where they develop hyaline deposits, these deposits of proteins, and these make them hard and inflexible. in capillaries, the basement membrane can thicken and make it hard for oxygen to easily move from the capillary to the tissues, causing hypoxia. one of the most significant effects is that diabetes increases the risk of medium and large arterial wall damage and subsequent atherosclerosis, which can leads to heart attacks and strokes, major causes of morbidity and mortality for patients with diabetes. in the eyes, diabetes can lead to retinopathy and evidence of that can be seen on a fundoscopic exam that shows cotton wools spots or flare hemorrhages - and can eventually cause blindness. in the kidneys, the afferent and efferent arterioles, as well as the glomerulus itself can get damaged which can lead to a nephrotic syndrome that slowly diminishes the kidney’s ability to filter blood over time - and can ultimately lead to dialysis. diabetes can also affect the function of nerves, causing symptoms like a decrease in sensation in the toes and fingers, sometimes called a stocking-glove distribution, as well as causing the autonomic nervous system to malfunction, and that system controls a number of body functions - everything from sweating to passing gas. finally, both the poor blood supply and nerve damage, can lead to ulcers (typically on the feet) that don’t heal quickly and can get pretty severe, and need to be amputated. these are some of the complications of uncontrolled diabetes, which is why it’s so important to prevent, diagnose, and control diabetes through a healthy lifestyle, medications to reduce insulin resistance and even insulin therapy if beta cells have been exhausted. in fact, many people with diabetes can control their blood sugar levels really effectively and live a full and active life without any of the complications. thanks for watching, you can help support us by donating on patreon, or subscribing to our channel, or telling your friends about us on social media.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_b2d6b32f6d94,"what is goodpasture syndrome? goodpasture syndrome is an autoimmune disease where the immune system attacks the basement membrane in the lungs and kidneys. goodpasture syndrome is an autoimmune disease that primarily affects two organs, the lungs and the kidneys. it causes inflammation and eventually bleeding in the lungs which leads to ‘hemoptysis’ or coughing up of blood, and hematuria or blood in the urine, a pattern first recognized by the pathologist dr. ernest goodpasture. to understand goodpasture syndrome, let’s start by thinking about the basement membrane which is a thin, sheet-like layer of tissue made of protein that keeps the epithelium stuck firmly to actual organ, kind of like double-sided tape which keeps gift wrapping paper stuck to the gift. the basement membrane is made up of various proteins, but the major one is collagen, and since basement membrane exists throughout every organ system, it’s no wonder that collagen is the most abundant protein in the human body. as far as proteins go, collagen is a pretty sweet looking one, with a triple-helix structure composed of three separate chains that are intertwined like braided hair. each of the chains can be one of six types, named α1 through α6, and the most common form of collagen found in the basement membrane is collagen type iv, which is made by mixing and matching these six α-chains. one version of type iv collagen combines the α3, α4, and α5 chains. another combines two α1’s and an α2. and a third version has two α5’s and an α6. and this list of combinations goes on. so it turns out that the α3/α4/α5 variant is most common in the glomerular basement membrane of the kidneys and the alveolar basement membrane of the lungs. in goodpasture syndrome, autoantibodies bind to a specific part of the α3 chain that is usually hidden deep within the folded chains. this is an example of a type ii hypersensitivity reaction, because once these autoantibodies, usually igg but rarely igm or iga, bind to the the α3 chain, they activate the complement system. now, the complement system is a series of small proteins present in the blood that act like an enzymatic cascade to fight off bacterial and other pathogenic invasions. when the fab portion of the igg molecule inappropriately binds to the α3 chain, c1, which is the first of the complement proteins, binds to the fc portion of the igg. this bound c1 is now activated and it starts engaging other members of the complement family, c2 through c9. some of these are activated by being cleaved or chopped by an enzyme. the cleaved fragments c3a, c4a, and c5a act as chemotactic agents meaning they attract certain cells like neutrophils. once neutrophils join the party, they dump a bunch of enzymes like peroxidase, myeloperoxidase, and proteinase-3 which all cause free oxygen radicals to form which damage the basement membrane as well as the nearby endothelium and the underlying organ itself. genetic risk factors for goodpasture syndrome include having genes that encode a specific type of immune molecule called hla-dr15 which is used to identify and bind to foreign molecules. environmental risk factors on the other hand also play a role, and it relates back to the fact that the autoantibodies bind to a specific part of the α3 chain that is usually hidden deep within the folded chains. when the collagen molecules are damaged by infection, smoking, oxidative stress, or some hydrocarbon-based solvents as in the case of people who work in the dry-cleaning industry, these antigenic regions on the α3 chain get exposed to the antibodies present in the blood of genetically susceptible people. this also helps explain why goodpasture syndrome specifically affects the kidney and the lungs. the kidney filters toxins from the blood, so as they pass through the basement membrane of the kidney they likely expose parts of the α3 chain and similarly, the lungs get exposed to various inhaled toxic substances, like cigarette smoke, once again, exposing the parts of the α3 chain that lead to goodpasture syndrome. in goodpasture syndrome, lung symptoms usually come before kidney symptoms. damage to the basement membrane in the lungs causes widespread damage to the alveoli, the small air-sacs where the gas exchange happens between the air we breathe in and the blood, leading to a cough and hemoptysis or blood in the sputum. the damage to the alveoli can also impair the ability of the lungs to exchange oxygen for carbon dioxide leading to a pattern of restrictive lung disease. damage to the basement membrane in the kidney affects its ability to filter properly, allowing blood to get into the urine, called hematuria, as well as protein to get into the urine, called proteinuria. this fits the nephritic syndrome pattern. the best way to diagnose goodpasture syndrome is by doing a biopsy, usually of the kidney because that’s the best-studied organ in this disease. under a microscope, you usually see inflammation of the basement membrane, and if fluorescent proteins that bind to the anti-basement membrane antibodies are used, they light up in a linear pattern along the basement membrane. in the past, goodpasture syndrome was usually fatal, but aggressive treatment with corticosteroids and immunosuppressive agents as well as plasmapheresis, which involves filtering out the fluid part of blood or plasma, has improved the prognosis with fewer individuals developing chronic renal failure and needing dialysis. alright, as a quick recap, goodpasture syndrome is an autoimmune disease in which the immune system attacks the α3 chain of type iv collagen present in basement membrane. the specific spot that gets affected is usually well hidden but gets exposed by various toxins, which is why the disease predominantly affects the lungs and kidneys causing symptoms like hemoptysis and hematuria.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_0ec4e5b2ce29,"what is pulmonary edema? pulmonary edema describes having excess fluid in the lungs.pulmonary edema refers to the buildup of fluid in the lungs including the airways like the alveoli - which are the tiny air sacs - as well as in the interstitium, which is the lung tissue that’s sandwiched between the alveoli and the capillaries. this space is mostly full of proteins, and when it starts filling up with fluid, it can make it hard for oxygen to cross over from the alveoli into the capillary, leaving the body hypoxic - or deprived of oxygen. to understand pulmonary edema, let’s first talk about the three main factors that determine how fluid moves between the capillaries and interstitial fluid, which are the hydrostatic pressure, oncotic pressure and capillary permeability. hydrostatic pressure refers to the pressure felt by fluid in a confined space, pushing the fluid out of that space. in the interstitial space, it’s the same thing as the blood pressure in the pulmonary capillaries, and because the pulmonary circulation is a low pressure system, the hydrostatic pressure is pretty low. but it’s still higher than the hydrostatic pressure exerted by the interstitial fluid of the lungs - which is almost zero. so, to be clear, if hydrostatic pressure was the only factor involved, a lot of fluid would be continuously leaking out of the pulmonary capillaries into the lung’s interstitial space. the next factor, though, is oncotic pressure; which is a type of osmotic pressure exerted by cells and proteins that can’t cross the capillary membrane and therefore tend to attract fluid. the oncotic pressure is higher in the pulmonary capillaries than in the interstitial fluid, so it opposes the hydrostatic pressure. finally, there’s capillary permeability or leakiness which affects how easily fluid is actually able to get through. when taking these three factors together, the net result is that a very small amount of fluid leaks into the interstitial space, and that fluid is normally whisked away by the lymphatic channels in the lungs, which keeps the lungs free of excess fluid. now, the underlying cause of pulmonary edema can be cardiogenic - meaning that it develops as a result of a heart disease, or can be non-cardiogenic which typically involves damage to the pulmonary capillaries or alveoli. the most common cardiogenic cause is left-sided heart-failure, and in left-sided heart failure, the left ventricle becomes unhealthy and can’t pump effectively, which means that blood starts to backup in the left atrium, and then the pulmonary veins and pulmonary capillaries. the extra blood in the pulmonary capillaries causes pulmonary hypertension - which is an increase in the hydrostatic pressure of the pulmonary blood vessels, and this pushes more fluid into the interstitial space of the lungs which leads to pulmonary edema. another cardiogenic cause is severe systemic hypertension - specifically a blood pressure that is greater than 180 systolic or 110 diastolic. in this situation, the left ventricle is healthy but simply can’t effectively pump blood in a system with such high afterload - in other words, under conditions with such high systemic pressures. once again, blood starts to back up in the left atrium, pulmonary veins, and pulmonary capillaries, ultimately leading to pulmonary hypertension and pulmonary edema. noncardiogenic causes of pulmonary edema include things like pulmonary infections, inhalation of toxic substances, and trauma to the chest. all of these can cause direct injury to the alveoli, and when this happens there is usually an inflammatory process that makes nearby capillaries more permeable. as a result, proteins and fluid enter the interstitial space. another cause is sepsis, and the key difference is that in sepsis the inflammatory process happens throughout the body rather than just in the lungs, so in addition to pulmonary edema, sepsis can cause extra fluid in the interstitial space of tissues throughout the body. another category of non-cardiogenic causes is having low oncotic pressure. and this could result from not making enough proteins like albumin due to malnutrition or from liver failure. alternatively it could be due to losing protein too quickly like in nephrotic syndrome. regardless of the cause, low oncotic pressure leads to fluid moving from the capillary and into the interstitial space throughout the body, and in the lungs that results in pulmonary edema. pulmonary edema can develop in a few ways and often develops through a combination of mechanisms. pulmonary edema makes gas exchange difficult because oxygen and carbon dioxide have to diffuse through a wide layer of interstitial fluid, to get from the alveoli to the pulmonary capillary and vice versa. that journey can take too long relative to how quickly blood moves through the lungs, and that makes it hard to fully oxygenate the blood. pulmonary edema can lead to severe shortness of breath, and in left-sided heart failure, it can lead to orthopnea which is when there’s worse shortness of breath while lying flat. this happens because there’s increased pulmonary congestion while lying down, and in left-sided ventricular heart failure, the pulmonary circulation is already overloaded. as a result, the extra blood can’t be pumped out efficiently, and it causes shortness of breath. this pulmonary congestion and shortness of breath decreases when a person sits up. the diagnosis of pulmonary edema is usually made with a chest x-ray or chest ct scan that shows fluid in the interstitial space. treatment for pulmonary edema typically involves giving supplemental oxygen. other treatments are dependent on the underlying cause - if the cause is cardiogenic in nature, medications aimed at boosting the heart’s performance or lowering the blood pressure can be helpful. if the cause is related to inflammation or low oncotic pressure, then managing that illness will help resolve the pulmonary edema. alright, as a quick recap, pulmonary edema refers to fluid accumulation in the interstitial space of the lungs which can be seen on a chest xray or chest ct scan. common cardiogenic causes include left sided heart failure and hypertension, both of which lead to increased hydrostatic pressure in the pulmonary capillaries. common non-cardiogenic causes include inflammation in the lungs or system-wide inflammation which causes the pulmonary capillaries to be more permeable. other causes include a low oncotic pressure which can be from malnutrition, liver failure, and nephrotic syndrome. regardless of the cause, pulmonary edema interferes with gas exchange and results in shortness of breath.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_31ce777de654,"what is angina pectoris? angina pectoris is chest pain that's felt due to lack of blood flow to the heart muscle. angina's most often caused by atherosclerosis, but may also be due to heart muscle growth. angina comes from the latin angere, which means to strangle, and pectoris comes from pectus, meaning chest—so angina pectoris loosely translates to “strangling of the chest”, which actually makes a lot of sense, because angina pectoris is caused by reduced blood flow which causes ischemia to the heart muscle, or lack of oxygen to the heart, almost like the heart’s being strangled which causes terrible chest pain. stable angina or chronic angina is the most common type of angina and it usually happens when the patient has greater than or equal to 70% stenosis, meaning 70% of the artery is blocked by plaque buildup. this small opening that blood flows through might be enough to supply the heart during rest, but if the body demands more blood and oxygen, like during exercise or stressful situations, the heart has to work harder, and therefore needs more blood and oxygen itself. it’s during these time of exertion or emotional stress that people with stable angina have chest pain, since the blood flow isn’t meeting the metabolic demands of the heart muscle, or myocardium. but the pain usually goes away with rest. in the majority of cases, the underlying cause of stable angina is atherosclerosis of one or more the coronary arteries—arteries supplying blood to the heart muscles. other heart conditions that might lead to stable angina are ones that cause a thickened heart muscle wall, which would require more oxygen. this increase in muscle size can be due to hypertrophic cardiomyopathy from a genetic cause, or as a result from the heart having to pump against higher pressures, as is the case in aortic stenosis, which is a narrowing of the aortic valve, or hypertension. these larger, thicker heart muscles require more oxygen, and if the patients can’t meet increasing demands, they feel pain in the form of angina. whatever the case, the heart needs blood, and if we look at the heart wall, there’s three layers—the outermost layer, the epicardium, then the myocardium in the middle, and the endocardium inside the heart. the coronary arteries start up in the epicardium, and then dive down and supply all the heart tissue. if blood flow’s reduced or the myocardium is thicker, blood has a harder time reaching this deeper layer just under the endocardium, called the subendocardium. therefore the classic finding with angina is subendocardial ischemia, meaning less oxygen is reaching the region just under the endocardium. this ischemia is thought to trigger release of adenosine, bradykinin, and other molecules that stimulate nerve fibers in the myocardium that result in the sensation of pain. that chest pain is usually described as feeling like pressure or squeezing and it can radiate to the left arm, jaw, shoulders, and back, and sometimes is accompanied by shortness of breath and diaphoresis or sweating. usually the pain and symptoms last less than 20 minutes and subside after the exertion or stress is taken away, and therefore the heart muscle isn’t demanding as much blood. now, unlike stable angina which describes when patients have pain only during periods of exertion or stress, but not during rest, there is also unstable angina which is when patients have pain during exercise or stress as well as during rest—it never really goes away. unstable angina is usually caused by rupture of atherosclerotic plaque with thrombosis, meaning a blood clot forms on top of a mound of plaque. although the occlusion might not block the entire vessel, there is now even less room left for blood to flow by, and the heart tissue is starting to feel starved for oxygen even while pumping at a normal rate. unstable angina, for the same reason as stable angina, involves subendocardial ischemia and it should be treated as an emergency, because patients are at a high risk of progressing to myocardial infarction, or heart attack. the key distinction is that unstable angina means that the heart tissue is alive but ischemic or starving for oxygen, whereas myocardial infarction means that the areas of heart tissue have already begun to necrose or die. now a third type of angina is vasospastic angina, also known as prinzmetal angina, and patients may or may not also have atherosclerosis. ischemia, and resulting chest pain is due to coronary artery vasospasms, meaning the smooth muscles around the arteries constrict extremely tightly and reduce blood flow enough to cause ischemia. episodes of vasospastic angina don’t correlate with exertion and can happen anytime, including at rest. the underlying mechanism causing vasospasms isn’t well understood, but likely involves vasoconstrictors like platelet thromboxane a2. unlike both stable and unstable angina, in this case the coronary artery’s constricted so severely that all layers of the heart wall being supplied are affected, therefore it’s referred to as transmural ischemia. alright, so if we line these three up side-to-side, there’s some important clinical similarities and differences. first, it’s super important to remember that in each case, the injury to cardiomyocytes isn’t permanent, meaning it’s reversible and the cardiomyocytes don’t die (which is how this differs from myocardial infarction). on an electrocardiogram, or ecg, both stable and unstable angina show an st-segment depression since ischemia’s limited to the subendocardium. in contrast, vasospastic angina shows st-segment elevation due to transmural ischemia. rest tends to relieve stable angina, whereas unstable angina and vasospastic angina can occur anytime, including at rest. in terms of medications, all three can be treated with nitroglycerin which is a vasodilator that increases blood vessel diameter to allow more blood flow. in addition, vasospastic angina also responds to calcium channel blockers.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_1de88786ede1,"what is pericarditis? pericarditis is inflammation of the pericardium, the fluid-filled sac that surrounds the heart. try free board-style questions and flashcards - https://goo.gl/3ogoei. with pericarditis, “peri” means “around,” card means “the heart”, and itis means “inflamed”. so pericarditis means the pericardial layer of tissue that covers the heart has inflammation. acute pericarditis generally lasts just a few weeks, whereas chronic pericarditis lasts longer, usually more than 6 months. people who develop pericarditis are also at risk of also developing a pericardial effusion - that’s when the inflammation causes fluid to accumulate around the heart. the pericardium is a pouch or cavity that the heart sits inside of. the outer layer of this pouch is the fibrous pericardium and it helps keep the heart in place within the chest cavity. the inner layer of the pouch is the serous pericardium that includes the pericardial cavity, and is filled with a small amount of fluid that lets the heart slip around as it beats. the cells of the serous pericardium secrete and reabsorb the fluid, so usually there’s no more than 50 milliliters of fluid in the pericardial cavity at one time - that’s about as much as a shot glass. now, the cause of acute pericarditis is usually idiopathic, meaning that we don’t know what causes it. when the cause is identified, it’s usually a viral infection, like coxsackie b virus. another cause is dressler syndrome which occurs several weeks after a myocardial infarction, or heart attack. basically, when heart cells die in a myocardial infarction, it leads to massive inflammation that also involves the serous pericardium. another cause of pericarditis, called uremic pericarditis, is when blood levels of urea, a nitrogen waste product, get really high usually due to kidney problems. the high levels of urea irritate the serous pericardium, making it secrete a thick pericardial fluid that’s full of fibrin strands and white blood cells. this gives the wall of the serous pericardium a “buttered bread” appearance. pericarditis can also be seen in autoimmune diseases, like rheumatoid arthritis, scleroderma, or systemic lupus erythematosus, because the immune system attacks its own tissues, including the pericardium. other causes of pericarditis include cancer, radiation therapy in the chest, and even medications like penicillin, and certain anticonvulsants. regardless of the cause, inflammation in the pericardium means that fluid as well as immune cells start moving from tiny blood vessels in the fibrous and serous pericardium into the tissue or interstitium of those layers, making the layer itself a bit thicker and more boggy - think of how a piece of dry flat pasta gets cooked and thickens up as it soaks up fluid. now, a pericardial effusion can also develop. that’s when pericardial fluid begins to pool in the pericardial space, because the serous pericardium can’t remove it as quickly as it comes in. if a lot of fluid starts to collect in the pericardial space - in other words, if that pericardial effusion gets really big, then it can start putting pressure on the heart itself, preventing it from fully stretching out or relaxing between contractions. this can lead to tamponade physiology which is where the cardiac chambers can’t fill with blood properly, causing a decrease in cardiac output - which can be a medical emergency. when the inflammation persists for weeks to months, the process is called chronic pericarditis. in chronic pericarditis, immune cells initiate fibrosis of the serous pericardium which can produce a inelastic shell around the heart making it hard for the ventricles to expand -it’s like the heart is wrapped by a boa constrictor. over time, it becomes harder for the heart to relax or expand, and the stroke volume - the amount of blood the heart squirts out with each heartbeat goes down, and to compensate the heart rate goes up. this is similar to tamponade physiology but happens more gradually and is a result of a change in the composition of the serous pericardium, rather than a fluid collection around the serous pericardium. the main symptom of pericarditis is fever and chest pain that worsens with deep breathing, but improves with sitting up and leaning forward. larger pericardial effusions, those over 100ml of fluid, can cause diminished heart sounds, and can even diminish cardiac output leading to shortness of breath, low blood pressure, and lightheadedness. there are a few ways to diagnose pericarditis and pericardial effusions. first, when the thickened layers of the pericardium rub up against each other - it creates a friction rub which can be heard on auscultation. it sounds like two pieces of leather rubbing against each other. next, on an electrocardiogram, there are a few changes that you can expect to see. in the first couple days to weeks, there can be st segment elevations and pr segment depressions. after that, the t waves tend to flatten and then becomes inverted over a few weeks, and then eventually the ecg returns back to normal. on an ecg, pericardial effusions, especially large ones, can show low qrs complex voltage or electrical alternans, which is where the qrs complexes have different heights, as a result of the heart swinging back and forth in a pool of pericardial fluid. on an x-ray of a heart with a large pericardial effusion, you can see a silhouette that pools to the bottom of the heart and gives a classic “water bottle” sign. on an echocardiogram, a pericardial effusion makes the heart looks like it’s dancing within the pericardium, whereas chronic pericarditis shows the stiff serous pericardium restricting the heart’s movement. in terms of treatment, the main goal is to relieve pain with analgesic medication, and to treat the underlying cause of inflammation. if there’s a severe pericardial effusion, a pericardiocentesis can be done by inserting a needle into the pericardial cavity and draining the excess fluid. okay, let’s recap - acute pericarditis is usually caused by a idiopathic causes, but can be caused by viruses or after a myocardial infarction. it usually results in a friction rub, as well as ecg changes like st elevation and pr depression, followed by t wave flattening and inversion. pericardial effusions typically lead to low qrs voltages or electrical alternans, and can be seen on an echocardiograph. chronic pericarditis typically results from fibrin deposition in the serous pericardium and it prevents the heart from fully relaxing.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_db601a4f95f8,"what is jaundice? well, jaundice is a condition where the skin and eyes take on a yellowish color due to increased levels of bilirubin in the bloodstream. jaundice, which doesn’t have the most intuitive name, comes from the french jaunice, meaning yellowing. it’s also sometimes referred to as icterus though, the origin of which is even less intuitive, coming from the thought that jaundice could once be cured by looking at a yellow bird, the more you know! anyways, as you’ve probably gathered, jaundice involves someone taking on yellow pigments, specifically in the skin and eyes. the yellowing pigment is caused by a compound called bilirubin, a component of bile and the main cause of bruises being yellow, and after its metabolism, the yellow-ness of urine and brown-ness of feces. so since bilirubin’s our main culprit of yellow-ness, it’s super important to know where it comes from. as red blood cells near the end of their lifespan—which is about 120 days—they’re eaten up or phagocytosed by macrophages in the reticuloendothelial system, aka the macrophage system, where the spleen plays the largest part, but it’s also made of parts of the lymph nodes. k so first the macrophage eats up the blood cell, and hemoglobin is broken up into heme and globin, the globin is further broken into amino acids. the heme on the other hand is split into iron and protoporphyrin, protoporphyrin is then converted into unconjugated bilirubin, or ucb. unconjugated bilirubin is the form of bilirubin that’s lipid-soluble, meaning it’s not water-soluble, sometimes it’s also known as indirect bilirubin. albumin in the blood then binds to ucb and gives it a lift over to the liver where it’s taken up by hepatocytes, where it’s conjugated by an enzyme called uridine glucuronyl transferase (ugt), making it now water soluble. at this point the conjugated bilirubin is secreted out the bile canaliculi where it drains into the bile ducts and sent to the gallbladder for storage as bile. now when you eat a donut or something, your gallbladder secretes the bile and cb, it moves through the common bile duct to the duodenum of the small intestine and is converted to urobilinogen, or ubg, by intestinal microbes in the gut. now some of that urobilinogen is reduced to stercobilin which is excreted and responsible for the brown color of feces. some of that ubg is actually recycled, though, and it gets reabsorbed into the blood and spontaneously oxidizes into urobilin, most of which is sent to the liver to the liver and some of which goes to the kidneys. it’s then excreted and is responsible for the yellow-ness of urine! and there you have it, bilirubin metabolism in a nutshell. now if some point in this process is disrupted, for example if your liver cells are damaged and can’t conjugate bilirubin anymore, or if they die and release their bilirubin, you can end up with increased bilirubin in the blood, which can be conjugated or unconjugated, or both! this is what accounts for the yellow color in the skin and eyes. usually it takes about 2.5 mg/dl or greater of serum bilirubin to give the skin that simpsons-esque yellow skin tone. the earliest sign of jaundice and increased bilirubin in the blood is by looking at the sclera of the eyes. scleral tissue is high in elastin, which has a particular fondness for bilirubin and binds it with a high affinity, giving the scleral tissue a yellow color often before the skin. now as you might imagine after looking at this process, there’re quite a few potential pitfalls along the way that can lead to jaundice, and they’re lumped together depending on whether they have more ucb in the blood, more cb in the blood, or more of both in the blood. two types of disorders that have increased ucb and similar presentation of jaundice are extravascular hemolytic anemias, where red blood cells are broken down earlier than they normally would, and ineffective hematopoesis, where your blood cells don’t form quite right in your bone marrow, causing macrophages to break them down. in both cases, the red blood cells are broken down, causing high levels of ucb. since your hepatocytes can only work so hard converting ucb to cb, they can get overwhelmed. as an imaginary example, say that this liver cell can conjugate 10 molecules of ucb a minute, max, but normally they only see 5, so that’s easy. if all the sudden your body starts breaking down more blood cells and the ucb molecules on this cell’s docket jumps to 15/min, this liver cell can’t keep up, and that excess of 5 molecules of ucb stays in the blood, that’s the first issue. in addition, as the liver cells max out, now there’s all this cb that goes to the bile, which increases the risk for pigmented bilirubin gallstones. not only that, once all that cb is sent to the duodenum, it’s converted to urobilinogen. remember some of that urobilinogen is recycled back into the blood, oxidized to urobilin,and excreted in the urine, giving it a much darker color. the ucb is not excreted because it’s not water soluble! in the previous two cases, too much ucb was created, but you can also have hepatocytes that just can’t work hard enough and keep up. physiologic jaundice of newborn is one of these cases; newborn livers having a lower amount of ugt in the liver to convert ucb, and after birth, ucb levels can be high due to the natural process of macrophages destroying fetal red blood cells. typically this is normal, but can cause complications if ucb rises a lot; since it’s fat soluble, it can collect in the basal ganglia of the brain, which is called kernicterus, and cause damage to the brain or death. treatment of this condition is usually phototherapy, which uses light to induce structural and configurational changes in the bilirubin molecule, basically it absorbs the energy from the light and changes shape. these new shapes are more soluble, and can be excreted in the urine. this can be a super effective and non-invasive way to get excess ucb out of the blood. another potential case where not enough ucb can be conjugated is through hereditary defects. one case is called gilbert’s syndrome, where their ugt enzyme activity is low and has a hard time cranking up when needed, so maybe this liver cell can only pump through a max of 6 molecules/minute. unfortunately, if something comes along that increases hemolysis, like infection, stress, or starvation, the unconjugated bilirubin load will increase which can easily overwhelm these hepatocytes, cause buildup of unconjugated bilirubin in the blood and lead to jaundice. another genetic example is called crigler najjar syndrome, where gilbert’s syndrome was a low amount of ugt, crigler najjar is where there’s pretty much no ugt and therefore no ability to conjugate ucb, this will lead to super high levels of ucb, and likely ucb deposits in the brain and kernicterus; crigler najjar syndrome is usually fatal. the previous couple examples focused on high levels of unconjugated bilirubin in the blood, but there are also examples of jaundice with high levels of conjugated bilirubin in the blood. dubin-johnson syndrome is an autosomal recessive disorder where there’s a deficiency in the protein that helps move cb from the liver cell to the bile ducts, called mrp2, so cb builds up in the hepatocyte. it’s thought that when the mrp2 transporter is defected, another transporter, mrp3 is upregulated, though this transporter moves it into the interstitial space and blood flow, as opposed to the bile canaliculus, so in this case you’ll have increased cb in the blood, which also gets excreted into the urine, giving it a darker color, this leakage also causes the liver itself to get super dark. another high-cb category of jaundice is called obstructive jaundice, and this is basically where something blocks the flow of bile, these blockages could be anything from gallstones, pancreatic carcinomas and cholangiocarcinomas, to parasites like the liver fluke. remember that bile’s made up of conjugated bilirubin and this blockage basically causes pressure to rise in the bile duct, which literally causes bile to leak through the tight junctions between hepatocytes, but that’s not the only thing that leaks out though; bile salts, bile acids, and cholesterol all can can get into the blood. if they deposit in the skin, it could lead to itchiness or pruritus, but also lead to things like hypercholesterolemia and xanthomas. the excess cb is excreted in the urine, leading again to dark urine. also, since you’re losing bile, you won’t be able to absorb fat as well, which (1) causes you to excrete a ton of fat, a condition called steatorrhea, and (2) causes you to not be able to absorb as many fat-soluble vitamins as you need. finally, viral hepatitis leads to both conjugated and unconjugated bilirubin in the blood. when hepatocytes get infected and start to die off, they both lose the ability to conjugate bilirubin, leading to excess ucb in the blood, and since they also line the bile ducts, when they die they let bile leak out into the blood, causing an increase in blood cb as well. again, since cb is up, patients will have more cb excreted and darker urine. thanks for watching, you can help us by donating on patreon, subscribing to our channel, or telling your friends about us on social media.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_0727bfba4307,"what are hiv & aids? hiv, or human immunodeficiency virus, is a type of virus that infects human immune cells. over time, immune cells are lost, which weakens the immune system and allows patients to be infected by other viruses and develop several types of tumors. hiv, or human immunodeficiency virus, is a virus that targets cells in the immune system. over time, the immune system begins to fail which is called immunodeficiency, and this increases the risk of infections and tumors that a healthy immune system would usually be able to fend off. these complications are referred to as aids, or acquired immunodeficiency syndrome. now there are two distinct types of hiv—hiv-1 and hiv-2. hiv-1 is the more commonly associated with aids in the us and worldwide, hiv-2 is more rare, and typically restricted to areas in western africa and southern asia. hiv-2 is so uncommon that “hiv” almost always refers to hiv-1. alright hiv targets cd4+ cells, meaning cells that have this specific molecule called cd4 on their membrane. macrophages, t-helper cells, and dendritic cells are all involved in the immune response and all have cd4 molecules; therefore they can be targeted by hiv. the cd4 molecule helps these cells attach to and communicate with other immune cells, which is particularly important when the cells are launching attacks against foreign pathogens. so this little molecule is pretty important for our immune system, but it’s also extremely important for hiv. hiv targets and attaches to the cd4 molecule via a protein called gp120 found on its envelope. hiv then again uses gp120 to attach to another receptor, called a co-receptor. hiv needs to bind to both the cd4 molecule and a coreceptor to get inside the cell. the most common co-receptors that hiv uses are the cxcr4 co-receptor, which is found mainly on t-cells, or the ccr5 co-receptor which is found on t-cells, macrophages, monocytes, and dendritic cells. these coreceptors are so important that some people with homogeneous genetic mutations in their ccr5 actually have resistance or immunity to hiv, since hiv can’t attach and get into the cell. in fact, even heterozygous mutations which lead to fewer co-receptors on the cells, can make it harder for the virus to spread, and results in a slower disease progression. for those without this mutation though, once hiv binds to cd4 and either ccr5 or cxcr4, it gains access to the cell. hiv is a single-stranded, positive-sense, enveloped rna retrovirus, meaning that it injects its single strand of rna into the t-helper cell. the “retro” part of retrovirus isn’t referring to its style, but refers to it needing to use an enzyme called reverse transcriptase to transcribe a complementary double-stranded piece of “proviral” dna. proviral just means that it’s ready to be integrated into the host’s dna, so it enters the t-helper cell’s nucleus and pops itself into the cell’s dna, ready to be transcribed into new viruses, pretty sneaky, huh? well here’s the actual sneaky part—when the immune cells become activated, they start transcribing and translating proteins needed for the immune response. ironically, this means that whenever the immune cell is exposed to something that causes it to start up an immune response, like any infection, the immune cell ends up inadvertently transcribing and translating new hiv viruses, which bud off from the cell membrane to infect more cells. very sneaky indeed! one thing to know is that hiv is notorious for making errors when it replicates and that during an infection it can mutate to create slightly different strains of viruses. these viruses are all still considered “hiv” but behave slightly differently from each other and target different cells in the host, in fact that host cell preference is called viral tropism. so let’s start with hiv entering the body through sexual intercourse which is how it typically spreads from person to person. at this early point, during what we call acute infection, the r5 strain of hiv, which bind to the ccr5 coreceptor will get into macrophages, dendritic cells, and t cells. usually dendritic cells hanging out in the epithelial or mucosal tissue where the virus entered the body, capture the virus and migrate to the lymph nodes, where a lot of immune cells live, and the r5 strain of hiv essentially has a field day, infecting t-helper cells, macrophages, and more dendritic cells, which leads to a big spike in hiv replication and the amount of virus found in the patient’s blood. patients typically experience flu-like or mononucleosis-like symptoms during the acute infection. in response, the immune system mounts a counterattack, and starts to control the amount of viral replication, and the amount of virus in the blood declines to lower but still detectable levels by 12 weeks—at which point the patient enters the chronic or clinically-latent phase, which can last between 2 and 10 years. if we also plot the amount of t cells alongside the amount of virus, we’ll see that they loosely mirror each other, which makes total sense, right? initially you have a considerable decline in the acute phase until the immune system mounts its counterattack. after this point, even though there may not be any clinical signs or symptoms of the virus, the virus is steadily chipping away at the immune system, and the number of viruses in the blood slowly increases, while at the same time t cells slowly decrease, losing about 1-2 billion t cells every day. during this chronic phase, t cell counts usually remain above 500 cells / mm3, about the size of the head of a pin, and patients can still fight off other infections fairly well, although some infections like tuberculosis become more common and severe. remember how hiv replication can create mutations? well during the chronic phase of hiv infection, it’s worth pointing out that some patients develop an x4 strain of hiv which targets the cxcr4 coreceptor, which is essentially only t-cells. these x4 strains kind of lay low in the lymphoid tissues, and steadily destroy of cd4 t cells, since about 90% of t cells are found in lymphoid tissue. not all patients develop the x4 strain, though, so it’s not completely clear what the presence of this strain implies about the disease course. when the body’s t cells drop low enough, between about 200 and 500 cells / mm3, patients start experiencing symptoms like swollen lymph nodes, or lymphadenopathy, as well as relatively minor infections like oral hairy leukoplakia, a hairy-looking white patch on the side of the tongue caused by the same epstein-barr virus that causes mononucleosis, as well as oral candidiasis, a yeast infection in the mouth. as more t cells are lost, and the level falls below 200 cells / mm3, the immune system becomes severely compromised and at this stage the condition has progressed from hiv disease to aids. at this point people experience things like persistent fever, fatigue, weight loss, and diarrhea. and the hiv count in the blood might increase significantly. at this point, certain conditions start to develop that are said to be “aids-defining”, such as recurrent bacterial pneumonia, pneumocystis pneumonia, and fungal infections like candidiasis of the esophagus. other conditions include certain tumors and malignancies like kaposi sarcoma which causes lesions on the skin and other soft tissues, and primary lymphoma of the brain. many people with aids die from infections that a healthy immune system would typically be able to fend off, like pneumocystis, cytomegalovirus, or mycobacterium avium complex. male-to-male transmission is the most common mode of transmission in the us, and male-to-female is the most common mode in resource-limited settings. although less common, female-to-male transmissions occur as well since hiv is present in the vaginal and cervical fluids of infected women. in fact, over 75% of all cases of hiv are contracted from sexual intercourse. the next most common means of transmission include things like intravenous drug abuse and mother-to-child transmission, which can be via the placenta during delivery, or via breast milk. other, much less common modes of transmission include accidental needlesticks, and use of blood products like blood transfusions. as far diagnosis goes, there are a few types of hiv tests that can be done—antibody tests, antibody/antigen tests, and rna/dna tests. antibody tests look for antibodies that the body’s made against hiv. antigen tests look for the virus directly, so antibody/antigen tests detect both antibodies to the virus as well as the virus itself. rna tests screen for viral rna, so they also detect the virus directly, and dna tests look for copies of the viral rna (since remember it’s a retrovirus so it copies its genetic material into dna). for screening purposes, the recommended test is the antibody/antigen test, which is better at identifying early infection. it’s also recommended, if the first test is positive, to follow it with a confirmatory test that looks for antibody or nucleic acids. there’s currently no cure for aids; treatment however, can help somebody with aids live longer, healthier lives and help reduce the risk of transmission. the primary method is to use antiretroviral therapy, or art. art isn’t a single medicine, but a combination of medicines that’s known as an hiv regimen. these help slow down hiv replication, which gives the immune system a chance to recover and help fight off other infections more effectively.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_e861560becfd,"what is eustachian tube dysfunction? eustachian tube dysfunction is when the eustachian tube becomes blocked, leading to problems equalizing pressure in the ear and subsequent symptoms. ",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_a8f4dcbffac3,"what is acute pyelonephritis? acute pyelonephritis is a type of upper urinary tract infection where bacteria infiltrate and infect the kidneys. [osmosis sound logo] with acute pyelonephritis, pyelo- means pelvis and neph- refers to the kidney --so in this case it's the renal pelvis, which is the funnel-like structure of the kidney that drains urine into the ureter-- and -itis means inflammation. so acute pyelonephritis describes an inflamed kidney that develops relatively quickly, usually as a result of a bacterial infection. now a urinary tract infection --or uti-- is any infection of the urinary tract, which includes the upper portion of the tract --the kidneys andthe ureters-- and the lower portion of the tract --the bladder and the urethra. so acute pyelonephritis is a type of upper urinary tract infection. acute pyelonephritis is most often caused by ascending infection: meaning bacteria start by colonizing the urethra and bladder, --which would be a lower urinary tract infection-- and make their way up the ureter to the kidney. therefore, upper uti shares a lot of the same risk factors as lower uti: things like female sex,sexual intercourse, indwelling catheters, diabetes mellitus, and urinary tract obstruction. one major factor that increases the risk of an upper uti [developing] from a lower uti spreading upward is vesicoureteral reflux --or vur-- which is where urine is allowed to move backward --up the urinary tract-- which can happen if the vesicoureteral orifice fails. the vesicoureteral orifice is the one-way valve that allows urine to flow from each ureter into the bladder, but not in the reverse direction. vur can be the result of a primary congenital defect or it can be caused by bladder outlet obstruction, which increases pressure in the bladder and distorts the valve. as kind of a double whammy, obstruction also leads to urinary stasis --where urine stands still-- which makes it easier for bacteria to adhere and colonize the urinary tract. so for ascending infections that cause acute pyelonephritis, the most common organisms are e. coli, proteus species, and enterobacter species, all of which are commonly found in the bowel flora. now, it's also possible that the kidneys get infected via hematogenous infection, or spread through the bloodstream, although this is a lot less common. usually, pyelonephritis from hematogenous spread is a consequence of septicemia or bacteremia --which is bacteria in the blood-- as well as infective endocarditis, an infection of the inner layer of the heart. in these situations, the most common organisms are staphylococcus species and, again, e.coli. acute pyelonephritis is most often unilateral --meaning it affects just one kidney-- and when bacteria mount an attack, they usually start by adhering to the renal epithelium of the tubules, which triggers an inflammatory response. chemokines attract neutrophils to the renal interstitium, but typically the glomeruli and vessels of the kidney are spared. as neutrophils infiltrate and die off, they make their way through the urinary tract, and are peed out; so people with acute pyelonephritis often have white blood cells in their urine. sometimes the cells and the surrounding inflammatory protein debris is even ""casted"" [sic] into the shape of the tubule which is then also peed out and is called a white blood cell cast. patients also can present with increased white blood cells in their blood --called leukocytosis-- and as a result of the inflammatory immune response, patients can also develop fevers, chills, nausea, and vomiting, as well as flank pain at the costovertebral angle. these systemic symptoms are what often distinguish acute pyelonephritis from a lower urinary tract infection. treatment is typically antibiotics and making sure that the individual stays well hydrated. like most bacterial infections, there's also a possibility of a renal abscess that can form as a complication. also, if there are recurrent infections --which can be the case in people with an anatomic problem that allows bacteria to easily cause infections-- then it can lead to chronic pyelonephritis, as well as papillary necrosis --or death of the renal papillae tissue-- which has a much worse prognosis because that can affect the kidney's overall ability to function. all right, as a quick recap: acute pyelonephritis is typically a bacterial infection of the upper urinary tract, which usually develops from a lower urinary tract infection, especially in individuals with vesicoureteral reflux. the infection causes systemic symptoms like fevers and flank pain at the costvertebral angle and is treated with antibiotics. thanks for watching![osmosis closing sound logo] you can help support us by donating on patreon, subscribing to our channel, or telling your friends about us on social media.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_17265b7a18a3,"what is non-alcoholic fatty liver disease (nafld)? nafld is a type of liver disease where fat is deposited (steatosis) in the liver due to non-alcohol-related reasons. nonalcoholic fatty liver disease is actually a spectrum of disease - going from least to most severe - steatosis, steatohepatitis, fibrosis, and finally cirrhosis. nonalcoholic fatty liver disease results from fat deposition in the liver, unrelated to alcohol or viral causes. typically, it affects individuals with metabolic syndrome, which includes a combination of three of the following five diagnosis: obesity, hypertension, diabetes, hypertriglyceridemia, and hyperlipidemia. given how common metabolic syndrome has become, it’s not surprising that the rate of nonalcoholic fatty liver disease has also increased dramatically. it’s a massive problem growing in lock-step with expanding waistlines, affecting about three quarters of all obese individuals, including many children. although the precise mechanism of nonalcoholic fatty liver disease is not clear, insulin resistance seems to play an important role. over time, insulin receptors on various tissues including the liver become less responsive to insulin, and as a result the liver goes into a mode where it increases fat storage and decreases fatty acid oxidation. that means decreased secretion of lipids into the bloodstream, in the form of lipoproteins, and increased synthesis and uptake of free fatty acids from the blood - a process called steatosis. steatosis causes fat droplets to form within hepatocytes, some of which become large enough to cause the hepatocytes to swell up with fat and pushing the nuclei to the edge of the cell. you can see this on a histopathology slide of the liver. all of these white circles are large deposits of fat. zooming out and looking at the liver, shows widespread steatosis which makes the liver appear large, soft, yellow, and greasy. over time, the fat in the hepatocytes is vulnerable to degradation. unsaturated fatty acids, or fatty acids that have at least one double bond in their carbon chain, have hydrogen atoms that are particularly vulnerable to initiators such as the reactive oxygen species like the hydroxy radical that have an unpaired electron. in this example the hydroxyl radical pairs with the vulnerable lipid hydrogen to make water and a fatty acid radical. the fatty acid radical is unstable and will react with non-radicals, including molecular oxygen and undamaged fatty acids. this goes on until one radical species reacts with another radical species terminating the reaction. this process damages lipid membranes leading to things like mitochondrial dysfunction and eventually cell death. cell death generates inflammation, and together the process of steatosis and inflammation is referred to as steatohepatitis. in the absence of alcohol this is called nonalcoholic steatohepatitis or nash. in addition to bloated and dying hepatocytes, there may be additional histopathologic changes like the presence of mallory-denk bodies which are tangles of intermediate filaments that can be seen in the cytoplasm of hepatocytes. the mechanism for how these form remains unclear. hepatocyte damage also attracts neutrophils into the liver tissues. finally, chronic steatohepatitis can cause liver stellate cells to lay down fibrotic tissue causing the disease to be classified as fibrosis. as the process of fibrosis continues, the overall architecture of the liver changes, to the point where the disease is classified as cirrhosis. even at the advanced stage of steatohepatitis, an individual might have no symptoms. and when there are symptoms, they are often vague - like fatigue or malaise. once there is significant liver damage, there can be hepatomegaly or enlargement of the liver, pain in the right upper quadrant of the abdomen, jaundice, and even an accumulation of fluid in the peritoneal cavity called ascites. because hepatocytes are being destroyed, there can be an increase in liver enzymes such as aspartate transaminase (ast) and alanine transaminase (alt). classically, progression of steatosis to steatohepatitis and then to cirrhosis causes an increase in the alt and sometimes ast. in contrast, alcoholic liver injury generally causes the a big increase in ast and a more modest increase in alt giving a ast:alt ratio generally &gt; 2. if nonalcoholic fatty liver disease is suspected, a diagnosis can be made with imaging studies such as ultrasound, a ct scan, or an mri to look for fatty infiltrates. in addition, a biopsy of the liver can be done to confirm the diagnosis and assess the severity of the disease. generally speaking, a liver with more than 5% fat content is considered abnormal. steatosis and to a lesser degree steatohepatitis is generally reversible by addressing the underlying cause, however, that’s generally not the case once fibrosis and cirrhosis have set in. the goal is to reverse the factors that contribute to insulin resistance, primarily through a healthy diet and an active lifestyle, as well as medications to control blood glucose levels if needed. ok, quick recap: nonalcoholic fatty liver disease occurs when fat is deposited in the liver - a process called steatosis. inflammation from steatosis can lead to steatohepatitis, and chronic steatohepatitis can lead to fibrosis, and ultimately to cirrhosis. this spectrum of disease is thought to be caused by insulin resistance, and depending on the stage of disease, it can be reversed with careful attention to diet and exercise - as well as medications to help control blood glucose levels. thanks for watching, you can help support us by donating on patreon, or subscribing to our channel, or telling your friends about us on social media.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_15ddb328da93,"what are nasal polyps? nasal polyps are typically non-cancerous overgrowths of epithelial cells that form in the lining of your nasal cavity.a nasal polyp is a clump of epithelial cells that forms a small bump or overgrowth of tissue along the lining the nasal cavity, the inside of the nose. the nasal cavity is made up of three regions. the first, is the nasal vestibule which is the area just inside the nostrils. beyond that, is the respiratory region which delivers air to the sinuses and lungs, and above it is the olfactory region, which is involved in smelling. lining the respiratory region are epithelial cells that create mucus to moisten the air and trap pathogens. there are also air-filled spaces within the skull that are on either side of the the nose called paranasal sinuses which are lined by the same layer of epithelial cells as the respiratory region. the paranasal sinuses are named for the bones that house the sinus: the sphenoid, located next to the eyes; the ethmoid, between the eyes; the frontal, above the eyes behind the forehead; and the maxillary, behind the cheeks and below the eyes. each of the sinuses normally produce mucus, which drain into the respiratory region. holes at the back of the respiratory region, called choanae act like funnels to direct the mucus into the throat to be swallowed. nasal polyps develop when epithelial cells that line the respiratory region simply overgrow - a process called hyperplasia. most of the time, one or more nasal polyps forms in the maxillary or ethmoid sinus. nasal polyps can get large - the size of a pea, but they are usually non-cancerous, meaning they don’t break through the basement membrane of the epithelium. unfortunately, they often obstruct air flow as well as mucus drainage which allows pathogens to linger in the sinuses and cause infections. recurrent infections causes mucosal swelling as immune cells infiltrate the tissue and create an inflammatory response. the swelling makes airway obstruction and mucus drainage even worse. the reason that the epithelial cells start to grow into a polyp isn’t entirely clear but they are associated with seasonal allergies, having frequent asthma exacerbations, and chronic sinusitis. there are some genetic factors that seem related as well, for example, individuals with cystic fibrosis and primary ciliary dyskinesia both have a high risk of developing nasal polyps. the symptoms of nasal polyps are usually related to blocked mucus drainage and obstructed air flow. as the polyps grow, they occlude the nearby choanae and block sinus mucus drainage. this can leave the sinuses full of secretions that get infected - causing bouts of fevers and headaches when that develops. obstructed air flow can prevent air from reaching the olfactory region and decrease the sense of smell. it can also cause snoring and sleep apnea, and in young infants it can cause reduced levels of oxygenation, called hypoxia, which gives a bluish tinge to their skin color. nasal polyps are diagnosed visually with nasal endoscopy or by medical imaging with a ct. diagnosis is often made after clinical symptoms become problematic, but changes to the respiratory mucosa can be detected even in their absence. the treatment for polyps is to shrink them using steroids, usually in the form of a nasal spray. the steroids act to decrease the inflammation and swelling from the polyp. but some polyps are unresponsive to steroids. this tends to happen when there are high levels of eosinophils, a specialized type of immune cell. in these cases, endoscopic sinus surgery may be needed to cut them out. unfortunately, because the underlying causes for polyps are often chronic conditions like allergies and asthma, polyps often return, so repeat treatments are typically needed. so, a quick recap: nasal polyps form as a result of hyperplasia of the epithelial cells that line the respiratory region - especially in the maxillary and ethmoidal sinuses. their growth obstructs air flow through the nasal cavity and prevents sinus mucus from draining normally. they are treated with steroids, or sometimes surgery, but have a high likelihood of returning. thanks for watching, you can help support us by donating on patreon, or subscribing to our channel, or telling your friends about us on social media.",t_b3fa23bfbeaa,t_b3fa23bfbeaa,16
c_669b5fb86307,"chapter 92 of the book on python.chapter 92: web scraping with python web scraping is an automated, programmatic process through which data can be constantly 'scraped' oﬀ webpages. also known as screen scraping or web harvesting, web scraping can provide instant data from any publicly accessible webpage. on some websites, web scraping may be illegal.  section 92.1: scraping using the scrapy framework first you have to set up a new scrapy project. enter a directory where you’d like to store your code and run: scrapy startproject projectname  to scrape we need a spider. spiders deﬁne how a certain site will be scraped. here’s the code for a spider that follows the links to the top voted questions on stackoverﬂow and scrapes some data from each page (source): import scrapy class stackoverflowspider(scrapy.spider): name = 'stackoverflow' # each spider has a unique name start_urls = ['http://stackoverflow.com/questions?sort=votes'] specific set of urls  # the parsing starts from a  def parse(self, response): # for each request this generator yields, its response is sent to parse_question for href in response.css('.question-summary h3 a::attr(href)'): # do some scraping stuff using css selectors to find question urls full_url = response.urljoin(href.extract()) yield scrapy.request(full_url, callback=self.parse_question) def parse_question(self, response): yield { 'title': response.css('h1 a::text').extract_first(), 'votes': response.css('.question .vote-count-post::text').extract_first(), 'body': response.css('.question .post-text').extract_first(), 'tags': response.css('.question .post-tag::text').extract(), 'link': response.url, }  save your spider classes in the projectname\spiders directory. in this case projectname\spiders\stackoverflow_spider.py.  now you can use your spider. for example, try running (in the project's directory): scrapy crawl stackoverflow  section 92.2: scraping using selenium webdriver some websites don’t like to be scraped. in these cases you may need to simulate a real user working with a browser. selenium launches and controls a web browser. from selenium import webdriver browser = webdriver.firefox()  # launch firefox browser  browser.get('http://stackoverflow.com/questions?sort=votes')  goalkicker.com – python® notes for professionals  # load url  458  title = browser.find_element_by_css_selector('h1').text  # page title (first h1 element)  questions = browser.find_elements_by_css_selector('.question-summary')  # question list  for question in questions: # iterate over questions question_title = question.find_element_by_css_selector('.summary h3 a').text question_excerpt = question.find_element_by_css_selector('.summary .excerpt').text question_vote = question.find_element_by_css_selector('.stats .vote .votes .vote-countpost').text print ""%s\n%s\n%s votes\n-----------\n"" % (question_title, question_excerpt, question_vote)  selenium can do much more. it can modify browser’s cookies, ﬁll in forms, simulate mouse clicks, take screenshots of web pages, and run custom javascript.  section 92.3: basic example of using requests and lxml to scrape some data # for python 2 compatibility. from __future__ import print_function import lxml.html import requests  def main(): r = requests.get(""https://httpbin.org"") html_source = r.text root_element = lxml.html.fromstring(html_source) # note root_element.xpath() gives a *list* of results. # xpath specifies a path to the element we want. page_title = root_element.xpath('/html/head/title/text()')[0] print(page_title) if __name__ == '__main__': main()  section 92.4: maintaining web-scraping session with requests it is a good idea to maintain a web-scraping session to persist the cookies and other parameters. additionally, it can result into a performance improvement because requests.session reuses the underlying tcp connection to a host: import requests with requests.session() as session: # all requests through session now have user-agent header set session.headers = {'user-agent': 'mozilla/5.0 (macintosh; intel mac os x 10_11_4) applewebkit/537.36 (khtml, like gecko) chrome/51.0.2704.103 safari/537.36'} # set cookies session.get('http://httpbin.org/cookies/set?key=value') # get cookies response = session.get('http://httpbin.org/cookies') print(response.text)  goalkicker.com – python® notes for professionals  459  section 92.5: scraping using beautifulsoup4 from bs4 import beautifulsoup import requests # use the requests module to obtain a page res = requests.get('https://www.codechef.com/problems/easy') # create a beautifulsoup object page = beautifulsoup(res.text, 'lxml')  # the text field contains the source of the page  # now use a css selector in order to get the table containing the list of problems datatable_tags = page.select('table.datatable') # the problems are in the <table> tag, # with class ""datatable"" # we extract the first tag from the list, since that's what we desire datatable = datatable_tags[0] # now since we want problem names, they are contained in <b> tags, which are # directly nested under <a> tags prob_tags = datatable.select('a > b') prob_names = [tag.gettext().strip() for tag in prob_tags] print prob_names  section 92.6: simple web content download with urllib.request the standard library module urllib.request can be used to download web content: from urllib.request import urlopen response = urlopen('http://stackoverflow.com/questions?sort=votes') data = response.read() # the received bytes should usually be decoded according the response's character set encoding = response.info().get_content_charset() html = data.decode(encoding)  a similar module is also available in python 2.  section 92.7: modify scrapy user agent sometimes the default scrapy user agent (""scrapy/version (+http://scrapy.org)"") is blocked by the host. to change the default user agent open settings.py, uncomment and edit the following line to whatever you want. #user_agent = 'projectname (+http://www.yourdomain.com)'  for example user_agent = 'mozilla/5.0 (macintosh; intel mac os x 10_11_4) applewebkit/537.36 (khtml, like gecko) chrome/51.0.2704.103 safari/537.36'  section 92.8: scraping with curl imports: from subprocess import popen, pipe from lxml import etree  goalkicker.com – python® notes for professionals  460  from io import stringio  downloading: user_agent = 'mozilla/5.0 (macintosh; intel mac os x 10_11_6) applewebkit/537.36 (khtml, like gecko) chrome/55.0.2883.95 safari/537.36' url = 'http://stackoverflow.com' get = popen(['curl', '-s', '-a', user_agent, url], stdout=pipe) result = get.stdout.read().decode('utf8') -s: silent download -a: user agent ﬂag  parsing: tree = etree.parse(stringio(result), etree.htmlparser()) divs = tree.xpath('//div')  goalkicker.com – python® notes for professionals  461",t_ba5de272b4cb,t_ba5de272b4cb,17
c_0e25410bed5f,"chapter 56 of the book on python.chapter 56: functools module section 56.1: partial the partial function creates partial function application from another function. it is used to bind values to some of the function's arguments (or keyword arguments) and produce a callable without the already deﬁned arguments. >>> from functools import partial >>> unhex = partial(int, base=16) >>> unhex.__doc__ = 'convert base16 string to int' >>> unhex('ca11ab1e') 3390155550 partial(), as the name suggests, allows a partial evaluation of a function. let's look at following example: in [2]: from functools import partial in [3]: def f(a, b, c, x): ...: return 1000*a + 100*b + 10*c + x ...: in [4]: g = partial(f, 1, 1, 1) in [5]: print g(2) 1112  when g is created, f, which takes four arguments(a, b, c, x), is also partially evaluated for the ﬁrst three arguments, a, b, c,. evaluation of f is completed when g is called, g(2), which passes the fourth argument to f. one way to think of partial is a shift register; pushing in one argument at the time into some function. partial comes handy for cases where data is coming in as stream and we cannot pass more than one argument.  section 56.2: cmp_to_key python changed its sorting methods to accept a key function. those functions take a value and return a key which is used to sort the arrays. old comparison functions used to take two values and return -1, 0 or +1 if the ﬁrst argument is small, equal or greater than the second argument respectively. this is incompatible to the new key-function. that's where functools.cmp_to_key comes in: >>> import functools >>> import locale >>> sorted([""a"", ""s"", ""f"", ""d""], key=functools.cmp_to_key(locale.strcoll)) ['a', 'd', 'f', 's']  example taken and adapted from the python standard library documentation.  section 56.3: lru_cache the @lru_cache decorator can be used wrap an expensive, computationally-intensive function with a least recently used cache. this allows function calls to be memoized, so that future calls with the same parameters can return instantly instead of having to be recomputed.  goalkicker.com – python® notes for professionals  312  @lru_cache(maxsize=none) # boundless cache def fibonacci(n): if n < 2: return n return fibonacci(n-1) + fibonacci(n-2) >>> fibonacci(15)  in the example above, the value of fibonacci(3) is only calculated once, whereas if fibonacci didn't have an lru cache, fibonacci(3) would have been computed upwards of 230 times. hence, @lru_cache is especially great for recursive functions or dynamic programming, where an expensive function could be called multiple times with the same exact parameters. @lru_cache has two arguments maxsize: number of calls to save. when the number of unique calls exceeds maxsize, the lru cache will  remove the least recently used calls. typed (added in 3.3): flag for determining if equivalent arguments of diﬀerent types belong to diﬀerent cache  records (i.e. if 3.0 and 3 count as diﬀerent arguments) we can see cache stats too: >>> fib.cache_info() cacheinfo(hits=13, misses=16, maxsize=none, currsize=16)  note: since @lru_cache uses dictionaries to cache results, all parameters for the function must be hashable for the cache to work. oﬃcial python docs for @lru_cache. @lru_cache was added in 3.2.  section 56.4: total_ordering when we want to create an orderable class, normally we need to deﬁne the methods __eq()__, __lt__(), __le__(), __gt__() and __ge__().  the total_ordering decorator, applied to a class, permits the deﬁnition of __eq__() and only one between __lt__(), __le__(), __gt__() and __ge__(), and still allow all the ordering operations on the class. @total_ordering class employee: ... def __eq__(self, other): return ((self.surname, self.name) == (other.surname, other.name)) def __lt__(self, other): return ((self.surname, self.name) < (other.surname, other.name))  the decorator uses a composition of the provided methods and algebraic operations to derive the other comparison methods. for example if we deﬁned __lt__() and __eq()__ and we want to derive __gt__(), we can simply check not __lt__() and not __eq()__. note: the total_ordering function is only available since python 2.7.  goalkicker.com – python® notes for professionals  313  section 56.5: reduce in python 3.x, the reduce function already explained here has been removed from the built-ins and must now be imported from functools. from functools import reduce def factorial(n): return reduce(lambda a, b: (a*b), range(1, n+1))  goalkicker.com – python® notes for professionals  314",t_ba5de272b4cb,t_ba5de272b4cb,17
c_090c113ba65f,"chapter 43 of the book on python.chapter 43: importing modules section 43.1: importing a module use the import statement: >>> import random >>> print(random.randint(1, 10)) 4 import module will import a module and then allow you to reference its objects -- values, functions and classes, for  example -- using the module.name syntax. in the above example, the random module is imported, which contains the randint function. so by importing random you can call randint with random.randint.  you can import a module and assign it to a diﬀerent name: >>> import random as rn >>> print(rn.randint(1, 10)) 4  if your python ﬁle main.py is in the same folder as custom.py. you can import it like this: import custom  it is also possible to import a function from a module: >>> from math import sin >>> sin(1) 0.8414709848078965  to import speciﬁc functions deeper down into a module, the dot operator may be used only on the left side of the import keyword: from urllib.request import urlopen  in python, we have two ways to call function from top level. one is import and another is from. we should use import when we have a possibility of name collision. suppose we have hello.py ﬁle and world.py ﬁles having same  function named function. then import statement will work good. from hello import function from world import function function() #world's function will be invoked. not hello's  in general import will provide you a namespace. import hello import world hello.function() # exclusively hello's function will be invoked world.function() # exclusively world's function will be invoked  but if you are sure enough, in your whole project there is no way having same function name you should use from statement goalkicker.com – python® notes for professionals  256  multiple imports can be made on the same line: >>> >>> >>> >>> >>> >>>  # multiple modules import time, sockets, random # multiple functions from math import sin, cos, tan # multiple constants from math import pi, e  >>> print(pi) 3.141592653589793 >>> print(cos(45)) 0.5253219888177297 >>> print(time.time()) 1482807222.7240417  the keywords and syntax shown above can also be used in combinations: >>> from urllib.request import urlopen as geturl, pathname2url as path2url, getproxies >>> from math import factorial as fact, gamma, atan as arctan >>> import random.randint, time, sys >>> print(time.time()) 1482807222.7240417 >>> print(arctan(60)) 1.554131203080956 >>> filepath = ""/dogs/jumping poodle (december).png"" >>> print(path2url(filepath)) /dogs/jumping%20poodle%20%28december%29.png  section 43.2: the __all__ special variable modules can have a special variable named __all__ to restrict what variables are imported when using from mymodule import *.  given the following module: # mymodule.py __all__ = ['imported_by_star'] imported_by_star = 42 not_imported_by_star = 21  only imported_by_star is imported when using from mymodule import *: >>> from mymodule import * >>> imported_by_star 42 >>> not_imported_by_star traceback (most recent call last): file ""<stdin>"", line 1, in <module> nameerror: name 'not_imported_by_star' is not defined  however, not_imported_by_star can be imported explicitly: >>> from mymodule import not_imported_by_star >>> not_imported_by_star  goalkicker.com – python® notes for professionals  257  21  section 43.3: import modules from an arbitrary ﬁlesystem location if you want to import a module that doesn't already exist as a built-in module in the python standard library nor as a side-package, you can do this by adding the path to the directory where your module is found to sys.path. this may be useful where multiple python environments exist on a host. import sys sys.path.append(""/path/to/directory/containing/your/module"") import mymodule  it is important that you append the path to the directory in which mymodule is found, not the path to the module itself.  section 43.4: importing all names from a module from module_name import *  for example: from math import * sqrt(2) # instead of math.sqrt(2) ceil(2.7) # instead of math.ceil(2.7)  this will import all names deﬁned in the math module into the global namespace, other than names that begin with an underscore (which indicates that the writer feels that it is for internal use only). warning: if a function with the same name was already deﬁned or imported, it will be overwritten. almost always importing only speciﬁc names from math import sqrt, ceil is the recommended way: def sqrt(num): print(""i don't know what's the square root of {}."".format(num)) sqrt(4) # output: i don't know what's the square root of 4. from math import * sqrt(4) # output: 2.0  starred imports are only allowed at the module level. attempts to perform them in class or function deﬁnitions result in a syntaxerror. def f(): from math import *  and class a: from math import *  both fail with:  goalkicker.com – python® notes for professionals  258  syntaxerror: import * only allowed at module level  section 43.5: programmatic importing python 2.x version  ≥ 2.7  to import a module through a function call, use the importlib module (included in python starting in version 2.7): import importlib random = importlib.import_module(""random"")  the importlib.import_module() function will also import the submodule of a package directly: collections_abc = importlib.import_module(""collections.abc"")  for older versions of python, use the imp module. python 2.x version  ≤ 2.7  use the functions imp.find_module and imp.load_module to perform a programmatic import. taken from standard library documentation import imp, sys def import_module(name): fp, pathname, description = imp.find_module(name) try: return imp.load_module(name, fp, pathname, description) finally: if fp: fp.close()  do not use __import__() to programmatically import modules! there are subtle details involving sys.modules, the fromlist argument, etc. that are easy to overlook which importlib.import_module() handles for you.  section 43.6: pep8 rules for imports some recommended pep8 style guidelines for imports: 1. imports should be on separate lines: from math import sqrt, ceil from math import sqrt from math import ceil  # not recommended # recommended  2. order imports as follows at the top of the module: standard library imports related third party imports local application/library speciﬁc imports 3. wildcard imports should be avoided as it leads to confusion in names in the current namespace. if you do from module import *, it can be unclear if a speciﬁc name in your code comes from module or not. this is  goalkicker.com – python® notes for professionals  259  doubly true if you have multiple from module import *-type statements. 4. avoid using relative imports; use explicit imports instead.  section 43.7: importing speciﬁc names from a module instead of importing the complete module you can import only speciﬁed names: from random import randint # syntax ""from modulename import name1[, name2[, ...]]"" print(randint(1, 10)) # out: 5 from random is needed, because the python interpreter has to know from which resource it should import a  function or class and import randint speciﬁes the function or class itself. another example below (similar to the one above): from math import pi print(pi)  # out: 3.14159265359  the following example will raise an error, because we haven't imported a module: random.randrange(1, 10)  # works only if ""import random"" has been run before  outputs: nameerror: name 'random' is not defined  the python interpreter does not understand what you mean with random. it needs to be declared by adding import random to the example: import random random.randrange(1, 10)  section 43.8: importing submodules from module.submodule import function  this imports function from module.submodule.  section 43.9: re-importing a module when using the interactive interpreter, you might want to reload a module. this can be useful if you're editing a module and want to import the newest version, or if you've monkey-patched an element of an existing module and want to revert your changes. note that you can't just import the module again to revert: import math math.pi = 3 print(math.pi) import math print(math.pi)  # 3 # 3  goalkicker.com – python® notes for professionals  260  this is because the interpreter registers every module you import. and when you try to reimport a module, the interpreter sees it in the register and does nothing. so the hard way to reimport is to use import after removing the corresponding item from the register: print(math.pi) # 3 import sys if 'math' in sys.modules: # is the ``math`` module in the register? del sys.modules['math'] # if so, remove it. import math print(math.pi) # 3.141592653589793  but there is more a straightforward and simple way. python 2 use the reload function: python 2.x version import math math.pi = 3 print(math.pi) reload(math) print(math.pi)  ≥ 2.3  # 3 # 3.141592653589793  python 3 the reload function has moved to importlib: python 3.x version  ≥ 3.0  import math math.pi = 3 print(math.pi) # 3 from importlib import reload reload(math) print(math.pi) # 3.141592653589793  section 43.10: __import__() function the __import__() function can be used to import modules where the name is only known at runtime if user_input == ""os"": os = __import__(""os"") # equivalent to import os  this function can also be used to specify the ﬁle path to a module mod = __import__(r""c:/path/to/file/anywhere/on/computer/module.py"")  goalkicker.com – python® notes for professionals  261",t_ba5de272b4cb,t_ba5de272b4cb,17
c_346f84f7f7f2,"chapter 146 of the book on python.chapter 146: abstract base classes (abc) section 146.1: setting the abcmeta metaclass abstract classes are classes that are meant to be inherited but avoid implementing speciﬁc methods, leaving behind only method signatures that subclasses must implement. abstract classes are useful for deﬁning and enforcing class abstractions at a high level, similar to the concept of interfaces in typed languages, without the need for method implementation. one conceptual approach to deﬁning an abstract class is to stub out the class methods, and then raise a notimplementederror if accessed. this prevents children classes from accessing parent methods without overriding them ﬁrst. like so: class fruit: def check_ripeness(self): raise notimplementederror(""check_ripeness method not implemented!"")  class apple(fruit): pass  a = apple() a.check_ripeness() # raises notimplementederror  creating an abstract class in this way prevents improper usage of methods that are not overridden, and certainly encourages methods to be deﬁned in child classes, but it does not enforce their deﬁnition. with the abc module we can prevent child classes from being instantiated when they fail to override abstract class methods of their parents and ancestors: from abc import abcmeta class abstractclass(object): # the metaclass attribute must always be set as a class variable __metaclass__ = abcmeta # the abstractmethod decorator registers this method as undefined @abstractmethod def virtual_method_subclasses_must_define(self): # can be left completely blank, or a base implementation can be provided # note that ordinarily a blank interpretation implicitly returns `none`, # but by registering, this behaviour is no longer enforced.  it is now possible to simply subclass and override: class subclass(abstractclass): def virtual_method_subclasses_must_define(self): return  section 146.2: why/how to use abcmeta and @abstractmethod abstract base classes (abcs) enforce what derived classes implement particular methods from the base class. goalkicker.com – python® notes for professionals  619  to understand how this works and why we should use it, let's take a look at an example that van rossum would enjoy. let's say we have a base class ""montypython"" with two methods (joke & punchline) that must be implemented by all derived classes. class montypython: def joke(self): raise notimplementederror() def punchline(self): raise notimplementederror() class argumentclinic(montypython): def joke(self): return ""hahahahahah""  when we instantiate an object and call it's two methods, we'll get an error (as expected) with the punchline() method. >>> sketch = argumentclinic() >>> sketch.punchline() notimplementederror  however, this still allows us to instantiate an object of the argumentclinic class without getting an error. in fact we don't get an error until we look for the punchline(). this is avoided by using the abstract base class (abc) module. let's see how this works with the same example: from abc import abcmeta, abstractmethod class montypython(metaclass=abcmeta): @abstractmethod def joke(self): pass @abstractmethod def punchline(self): pass class argumentclinic(montypython): def joke(self): return ""hahahahahah""  this time when we try to instantiate an object from the incomplete class, we immediately get a typeerror! >>> c = argumentclinic() typeerror: ""can't instantiate abstract class argumentclinic with abstract methods punchline""  in this case, it's easy to complete the class to avoid any typeerrors: class argumentclinic(montypython): def joke(self): return ""hahahahahah"" def punchline(self): return ""send in the constable!""  this time when you instantiate an object it works! goalkicker.com – python® notes for professionals  620",t_ba5de272b4cb,t_ba5de272b4cb,17
c_fe6fc756cb19,"chapter 2 of the book on python.chapter 2: python data types data types are nothing but variables you use to reserve some space in memory. python variables do not need an explicit declaration to reserve memory space. the declaration happens automatically when you assign a value to a variable.  section 2.1: string data type string are identiﬁed as a contiguous set of characters represented in the quotation marks. python allows for either pairs of single or double quotes. strings are immutable sequence data type, i.e each time one makes any changes to a string, completely new string object is created. a_str = 'hello world' print(a_str) #output will be whole string. hello world print(a_str[0]) #output will be first character. h print(a_str[0:5]) #output will be first five characters. hello  section 2.2: set data types sets are unordered collections of unique objects, there are two types of set: 1. sets - they are mutable and new elements can be added once sets are deﬁned basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'} print(basket) # duplicates will be removed > {'orange', 'banana', 'pear', 'apple'} a = set('abracadabra') print(a) # unique letters in a > {'a', 'r', 'b', 'c', 'd'} a.add('z') print(a) > {'a', 'c', 'r', 'b', 'z', 'd'}  2. frozen sets - they are immutable and new elements cannot added after its deﬁned. b = frozenset('asdfagsa') print(b) > frozenset({'f', 'g', 'd', 'a', 's'}) cities = frozenset([""frankfurt"", ""basel"",""freiburg""]) print(cities) > frozenset({'frankfurt', 'basel', 'freiburg'})  section 2.3: numbers data type numbers have four types in python. int, ﬂoat, complex, and long. int_num = 10 #int value float_num = 10.2 #float value complex_num = 3.14j #complex value long_num = 1234567l #long value  goalkicker.com – python® notes for professionals  33  section 2.4: list data type a list contains items separated by commas and enclosed within square brackets [].lists are almost similar to arrays in c. one diﬀerence is that all the items belonging to a list can be of diﬀerent data type. list = [123,'abcd',10.2,'d'] #can be an array of any data type or single data type. list1 = ['hello','world'] print(list) #will output whole list. [123,'abcd',10.2,'d'] print(list[0:2]) #will output first two element of list. [123,'abcd'] print(list1 * 2) #will gave list1 two times. ['hello','world','hello','world'] print(list + list1) #will gave concatenation of both the lists. [123,'abcd',10.2,'d','hello','world']  section 2.5: dictionary data type dictionary consists of key-value pairs. it is enclosed by curly braces {} and values can be assigned and accessed using square brackets[]. dic={'name':'red','age':10} print(dic) #will output all the key-value pairs. {'name':'red','age':10} print(dic['name']) #will output only value with 'name' key. 'red' print(dic.values()) #will output list of values in dic. ['red',10] print(dic.keys()) #will output list of keys. ['name','age']  section 2.6: tuple data type lists are enclosed in brackets [ ] and their elements and size can be changed, while tuples are enclosed in parentheses ( ) and cannot be updated. tuples are immutable. tuple = (123,'hello') tuple1 = ('world') print(tuple) #will output whole tuple. (123,'hello') print(tuple[0]) #will output first value. (123) print(tuple + tuple1) #will output (123,'hello','world') tuple[1]='update' #this will give you error.  goalkicker.com – python® notes for professionals  34",t_ba5de272b4cb,t_ba5de272b4cb,17
c_399b14671035,"chapter 83 of the book on python.chapter 83: parsing command line arguments most command line tools rely on arguments passed to the program upon its execution. instead of prompting for input, these programs expect data or speciﬁc ﬂags (which become booleans) to be set. this allows both the user and other programs to run the python ﬁle passing it data as it starts. this section explains and demonstrates the implementation and usage of command line arguments in python.  section 83.1: hello world in argparse the following program says hello to the user. it takes one positional argument, the name of the user, and can also be told the greeting. import argparse parser = argparse.argumentparser() parser.add_argument('name', help='name of user' ) parser.add_argument('-g', '--greeting', default='hello', help='optional alternate greeting' ) args = parser.parse_args() print(""{greeting}, {name}!"".format( greeting=args.greeting, name=args.name) ) $ python hello.py --help usage: hello.py [-h] [-g greeting] name positional arguments: name  name of user  optional arguments: -h, --help show this help message and exit -g greeting, --greeting greeting optional alternate greeting $ python hello.py world hello, world! $ python hello.py john -g howdy howdy, john!  for more details please read the argparse documentation.  section 83.2: using command line arguments with argv whenever a python script is invoked from the command line, the user may supply additional command line arguments which will be passed on to the script. these arguments will be available to the programmer from the system variable sys.argv (""argv"" is a traditional name used in most programming languages, and it means ""argument vector""). goalkicker.com – python® notes for professionals  418  by convention, the ﬁrst element in the sys.argv list is the name of the python script itself, while the rest of the elements are the tokens passed by the user when invoking the script. # cli.py import sys print(sys.argv) $ python cli.py => ['cli.py'] $ python cli.py fizz => ['cli.py', 'fizz'] $ python cli.py fizz buzz => ['cli.py', 'fizz', 'buzz']  here's another example of how to use argv. we ﬁrst strip oﬀ the initial element of sys.argv because it contains the script's name. then we combine the rest of the arguments into a single sentence, and ﬁnally print that sentence prepending the name of the currently logged-in user (so that it emulates a chat program). import getpass import sys words = sys.argv[1:] sentence = "" "".join(words) print(""[%s] %s"" % (getpass.getuser(), sentence))  the algorithm commonly used when ""manually"" parsing a number of non-positional arguments is to iterate over the sys.argv list. one way is to go over the list and pop each element of it: # reverse and copy sys.argv argv = reversed(sys.argv) # extract the first element arg = argv.pop() # stop iterating when there's no more args to pop() while len(argv) > 0: if arg in ('-f', '--foo'): print('seen foo!') elif arg in ('-b', '--bar'): print('seen bar!') elif arg in ('-a', '--with-arg'): arg = arg.pop() print('seen value: {}'.format(arg)) # get the next value arg = argv.pop()  section 83.3: setting mutually exclusive arguments with argparse if you want two or more arguments to be mutually exclusive. you can use the function argparse.argumentparser.add_mutually_exclusive_group(). in the example below, either foo or bar can exist  but not both at the same time. import argparse parser = argparse.argumentparser() group = parser.add_mutually_exclusive_group()  goalkicker.com – python® notes for professionals  419  group.add_argument(""-f"", ""--foo"") group.add_argument(""-b"", ""--bar"") args = parser.parse_args() print ""foo = "", args.foo print ""bar = "", args.bar  if you try to run the script specifying both --foo and --bar arguments, the script will complain with the below message. error: argument -b/--bar: not allowed with argument -f/--foo  section 83.4: basic example with docopt docopt turns command-line argument parsing on its head. instead of parsing the arguments, you just write the usage string for your program, and docopt parses the usage string and uses it to extract the command line arguments. """""" usage: script_name.py [-a] [-b] <path> options: -a print all the things. -b get more bees into the path. """""" from docopt import docopt  if __name__ == ""__main__"": args = docopt(__doc__) import pprint; pprint.pprint(args)  sample runs: $ python script_name.py usage: script_name.py [-a] $ python script_name.py {'-a': false, '-b': false, '<path>': 'something'} $ python script_name.py {'-a': true, '-b': false, '<path>': 'something'} $ python script_name.py {'-a': true, '-b': true, '<path>': 'something'}  [-b] <path> something  something -a  -b something -a  section 83.5: custom parser error message with argparse you can create parser error messages according to your script needs. this is through the argparse.argumentparser.error function. the below example shows the script printing a usage and an error  message to stderr when --foo is given but not --bar. import argparse  goalkicker.com – python® notes for professionals  420  parser = argparse.argumentparser() parser.add_argument(""-f"", ""--foo"") parser.add_argument(""-b"", ""--bar"") args = parser.parse_args() if args.foo and args.bar is none: parser.error(""--foo requires --bar. you did not specify bar."") print ""foo ="", args.foo print ""bar ="", args.bar  assuming your script name is sample.py, and we run: python sample.py --foo ds_in_fridge the script will complain with the following: usage: sample.py [-h] [-f foo] [-b bar] sample.py: error: --foo requires --bar. you did not specify bar.  section 83.6: conceptual grouping of arguments with argparse.add_argument_group() when you create an argparse argumentparser() and run your program with '-h' you get an automated usage message explaining what arguments you can run your software with. by default, positional arguments and conditional arguments are separated into two categories, for example, here is a small script (example.py) and the output when you run python example.py -h. import argparse parser = argparse.argumentparser(description='simple example') parser.add_argument('name', help='who to greet', default='world') parser.add_argument('--bar_this') parser.add_argument('--bar_that') parser.add_argument('--foo_this') parser.add_argument('--foo_that') args = parser.parse_args() usage: example.py [-h] [--bar_this bar_this] [--bar_that bar_that] [--foo_this foo_this] [--foo_that foo_that] name simple example positional arguments: name optional arguments: -h, --help --bar_this bar_this --bar_that bar_that --foo_this foo_this --foo_that foo_that  who to greet  show this help message and exit  there are some situations where you want to separate your arguments into further conceptual sections to assist your user. for example, you may wish to have all the input options in one group, and all the output formatting options in another. the above example can be adjusted to separate the --foo_* args from the --bar_* args like so. import argparse parser = argparse.argumentparser(description='simple example')  goalkicker.com – python® notes for professionals  421  parser.add_argument('name', help='who to greet', default='world') # create two argument groups foo_group = parser.add_argument_group(title='foo options') bar_group = parser.add_argument_group(title='bar options') # add arguments to those groups foo_group.add_argument('--bar_this') foo_group.add_argument('--bar_that') bar_group.add_argument('--foo_this') bar_group.add_argument('--foo_that') args = parser.parse_args()  which produces this output when python example.py -h is run: usage: example.py [-h] [--bar_this bar_this] [--bar_that bar_that] [--foo_this foo_this] [--foo_that foo_that] name simple example positional arguments: name  who to greet  optional arguments: -h, --help  show this help message and exit  foo options: --bar_this bar_this --bar_that bar_that bar options: --foo_this foo_this --foo_that foo_that  section 83.7: advanced example with docopt and docopt_dispatch as with docopt, with [docopt_dispatch] you craft your --help in the __doc__ variable of your entry-point module. there, you call dispatch with the doc string as argument, so it can run the parser over it. that being done, instead of handling manually the arguments (which usually ends up in a high cyclomatic if/else structure), you leave it to dispatch giving only how you want to handle the set of arguments. this is what the dispatch.on decorator is for: you give it the argument or sequence of arguments that should trigger the function, and that function will be executed with the matching values as parameters. """"""run something in development or production mode. usage: run.py run.py run.py run.py  --development <host> <port> --production <host> <port> items add <item> items delete <item>  """""" from docopt_dispatch import dispatch @dispatch.on('--development') def development(host, port, **kwargs): print('in *development* mode')  goalkicker.com – python® notes for professionals  422  @dispatch.on('--production') def development(host, port, **kwargs): print('in *production* mode') @dispatch.on('items', 'add') def items_add(item, **kwargs): print('adding item...') @dispatch.on('items', 'delete') def items_delete(item, **kwargs): print('deleting item...') if __name__ == '__main__': dispatch(__doc__)  goalkicker.com – python® notes for professionals  423",t_ba5de272b4cb,t_ba5de272b4cb,17
c_45d12de38986,"chapter 185 of the book on python.chapter 185: kivy - cross-platform python framework for nui development nui : a natural user interface (nui) is a system for human-computer interaction that the user operates through intuitive actions related to natural, everyday human behavior. kivy is a python library for development of multi-touch enabled media rich applications which can be installed on diﬀerent devices. multi-touch refers to the ability of a touch-sensing surface (usually a touch screen or a trackpad) to detect or sense input from two or more points of contact simultaneously.  section 185.1: first app to create an kivy application 1. sub class the app class 2. implement the build method, which will return the widget. 3. instantiate the class an invoke the run. from kivy.app import app from kivy.uix.label import label class test(app): def build(self): return label(text='hello world') if __name__ == '__main__': test().run()  explanation from kivy.app import app  the above statement will import the parent class app. this will be present in your installation directory your_installtion_directory/kivy/app.py from kivy.uix.label import label  the above statement will import the ux element label. all the ux element are present in your installation directory your_installation_directory/kivy/uix/. class test(app):  the above statement is for to create your app and class name will be your app name. this class is inherited the parent app class. def build(self):  the above statement override the build method of app class. which will return the widget that needs to be shown when you will start the app. return label(text='hello world')  the above statement is the body of the build method. it is returning the label with its text hello world. goalkicker.com – python® notes for professionals  748  if __name__ == '__main__':  the above statement is the entry point from where python interpreter start executing your app. test().run()  the above statement initialise your test class by creating its instance. and invoke the app class function run(). your app will look like the below picture.  goalkicker.com – python® notes for professionals  749",t_ba5de272b4cb,t_ba5de272b4cb,17
c_a2a35a5ac7c2,"chapter 130 of the book on python.chapter 130: input, subset and output external data files using pandas this section shows basic code for reading, sub-setting and writing external data ﬁles using pandas.  section 130.1: basic code to import, subset and write external data files using pandas # print the working directory import os print os.getcwd() # c:\python27\scripts # set the working directory os.chdir('c:/users/general1/documents/simple python files') print os.getcwd() # c:\users\general1\documents\simple python files # load pandas import pandas as pd # read a csv data file named 'small_dataset.csv' containing 4 lines and 3 variables my_data = pd.read_csv(""small_dataset.csv"") my_data # x y z # 0 1 2 3 # 1 4 5 6 # 2 7 8 9 # 3 10 11 12 my_data.shape # (4, 3)  # number of rows and columns in data set  my_data.shape[0] # 4  # number of rows in data set  my_data.shape[1] # 3  # number of columns in data set  # python uses 0-based indexing. the first row or column in a data set is located # at position 0. in r the first row or column in a data set is located # at position 1. # select the my_data[0:2] # x y #0 1 2 #1 4 5  first two rows z 3 6  # select the second and third rows my_data[1:3] # x y z # 1 4 5 6 # 2 7 8 9 # select the third row my_data[2:3] # x y z #2 7 8 9  goalkicker.com – python® notes for professionals  584  # select the first two elements of the first column my_data.iloc[0:2, 0:1] # x # 0 1 # 1 4 # select the first element of the variables y and z my_data.loc[0, ['y', 'z']] # y 2 # z 3 # select the first three elements of the variables y and z my_data.loc[0:2, ['y', 'z']] # y z # 0 2 3 # 1 5 6 # 2 8 9 # write the first three elements of the variables y and z # to an external file. here index = 0 means do not write row names. my_data2 = my_data.loc[0:2, ['y', 'z']] my_data2.to_csv('my.output.csv', index = 0)  goalkicker.com – python® notes for professionals  585",t_ba5de272b4cb,t_ba5de272b4cb,17
c_315be5a0c65c,"chapter 112 of the book on python.chapter 112: pickle data serialisation parameter details object the object which is to be stored ﬁle  the open ﬁle which will contain the object  protocol  the protocol used for pickling the object (optional parameter)  buﬀer  a bytes object that contains a serialized object  section 112.1: using pickle to serialize and deserialize an object the pickle module implements an algorithm for turning an arbitrary python object into a series of bytes. this process is also called serializing the object. the byte stream representing the object can then be transmitted or stored, and later reconstructed to create a new object with the same characteristics. for the simplest code, we use the dump() and load() functions. to serialize the object import pickle # an arbitrary collection of objects supported by pickle. data = { 'a': [1, 2.0, 3, 4+6j], 'b': (""character string"", b""byte string""), 'c': {none, true, false} } with open('data.pickle', 'wb') as f: # pickle the 'data' dictionary using the highest protocol available. pickle.dump(data, f, pickle.highest_protocol)  to deserialize the object import pickle with open('data.pickle', 'rb') as f: # the protocol version used is detected automatically, so we do not # have to specify it. data = pickle.load(f)  using pickle and byte objects it is also possible to serialize into and deserialize out of byte objects, using the dumps and loads function, which are equivalent to dump and load. serialized_data = pickle.dumps(data, pickle.highest_protocol) # type(serialized_data) is bytes deserialized_data = pickle.loads(serialized_data) # deserialized_data == data  section 112.2: customize pickled data some data cannot be pickled. other data should not be pickled for other reasons. what will be pickled can be deﬁned in __getstate__ method. this method must return something that is picklable. goalkicker.com – python® notes for professionals  526  on the opposite side is __setstate__: it will receive what __getstate__ created and has to initialize the object. class a(object): def __init__(self, important_data): self.important_data = important_data # add data which cannot be pickled: self.func = lambda: 7 # add data which should never be pickled, because it expires quickly: self.is_up_to_date = false def __getstate__(self): return [self.important_data] # only this is needed def __setstate__(self, state): self.important_data = state[0] self.func = lambda: 7  # just some hard-coded unpicklable function  self.is_up_to_date = false  # even if it was before pickling  now, this can be done: >>> a1 = a('very important') >>> >>> s = pickle.dumps(a1) # calls a1.__getstate__() >>> >>> a2 = pickle.loads(s) # calls a1.__setstate__(['very important']) >>> a2 <__main__.a object at 0x0000000002742470> >>> a2.important_data 'very important' >>> a2.func() 7  the implementation here pikles a list with one value: [self.important_data]. that was just an example, __getstate__ could have returned anything that is picklable, as long as __setstate__ knows how to do the  opposite. a good alternative is a dictionary of all values: {'important_data': self.important_data}. constructor is not called! note that in the previous example instance a2 was created in pickle.loads without ever calling a.__init__, so a.__setstate__ had to initialize everything that __init__ would have initialized if it were called.  goalkicker.com – python® notes for professionals  527",t_ba5de272b4cb,t_ba5de272b4cb,17
c_7429ce05bb88,"chapter 47 of the book on python.chapter 47: collections module the built-in collections package provides several specialized, ﬂexible collection types that are both highperformance and provide alternatives to the general collection types of dict, list, tuple and set. the module also deﬁnes abstract base classes describing diﬀerent types of collection functionality (such as mutableset and itemsview).  section 47.1: collections.counter counter is a dict sub class that allows you to easily count objects. it has utility methods for working with the frequencies of the objects that you are counting. import collections counts = collections.counter([1,2,3])  the above code creates an object, counts, which has the frequencies of all the elements passed to the constructor. this example has the value counter({1: 1, 2: 1, 3: 1}) constructor examples letter counter >>> collections.counter('happy birthday') counter({'a': 2, 'p': 2, 'y': 2, 'i': 1, 'r': 1, 'b': 1, ' ': 1, 'h': 1, 'd': 1, 'h': 1, 't': 1})  word counter >>> collections.counter('i am sam sam i am that sam-i-am that sam-i-am! i do not like that sam-iam'.split()) counter({'i': 3, 'sam': 2, 'sam-i-am': 2, 'that': 2, 'am': 2, 'do': 1, 'sam-i-am!': 1, 'that': 1, 'not': 1, 'like': 1})  recipes >>> c = collections.counter({'a': 4, 'b': 2, 'c': -2, 'd': 0})  get count of individual element >>> c['a'] 4  set count of individual element >>> c['c'] = -3 >>> c counter({'a': 4, 'b': 2, 'd': 0, 'c': -3})  get total number of elements in counter (4 + 2 + 0 - 3) >>> sum(c.itervalues()) 3  # negative numbers are counted!  get elements (only those with positive counter are kept)  goalkicker.com – python® notes for professionals  275  >>> list(c.elements()) ['a', 'a', 'a', 'a', 'b', 'b']  remove keys with 0 or negative value >>> c - collections.counter() counter({'a': 4, 'b': 2})  remove everything >>> c.clear() >>> c counter()  add remove individual elements >>> c.update({'a': 3, 'b':3}) >>> c.update({'a': 2, 'c':2}) # adds to existing, sets if they don't exist >>> c counter({'a': 5, 'b': 3, 'c': 2}) >>> c.subtract({'a': 3, 'b': 3, 'c': 3}) # subtracts (negative values are allowed) >>> c counter({'a': 2, 'b': 0, 'c': -1})  section 47.2: collections.ordereddict the order of keys in python dictionaries is arbitrary: they are not governed by the order in which you add them. for example: >>> d = {'foo': 5, 'bar': 6} >>> print(d) {'foo': 5, 'bar': 6} >>> d['baz'] = 7 >>> print(a) {'baz': 7, 'foo': 5, 'bar': 6} >>> d['foobar'] = 8 >>> print(a) {'baz': 7, 'foo': 5, 'bar': 6, 'foobar': 8} ```  (the arbitrary ordering implied above means that you may get diﬀerent results with the above code to that shown here.) the order in which the keys appear is the order which they would be iterated over, e.g. using a for loop. the collections.ordereddict class provides dictionary objects that retain the order of keys. ordereddicts can be created as shown below with a series of ordered items (here, a list of tuple key-value pairs): >>> from collections import ordereddict >>> d = ordereddict([('foo', 5), ('bar', 6)]) >>> print(d) ordereddict([('foo', 5), ('bar', 6)]) >>> d['baz'] = 7 >>> print(d) ordereddict([('foo', 5), ('bar', 6), ('baz', 7)]) >>> d['foobar'] = 8  goalkicker.com – python® notes for professionals  276  >>> print(d) ordereddict([('foo', 5), ('bar', 6), ('baz', 7), ('foobar', 8)])  or we can create an empty ordereddict and then add items: >>> o = ordereddict() >>> o['key1'] = ""value1"" >>> o['key2'] = ""value2"" >>> print(o) ordereddict([('key1', 'value1'), ('key2', 'value2')])  iterating through an ordereddict allows key access in the order they were added. what happens if we assign a new value to an existing key? >>> d['foo'] = 4 >>> print(d) ordereddict([('foo', 4), ('bar', 6), ('baz', 7), ('foobar', 8)])  the key retains its original place in the ordereddict.  section 47.3: collections.defaultdict collections.defaultdict(default_factory) returns a subclass of dict that has a default value for missing keys. the argument should be a function that returns the default value when called with no arguments. if there is nothing passed, it defaults to none. >>> state_capitals = collections.defaultdict(str) >>> state_capitals defaultdict(<class 'str'>, {})  returns a reference to a defaultdict that will create a string object with its default_factory method. a typical usage of defaultdict is to use one of the builtin types such as str, int, list or dict as the default_factory, since these return empty types when called with no arguments: >>> str() '' >>> int() 0 >>> list []  calling the defaultdict with a key that does not exist does not produce an error as it would in a normal dictionary. >>> state_capitals['alaska'] '' >>> state_capitals defaultdict(<class 'str'>, {'alaska': ''})  another example with int: >>> fruit_counts = defaultdict(int) >>> fruit_counts['apple'] += 2 # no errors should occur >>> fruit_counts default_dict(int, {'apple': 2}) >>> fruit_counts['banana'] # no errors should occur  goalkicker.com – python® notes for professionals  277  0 >>> fruit_counts # a new key is created default_dict(int, {'apple': 2, 'banana': 0})  normal dictionary methods work with the default dictionary >>> state_capitals['alabama'] = 'montgomery' >>> state_capitals defaultdict(<class 'str'>, {'alabama': 'montgomery', 'alaska': ''})  using list as the default_factory will create a list for each new key. >>> s = [('nc', 'raleigh'), ('va', 'richmond'), ('wa', 'seattle'), ('nc', 'asheville')] >>> dd = collections.defaultdict(list) >>> for k, v in s: ... dd[k].append(v) >>> dd defaultdict(<class 'list'>, {'va': ['richmond'], 'nc': ['raleigh', 'asheville'], 'wa': ['seattle']})  section 47.4: collections.namedtuple deﬁne a new type person using namedtuple like this: person = namedtuple('person', ['age', 'height', 'name'])  the second argument is the list of attributes that the tuple will have. you can list these attributes also as either space or comma separated string: person = namedtuple('person', 'age, height, name')  or person = namedtuple('person', 'age height name')  once deﬁned, a named tuple can be instantiated by calling the object with the necessary parameters, e.g.: dave = person(30, 178, 'dave')  named arguments can also be used: jack = person(age=30, height=178, name='jack s.')  now you can access the attributes of the namedtuple: print(jack.age) # 30 print(jack.name) # 'jack s.'  the ﬁrst argument to the namedtuple constructor (in our example 'person') is the typename. it is typical to use the same word for the constructor and the typename, but they can be diﬀerent: human = namedtuple('person', 'age, height, name') dave = human(30, 178, 'dave')  goalkicker.com – python® notes for professionals  278  print(dave)  # yields: person(age=30, height=178, name='dave')  section 47.5: collections.deque returns a new deque object initialized left-to-right (using append()) with data from iterable. if iterable is not speciﬁed, the new deque is empty. deques are a generalization of stacks and queues (the name is pronounced “deck” and is short for “double-ended queue”). deques support thread-safe, memory eﬃcient appends and pops from either side of the deque with approximately the same o(1) performance in either direction. though list objects support similar operations, they are optimized for fast ﬁxed-length operations and incur o(n) memory movement costs for pop(0) and insert(0, v) operations which change both the size and position of the underlying data representation. new in version 2.4. if maxlen is not speciﬁed or is none, deques may grow to an arbitrary length. otherwise, the deque is bounded to the speciﬁed maximum length. once a bounded length deque is full, when new items are added, a corresponding number of items are discarded from the opposite end. bounded length deques provide functionality similar to the tail ﬁlter in unix. they are also useful for tracking transactions and other pools of data where only the most recent activity is of interest. changed in version 2.6: added maxlen parameter. >>> from collections import deque >>> d = deque('ghi') >>> for elem in d: ... print elem.upper() g h i  # make a new deque with three items # iterate over the deque's elements  >>> d.append('j') >>> d.appendleft('f') >>> d deque(['f', 'g', 'h', 'i', 'j'])  # add a new entry to the right side # add a new entry to the left side # show the representation of the deque  >>> d.pop() 'j' >>> d.popleft() 'f' >>> list(d) ['g', 'h', 'i'] >>> d[0] 'g' >>> d[-1] 'i'  # return and remove the rightmost item # return and remove the leftmost item # list the contents of the deque # peek at leftmost item # peek at rightmost item  >>> list(reversed(d)) # ['i', 'h', 'g'] >>> 'h' in d # true >>> d.extend('jkl') # >>> d deque(['g', 'h', 'i', 'j', 'k', 'l']) >>> d.rotate(1) # >>> d  list the contents of a deque in reverse search the deque add multiple elements at once  right rotation  goalkicker.com – python® notes for professionals  279  deque(['l', 'g', 'h', 'i', 'j', 'k']) >>> d.rotate(-1) # left rotation >>> d deque(['g', 'h', 'i', 'j', 'k', 'l']) >>> deque(reversed(d)) # make a new deque in reverse order deque(['l', 'k', 'j', 'i', 'h', 'g']) >>> d.clear() # empty the deque >>> d.pop() # cannot pop from an empty deque traceback (most recent call last): file ""<pyshell#6>"", line 1, in -topleveld.pop() indexerror: pop from an empty deque >>> d.extendleft('abc') >>> d deque(['c', 'b', 'a'])  # extendleft() reverses the input order  source: https://docs.python.org/2/library/collections.html  section 47.6: collections.chainmap chainmap is new in version 3.3  returns a new chainmap object given a number of maps. this object groups multiple dicts or other mappings together to create a single, updateable view. chainmaps are useful managing nested contexts and overlays. an example in the python world is found in the  implementation of the context class in django's template engine. it is useful for quickly linking a number of mappings so that the result can be treated as a single unit. it is often much faster than creating a new dictionary and running multiple update() calls. anytime one has a chain of lookup values there can be a case for chainmap. an example includes having both user speciﬁed values and a dictionary of default values. another example is the post and get parameter maps found in web use, e.g. django or flask. through the use of chainmap one returns a combined view of two distinct dictionaries. the maps parameter list is ordered from ﬁrst-searched to last-searched. lookups search the underlying mappings successively until a key is found. in contrast, writes, updates, and deletions only operate on the ﬁrst mapping. import collections # define two dictionaries with at least some keys overlapping. dict1 = {'apple': 1, 'banana': 2} dict2 = {'coconut': 1, 'date': 1, 'apple': 3} # create two chainmaps with different ordering of those dicts. combined_dict = collections.chainmap(dict1, dict2) reverse_ordered_dict = collections.chainmap(dict2, dict1)  note the impact of order on which value is found ﬁrst in the subsequent lookup for k, v in combined_dict.items(): print(k, v) date 1 apple 1 banana 2  goalkicker.com – python® notes for professionals  280  coconut 1 for k, v in reverse_ordered_dict.items(): print(k, v) date 1 apple 3 banana 2 coconut 1  goalkicker.com – python® notes for professionals  281",t_ba5de272b4cb,t_ba5de272b4cb,17
c_75d3c3d146fa,"chapter 83 of the book on php.chapter 83: websockets usage of socket extension implements a low-level interface to the socket communication functions based on the popular bsd sockets, providing the possibility to act as a socket server as well as a client.  section 83.1: simple tcp/ip server minimal example based on php manual example found here: http://php.net/manual/en/sockets.examples.php create a websocket script that listens to port 5000 use putty, terminal to run telnet 127.0.0.1 5000 (localhost). this script replies with the message you sent (as a ping-back) <?php set_time_limit(0); // disable timeout ob_implicit_flush(); // disable output caching // settings $address = '127.0.0.1'; $port = 5000;  /* function socket_create ( int $domain , int $type , int $protocol ) $domain can be af_inet, af_inet6 for ipv6 , af_unix for local communication protocol $protocol can be sol_tcp, sol_udp (tcp/udp) @returns true on success */ if (($socket = socket_create(af_inet, sock_stream, sol_tcp)) === false) { echo ""couldn't create socket"".socket_strerror(socket_last_error()).""\n""; }  /* socket_bind ( resource $socket , string $address [, int $port = 0 ] ) bind socket to listen to address and port */ if (socket_bind($socket, $address, $port) === false) { echo ""bind error "".socket_strerror(socket_last_error($sock)) .""\n""; } if (socket_listen($socket, 5) === false) { echo ""listen failed "".socket_strerror(socket_last_error($socket)) . ""\n""; } do { if (($msgsock = socket_accept($socket)) === false) { echo ""error: socket_accept: "" . socket_strerror(socket_last_error($socket)) . ""\n""; break; } /* send welcome message. */ $msg = ""\nphp websocket \n""; // listen to user input do { if (false === ($buf = socket_read($msgsock, 2048, php_normal_read))) { echo ""socket read error: "".socket_strerror(socket_last_error($msgsock)) . ""\n"";  goalkicker.com – php notes for professionals  392  break 2; } if (!$buf = trim($buf)) { continue; } // reply to user with their message $talkback = ""php: you said '$buf'.\n""; socket_write($msgsock, $talkback, strlen($talkback)); // print message in terminal echo ""$buf\n""; } while (true); socket_close($msgsock); } while (true); socket_close($socket); ?>  goalkicker.com – php notes for professionals  393",t_c341f777c725,t_c341f777c725,18
c_591327283bd6,"chapter 94 of the book on php.chapter 94: exception handling and error reporting section 94.1: setting error reporting and where to display them if it's not already done in php.ini, error reporting can be set dynamically and should be set to allow most errors to be shown: syntax int error_reporting ([ int $level ] )  examples // should always be used prior to 5.4 error_reporting(e_all); // -1 will show every possible error, even when new levels and constants are added // in future php versions. e_all does the same up to 5.4. error_reporting(-1); // without notices error_reporting(e_all & ~e_notice); // only warnings and notices. // for the sake of example, one shouldn't report only those error_reporting(e_warning | e_notice);  errors will be logged by default by php, normally in a error.log ﬁle at the same level than the running script. in development environment, one can also show them on screen: ini_set('display_errors', 1);  in production however, one should ini_set('display_errors', 0);  and show a friendly problem message through the use of an exception or error handler.  section 94.2: logging fatal errors in php, a fatal error is a kind of error that cannot be caught, that is, after experiencing a fatal error a program does not resume. however, to log this error or somehow handle the crash you can use register_shutdown_function to register shutdown handler. function fatalerrorhandler() { // let's get last error that was fatal. $error = error_get_last(); // this is error-only handler for example purposes; no error means that // there were no error and shutdown was proper. also ensure it will handle // only fatal errors.  goalkicker.com – php notes for professionals  415  if (null === $error || e_error != $error['type']) { return; } // log last error to a log file. // let's naively assume that logs are in the folder inside the app folder. $logfile = fopen(""./app/logs/error.log"", ""a+""); // get useful info out of error. $type = $error[""type""]; $file = $error[""file""]; $line = $error[""line""]; $message = $error[""message""] fprintf( $logfile, ""[%s] %s: %s in %s:%d\n"", date(""y-m-d h:i:s""), $type, $message, $file, $line); fclose($logfile); }  register_shutdown_function('fatalerrorhandler');  reference: http://php.net/manual/en/function.register-shutdown-function.php http://php.net/manual/en/function.error-get-last.php http://php.net/manual/en/errorfunc.constants.php  goalkicker.com – php notes for professionals  416",t_c341f777c725,t_c341f777c725,18
c_e08dc4dfeda6,"chapter 59 of the book on php.chapter 59: php mysqli the mysqli interface is an improvement (it means ""mysql improvement extension"") of the mysql interface, which was deprecated in version 5.5 and is removed in version 7.0. the mysqli extension, or as it is sometimes known, the mysql improved extension, was developed to take advantage of new features found in mysql systems versions 4.1.3 and newer. the mysqli extension is included with php versions 5 and later.  section 59.1: close connection when we are ﬁnished querying the database, it is recommended to close the connection to free up resources. object oriented style $conn->close();  procedural style mysqli_close($conn);  note: the connection to the server will be closed as soon as the execution of the script ends, unless it's closed earlier by explicitly calling the close connection function. use case: if our script has a fair amount of processing to perform after fetching the result and has retrieved the full result set, we deﬁnitely should close the connection. if we were not to, there's a chance the mysql server will reach its connection limit when the web server is under heavy use.  section 59.2: mysqli connect object oriented style connect to server $conn = new mysqli(""localhost"",""my_user"",""my_password"");  set the default database: $conn->select_db(""my_db""); connect to database $conn = new mysqli(""localhost"",""my_user"",""my_password"",""my_db"");  procedural style connect to server $conn = mysqli_connect(""localhost"",""my_user"",""my_password"");  set the default database: mysqli_select_db($conn, ""my_db""); connect to database $conn = mysqli_connect(""localhost"",""my_user"",""my_password"",""my_db"");  verify database connection goalkicker.com – php notes for professionals  308  object oriented style if ($conn->connect_errno > 0) { trigger_error($db->connect_error); } // else: successfully connected  procedural style if (!$conn) { trigger_error(mysqli_connect_error()); } // else: successfully connected  section 59.3: loop through mysqli results php makes it easy to get data from your results and loop over it using a while statement. when it fails to get the next row, it returns false, and your loop ends. these examples work with mysqli_fetch_assoc - associative array with column names as keys mysqli_fetch_object - stdclass object with column names as variables mysqli_fetch_array - associative and numeric array (can use arguments to get one or the other) mysqli_fetch_row - numeric array object oriented style while($row = $result->fetch_assoc()) { var_dump($row); }  procedural style while($row = mysqli_fetch_assoc($result)) { var_dump($row); }  to get exact information from results, we can use: while ($row = $result->fetch_assoc()) { echo 'name and surname: '.$row['name'].' '.$row['surname'].'<br>'; echo 'age: '.$row['age'].'<br>'; // prints info from 'age' column }  section 59.4: prepared statements in mysqli please read preventing sql injection with parametrized queries for a complete discussion of why prepared statements help you secure your sql statements from sql injection attacks the $conn variable here is a mysqli object. see mysqli connect example for more details. for both examples, we assume that $sql is $sql = ""select column_1 from table where column_2 = ? and column_3 > ?"";  goalkicker.com – php notes for professionals  309  the ? represents the values we will provide later. please note that we do not need quotes for the placeholders, regardless of the type. we can also only provide placeholders in the data portions of the query, meaning set, values and where. you cannot use placeholders in the select or from portions.  object oriented style if ($stmt = $conn->prepare($sql)) { $stmt->bind_param(""si"", $column_2_value, $column_3_value); $stmt->execute(); $stmt->bind_result($column_1); $stmt->fetch(); //now use variable $column_1 one as if it were any other php variable $stmt->close(); }  procedural style if ($stmt = mysqli_prepare($conn, $sql)) { mysqli_stmt_bind_param($stmt, ""si"", $column_2_value, $column_3_value); mysqli_stmt_execute($stmt); // fetch data here mysqli_stmt_close($stmt); }  the ﬁrst parameter of $stmt->bind_param or the second parameter of mysqli_stmt_bind_param is determined by the data type of the corresponding parameter in the sql query: parameter data type of the bound parameter i integer d  double  s  string  b  blob  your list of parameters needs to be in the order provided in your query. in this example si means the ﬁrst parameter (column_2 = ?) is string and the second parameter (column_3 > ?) is integer. for retrieving data, see how to get data from a prepared statement  section 59.5: escaping strings escaping strings is an older (and less secure) method of securing data for insertion into a query. it works by using mysql's function mysql_real_escape_string() to process and sanitize the data (in other words, php is not doing the escaping). the mysqli api provides direct access to this function $escaped = $conn->real_escape_string($_get['var']); // or $escaped = mysqli_real_escape_string($conn, $_get['var']);  at this point, you have a string that mysql considers to be safe for use in a direct query $sql = 'select * from users where username = ""' . $escaped . '""'; $result = $conn->query($sql);  so why is this not as secure as prepared statements? there are ways to trick mysql to produce a string it considers goalkicker.com – php notes for professionals  310  safe. consider the following example $id = mysqli_real_escape_string(""1 or 1=1""); $sql = 'select * from table where id = ' . $id; 1 or 1=1 does not represent data that mysql will escape, yet this still represents sql injection. there are other  examples as well that represent places where it returns unsafe data. the problem is that mysql's escaping function is designed to make data comply with sql syntax. it's not designed to make sure that mysql can't confuse user data for sql instructions.  section 59.6: debugging sql in mysqli so your query has failed (see mysqli connect for how we made $conn) $result = $conn->query('select * from non_existent_table'); // this query will fail  how do we ﬁnd out what happened? $result is false so that's no help. thankfully the connect $conn can tell us what mysql told us about the failure trigger_error($conn->error);  or procedural trigger_error(mysqli_error($conn));  you should get an error similar to table 'my_db.non_existent_table' doesn't exist  section 59.7: mysqli query the query function takes a valid sql string and executes it directly against the database connection $conn object oriented style $result = $conn->query(""select * from `people`"");  procedural style $result = mysqli_query($conn, ""select * from `people`"");  caution a common problem here is that people will simply execute the query and expect it to work (i.e. return a mysqli_stmt object). since this function takes only a string, you're building the query ﬁrst yourself. if there are any mistakes in the sql at all, the mysql compiler will fail, at which point this function will return false. $result = $conn->query('select * from non_existent_table'); // this query will fail $row = $result->fetch_assoc();  goalkicker.com – php notes for professionals  311  the above code will generate a e_fatal error because $result is false, and not an object. php fatal error: call to a member function fetch_assoc() on a non-object the procedural error is similar, but not fatal, because we're just violating the expectations of the function. $row = mysqli_fetch_assoc($result); // same query as previous  you will get the following message from php mysqli_fetch_array() expects parameter 1 to be mysqli_result, boolean given you can avoid this by doing a test ﬁrst if($result) $row = mysqli_fetch_assoc($result);  section 59.8: how to get data from a prepared statement prepared statements see prepared statements in mysqli for how to prepare and execute a query. binding of results object-oriented style $stmt->bind_result($forename);  procedural style mysqli_stmt_bind_result($stmt, $forename);  the problem with using bind_result is that it requires the statement to specify the columns that will be used. this means that for the above to work the query must have looked like this select forename from users. to include more columns simply add them as parameters to the bind_result function (and ensure that you add them to the sql query). in both cases, we're assigning the forename column to the $forename variable. these functions take as many arguments as columns you want to assign. the assignment is only done once, since the function binds by reference. we can then loop as follows: object-oriented style while ($stmt->fetch()) echo ""$forename<br />"";  procedural style while (mysqli_stmt_fetch($stmt)) echo ""$forename<br />"";  goalkicker.com – php notes for professionals  312  the drawback to this is that you have to assign a lot of variables at once. this makes keeping track of large queries diﬃcult. if you have mysql native driver (mysqlnd) installed, all you need to do is use get_result. object-oriented style $result = $stmt->get_result();  procedural style $result = mysqli_stmt_get_result($stmt);  this is much easier to work with because now we're getting a mysqli_result object. this is the same object that mysqli_query returns. this means you can use a regular result loop to get your data.  what if i cannot install mysqlnd? if that is the case then @sophivorus has you covered with this amazing answer. this function can perform the task of get_result without it being installed on the server. it simply loops through the results and builds an associative array function get_result(\mysqli_stmt $statement) { $result = array(); $statement->store_result(); for ($i = 0; $i < $statement->num_rows; $i++) { $metadata = $statement->result_metadata(); $params = array(); while ($field = $metadata->fetch_field()) { $params[] = &$result[$i][$field->name]; } call_user_func_array(array($statement, 'bind_result'), $params); $statement->fetch(); } return $result; }  we can then use the function to get results like this, just as if we were using mysqli_fetch_assoc() <?php $query = $mysqli->prepare(""select * from users where forename like ?""); $condition = ""j%""; $query->bind_param(""s"", $condition); $query->execute(); $result = get_result($query); while ($row = array_shift($result)) { echo $row[""id""] . ' - ' . $row[""forename""] . ' ' . $row[""surname""] . '<br>'; }  it will have the same output as if you were using the mysqlnd driver, except it does not have to be installed. this is very useful if you are unable to install said driver on your system. just implement this solution.  goalkicker.com – php notes for professionals  313  section 59.9: mysqli insert id retrieve the last id generated by an insert query on a table with an auto_increment column. object-oriented style $id = $conn->insert_id;  procedural style $id = mysqli_insert_id($conn);  returns zero if there was no previous query on the connection or if the query did not update an auto_increment value. insert id when updating rows normally an update statement does not return an insert id, since an auto_increment id is only returned when a new row has been saved (or inserted). one way of making updates to the new id is to use insert ... on duplicate key update syntax for updating.  setup for examples to follow: create table iodku ( id int auto_increment not null, name varchar(99) not null, misc int not null, primary key(id), unique(name) ) engine=innodb; insert into iodku (name, misc) values ('leslie', 123), ('sally', 456); query ok, 2 rows affected (0.00 sec) records: 2 duplicates: 0 warnings: 0 +----+--------+------+ | id | name | misc | +----+--------+------+ | 1 | leslie | 123 | | 2 | sally | 456 | +----+--------+------+  the case of iodku performing an ""update"" and last_insert_id() retrieving the relevant id: $sql = ""insert into iodku (name, misc) values ('sally', 3333) -- should update on duplicate key update -- `name` will trigger ""duplicate key"" id = last_insert_id(id), misc = values(misc)""; $conn->query($sql); $id = $conn->insert_id; -- picking up existing value (2)  the case where iodku performs an ""insert"" and last_insert_id() retrieves the new id: goalkicker.com – php notes for professionals  314  $sql = ""insert into iodku (name, misc) values ('dana', 789) -- should insert on duplicate key update id = last_insert_id(id), misc = values(misc); $conn->query($sql); $id = $conn->insert_id; -- picking up new value (3)  resulting table contents: select * from iodku; +----+--------+------+ | id | name | misc | +----+--------+------+ | 1 | leslie | 123 | | 2 | sally | 3333 | | 3 | dana | 789 | +----+--------+------+  -- iodku changed this -- iodku added this  goalkicker.com – php notes for professionals  315",t_c341f777c725,t_c341f777c725,18
c_ad9657992684,"chapter 16 of the book on php.chapter 16: processing multiple arrays together section 16.1: array intersection the array_intersect function will return an array of values that exist in all arrays that were passed to this function. $array_one = ['one', 'two', 'three']; $array_two = ['two', 'three', 'four']; $array_three = ['two', 'three']; $intersect = array_intersect($array_one, $array_two, $array_three); // $intersect contains ['two', 'three']  array keys are preserved. indexes from the original arrays are not. array_intersect only check the values of the arrays. array_intersect_assoc function will return intersection of  arrays with keys. $array_one = [1 => 'one',2 => 'two',3 => 'three']; $array_two = [1 => 'one', 2 => 'two', 3 => 'two', 4 => 'three']; $array_three = [1 => 'one', 2 => 'two']; $intersect = array_intersect_assoc($array_one, $array_two, $array_three); // $intersect contains [1 =>'one',2 => 'two'] array_intersect_key function only check the intersection of keys. it will returns keys exist in all arrays. $array_one = [1 => 'one',2 => 'two',3 => 'three']; $array_two = [1 => 'one', 2 => 'two', 3 => 'four']; $array_three = [1 => 'one', 3 => 'five']; $intersect = array_intersect_key($array_one, $array_two, $array_three); // $intersect contains [1 =>'one',3 => 'three']  section 16.2: merge or concatenate arrays $fruit1 = ['apples', 'pears']; $fruit2 = ['bananas', 'oranges']; $all_of_fruits = array_merge($fruit1, $fruit2); // now value of $all_of_fruits is [0 => 'apples', 1 => 'pears', 2 => 'bananas', 3 => 'oranges']  note that array_merge will change numeric indexes, but overwrite string indexes $fruit1 = ['one' => 'apples', 'two' => 'pears']; $fruit2 = ['one' => 'bananas', 'two' => 'oranges']; $all_of_fruits = array_merge($fruit1, $fruit2); // now value of $all_of_fruits is ['one' => 'bananas', 'two' => 'oranges'] array_merge overwrites the values of the ﬁrst array with the values of the second array, if it cannot renumber the  index. you can use the + operator to merge two arrays in a way that the values of the ﬁrst array never get overwritten, but goalkicker.com – php notes for professionals  99  it does not renumber numeric indexes, so you lose values of arrays that have an index that is also used in the ﬁrst array. $fruit1 = ['one' => 'apples', 'two' => 'pears']; $fruit2 = ['one' => 'bananas', 'two' => 'oranges']; $all_of_fruits = $fruit1 + $fruit2; // now value of $all_of_fruits is ['one' => 'apples', 'two' => 'pears'] $fruit1 = ['apples', 'pears']; $fruit2 = ['bananas', 'oranges']; $all_of_fruits = $fruit1 + $fruit2; // now value of $all_of_fruits is [0 => 'apples', 1 => 'pears']  section 16.3: changing a multidimensional array to associative array if you have a multidimensional array like this: [ ['foo', 'bar'], ['fizz', 'buzz'], ]  and you want to change it to an associative array like this: [ 'foo' => 'bar', 'fizz' => 'buzz', ]  you can use this code: $multidimensionalarray = [ ['foo', 'bar'], ['fizz', 'buzz'], ]; $associativearraykeys = array_column($multidimensionalarray, 0); $associativearrayvalues = array_column($multidimensionalarray, 1); $associativearray = array_combine($associativearraykeys, $associativearrayvalues);  or, you can skip setting $associativearraykeys and $associativearrayvalues and use this simple one liner: $associativearray = array_combine(array_column($multidimensionalarray, 0), array_column($multidimensionalarray, 1));  section 16.4: combining two arrays (keys from one, values from another) the following example shows how to merge two arrays into one associative array, where the key values will be the items of the ﬁrst array, and the values will be from the second: $array_one = ['key1', 'key2', 'key3']; $array_two = ['value1', 'value2', 'value3'];  goalkicker.com – php notes for professionals  100  $array_three = array_combine($array_one, $array_two); var_export($array_three); /* array ( 'key1' => 'value1', 'key2' => 'value2', 'key3' => 'value3', ) */  goalkicker.com – php notes for professionals  101",t_c341f777c725,t_c341f777c725,18
c_9c83c69c21b3,"chapter 62 of the book on php.chapter 62: mongo-php section 62.1: everything in between mongodb and php requirements mongodb server running on port usually 27017. (type mongod on command prompt to run mongodb server) php installed as either cgi or fpm with mongodb extension installed(mongodb extension is not bundled with default php) composer library(mongodb/mongodb).(in the project root run php composer.phar require ""mongodb/mongodb=^1.0.0"" to install the mongodb library)  if everything is ok you are ready to move on. check for php installation if not sure check php installation by running php -v on command prompt will return something like this php 7.0.6 (cli) (built: apr 28 2016 14:12:14) ( zts ) copyright (c) 1997-2016 the php group zend engine v3.0.0, copyright (c) 1998-2016 zend technologies  check for mongodb installation check mongodb installation by running mongo --version will return mongodb shell version: 3.2.6 check for composer installation check for composer installation by running php composer.phar --version will return composer version 1.2-dev (3d09c17b489cd29a0c0b3b11e731987e7097797d) 2016-08-30 16:12:39 `  connecting to mongodb from php <?php //this path should point to composer's autoloader from where your mongodb library will be loaded require 'vendor/autoload.php';  // when using custom username password try { $mongo = new mongodb\client('mongodb://username:password@localhost:27017'); print_r($mongo->listdatabases()); } catch (exception $e) { echo $e->getmessage(); }  // when using default settings try { $mongo = new mongodb\client('mongodb://localhost:27017');  goalkicker.com – php notes for professionals  321  print_r($mongo->listdatabases()); } catch (exception $e) { echo $e->getmessage(); }  the above code will connect using mongodb composer library(mongodb/mongodb) included as vendor/autoload.php to connect to the mongodb server running on port: 27017. if everything is ok it will connect and list an array, if exception occurs connecting to mongodb server the message will be printed. create(inserting) into mongodb <?php //mongodb uses collection rather than tables as in case on sql. //use $mongo instance to select the database and collection //note: if database(here demo) and collection(here beers) are not found in mongodb both will be created automatically by mongodb. $collection = $mongo->demo->beers; //using $collection we can insert one document into mongodb //document is similar to row in sql. $result = $collection->insertone( [ 'name' => 'hinterland', 'brewery' => 'brewdog' ] ); //every inserted document will have a unique id. echo ""inserted with object id '{$result->getinsertedid()}'""; ?>  in the example we are using the $mongo instance previously used in the connecting to mongodb from php part. mongodb uses json type data format, so in php we will use array to insert data into mongodb, this conversion from array to json and vice versa will be done by mongo library. every document in mongodb has a unique id named as _id,during insertion we can get this by using $result->getinsertedid(); read(find) in mongodb <?php //use find() method to query for records, where parameter will be array containing key value pair we need to find. $result = $collection->find( [ 'name' => 'hinterland', 'brewery' => 'brewdog' ] ); // all the data(result) returned as array // use for each to filter the required keys foreach ($result as $entry) { echo $entry['_id'], ': ', $entry['name'], ""\n""; } ?>  drop in mongodb <?php $result = $collection->drop( [ 'name' => 'hinterland'] ); //return 1 if the drop was sucessfull and 0 for failure print_r($result->ok); ?>  goalkicker.com – php notes for professionals  322  there are many methods that can be performed on $collection see oﬃcial documentation from mongodb  goalkicker.com – php notes for professionals  323",t_c341f777c725,t_c341f777c725,18
c_a217d628bf5e,"chapter 46 of the book on php.chapter 46: filters & filter functions parameter details variable value to ﬁlter. note that scalar values are converted to string internally before they are ﬁltered. ------  ------  ﬁlter  the id of the ﬁlter to apply. the types of ﬁlters manual page lists the available ﬁlters.if omitted, filter_default will be used, which is equivalent to filter_unsafe_raw. this will result in no ﬁltering taking place by default.  ------  ------  options  associative array of options or bitwise disjunction of ﬂags. if ﬁlter accepts options, ﬂags can be provided in ""ﬂags"" ﬁeld of array. for the ""callback"" ﬁlter, callable type should be passed. the callback must accept one argument, the value to be ﬁltered, and return the value after ﬁltering/sanitizing it.  this extension ﬁlters data by either validating or sanitizing it. this is especially useful when the data source contains unknown (or foreign) data, like user supplied input. for example, this data may come from an html form.  section 46.1: validating boolean values var_dump(filter_var(true, filter_validate_boolean, filter_null_on_failure)); // true var_dump(filter_var(false, filter_validate_boolean, filter_null_on_failure)); // false var_dump(filter_var(1, filter_validate_boolean, filter_null_on_failure)); // true var_dump(filter_var(0, filter_validate_boolean, filter_null_on_failure)); // false var_dump(filter_var('1', filter_validate_boolean, filter_null_on_failure)); // true var_dump(filter_var('0', filter_validate_boolean, filter_null_on_failure)); // false var_dump(filter_var('', filter_validate_boolean, filter_null_on_failure)); // false var_dump(filter_var(' ', filter_validate_boolean, filter_null_on_failure)); // false var_dump(filter_var('true', filter_validate_boolean, filter_null_on_failure)); // true var_dump(filter_var('false', filter_validate_boolean, filter_null_on_failure)); // false var_dump(filter_var([], filter_validate_boolean, filter_null_on_failure)); // null var_dump(filter_var(null, filter_validate_boolean, filter_null_on_failure)); // false  section 46.2: validating a number is a float validates value as ﬂoat, and converts to ﬂoat on success. var_dump(filter_var(1, filter_validate_float)); var_dump(filter_var(1.0, filter_validate_float)); var_dump(filter_var(1.0000, filter_validate_float)); var_dump(filter_var(1.00001, filter_validate_float)); var_dump(filter_var('1', filter_validate_float)); var_dump(filter_var('1.0', filter_validate_float)); var_dump(filter_var('1.0000', filter_validate_float)); var_dump(filter_var('1.00001', filter_validate_float)); var_dump(filter_var('1,000', filter_validate_float)); var_dump(filter_var('1,000.0', filter_validate_float)); var_dump(filter_var('1,000.0000', filter_validate_float)); var_dump(filter_var('1,000.00001', filter_validate_float));  var_dump(filter_var(1, filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var(1.0, filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var(1.0000, filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var(1.00001, filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1', filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1.0', filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1.0000', filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1.00001', filter_validate_float, filter_flag_allow_thousand));  goalkicker.com – php notes for professionals  253  var_dump(filter_var('1,000', filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000.0', filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000.0000', filter_validate_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000.00001', filter_validate_float, filter_flag_allow_thousand));  results float(1) float(1) float(1) float(1.00001) float(1) float(1) float(1) float(1.00001) bool(false) bool(false) bool(false) bool(false) float(1) float(1) float(1) float(1.00001) float(1) float(1) float(1) float(1.00001) float(1000) float(1000) float(1000) float(1000.00001)  section 46.3: validate a mac address validates a value is a valid mac address var_dump(filter_var('fa-f9-dd-b2-5e-0d', filter_validate_mac)); var_dump(filter_var('dc-bb-17-9a-ce-81', filter_validate_mac)); var_dump(filter_var('96-d5-9e-67-40-ab', filter_validate_mac)); var_dump(filter_var('96-d5-9e-67-40', filter_validate_mac)); var_dump(filter_var('', filter_validate_mac));  results: string(17) ""fa-f9-dd-b2-5e-0d"" string(17) ""dc-bb-17-9a-ce-81"" string(17) ""96-d5-9e-67-40-ab"" bool(false) bool(false)  section 46.4: sanitze email addresses remove all characters except letters, digits and !#$%&'*+-=?^_`{|}~@.[]. var_dump(filter_var('john@example.com', filter_sanitize_email)); var_dump(filter_var(""!#$%&'*+-=?^_`{|}~.[]@example.com"", filter_sanitize_email)); var_dump(filter_var('john/@example.com', filter_sanitize_email));  goalkicker.com – php notes for professionals  254  var_dump(filter_var('john\@example.com', filter_sanitize_email)); var_dump(filter_var('joh n@example.com', filter_sanitize_email));  results: string(16) string(33) string(16) string(16) string(16)  ""john@example.com"" ""!#$%&'*+-=?^_`{|}~.[]@example.com"" ""john@example.com"" ""john@example.com"" ""john@example.com""  section 46.5: sanitize integers remove all characters except digits, plus and minus sign. var_dump(filter_var(1, filter_sanitize_number_int)); var_dump(filter_var(-1, filter_sanitize_number_int)); var_dump(filter_var(+1, filter_sanitize_number_int)); var_dump(filter_var(1.00, filter_sanitize_number_int)); var_dump(filter_var(+1.00, filter_sanitize_number_int)); var_dump(filter_var(-1.00, filter_sanitize_number_int)); var_dump(filter_var('1', filter_sanitize_number_int)); var_dump(filter_var('-1', filter_sanitize_number_int)); var_dump(filter_var('+1', filter_sanitize_number_int)); var_dump(filter_var('1.00', filter_sanitize_number_int)); var_dump(filter_var('+1.00', filter_sanitize_number_int)); var_dump(filter_var('-1.00', filter_sanitize_number_int)); var_dump(filter_var('1 unicorn', filter_sanitize_number_int)); var_dump(filter_var('-1 unicorn', filter_sanitize_number_int)); var_dump(filter_var('+1 unicorn', filter_sanitize_number_int)); var_dump(filter_var(""!#$%&'*+-=?^_`{|}~@.[]0123456789abcdefghijklmnopqrstuvwxyz"", filter_sanitize_number_int));  results: string(1) ""1"" string(2) ""-1"" string(1) ""1"" string(1) ""1"" string(1) ""1"" string(2) ""-1"" string(1) ""1"" string(2) ""-1"" string(2) ""+1"" string(3) ""100"" string(4) ""+100"" string(4) ""-100"" string(1) ""1"" string(2) ""-1"" string(2) ""+1"" string(12) ""+-0123456789""  section 46.6: sanitize urls sanitze urls remove all characters except letters, digits and $-_.+!*'(),{}|\^~[]`<>#%"";/?:@&=  goalkicker.com – php notes for professionals  255  var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=y', filter_sanitize_url)); var_dump(filter_var(""http://www.example.com/path/to/dir/index.php?test=y!#$%&'*+-=?^_`{|}~.[]"", filter_sanitize_url)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=a b c', filter_sanitize_url));  results: string(51) ""http://www.example.com/path/to/dir/index.php?test=y"" string(72) ""http://www.example.com/path/to/dir/index.php?test=y!#$%&'*+-=?^_`{|}~.[]"" string(53) ""http://www.example.com/path/to/dir/index.php?test=abc""  section 46.7: validate email address when ﬁltering an email address filter_var() will return the ﬁltered data, in this case the email address, or false if a valid email address cannot be found: var_dump(filter_var('john@example.com', filter_validate_email)); var_dump(filter_var('notvalidemail', filter_validate_email));  results: string(16) ""john@example.com"" bool(false)  this function doesn't validate not-latin characters. internationalized domain name can be validated in their xn-form. note that you cannot know if the email address is correct before sending an email to it. you may want to do some extra checks such as checking for a mx record, but this is not necessary. if you send a conﬁrmation email, don't forget to remove unused accounts after a short period.  section 46.8: validating a value is an integer when ﬁltering a value that should be an integer filter_var() will return the ﬁltered data, in this case the integer, or false if the value is not an integer. floats are not integers: var_dump(filter_var('10', filter_validate_int)); var_dump(filter_var('a10', filter_validate_int)); var_dump(filter_var('10a', filter_validate_int)); var_dump(filter_var(' ', filter_validate_int)); var_dump(filter_var('10.00', filter_validate_int)); var_dump(filter_var('10,000', filter_validate_int)); var_dump(filter_var('-5', filter_validate_int)); var_dump(filter_var('+7', filter_validate_int));  results: int(10) bool(false) bool(false) bool(false) bool(false) bool(false) int(-5)  goalkicker.com – php notes for professionals  256  int(7)  if you are expecting only digits, you can use a regular expression: if(is_string($_get['entry']) && preg_match('#^[0-9]+$#', $_get['entry'])) // this is a digit (positive) integer else // entry is incorrect  if you convert this value into an integer, you don't have to do this check and so you can use filter_var.  section 46.9: validating an integer falls in a range when validating that an integer falls in a range the check includes the minimum and maximum bounds: $options = array( 'options' => array( 'min_range' => 5, 'max_range' => 10, ) ); var_dump(filter_var('5', filter_validate_int, $options)); var_dump(filter_var('10', filter_validate_int, $options)); var_dump(filter_var('8', filter_validate_int, $options)); var_dump(filter_var('4', filter_validate_int, $options)); var_dump(filter_var('11', filter_validate_int, $options)); var_dump(filter_var('-6', filter_validate_int, $options));  results: int(5) int(10) int(8) bool(false) bool(false) bool(false)  section 46.10: validate a url when ﬁltering a url filter_var() will return the ﬁltered data, in this case the url, or false if a valid url cannot be found: url: example.com var_dump(filter_var('example.com', var_dump(filter_var('example.com', var_dump(filter_var('example.com', var_dump(filter_var('example.com', var_dump(filter_var('example.com',  filter_validate_url)); filter_validate_url, filter_flag_scheme_required)); filter_validate_url, filter_flag_host_required)); filter_validate_url, filter_flag_path_required)); filter_validate_url, filter_flag_query_required));  results: bool(false) bool(false) bool(false) bool(false) bool(false)  goalkicker.com – php notes for professionals  257  url: http://example.com var_dump(filter_var('http://example.com', var_dump(filter_var('http://example.com', var_dump(filter_var('http://example.com', var_dump(filter_var('http://example.com', var_dump(filter_var('http://example.com',  filter_validate_url)); filter_validate_url, filter_flag_scheme_required)); filter_validate_url, filter_flag_host_required)); filter_validate_url, filter_flag_path_required)); filter_validate_url, filter_flag_query_required));  results: string(18) ""http://example.com"" string(18) ""http://example.com"" string(18) ""http://example.com"" bool(false) bool(false)  url: http://www.example.com var_dump(filter_var('http://www.example.com', var_dump(filter_var('http://www.example.com', var_dump(filter_var('http://www.example.com', var_dump(filter_var('http://www.example.com', var_dump(filter_var('http://www.example.com',  filter_validate_url)); filter_validate_url, filter_flag_scheme_required)); filter_validate_url, filter_flag_host_required)); filter_validate_url, filter_flag_path_required)); filter_validate_url, filter_flag_query_required));  results: string(22) ""http://www.example.com"" string(22) ""http://www.example.com"" string(22) ""http://www.example.com"" bool(false) bool(false)  url: http://www.example.com/path/to/dir/ var_dump(filter_var('http://www.example.com/path/to/dir/', var_dump(filter_var('http://www.example.com/path/to/dir/', filter_flag_scheme_required)); var_dump(filter_var('http://www.example.com/path/to/dir/', filter_flag_host_required)); var_dump(filter_var('http://www.example.com/path/to/dir/', filter_flag_path_required)); var_dump(filter_var('http://www.example.com/path/to/dir/', filter_flag_query_required));  filter_validate_url)); filter_validate_url, filter_validate_url, filter_validate_url, filter_validate_url,  results: string(35) ""http://www.example.com/path/to/dir/"" string(35) ""http://www.example.com/path/to/dir/"" string(35) ""http://www.example.com/path/to/dir/"" string(35) ""http://www.example.com/path/to/dir/"" bool(false)  url: http://www.example.com/path/to/dir/index.php var_dump(filter_var('http://www.example.com/path/to/dir/index.php', filter_validate_url)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php', filter_validate_url, filter_flag_scheme_required)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php', filter_validate_url,  goalkicker.com – php notes for professionals  258  filter_flag_host_required)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php', filter_validate_url, filter_flag_path_required)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php', filter_validate_url, filter_flag_query_required));  results: string(44) ""http://www.example.com/path/to/dir/index.php"" string(44) ""http://www.example.com/path/to/dir/index.php"" string(44) ""http://www.example.com/path/to/dir/index.php"" string(44) ""http://www.example.com/path/to/dir/index.php"" bool(false)  url: http://www.example.com/path/to/dir/index.php?test=y var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=y', var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=y', filter_flag_scheme_required)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=y', filter_flag_host_required)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=y', filter_flag_path_required)); var_dump(filter_var('http://www.example.com/path/to/dir/index.php?test=y', filter_flag_query_required));  filter_validate_url)); filter_validate_url, filter_validate_url, filter_validate_url, filter_validate_url,  results: string(51) string(51) string(51) string(51) string(51)  ""http://www.example.com/path/to/dir/index.php?test=y"" ""http://www.example.com/path/to/dir/index.php?test=y"" ""http://www.example.com/path/to/dir/index.php?test=y"" ""http://www.example.com/path/to/dir/index.php?test=y"" ""http://www.example.com/path/to/dir/index.php?test=y""  warning: you must check the protocol to protect you against an xss attack: var_dump(filter_var('javascript://comment%0aalert(1)', filter_validate_url)); // string(31) ""javascript://comment%0aalert(1)""  section 46.11: sanitize floats remove all characters except digits, +- and optionally .,ee. var_dump(filter_var(1, filter_sanitize_number_float)); var_dump(filter_var(1.0, filter_sanitize_number_float)); var_dump(filter_var(1.0000, filter_sanitize_number_float)); var_dump(filter_var(1.00001, filter_sanitize_number_float)); var_dump(filter_var('1', filter_sanitize_number_float)); var_dump(filter_var('1.0', filter_sanitize_number_float)); var_dump(filter_var('1.0000', filter_sanitize_number_float)); var_dump(filter_var('1.00001', filter_sanitize_number_float)); var_dump(filter_var('1,000', filter_sanitize_number_float)); var_dump(filter_var('1,000.0', filter_sanitize_number_float)); var_dump(filter_var('1,000.0000', filter_sanitize_number_float)); var_dump(filter_var('1,000.00001', filter_sanitize_number_float)); var_dump(filter_var('1.8281e-009', filter_sanitize_number_float));  results: goalkicker.com – php notes for professionals  259  string(1) string(1) string(1) string(6) string(1) string(2) string(5) string(6) string(4) string(5) string(8) string(9) string(9)  ""1"" ""1"" ""1"" ""100001"" ""1"" ""10"" ""10000"" ""100001"" ""1000"" ""10000"" ""10000000"" ""100000001"" ""18281-009""  with the filter_flag_allow_thousand option: var_dump(filter_var(1, filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var(1.0, filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var(1.0000, filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var(1.00001, filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1.0', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1.0000', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1.00001', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000.0', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000.0000', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1,000.00001', filter_sanitize_number_float, filter_flag_allow_thousand)); var_dump(filter_var('1.8281e-009', filter_sanitize_number_float, filter_flag_allow_thousand));  results: string(1) ""1"" string(1) ""1"" string(6) ""100001"" string(1) ""1"" string(2) ""10"" string(5) ""10000"" string(6) ""100001"" string(5) ""1,000"" string(6) ""1,0000"" string(9) ""1,0000000"" string(10) ""1,00000001"" string(9) ""18281-009""  with the filter_flag_allow_scientific option: var_dump(filter_var(1, filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var(1.0, filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var(1.0000, filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var(1.00001, filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1.0', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1.0000', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1.00001', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1,000', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1,000.0', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1,000.0000', filter_sanitize_number_float, filter_flag_allow_scientific)); var_dump(filter_var('1,000.00001', filter_sanitize_number_float, filter_flag_allow_scientific));  goalkicker.com – php notes for professionals  260  var_dump(filter_var('1.8281e-009', filter_sanitize_number_float, filter_flag_allow_scientific));  results: string(1) ""1"" string(1) ""1"" string(1) ""1"" string(6) ""100001"" string(1) ""1"" string(2) ""10"" string(5) ""10000"" string(6) ""100001"" string(4) ""1000"" string(5) ""10000"" string(8) ""10000000"" string(9) ""100000001"" string(10) ""18281e-009""  section 46.12: validate ip addresses validates a value is a valid ip address var_dump(filter_var('185.158.24.24', filter_validate_ip)); var_dump(filter_var('2001:0db8:0a0b:12f0:0000:0000:0000:0001', filter_validate_ip)); var_dump(filter_var('192.168.0.1', filter_validate_ip)); var_dump(filter_var('127.0.0.1', filter_validate_ip));  results: string(13) ""185.158.24.24"" string(39) ""2001:0db8:0a0b:12f0:0000:0000:0000:0001"" string(11) ""192.168.0.1"" string(9) ""127.0.0.1""  validate an valid ipv4 ip address: var_dump(filter_var('185.158.24.24', filter_validate_ip, filter_flag_ipv4)); var_dump(filter_var('2001:0db8:0a0b:12f0:0000:0000:0000:0001', filter_validate_ip, filter_flag_ipv4)); var_dump(filter_var('192.168.0.1', filter_validate_ip, filter_flag_ipv4)); var_dump(filter_var('127.0.0.1', filter_validate_ip, filter_flag_ipv4));  results: string(13) ""185.158.24.24"" bool(false) string(11) ""192.168.0.1"" string(9) ""127.0.0.1""  validate an valid ipv6 ip address: var_dump(filter_var('185.158.24.24', filter_validate_ip, filter_flag_ipv6)); var_dump(filter_var('2001:0db8:0a0b:12f0:0000:0000:0000:0001', filter_validate_ip, filter_flag_ipv6)); var_dump(filter_var('192.168.0.1', filter_validate_ip, filter_flag_ipv6)); var_dump(filter_var('127.0.0.1', filter_validate_ip, filter_flag_ipv6));  goalkicker.com – php notes for professionals  261  results: bool(false) string(39) ""2001:0db8:0a0b:12f0:0000:0000:0000:0001"" bool(false) bool(false)  validate an ip address is not in a private range: var_dump(filter_var('185.158.24.24', filter_validate_ip, filter_flag_no_priv_range)); var_dump(filter_var('2001:0db8:0a0b:12f0:0000:0000:0000:0001', filter_validate_ip, filter_flag_no_priv_range)); var_dump(filter_var('192.168.0.1', filter_validate_ip, filter_flag_no_priv_range)); var_dump(filter_var('127.0.0.1', filter_validate_ip, filter_flag_no_priv_range));  results: string(13) ""185.158.24.24"" string(39) ""2001:0db8:0a0b:12f0:0000:0000:0000:0001"" bool(false) string(9) ""127.0.0.1""  validate an ip address is not in a reserved range: var_dump(filter_var('185.158.24.24', filter_validate_ip, filter_flag_no_res_range)); var_dump(filter_var('2001:0db8:0a0b:12f0:0000:0000:0000:0001', filter_validate_ip, filter_flag_no_res_range)); var_dump(filter_var('192.168.0.1', filter_validate_ip, filter_flag_no_res_range)); var_dump(filter_var('127.0.0.1', filter_validate_ip, filter_flag_no_res_range));  results: string(13) ""185.158.24.24"" bool(false) string(11) ""192.168.0.1"" bool(false)  section 46.13: sanitize ﬁlters we can use ﬁlters to sanitize our variable according to our need. example $string = ""<p>example</p>""; $newstring = filter_var($string, filter_sanitize_string); var_dump($newstring); // string(7) ""example""  above will remove the html tags from $string variable.  goalkicker.com – php notes for professionals  262",t_c341f777c725,t_c341f777c725,18
c_f965fd6b1c10,"the census of marine life is a growing global network of researchers in more than 70 nations engaged in a ten year (2000-2010) mission to assess and explain the diversity, distribution, and abundance of marine life in the oceans. rolf gradinger is an expert in sea ice communities, studying the tiny animals that actually live inside the ice and those that live on the bottom of the ice sheets. we'll chat with rolf about his current work, drilling ice cores just off barrow, and looking for some of the world's most unique fauna.",t_f3754353b800,t_f3754353b800,19
c_07c8c2ebb0fb,brendan kelly learned from inuit hunters how to train labrador retrievers to find ringed seals.  this allows brendan and his colleagues to set up live-capture nets to keep the seals from diving after they come up for air. the seals are tagged with satellite transponders so they can be tracked to learn about their breeding grounds and migration habits.,t_f3754353b800,t_f3754353b800,19
c_e57bfd1aa14c,dr. vladimir romanovsky is researching permafrost geophysics: the relationship between the frozen ground (permafrost) and climate. join host julie konop as she asks vladimir about his most recent data.,t_f3754353b800,t_f3754353b800,19
c_c85ffe1c0b06,"shots of the calving front of the jakobsavn glacier, greenland's fastest moving glacier.  includes two shots of mark fahnestock's helicopter flying over.",t_f3754353b800,t_f3754353b800,19
c_52720cd67fdb,"this short video summarizes all of the steps in collecting an ice core using the deep ice sheet coring (disc) drill. thomas bauska, of oregon state university helped heidi roop put together this video.",t_f3754353b800,t_f3754353b800,19
